package	TokenNamepackage	
org	TokenNameIdentifier	 org
.	TokenNameDOT	
apache	TokenNameIdentifier	 apache
.	TokenNameDOT	
lucene	TokenNameIdentifier	 lucene
.	TokenNameDOT	
index	TokenNameIdentifier	 index
;	TokenNameSEMICOLON	
/** * Licensed to the Apache Software Foundation (ASF) under one or more * contributor license agreements. See the NOTICE file distributed with * this work for additional information regarding copyright ownership. * The ASF licenses this file to You under the Apache License, Version 2.0 * (the "License"); you may not use this file except in compliance with * the License. You may obtain a copy of the License at * * http://www.apache.org/licenses/LICENSE-2.0 * * Unless required by applicable law or agreed to in writing, software * distributed under the License is distributed on an "AS IS" BASIS, * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. * See the License for the specific language governing permissions and * limitations under the License. */	TokenNameCOMMENT_JAVADOC	 Licensed to the Apache Software Foundation (ASF) under one or more contributor license agreements. See the NOTICE file distributed with this work for additional information regarding copyright ownership. The ASF licenses this file to You under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with the License. You may obtain a copy of the License at * http://www.apache.org/licenses/LICENSE-2.0 * Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License. 
import	TokenNameimport	
java	TokenNameIdentifier	 java
.	TokenNameDOT	
io	TokenNameIdentifier	 io
.	TokenNameDOT	
Closeable	TokenNameIdentifier	 Closeable
;	TokenNameSEMICOLON	
import	TokenNameimport	
java	TokenNameIdentifier	 java
.	TokenNameDOT	
io	TokenNameIdentifier	 io
.	TokenNameDOT	
IOException	TokenNameIdentifier	 IO Exception
;	TokenNameSEMICOLON	
import	TokenNameimport	
java	TokenNameIdentifier	 java
.	TokenNameDOT	
io	TokenNameIdentifier	 io
.	TokenNameDOT	
PrintStream	TokenNameIdentifier	 Print Stream
;	TokenNameSEMICOLON	
import	TokenNameimport	
java	TokenNameIdentifier	 java
.	TokenNameDOT	
util	TokenNameIdentifier	 util
.	TokenNameDOT	
ArrayList	TokenNameIdentifier	 Array List
;	TokenNameSEMICOLON	
import	TokenNameimport	
java	TokenNameIdentifier	 java
.	TokenNameDOT	
util	TokenNameIdentifier	 util
.	TokenNameDOT	
Collection	TokenNameIdentifier	 Collection
;	TokenNameSEMICOLON	
import	TokenNameimport	
java	TokenNameIdentifier	 java
.	TokenNameDOT	
util	TokenNameIdentifier	 util
.	TokenNameDOT	
Collections	TokenNameIdentifier	 Collections
;	TokenNameSEMICOLON	
import	TokenNameimport	
java	TokenNameIdentifier	 java
.	TokenNameDOT	
util	TokenNameIdentifier	 util
.	TokenNameDOT	
Comparator	TokenNameIdentifier	 Comparator
;	TokenNameSEMICOLON	
import	TokenNameimport	
java	TokenNameIdentifier	 java
.	TokenNameDOT	
util	TokenNameIdentifier	 util
.	TokenNameDOT	
Date	TokenNameIdentifier	 Date
;	TokenNameSEMICOLON	
import	TokenNameimport	
java	TokenNameIdentifier	 java
.	TokenNameDOT	
util	TokenNameIdentifier	 util
.	TokenNameDOT	
HashMap	TokenNameIdentifier	 Hash Map
;	TokenNameSEMICOLON	
import	TokenNameimport	
java	TokenNameIdentifier	 java
.	TokenNameDOT	
util	TokenNameIdentifier	 util
.	TokenNameDOT	
HashSet	TokenNameIdentifier	 Hash Set
;	TokenNameSEMICOLON	
import	TokenNameimport	
java	TokenNameIdentifier	 java
.	TokenNameDOT	
util	TokenNameIdentifier	 util
.	TokenNameDOT	
LinkedList	TokenNameIdentifier	 Linked List
;	TokenNameSEMICOLON	
import	TokenNameimport	
java	TokenNameIdentifier	 java
.	TokenNameDOT	
util	TokenNameIdentifier	 util
.	TokenNameDOT	
List	TokenNameIdentifier	 List
;	TokenNameSEMICOLON	
import	TokenNameimport	
java	TokenNameIdentifier	 java
.	TokenNameDOT	
util	TokenNameIdentifier	 util
.	TokenNameDOT	
Map	TokenNameIdentifier	 Map
;	TokenNameSEMICOLON	
import	TokenNameimport	
java	TokenNameIdentifier	 java
.	TokenNameDOT	
util	TokenNameIdentifier	 util
.	TokenNameDOT	
Set	TokenNameIdentifier	 Set
;	TokenNameSEMICOLON	
import	TokenNameimport	
java	TokenNameIdentifier	 java
.	TokenNameDOT	
util	TokenNameIdentifier	 util
.	TokenNameDOT	
concurrent	TokenNameIdentifier	 concurrent
.	TokenNameDOT	
atomic	TokenNameIdentifier	 atomic
.	TokenNameDOT	
AtomicInteger	TokenNameIdentifier	 Atomic Integer
;	TokenNameSEMICOLON	
import	TokenNameimport	
org	TokenNameIdentifier	 org
.	TokenNameDOT	
apache	TokenNameIdentifier	 apache
.	TokenNameDOT	
lucene	TokenNameIdentifier	 lucene
.	TokenNameDOT	
analysis	TokenNameIdentifier	 analysis
.	TokenNameDOT	
Analyzer	TokenNameIdentifier	 Analyzer
;	TokenNameSEMICOLON	
import	TokenNameimport	
org	TokenNameIdentifier	 org
.	TokenNameDOT	
apache	TokenNameIdentifier	 apache
.	TokenNameDOT	
lucene	TokenNameIdentifier	 lucene
.	TokenNameDOT	
analysis	TokenNameIdentifier	 analysis
.	TokenNameDOT	
LimitTokenCountAnalyzer	TokenNameIdentifier	 Limit Token Count Analyzer
;	TokenNameSEMICOLON	
import	TokenNameimport	
org	TokenNameIdentifier	 org
.	TokenNameDOT	
apache	TokenNameIdentifier	 apache
.	TokenNameDOT	
lucene	TokenNameIdentifier	 lucene
.	TokenNameDOT	
document	TokenNameIdentifier	 document
.	TokenNameDOT	
Document	TokenNameIdentifier	 Document
;	TokenNameSEMICOLON	
import	TokenNameimport	
org	TokenNameIdentifier	 org
.	TokenNameDOT	
apache	TokenNameIdentifier	 apache
.	TokenNameDOT	
lucene	TokenNameIdentifier	 lucene
.	TokenNameDOT	
index	TokenNameIdentifier	 index
.	TokenNameDOT	
IndexWriterConfig	TokenNameIdentifier	 Index Writer Config
.	TokenNameDOT	
OpenMode	TokenNameIdentifier	 Open Mode
;	TokenNameSEMICOLON	
import	TokenNameimport	
org	TokenNameIdentifier	 org
.	TokenNameDOT	
apache	TokenNameIdentifier	 apache
.	TokenNameDOT	
lucene	TokenNameIdentifier	 lucene
.	TokenNameDOT	
search	TokenNameIdentifier	 search
.	TokenNameDOT	
Query	TokenNameIdentifier	 Query
;	TokenNameSEMICOLON	
import	TokenNameimport	
org	TokenNameIdentifier	 org
.	TokenNameDOT	
apache	TokenNameIdentifier	 apache
.	TokenNameDOT	
lucene	TokenNameIdentifier	 lucene
.	TokenNameDOT	
search	TokenNameIdentifier	 search
.	TokenNameDOT	
Similarity	TokenNameIdentifier	 Similarity
;	TokenNameSEMICOLON	
import	TokenNameimport	
org	TokenNameIdentifier	 org
.	TokenNameDOT	
apache	TokenNameIdentifier	 apache
.	TokenNameDOT	
lucene	TokenNameIdentifier	 lucene
.	TokenNameDOT	
store	TokenNameIdentifier	 store
.	TokenNameDOT	
AlreadyClosedException	TokenNameIdentifier	 Already Closed Exception
;	TokenNameSEMICOLON	
import	TokenNameimport	
org	TokenNameIdentifier	 org
.	TokenNameDOT	
apache	TokenNameIdentifier	 apache
.	TokenNameDOT	
lucene	TokenNameIdentifier	 lucene
.	TokenNameDOT	
store	TokenNameIdentifier	 store
.	TokenNameDOT	
BufferedIndexInput	TokenNameIdentifier	 Buffered Index Input
;	TokenNameSEMICOLON	
import	TokenNameimport	
org	TokenNameIdentifier	 org
.	TokenNameDOT	
apache	TokenNameIdentifier	 apache
.	TokenNameDOT	
lucene	TokenNameIdentifier	 lucene
.	TokenNameDOT	
store	TokenNameIdentifier	 store
.	TokenNameDOT	
Directory	TokenNameIdentifier	 Directory
;	TokenNameSEMICOLON	
import	TokenNameimport	
org	TokenNameIdentifier	 org
.	TokenNameDOT	
apache	TokenNameIdentifier	 apache
.	TokenNameDOT	
lucene	TokenNameIdentifier	 lucene
.	TokenNameDOT	
store	TokenNameIdentifier	 store
.	TokenNameDOT	
Lock	TokenNameIdentifier	 Lock
;	TokenNameSEMICOLON	
import	TokenNameimport	
org	TokenNameIdentifier	 org
.	TokenNameDOT	
apache	TokenNameIdentifier	 apache
.	TokenNameDOT	
lucene	TokenNameIdentifier	 lucene
.	TokenNameDOT	
store	TokenNameIdentifier	 store
.	TokenNameDOT	
LockObtainFailedException	TokenNameIdentifier	 Lock Obtain Failed Exception
;	TokenNameSEMICOLON	
import	TokenNameimport	
org	TokenNameIdentifier	 org
.	TokenNameDOT	
apache	TokenNameIdentifier	 apache
.	TokenNameDOT	
lucene	TokenNameIdentifier	 lucene
.	TokenNameDOT	
util	TokenNameIdentifier	 util
.	TokenNameDOT	
Constants	TokenNameIdentifier	 Constants
;	TokenNameSEMICOLON	
import	TokenNameimport	
org	TokenNameIdentifier	 org
.	TokenNameDOT	
apache	TokenNameIdentifier	 apache
.	TokenNameDOT	
lucene	TokenNameIdentifier	 lucene
.	TokenNameDOT	
util	TokenNameIdentifier	 util
.	TokenNameDOT	
StringHelper	TokenNameIdentifier	 String Helper
;	TokenNameSEMICOLON	
import	TokenNameimport	
org	TokenNameIdentifier	 org
.	TokenNameDOT	
apache	TokenNameIdentifier	 apache
.	TokenNameDOT	
lucene	TokenNameIdentifier	 lucene
.	TokenNameDOT	
util	TokenNameIdentifier	 util
.	TokenNameDOT	
ThreadInterruptedException	TokenNameIdentifier	 Thread Interrupted Exception
;	TokenNameSEMICOLON	
import	TokenNameimport	
org	TokenNameIdentifier	 org
.	TokenNameDOT	
apache	TokenNameIdentifier	 apache
.	TokenNameDOT	
lucene	TokenNameIdentifier	 lucene
.	TokenNameDOT	
util	TokenNameIdentifier	 util
.	TokenNameDOT	
TwoPhaseCommit	TokenNameIdentifier	 Two Phase Commit
;	TokenNameSEMICOLON	
import	TokenNameimport	
org	TokenNameIdentifier	 org
.	TokenNameDOT	
apache	TokenNameIdentifier	 apache
.	TokenNameDOT	
lucene	TokenNameIdentifier	 lucene
.	TokenNameDOT	
util	TokenNameIdentifier	 util
.	TokenNameDOT	
Version	TokenNameIdentifier	 Version
;	TokenNameSEMICOLON	
/** An <code>IndexWriter</code> creates and maintains an index. <p>The <code>create</code> argument to the {@link #IndexWriter(Directory, Analyzer, boolean, MaxFieldLength) constructor} determines whether a new index is created, or whether an existing index is opened. Note that you can open an index with <code>create=true</code> even while readers are using the index. The old readers will continue to search the "point in time" snapshot they had opened, and won't see the newly created index until they re-open. There are also {@link #IndexWriter(Directory, Analyzer, MaxFieldLength) constructors} with no <code>create</code> argument which will create a new index if there is not already an index at the provided path and otherwise open the existing index.</p> <p>In either case, documents are added with {@link #addDocument(Document) addDocument} and removed with {@link #deleteDocuments(Term)} or {@link #deleteDocuments(Query)}. A document can be updated with {@link #updateDocument(Term, Document) updateDocument} (which just deletes and then adds the entire document). When finished adding, deleting and updating documents, {@link #close() close} should be called.</p> <a name="flush"></a> <p>These changes are buffered in memory and periodically flushed to the {@link Directory} (during the above method calls). A flush is triggered when there are enough buffered deletes (see {@link #setMaxBufferedDeleteTerms}) or enough added documents since the last flush, whichever is sooner. For the added documents, flushing is triggered either by RAM usage of the documents (see {@link #setRAMBufferSizeMB}) or the number of added documents. The default is to flush when RAM usage hits 16 MB. For best indexing speed you should flush by RAM usage with a large RAM buffer. Note that flushing just moves the internal buffered state in IndexWriter into the index, but these changes are not visible to IndexReader until either {@link #commit()} or {@link #close} is called. A flush may also trigger one or more segment merges which by default run with a background thread so as not to block the addDocument calls (see <a href="#mergePolicy">below</a> for changing the {@link MergeScheduler}).</p> <p>Opening an <code>IndexWriter</code> creates a lock file for the directory in use. Trying to open another <code>IndexWriter</code> on the same directory will lead to a {@link LockObtainFailedException}. The {@link LockObtainFailedException} is also thrown if an IndexReader on the same directory is used to delete documents from the index.</p> <a name="deletionPolicy"></a> <p>Expert: <code>IndexWriter</code> allows an optional {@link IndexDeletionPolicy} implementation to be specified. You can use this to control when prior commits are deleted from the index. The default policy is {@link KeepOnlyLastCommitDeletionPolicy} which removes all prior commits as soon as a new commit is done (this matches behavior before 2.2). Creating your own policy can allow you to explicitly keep previous "point in time" commits alive in the index for some time, to allow readers to refresh to the new commit without having the old commit deleted out from under them. This is necessary on filesystems like NFS that do not support "delete on last close" semantics, which Lucene's "point in time" search normally relies on. </p> <a name="mergePolicy"></a> <p>Expert: <code>IndexWriter</code> allows you to separately change the {@link MergePolicy} and the {@link MergeScheduler}. The {@link MergePolicy} is invoked whenever there are changes to the segments in the index. Its role is to select which merges to do, if any, and return a {@link MergePolicy.MergeSpecification} describing the merges. The default is {@link LogByteSizeMergePolicy}. Then, the {@link MergeScheduler} is invoked with the requested merges and it decides when and how to run the merges. The default is {@link ConcurrentMergeScheduler}. </p> <a name="OOME"></a><p><b>NOTE</b>: if you hit an OutOfMemoryError then IndexWriter will quietly record this fact and block all future segment commits. This is a defensive measure in case any internal state (buffered documents and deletions) were corrupted. Any subsequent calls to {@link #commit()} will throw an IllegalStateException. The only course of action is to call {@link #close()}, which internally will call {@link #rollback()}, to undo any changes to the index since the last commit. You can also just call {@link #rollback()} directly.</p> <a name="thread-safety"></a><p><b>NOTE</b>: {@link IndexWriter} instances are completely thread safe, meaning multiple threads can call any of its methods, concurrently. If your application requires external synchronization, you should <b>not</b> synchronize on the <code>IndexWriter</code> instance as this may cause deadlock; use your own (non-Lucene) objects instead. </p> <p><b>NOTE</b>: If you call <code>Thread.interrupt()</code> on a thread that's within IndexWriter, IndexWriter will try to catch this (eg, if it's in a wait() or Thread.sleep()), and will then throw the unchecked exception {@link ThreadInterruptedException} and <b>clear</b> the interrupt status on the thread.</p> */	TokenNameCOMMENT_JAVADOC	 An <code>IndexWriter</code> creates and maintains an index. <p>The <code>create</code> argument to the {@link #IndexWriter(Directory, Analyzer, boolean, MaxFieldLength) constructor} determines whether a new index is created, or whether an existing index is opened. Note that you can open an index with <code>create=true</code> even while readers are using the index. The old readers will continue to search the "point in time" snapshot they had opened, and won't see the newly created index until they re-open. There are also {@link #IndexWriter(Directory, Analyzer, MaxFieldLength) constructors} with no <code>create</code> argument which will create a new index if there is not already an index at the provided path and otherwise open the existing index.</p> <p>In either case, documents are added with {@link #addDocument(Document) addDocument} and removed with {@link #deleteDocuments(Term)} or {@link #deleteDocuments(Query)}. A document can be updated with {@link #updateDocument(Term, Document) updateDocument} (which just deletes and then adds the entire document). When finished adding, deleting and updating documents, {@link #close() close} should be called.</p> <a name="flush"></a> <p>These changes are buffered in memory and periodically flushed to the {@link Directory} (during the above method calls). A flush is triggered when there are enough buffered deletes (see {@link #setMaxBufferedDeleteTerms}) or enough added documents since the last flush, whichever is sooner. For the added documents, flushing is triggered either by RAM usage of the documents (see {@link #setRAMBufferSizeMB}) or the number of added documents. The default is to flush when RAM usage hits 16 MB. For best indexing speed you should flush by RAM usage with a large RAM buffer. Note that flushing just moves the internal buffered state in IndexWriter into the index, but these changes are not visible to IndexReader until either {@link #commit()} or {@link #close} is called. A flush may also trigger one or more segment merges which by default run with a background thread so as not to block the addDocument calls (see <a href="#mergePolicy">below</a> for changing the {@link MergeScheduler}).</p> <p>Opening an <code>IndexWriter</code> creates a lock file for the directory in use. Trying to open another <code>IndexWriter</code> on the same directory will lead to a {@link LockObtainFailedException}. The {@link LockObtainFailedException} is also thrown if an IndexReader on the same directory is used to delete documents from the index.</p> <a name="deletionPolicy"></a> <p>Expert: <code>IndexWriter</code> allows an optional {@link IndexDeletionPolicy} implementation to be specified. You can use this to control when prior commits are deleted from the index. The default policy is {@link KeepOnlyLastCommitDeletionPolicy} which removes all prior commits as soon as a new commit is done (this matches behavior before 2.2). Creating your own policy can allow you to explicitly keep previous "point in time" commits alive in the index for some time, to allow readers to refresh to the new commit without having the old commit deleted out from under them. This is necessary on filesystems like NFS that do not support "delete on last close" semantics, which Lucene's "point in time" search normally relies on. </p> <a name="mergePolicy"></a> <p>Expert: <code>IndexWriter</code> allows you to separately change the {@link MergePolicy} and the {@link MergeScheduler}. The {@link MergePolicy} is invoked whenever there are changes to the segments in the index. Its role is to select which merges to do, if any, and return a {@link MergePolicy.MergeSpecification} describing the merges. The default is {@link LogByteSizeMergePolicy}. Then, the {@link MergeScheduler} is invoked with the requested merges and it decides when and how to run the merges. The default is {@link ConcurrentMergeScheduler}. </p> <a name="OOME"></a><p><b>NOTE</b>: if you hit an OutOfMemoryError then IndexWriter will quietly record this fact and block all future segment commits. This is a defensive measure in case any internal state (buffered documents and deletions) were corrupted. Any subsequent calls to {@link #commit()} will throw an IllegalStateException. The only course of action is to call {@link #close()}, which internally will call {@link #rollback()}, to undo any changes to the index since the last commit. You can also just call {@link #rollback()} directly.</p> <a name="thread-safety"></a><p><b>NOTE</b>: {@link IndexWriter} instances are completely thread safe, meaning multiple threads can call any of its methods, concurrently. If your application requires external synchronization, you should <b>not</b> synchronize on the <code>IndexWriter</code> instance as this may cause deadlock; use your own (non-Lucene) objects instead. </p> <p><b>NOTE</b>: If you call <code>Thread.interrupt()</code> on a thread that's within IndexWriter, IndexWriter will try to catch this (eg, if it's in a wait() or Thread.sleep()), and will then throw the unchecked exception {@link ThreadInterruptedException} and <b>clear</b> the interrupt status on the thread.</p> 
/* * Clarification: Check Points (and commits) * IndexWriter writes new index files to the directory without writing a new segments_N * file which references these new files. It also means that the state of * the in memory SegmentInfos object is different than the most recent * segments_N file written to the directory. * * Each time the SegmentInfos is changed, and matches the (possibly * modified) directory files, we have a new "check point". * If the modified/new SegmentInfos is written to disk - as a new * (generation of) segments_N file - this check point is also an * IndexCommit. * * A new checkpoint always replaces the previous checkpoint and * becomes the new "front" of the index. This allows the IndexFileDeleter * to delete files that are referenced only by stale checkpoints. * (files that were created since the last commit, but are no longer * referenced by the "front" of the index). For this, IndexFileDeleter * keeps track of the last non commit checkpoint. */	TokenNameCOMMENT_BLOCK	 Clarification: Check Points (and commits) IndexWriter writes new index files to the directory without writing a new segments_N file which references these new files. It also means that the state of the in memory SegmentInfos object is different than the most recent segments_N file written to the directory. * Each time the SegmentInfos is changed, and matches the (possibly modified) directory files, we have a new "check point". If the modified/new SegmentInfos is written to disk - as a new (generation of) segments_N file - this check point is also an IndexCommit. * A new checkpoint always replaces the previous checkpoint and becomes the new "front" of the index. This allows the IndexFileDeleter to delete files that are referenced only by stale checkpoints. (files that were created since the last commit, but are no longer referenced by the "front" of the index). For this, IndexFileDeleter keeps track of the last non commit checkpoint. 
public	TokenNamepublic	
class	TokenNameclass	
IndexWriter	TokenNameIdentifier	 Index Writer
implements	TokenNameimplements	
Closeable	TokenNameIdentifier	 Closeable
,	TokenNameCOMMA	
TwoPhaseCommit	TokenNameIdentifier	 Two Phase Commit
{	TokenNameLBRACE	
/** * Default value for the write lock timeout (1,000). * @see #setDefaultWriteLockTimeout * @deprecated use {@link IndexWriterConfig#WRITE_LOCK_TIMEOUT} instead */	TokenNameCOMMENT_JAVADOC	 Default value for the write lock timeout (1,000). @see #setDefaultWriteLockTimeout @deprecated use {@link IndexWriterConfig#WRITE_LOCK_TIMEOUT} instead 
@	TokenNameAT	
Deprecated	TokenNameIdentifier	 Deprecated
public	TokenNamepublic	
static	TokenNamestatic	
long	TokenNamelong	
WRITE_LOCK_TIMEOUT	TokenNameIdentifier	 WRITE  LOCK  TIMEOUT
=	TokenNameEQUAL	
IndexWriterConfig	TokenNameIdentifier	 Index Writer Config
.	TokenNameDOT	
WRITE_LOCK_TIMEOUT	TokenNameIdentifier	 WRITE  LOCK  TIMEOUT
;	TokenNameSEMICOLON	
private	TokenNameprivate	
long	TokenNamelong	
writeLockTimeout	TokenNameIdentifier	 write Lock Timeout
;	TokenNameSEMICOLON	
/** * Name of the write lock in the index. */	TokenNameCOMMENT_JAVADOC	 Name of the write lock in the index. 
public	TokenNamepublic	
static	TokenNamestatic	
final	TokenNamefinal	
String	TokenNameIdentifier	 String
WRITE_LOCK_NAME	TokenNameIdentifier	 WRITE  LOCK  NAME
=	TokenNameEQUAL	
"write.lock"	TokenNameStringLiteral	write.lock
;	TokenNameSEMICOLON	
/** * Value to denote a flush trigger is disabled * @deprecated use {@link IndexWriterConfig#DISABLE_AUTO_FLUSH} instead */	TokenNameCOMMENT_JAVADOC	 Value to denote a flush trigger is disabled @deprecated use {@link IndexWriterConfig#DISABLE_AUTO_FLUSH} instead 
@	TokenNameAT	
Deprecated	TokenNameIdentifier	 Deprecated
public	TokenNamepublic	
final	TokenNamefinal	
static	TokenNamestatic	
int	TokenNameint	
DISABLE_AUTO_FLUSH	TokenNameIdentifier	 DISABLE  AUTO  FLUSH
=	TokenNameEQUAL	
IndexWriterConfig	TokenNameIdentifier	 Index Writer Config
.	TokenNameDOT	
DISABLE_AUTO_FLUSH	TokenNameIdentifier	 DISABLE  AUTO  FLUSH
;	TokenNameSEMICOLON	
/** * Disabled by default (because IndexWriter flushes by RAM usage * by default). Change using {@link #setMaxBufferedDocs(int)}. * @deprecated use {@link IndexWriterConfig#DEFAULT_MAX_BUFFERED_DOCS} instead. */	TokenNameCOMMENT_JAVADOC	 Disabled by default (because IndexWriter flushes by RAM usage by default). Change using {@link #setMaxBufferedDocs(int)}. @deprecated use {@link IndexWriterConfig#DEFAULT_MAX_BUFFERED_DOCS} instead. 
@	TokenNameAT	
Deprecated	TokenNameIdentifier	 Deprecated
public	TokenNamepublic	
final	TokenNamefinal	
static	TokenNamestatic	
int	TokenNameint	
DEFAULT_MAX_BUFFERED_DOCS	TokenNameIdentifier	 DEFAULT  MAX  BUFFERED  DOCS
=	TokenNameEQUAL	
IndexWriterConfig	TokenNameIdentifier	 Index Writer Config
.	TokenNameDOT	
DEFAULT_MAX_BUFFERED_DOCS	TokenNameIdentifier	 DEFAULT  MAX  BUFFERED  DOCS
;	TokenNameSEMICOLON	
/** * Default value is 16 MB (which means flush when buffered * docs consume 16 MB RAM). Change using {@link #setRAMBufferSizeMB}. * @deprecated use {@link IndexWriterConfig#DEFAULT_RAM_BUFFER_SIZE_MB} instead. */	TokenNameCOMMENT_JAVADOC	 Default value is 16 MB (which means flush when buffered docs consume 16 MB RAM). Change using {@link #setRAMBufferSizeMB}. @deprecated use {@link IndexWriterConfig#DEFAULT_RAM_BUFFER_SIZE_MB} instead. 
@	TokenNameAT	
Deprecated	TokenNameIdentifier	 Deprecated
public	TokenNamepublic	
final	TokenNamefinal	
static	TokenNamestatic	
double	TokenNamedouble	
DEFAULT_RAM_BUFFER_SIZE_MB	TokenNameIdentifier	 DEFAULT  RAM  BUFFER  SIZE  MB
=	TokenNameEQUAL	
IndexWriterConfig	TokenNameIdentifier	 Index Writer Config
.	TokenNameDOT	
DEFAULT_RAM_BUFFER_SIZE_MB	TokenNameIdentifier	 DEFAULT  RAM  BUFFER  SIZE  MB
;	TokenNameSEMICOLON	
/** * Disabled by default (because IndexWriter flushes by RAM usage * by default). Change using {@link #setMaxBufferedDeleteTerms(int)}. * @deprecated use {@link IndexWriterConfig#DEFAULT_MAX_BUFFERED_DELETE_TERMS} instead */	TokenNameCOMMENT_JAVADOC	 Disabled by default (because IndexWriter flushes by RAM usage by default). Change using {@link #setMaxBufferedDeleteTerms(int)}. @deprecated use {@link IndexWriterConfig#DEFAULT_MAX_BUFFERED_DELETE_TERMS} instead 
@	TokenNameAT	
Deprecated	TokenNameIdentifier	 Deprecated
public	TokenNamepublic	
final	TokenNamefinal	
static	TokenNamestatic	
int	TokenNameint	
DEFAULT_MAX_BUFFERED_DELETE_TERMS	TokenNameIdentifier	 DEFAULT  MAX  BUFFERED  DELETE  TERMS
=	TokenNameEQUAL	
IndexWriterConfig	TokenNameIdentifier	 Index Writer Config
.	TokenNameDOT	
DEFAULT_MAX_BUFFERED_DELETE_TERMS	TokenNameIdentifier	 DEFAULT  MAX  BUFFERED  DELETE  TERMS
;	TokenNameSEMICOLON	
/** * Default value is 10,000. Change using {@link #setMaxFieldLength(int)}. * * @deprecated see {@link IndexWriterConfig} */	TokenNameCOMMENT_JAVADOC	 Default value is 10,000. Change using {@link #setMaxFieldLength(int)}. * @deprecated see {@link IndexWriterConfig} 
@	TokenNameAT	
Deprecated	TokenNameIdentifier	 Deprecated
public	TokenNamepublic	
final	TokenNamefinal	
static	TokenNamestatic	
int	TokenNameint	
DEFAULT_MAX_FIELD_LENGTH	TokenNameIdentifier	 DEFAULT  MAX  FIELD  LENGTH
=	TokenNameEQUAL	
MaxFieldLength	TokenNameIdentifier	 Max Field Length
.	TokenNameDOT	
UNLIMITED	TokenNameIdentifier	 UNLIMITED
.	TokenNameDOT	
getLimit	TokenNameIdentifier	 get Limit
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
/** * Default value is 128. Change using {@link #setTermIndexInterval(int)}. * @deprecated use {@link IndexWriterConfig#DEFAULT_TERM_INDEX_INTERVAL} instead. */	TokenNameCOMMENT_JAVADOC	 Default value is 128. Change using {@link #setTermIndexInterval(int)}. @deprecated use {@link IndexWriterConfig#DEFAULT_TERM_INDEX_INTERVAL} instead. 
@	TokenNameAT	
Deprecated	TokenNameIdentifier	 Deprecated
public	TokenNamepublic	
final	TokenNamefinal	
static	TokenNamestatic	
int	TokenNameint	
DEFAULT_TERM_INDEX_INTERVAL	TokenNameIdentifier	 DEFAULT  TERM  INDEX  INTERVAL
=	TokenNameEQUAL	
IndexWriterConfig	TokenNameIdentifier	 Index Writer Config
.	TokenNameDOT	
DEFAULT_TERM_INDEX_INTERVAL	TokenNameIdentifier	 DEFAULT  TERM  INDEX  INTERVAL
;	TokenNameSEMICOLON	
/** * Absolute hard maximum length for a term. If a term * arrives from the analyzer longer than this length, it * is skipped and a message is printed to infoStream, if * set (see {@link #setInfoStream}). */	TokenNameCOMMENT_JAVADOC	 Absolute hard maximum length for a term. If a term arrives from the analyzer longer than this length, it is skipped and a message is printed to infoStream, if set (see {@link #setInfoStream}). 
public	TokenNamepublic	
final	TokenNamefinal	
static	TokenNamestatic	
int	TokenNameint	
MAX_TERM_LENGTH	TokenNameIdentifier	 MAX  TERM  LENGTH
=	TokenNameEQUAL	
DocumentsWriter	TokenNameIdentifier	 Documents Writer
.	TokenNameDOT	
MAX_TERM_LENGTH	TokenNameIdentifier	 MAX  TERM  LENGTH
;	TokenNameSEMICOLON	
// The normal read buffer size defaults to 1024, but 	TokenNameCOMMENT_LINE	The normal read buffer size defaults to 1024, but 
// increasing this during merging seems to yield 	TokenNameCOMMENT_LINE	increasing this during merging seems to yield 
// performance gains. However we don't want to increase 	TokenNameCOMMENT_LINE	performance gains. However we don't want to increase 
// it too much because there are quite a few 	TokenNameCOMMENT_LINE	it too much because there are quite a few 
// BufferedIndexInputs created during merging. See 	TokenNameCOMMENT_LINE	BufferedIndexInputs created during merging. See 
// LUCENE-888 for details. 	TokenNameCOMMENT_LINE	LUCENE-888 for details. 
private	TokenNameprivate	
final	TokenNamefinal	
static	TokenNamestatic	
int	TokenNameint	
MERGE_READ_BUFFER_SIZE	TokenNameIdentifier	 MERGE  READ  BUFFER  SIZE
=	TokenNameEQUAL	
4096	TokenNameIntegerLiteral	
;	TokenNameSEMICOLON	
// Used for printing messages 	TokenNameCOMMENT_LINE	Used for printing messages 
private	TokenNameprivate	
static	TokenNamestatic	
final	TokenNamefinal	
AtomicInteger	TokenNameIdentifier	 Atomic Integer
MESSAGE_ID	TokenNameIdentifier	 MESSAGE  ID
=	TokenNameEQUAL	
new	TokenNamenew	
AtomicInteger	TokenNameIdentifier	 Atomic Integer
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
private	TokenNameprivate	
int	TokenNameint	
messageID	TokenNameIdentifier	 message ID
=	TokenNameEQUAL	
MESSAGE_ID	TokenNameIdentifier	 MESSAGE  ID
.	TokenNameDOT	
getAndIncrement	TokenNameIdentifier	 get And Increment
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
volatile	TokenNamevolatile	
private	TokenNameprivate	
boolean	TokenNameboolean	
hitOOM	TokenNameIdentifier	 hit OOM
;	TokenNameSEMICOLON	
private	TokenNameprivate	
final	TokenNamefinal	
Directory	TokenNameIdentifier	 Directory
directory	TokenNameIdentifier	 directory
;	TokenNameSEMICOLON	
// where this index resides 	TokenNameCOMMENT_LINE	where this index resides 
private	TokenNameprivate	
final	TokenNamefinal	
Analyzer	TokenNameIdentifier	 Analyzer
analyzer	TokenNameIdentifier	 analyzer
;	TokenNameSEMICOLON	
// how to analyze text 	TokenNameCOMMENT_LINE	how to analyze text 
// TODO 4.0: this should be made final once the setter is out 	TokenNameCOMMENT_LINE	TODO 4.0: this should be made final once the setter is out 
private	TokenNameprivate	
/*final*/	TokenNameCOMMENT_BLOCK	final
Similarity	TokenNameIdentifier	 Similarity
similarity	TokenNameIdentifier	 similarity
=	TokenNameEQUAL	
Similarity	TokenNameIdentifier	 Similarity
.	TokenNameDOT	
getDefault	TokenNameIdentifier	 get Default
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
// how to normalize 	TokenNameCOMMENT_LINE	how to normalize 
private	TokenNameprivate	
volatile	TokenNamevolatile	
long	TokenNamelong	
changeCount	TokenNameIdentifier	 change Count
;	TokenNameSEMICOLON	
// increments every time a change is completed 	TokenNameCOMMENT_LINE	increments every time a change is completed 
private	TokenNameprivate	
long	TokenNamelong	
lastCommitChangeCount	TokenNameIdentifier	 last Commit Change Count
;	TokenNameSEMICOLON	
// last changeCount that was committed 	TokenNameCOMMENT_LINE	last changeCount that was committed 
private	TokenNameprivate	
List	TokenNameIdentifier	 List
<	TokenNameLESS	
SegmentInfo	TokenNameIdentifier	 Segment Info
>	TokenNameGREATER	
rollbackSegments	TokenNameIdentifier	 rollback Segments
;	TokenNameSEMICOLON	
// list of segmentInfo we will fallback to if the commit fails 	TokenNameCOMMENT_LINE	list of segmentInfo we will fallback to if the commit fails 
volatile	TokenNamevolatile	
SegmentInfos	TokenNameIdentifier	 Segment Infos
pendingCommit	TokenNameIdentifier	 pending Commit
;	TokenNameSEMICOLON	
// set when a commit is pending (after prepareCommit() & before commit()) 	TokenNameCOMMENT_LINE	set when a commit is pending (after prepareCommit() & before commit()) 
volatile	TokenNamevolatile	
long	TokenNamelong	
pendingCommitChangeCount	TokenNameIdentifier	 pending Commit Change Count
;	TokenNameSEMICOLON	
final	TokenNamefinal	
SegmentInfos	TokenNameIdentifier	 Segment Infos
segmentInfos	TokenNameIdentifier	 segment Infos
=	TokenNameEQUAL	
new	TokenNamenew	
SegmentInfos	TokenNameIdentifier	 Segment Infos
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
// the segments 	TokenNameCOMMENT_LINE	the segments 
private	TokenNameprivate	
Collection	TokenNameIdentifier	 Collection
<	TokenNameLESS	
String	TokenNameIdentifier	 String
>	TokenNameGREATER	
filesToCommit	TokenNameIdentifier	 files To Commit
;	TokenNameSEMICOLON	
private	TokenNameprivate	
DocumentsWriter	TokenNameIdentifier	 Documents Writer
docWriter	TokenNameIdentifier	 doc Writer
;	TokenNameSEMICOLON	
private	TokenNameprivate	
IndexFileDeleter	TokenNameIdentifier	 Index File Deleter
deleter	TokenNameIdentifier	 deleter
;	TokenNameSEMICOLON	
// used by forceMerge to note those needing merging 	TokenNameCOMMENT_LINE	used by forceMerge to note those needing merging 
private	TokenNameprivate	
Map	TokenNameIdentifier	 Map
<	TokenNameLESS	
SegmentInfo	TokenNameIdentifier	 Segment Info
,	TokenNameCOMMA	
Boolean	TokenNameIdentifier	 Boolean
>	TokenNameGREATER	
segmentsToMerge	TokenNameIdentifier	 segments To Merge
=	TokenNameEQUAL	
new	TokenNamenew	
HashMap	TokenNameIdentifier	 Hash Map
<	TokenNameLESS	
SegmentInfo	TokenNameIdentifier	 Segment Info
,	TokenNameCOMMA	
Boolean	TokenNameIdentifier	 Boolean
>	TokenNameGREATER	
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
private	TokenNameprivate	
int	TokenNameint	
mergeMaxNumSegments	TokenNameIdentifier	 merge Max Num Segments
;	TokenNameSEMICOLON	
private	TokenNameprivate	
Lock	TokenNameIdentifier	 Lock
writeLock	TokenNameIdentifier	 write Lock
;	TokenNameSEMICOLON	
private	TokenNameprivate	
volatile	TokenNamevolatile	
boolean	TokenNameboolean	
closed	TokenNameIdentifier	 closed
;	TokenNameSEMICOLON	
private	TokenNameprivate	
volatile	TokenNamevolatile	
boolean	TokenNameboolean	
closing	TokenNameIdentifier	 closing
;	TokenNameSEMICOLON	
// Holds all SegmentInfo instances currently involved in 	TokenNameCOMMENT_LINE	Holds all SegmentInfo instances currently involved in 
// merges 	TokenNameCOMMENT_LINE	merges 
private	TokenNameprivate	
HashSet	TokenNameIdentifier	 Hash Set
<	TokenNameLESS	
SegmentInfo	TokenNameIdentifier	 Segment Info
>	TokenNameGREATER	
mergingSegments	TokenNameIdentifier	 merging Segments
=	TokenNameEQUAL	
new	TokenNamenew	
HashSet	TokenNameIdentifier	 Hash Set
<	TokenNameLESS	
SegmentInfo	TokenNameIdentifier	 Segment Info
>	TokenNameGREATER	
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
private	TokenNameprivate	
MergePolicy	TokenNameIdentifier	 Merge Policy
mergePolicy	TokenNameIdentifier	 merge Policy
;	TokenNameSEMICOLON	
// TODO 4.0: this should be made final once the setter is removed 	TokenNameCOMMENT_LINE	TODO 4.0: this should be made final once the setter is removed 
private	TokenNameprivate	
/*final*/	TokenNameCOMMENT_BLOCK	final
MergeScheduler	TokenNameIdentifier	 Merge Scheduler
mergeScheduler	TokenNameIdentifier	 merge Scheduler
;	TokenNameSEMICOLON	
private	TokenNameprivate	
LinkedList	TokenNameIdentifier	 Linked List
<	TokenNameLESS	
MergePolicy	TokenNameIdentifier	 Merge Policy
.	TokenNameDOT	
OneMerge	TokenNameIdentifier	 One Merge
>	TokenNameGREATER	
pendingMerges	TokenNameIdentifier	 pending Merges
=	TokenNameEQUAL	
new	TokenNamenew	
LinkedList	TokenNameIdentifier	 Linked List
<	TokenNameLESS	
MergePolicy	TokenNameIdentifier	 Merge Policy
.	TokenNameDOT	
OneMerge	TokenNameIdentifier	 One Merge
>	TokenNameGREATER	
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
private	TokenNameprivate	
Set	TokenNameIdentifier	 Set
<	TokenNameLESS	
MergePolicy	TokenNameIdentifier	 Merge Policy
.	TokenNameDOT	
OneMerge	TokenNameIdentifier	 One Merge
>	TokenNameGREATER	
runningMerges	TokenNameIdentifier	 running Merges
=	TokenNameEQUAL	
new	TokenNamenew	
HashSet	TokenNameIdentifier	 Hash Set
<	TokenNameLESS	
MergePolicy	TokenNameIdentifier	 Merge Policy
.	TokenNameDOT	
OneMerge	TokenNameIdentifier	 One Merge
>	TokenNameGREATER	
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
private	TokenNameprivate	
List	TokenNameIdentifier	 List
<	TokenNameLESS	
MergePolicy	TokenNameIdentifier	 Merge Policy
.	TokenNameDOT	
OneMerge	TokenNameIdentifier	 One Merge
>	TokenNameGREATER	
mergeExceptions	TokenNameIdentifier	 merge Exceptions
=	TokenNameEQUAL	
new	TokenNamenew	
ArrayList	TokenNameIdentifier	 Array List
<	TokenNameLESS	
MergePolicy	TokenNameIdentifier	 Merge Policy
.	TokenNameDOT	
OneMerge	TokenNameIdentifier	 One Merge
>	TokenNameGREATER	
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
private	TokenNameprivate	
long	TokenNamelong	
mergeGen	TokenNameIdentifier	 merge Gen
;	TokenNameSEMICOLON	
private	TokenNameprivate	
boolean	TokenNameboolean	
stopMerges	TokenNameIdentifier	 stop Merges
;	TokenNameSEMICOLON	
private	TokenNameprivate	
final	TokenNamefinal	
AtomicInteger	TokenNameIdentifier	 Atomic Integer
flushCount	TokenNameIdentifier	 flush Count
=	TokenNameEQUAL	
new	TokenNamenew	
AtomicInteger	TokenNameIdentifier	 Atomic Integer
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
private	TokenNameprivate	
final	TokenNamefinal	
AtomicInteger	TokenNameIdentifier	 Atomic Integer
flushDeletesCount	TokenNameIdentifier	 flush Deletes Count
=	TokenNameEQUAL	
new	TokenNamenew	
AtomicInteger	TokenNameIdentifier	 Atomic Integer
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
final	TokenNamefinal	
ReaderPool	TokenNameIdentifier	 Reader Pool
readerPool	TokenNameIdentifier	 reader Pool
=	TokenNameEQUAL	
new	TokenNamenew	
ReaderPool	TokenNameIdentifier	 Reader Pool
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
final	TokenNamefinal	
BufferedDeletesStream	TokenNameIdentifier	 Buffered Deletes Stream
bufferedDeletesStream	TokenNameIdentifier	 buffered Deletes Stream
;	TokenNameSEMICOLON	
// This is a "write once" variable (like the organic dye 	TokenNameCOMMENT_LINE	This is a "write once" variable (like the organic dye 
// on a DVD-R that may or may not be heated by a laser and 	TokenNameCOMMENT_LINE	on a DVD-R that may or may not be heated by a laser and 
// then cooled to permanently record the event): it's 	TokenNameCOMMENT_LINE	then cooled to permanently record the event): it's 
// false, until getReader() is called for the first time, 	TokenNameCOMMENT_LINE	false, until getReader() is called for the first time, 
// at which point it's switched to true and never changes 	TokenNameCOMMENT_LINE	at which point it's switched to true and never changes 
// back to false. Once this is true, we hold open and 	TokenNameCOMMENT_LINE	back to false. Once this is true, we hold open and 
// reuse SegmentReader instances internally for applying 	TokenNameCOMMENT_LINE	reuse SegmentReader instances internally for applying 
// deletes, doing merges, and reopening near real-time 	TokenNameCOMMENT_LINE	deletes, doing merges, and reopening near real-time 
// readers. 	TokenNameCOMMENT_LINE	readers. 
private	TokenNameprivate	
volatile	TokenNamevolatile	
boolean	TokenNameboolean	
poolReaders	TokenNameIdentifier	 pool Readers
;	TokenNameSEMICOLON	
// The instance that was passed to the constructor. It is saved only in order 	TokenNameCOMMENT_LINE	The instance that was passed to the constructor. It is saved only in order 
// to allow users to query an IndexWriter settings. 	TokenNameCOMMENT_LINE	to allow users to query an IndexWriter settings. 
private	TokenNameprivate	
final	TokenNamefinal	
IndexWriterConfig	TokenNameIdentifier	 Index Writer Config
config	TokenNameIdentifier	 config
;	TokenNameSEMICOLON	
// The PayloadProcessorProvider to use when segments are merged 	TokenNameCOMMENT_LINE	The PayloadProcessorProvider to use when segments are merged 
private	TokenNameprivate	
PayloadProcessorProvider	TokenNameIdentifier	 Payload Processor Provider
payloadProcessorProvider	TokenNameIdentifier	 payload Processor Provider
;	TokenNameSEMICOLON	
// for testing 	TokenNameCOMMENT_LINE	for testing 
boolean	TokenNameboolean	
anyNonBulkMerges	TokenNameIdentifier	 any Non Bulk Merges
;	TokenNameSEMICOLON	
/** * Expert: returns a readonly reader, covering all * committed as well as un-committed changes to the index. * This provides "near real-time" searching, in that * changes made during an IndexWriter session can be * quickly made available for searching without closing * the writer nor calling {@link #commit}. * * <p>Note that this is functionally equivalent to calling * {#flush} and then using {@link IndexReader#open} to * open a new reader. But the turarnound time of this * method should be faster since it avoids the potentially * costly {@link #commit}.</p> * * <p>You must close the {@link IndexReader} returned by * this method once you are done using it.</p> * * <p>It's <i>near</i> real-time because there is no hard * guarantee on how quickly you can get a new reader after * making changes with IndexWriter. You'll have to * experiment in your situation to determine if it's * fast enough. As this is a new and experimental * feature, please report back on your findings so we can * learn, improve and iterate.</p> * * <p>The resulting reader supports {@link * IndexReader#reopen}, but that call will simply forward * back to this method (though this may change in the * future).</p> * * <p>The very first time this method is called, this * writer instance will make every effort to pool the * readers that it opens for doing merges, applying * deletes, etc. This means additional resources (RAM, * file descriptors, CPU time) will be consumed.</p> * * <p>For lower latency on reopening a reader, you should * call {@link #setMergedSegmentWarmer} to * pre-warm a newly merged segment before it's committed * to the index. This is important for minimizing * index-to-search delay after a large merge. </p> * * <p>If an addIndexes* call is running in another thread, * then this reader will only search those segments from * the foreign index that have been successfully copied * over, so far</p>. * * <p><b>NOTE</b>: Once the writer is closed, any * outstanding readers may continue to be used. However, * if you attempt to reopen any of those readers, you'll * hit an {@link AlreadyClosedException}.</p> * * @lucene.experimental * * @return IndexReader that covers entire index plus all * changes made so far by this IndexWriter instance * * @deprecated Please use {@link * IndexReader#open(IndexWriter,boolean)} instead. * * @throws IOException */	TokenNameCOMMENT_JAVADOC	 Expert: returns a readonly reader, covering all committed as well as un-committed changes to the index. This provides "near real-time" searching, in that changes made during an IndexWriter session can be quickly made available for searching without closing the writer nor calling {@link #commit}. * <p>Note that this is functionally equivalent to calling {#flush} and then using {@link IndexReader#open} to open a new reader. But the turarnound time of this method should be faster since it avoids the potentially costly {@link #commit}.</p> * <p>You must close the {@link IndexReader} returned by this method once you are done using it.</p> * <p>It's <i>near</i> real-time because there is no hard guarantee on how quickly you can get a new reader after making changes with IndexWriter. You'll have to experiment in your situation to determine if it's fast enough. As this is a new and experimental feature, please report back on your findings so we can learn, improve and iterate.</p> * <p>The resulting reader supports {@link IndexReader#reopen}, but that call will simply forward back to this method (though this may change in the future).</p> * <p>The very first time this method is called, this writer instance will make every effort to pool the readers that it opens for doing merges, applying deletes, etc. This means additional resources (RAM, file descriptors, CPU time) will be consumed.</p> * <p>For lower latency on reopening a reader, you should call {@link #setMergedSegmentWarmer} to pre-warm a newly merged segment before it's committed to the index. This is important for minimizing index-to-search delay after a large merge. </p> * <p>If an addIndexes* call is running in another thread, then this reader will only search those segments from the foreign index that have been successfully copied over, so far</p>. * <p><b>NOTE</b>: Once the writer is closed, any outstanding readers may continue to be used. However, if you attempt to reopen any of those readers, you'll hit an {@link AlreadyClosedException}.</p> * @lucene.experimental * @return IndexReader that covers entire index plus all changes made so far by this IndexWriter instance * @deprecated Please use {@link IndexReader#open(IndexWriter,boolean)} instead. * @throws IOException 
@	TokenNameAT	
Deprecated	TokenNameIdentifier	 Deprecated
public	TokenNamepublic	
IndexReader	TokenNameIdentifier	 Index Reader
getReader	TokenNameIdentifier	 get Reader
(	TokenNameLPAREN	
)	TokenNameRPAREN	
throws	TokenNamethrows	
IOException	TokenNameIdentifier	 IO Exception
{	TokenNameLBRACE	
return	TokenNamereturn	
getReader	TokenNameIdentifier	 get Reader
(	TokenNameLPAREN	
config	TokenNameIdentifier	 config
.	TokenNameDOT	
getReaderTermsIndexDivisor	TokenNameIdentifier	 get Reader Terms Index Divisor
(	TokenNameLPAREN	
)	TokenNameRPAREN	
,	TokenNameCOMMA	
true	TokenNametrue	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
IndexReader	TokenNameIdentifier	 Index Reader
getReader	TokenNameIdentifier	 get Reader
(	TokenNameLPAREN	
boolean	TokenNameboolean	
applyAllDeletes	TokenNameIdentifier	 apply All Deletes
)	TokenNameRPAREN	
throws	TokenNamethrows	
IOException	TokenNameIdentifier	 IO Exception
{	TokenNameLBRACE	
return	TokenNamereturn	
getReader	TokenNameIdentifier	 get Reader
(	TokenNameLPAREN	
config	TokenNameIdentifier	 config
.	TokenNameDOT	
getReaderTermsIndexDivisor	TokenNameIdentifier	 get Reader Terms Index Divisor
(	TokenNameLPAREN	
)	TokenNameRPAREN	
,	TokenNameCOMMA	
applyAllDeletes	TokenNameIdentifier	 apply All Deletes
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
/** Expert: like {@link #getReader}, except you can * specify which termInfosIndexDivisor should be used for * any newly opened readers. * @param termInfosIndexDivisor Subsamples which indexed * terms are loaded into RAM. This has the same effect as {@link * IndexWriter#setTermIndexInterval} except that setting * must be done at indexing time while this setting can be * set per reader. When set to N, then one in every * N*termIndexInterval terms in the index is loaded into * memory. By setting this to a value > 1 you can reduce * memory usage, at the expense of higher latency when * loading a TermInfo. The default value is 1. Set this * to -1 to skip loading the terms index entirely. * * @deprecated Please use {@link * IndexReader#open(IndexWriter,boolean)} instead. Furthermore, * this method cannot guarantee the reader (and its * sub-readers) will be opened with the * termInfosIndexDivisor setting because some of them may * have already been opened according to {@link * IndexWriterConfig#setReaderTermsIndexDivisor}. You * should set the requested termInfosIndexDivisor through * {@link IndexWriterConfig#setReaderTermsIndexDivisor} and use * {@link #getReader()}. */	TokenNameCOMMENT_JAVADOC	 Expert: like {@link #getReader}, except you can specify which termInfosIndexDivisor should be used for any newly opened readers. @param termInfosIndexDivisor Subsamples which indexed terms are loaded into RAM. This has the same effect as {@link IndexWriter#setTermIndexInterval} except that setting must be done at indexing time while this setting can be set per reader. When set to N, then one in every N*termIndexInterval terms in the index is loaded into memory. By setting this to a value > 1 you can reduce memory usage, at the expense of higher latency when loading a TermInfo. The default value is 1. Set this to -1 to skip loading the terms index entirely. * @deprecated Please use {@link IndexReader#open(IndexWriter,boolean)} instead. Furthermore, this method cannot guarantee the reader (and its sub-readers) will be opened with the termInfosIndexDivisor setting because some of them may have already been opened according to {@link IndexWriterConfig#setReaderTermsIndexDivisor}. You should set the requested termInfosIndexDivisor through {@link IndexWriterConfig#setReaderTermsIndexDivisor} and use {@link #getReader()}. 
@	TokenNameAT	
Deprecated	TokenNameIdentifier	 Deprecated
public	TokenNamepublic	
IndexReader	TokenNameIdentifier	 Index Reader
getReader	TokenNameIdentifier	 get Reader
(	TokenNameLPAREN	
int	TokenNameint	
termInfosIndexDivisor	TokenNameIdentifier	 term Infos Index Divisor
)	TokenNameRPAREN	
throws	TokenNamethrows	
IOException	TokenNameIdentifier	 IO Exception
{	TokenNameLBRACE	
return	TokenNamereturn	
getReader	TokenNameIdentifier	 get Reader
(	TokenNameLPAREN	
termInfosIndexDivisor	TokenNameIdentifier	 term Infos Index Divisor
,	TokenNameCOMMA	
true	TokenNametrue	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
IndexReader	TokenNameIdentifier	 Index Reader
getReader	TokenNameIdentifier	 get Reader
(	TokenNameLPAREN	
int	TokenNameint	
termInfosIndexDivisor	TokenNameIdentifier	 term Infos Index Divisor
,	TokenNameCOMMA	
boolean	TokenNameboolean	
applyAllDeletes	TokenNameIdentifier	 apply All Deletes
)	TokenNameRPAREN	
throws	TokenNamethrows	
IOException	TokenNameIdentifier	 IO Exception
{	TokenNameLBRACE	
ensureOpen	TokenNameIdentifier	 ensure Open
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
final	TokenNamefinal	
long	TokenNamelong	
tStart	TokenNameIdentifier	 t Start
=	TokenNameEQUAL	
System	TokenNameIdentifier	 System
.	TokenNameDOT	
currentTimeMillis	TokenNameIdentifier	 current Time Millis
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
if	TokenNameif	
(	TokenNameLPAREN	
infoStream	TokenNameIdentifier	 info Stream
!=	TokenNameNOT_EQUAL	
null	TokenNamenull	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
message	TokenNameIdentifier	 message
(	TokenNameLPAREN	
"flush at getReader"	TokenNameStringLiteral	flush at getReader
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
// Do this up front before flushing so that the readers 	TokenNameCOMMENT_LINE	Do this up front before flushing so that the readers 
// obtained during this flush are pooled, the first time 	TokenNameCOMMENT_LINE	obtained during this flush are pooled, the first time 
// this method is called: 	TokenNameCOMMENT_LINE	this method is called: 
poolReaders	TokenNameIdentifier	 pool Readers
=	TokenNameEQUAL	
true	TokenNametrue	
;	TokenNameSEMICOLON	
// Prevent segmentInfos from changing while opening the 	TokenNameCOMMENT_LINE	Prevent segmentInfos from changing while opening the 
// reader; in theory we could do similar retry logic, 	TokenNameCOMMENT_LINE	reader; in theory we could do similar retry logic, 
// just like we do when loading segments_N 	TokenNameCOMMENT_LINE	just like we do when loading segments_N 
IndexReader	TokenNameIdentifier	 Index Reader
r	TokenNameIdentifier	 r
;	TokenNameSEMICOLON	
synchronized	TokenNamesynchronized	
(	TokenNameLPAREN	
this	TokenNamethis	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
flush	TokenNameIdentifier	 flush
(	TokenNameLPAREN	
false	TokenNamefalse	
,	TokenNameCOMMA	
applyAllDeletes	TokenNameIdentifier	 apply All Deletes
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
r	TokenNameIdentifier	 r
=	TokenNameEQUAL	
new	TokenNamenew	
ReadOnlyDirectoryReader	TokenNameIdentifier	 Read Only Directory Reader
(	TokenNameLPAREN	
this	TokenNamethis	
,	TokenNameCOMMA	
segmentInfos	TokenNameIdentifier	 segment Infos
,	TokenNameCOMMA	
termInfosIndexDivisor	TokenNameIdentifier	 term Infos Index Divisor
,	TokenNameCOMMA	
applyAllDeletes	TokenNameIdentifier	 apply All Deletes
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
if	TokenNameif	
(	TokenNameLPAREN	
infoStream	TokenNameIdentifier	 info Stream
!=	TokenNameNOT_EQUAL	
null	TokenNamenull	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
message	TokenNameIdentifier	 message
(	TokenNameLPAREN	
"return reader version="	TokenNameStringLiteral	return reader version=
+	TokenNamePLUS	
r	TokenNameIdentifier	 r
.	TokenNameDOT	
getVersion	TokenNameIdentifier	 get Version
(	TokenNameLPAREN	
)	TokenNameRPAREN	
+	TokenNamePLUS	
" reader="	TokenNameStringLiteral	 reader=
+	TokenNamePLUS	
r	TokenNameIdentifier	 r
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
}	TokenNameRBRACE	
maybeMerge	TokenNameIdentifier	 maybe Merge
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
if	TokenNameif	
(	TokenNameLPAREN	
infoStream	TokenNameIdentifier	 info Stream
!=	TokenNameNOT_EQUAL	
null	TokenNamenull	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
message	TokenNameIdentifier	 message
(	TokenNameLPAREN	
"getReader took "	TokenNameStringLiteral	getReader took 
+	TokenNamePLUS	
(	TokenNameLPAREN	
System	TokenNameIdentifier	 System
.	TokenNameDOT	
currentTimeMillis	TokenNameIdentifier	 current Time Millis
(	TokenNameLPAREN	
)	TokenNameRPAREN	
-	TokenNameMINUS	
tStart	TokenNameIdentifier	 t Start
)	TokenNameRPAREN	
+	TokenNamePLUS	
" msec"	TokenNameStringLiteral	 msec
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
return	TokenNamereturn	
r	TokenNameIdentifier	 r
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
/** Holds shared SegmentReader instances. IndexWriter uses * SegmentReaders for 1) applying deletes, 2) doing * merges, 3) handing out a real-time reader. This pool * reuses instances of the SegmentReaders in all these * places if it is in "near real-time mode" (getReader() * has been called on this instance). */	TokenNameCOMMENT_JAVADOC	 Holds shared SegmentReader instances. IndexWriter uses SegmentReaders for 1) applying deletes, 2) doing merges, 3) handing out a real-time reader. This pool reuses instances of the SegmentReaders in all these places if it is in "near real-time mode" (getReader() has been called on this instance). 
class	TokenNameclass	
ReaderPool	TokenNameIdentifier	 Reader Pool
{	TokenNameLBRACE	
private	TokenNameprivate	
final	TokenNamefinal	
Map	TokenNameIdentifier	 Map
<	TokenNameLESS	
SegmentInfo	TokenNameIdentifier	 Segment Info
,	TokenNameCOMMA	
SegmentReader	TokenNameIdentifier	 Segment Reader
>	TokenNameGREATER	
readerMap	TokenNameIdentifier	 reader Map
=	TokenNameEQUAL	
new	TokenNamenew	
HashMap	TokenNameIdentifier	 Hash Map
<	TokenNameLESS	
SegmentInfo	TokenNameIdentifier	 Segment Info
,	TokenNameCOMMA	
SegmentReader	TokenNameIdentifier	 Segment Reader
>	TokenNameGREATER	
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
/** Forcefully clear changes for the specified segments. This is called on successful merge. */	TokenNameCOMMENT_JAVADOC	 Forcefully clear changes for the specified segments. This is called on successful merge. 
synchronized	TokenNamesynchronized	
void	TokenNamevoid	
clear	TokenNameIdentifier	 clear
(	TokenNameLPAREN	
List	TokenNameIdentifier	 List
<	TokenNameLESS	
SegmentInfo	TokenNameIdentifier	 Segment Info
>	TokenNameGREATER	
infos	TokenNameIdentifier	 infos
)	TokenNameRPAREN	
throws	TokenNamethrows	
IOException	TokenNameIdentifier	 IO Exception
{	TokenNameLBRACE	
if	TokenNameif	
(	TokenNameLPAREN	
infos	TokenNameIdentifier	 infos
==	TokenNameEQUAL_EQUAL	
null	TokenNamenull	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
for	TokenNamefor	
(	TokenNameLPAREN	
Map	TokenNameIdentifier	 Map
.	TokenNameDOT	
Entry	TokenNameIdentifier	 Entry
<	TokenNameLESS	
SegmentInfo	TokenNameIdentifier	 Segment Info
,	TokenNameCOMMA	
SegmentReader	TokenNameIdentifier	 Segment Reader
>	TokenNameGREATER	
ent	TokenNameIdentifier	 ent
:	TokenNameCOLON	
readerMap	TokenNameIdentifier	 reader Map
.	TokenNameDOT	
entrySet	TokenNameIdentifier	 entry Set
(	TokenNameLPAREN	
)	TokenNameRPAREN	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
ent	TokenNameIdentifier	 ent
.	TokenNameDOT	
getValue	TokenNameIdentifier	 get Value
(	TokenNameLPAREN	
)	TokenNameRPAREN	
.	TokenNameDOT	
hasChanges	TokenNameIdentifier	 has Changes
=	TokenNameEQUAL	
false	TokenNamefalse	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
}	TokenNameRBRACE	
else	TokenNameelse	
{	TokenNameLBRACE	
for	TokenNamefor	
(	TokenNameLPAREN	
final	TokenNamefinal	
SegmentInfo	TokenNameIdentifier	 Segment Info
info	TokenNameIdentifier	 info
:	TokenNameCOLON	
infos	TokenNameIdentifier	 infos
)	TokenNameRPAREN	
{	TokenNameLBRACE	
final	TokenNamefinal	
SegmentReader	TokenNameIdentifier	 Segment Reader
r	TokenNameIdentifier	 r
=	TokenNameEQUAL	
readerMap	TokenNameIdentifier	 reader Map
.	TokenNameDOT	
get	TokenNameIdentifier	 get
(	TokenNameLPAREN	
info	TokenNameIdentifier	 info
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
if	TokenNameif	
(	TokenNameLPAREN	
r	TokenNameIdentifier	 r
!=	TokenNameNOT_EQUAL	
null	TokenNamenull	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
r	TokenNameIdentifier	 r
.	TokenNameDOT	
hasChanges	TokenNameIdentifier	 has Changes
=	TokenNameEQUAL	
false	TokenNamefalse	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
}	TokenNameRBRACE	
}	TokenNameRBRACE	
}	TokenNameRBRACE	
// used only by asserts 	TokenNameCOMMENT_LINE	used only by asserts 
public	TokenNamepublic	
synchronized	TokenNamesynchronized	
boolean	TokenNameboolean	
infoIsLive	TokenNameIdentifier	 info Is Live
(	TokenNameLPAREN	
SegmentInfo	TokenNameIdentifier	 Segment Info
info	TokenNameIdentifier	 info
)	TokenNameRPAREN	
{	TokenNameLBRACE	
int	TokenNameint	
idx	TokenNameIdentifier	 idx
=	TokenNameEQUAL	
segmentInfos	TokenNameIdentifier	 segment Infos
.	TokenNameDOT	
indexOf	TokenNameIdentifier	 index Of
(	TokenNameLPAREN	
info	TokenNameIdentifier	 info
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
assert	TokenNameassert	
idx	TokenNameIdentifier	 idx
!=	TokenNameNOT_EQUAL	
-	TokenNameMINUS	
1	TokenNameIntegerLiteral	
:	TokenNameCOLON	
"info="	TokenNameStringLiteral	info=
+	TokenNamePLUS	
info	TokenNameIdentifier	 info
+	TokenNamePLUS	
" isn't in pool"	TokenNameStringLiteral	 isn't in pool
;	TokenNameSEMICOLON	
assert	TokenNameassert	
segmentInfos	TokenNameIdentifier	 segment Infos
.	TokenNameDOT	
info	TokenNameIdentifier	 info
(	TokenNameLPAREN	
idx	TokenNameIdentifier	 idx
)	TokenNameRPAREN	
==	TokenNameEQUAL_EQUAL	
info	TokenNameIdentifier	 info
:	TokenNameCOLON	
"info="	TokenNameStringLiteral	info=
+	TokenNamePLUS	
info	TokenNameIdentifier	 info
+	TokenNamePLUS	
" doesn't match live info in segmentInfos"	TokenNameStringLiteral	 doesn't match live info in segmentInfos
;	TokenNameSEMICOLON	
return	TokenNamereturn	
true	TokenNametrue	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
public	TokenNamepublic	
synchronized	TokenNamesynchronized	
SegmentInfo	TokenNameIdentifier	 Segment Info
mapToLive	TokenNameIdentifier	 map To Live
(	TokenNameLPAREN	
SegmentInfo	TokenNameIdentifier	 Segment Info
info	TokenNameIdentifier	 info
)	TokenNameRPAREN	
{	TokenNameLBRACE	
int	TokenNameint	
idx	TokenNameIdentifier	 idx
=	TokenNameEQUAL	
segmentInfos	TokenNameIdentifier	 segment Infos
.	TokenNameDOT	
indexOf	TokenNameIdentifier	 index Of
(	TokenNameLPAREN	
info	TokenNameIdentifier	 info
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
if	TokenNameif	
(	TokenNameLPAREN	
idx	TokenNameIdentifier	 idx
!=	TokenNameNOT_EQUAL	
-	TokenNameMINUS	
1	TokenNameIntegerLiteral	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
info	TokenNameIdentifier	 info
=	TokenNameEQUAL	
segmentInfos	TokenNameIdentifier	 segment Infos
.	TokenNameDOT	
info	TokenNameIdentifier	 info
(	TokenNameLPAREN	
idx	TokenNameIdentifier	 idx
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
return	TokenNamereturn	
info	TokenNameIdentifier	 info
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
/** * Release the segment reader (i.e. decRef it and close if there * are no more references. * @return true if this release altered the index (eg * the SegmentReader had pending changes to del docs and * was closed). Caller must call checkpoint() if so. * @param sr * @throws IOException */	TokenNameCOMMENT_JAVADOC	 Release the segment reader (i.e. decRef it and close if there are no more references. @return true if this release altered the index (eg the SegmentReader had pending changes to del docs and was closed). Caller must call checkpoint() if so. @param sr @throws IOException 
public	TokenNamepublic	
synchronized	TokenNamesynchronized	
boolean	TokenNameboolean	
release	TokenNameIdentifier	 release
(	TokenNameLPAREN	
SegmentReader	TokenNameIdentifier	 Segment Reader
sr	TokenNameIdentifier	 sr
)	TokenNameRPAREN	
throws	TokenNamethrows	
IOException	TokenNameIdentifier	 IO Exception
{	TokenNameLBRACE	
return	TokenNamereturn	
release	TokenNameIdentifier	 release
(	TokenNameLPAREN	
sr	TokenNameIdentifier	 sr
,	TokenNameCOMMA	
false	TokenNamefalse	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
/** * Release the segment reader (i.e. decRef it and close if there * are no more references. * @return true if this release altered the index (eg * the SegmentReader had pending changes to del docs and * was closed). Caller must call checkpoint() if so. * @param sr * @throws IOException */	TokenNameCOMMENT_JAVADOC	 Release the segment reader (i.e. decRef it and close if there are no more references. @return true if this release altered the index (eg the SegmentReader had pending changes to del docs and was closed). Caller must call checkpoint() if so. @param sr @throws IOException 
public	TokenNamepublic	
synchronized	TokenNamesynchronized	
boolean	TokenNameboolean	
release	TokenNameIdentifier	 release
(	TokenNameLPAREN	
SegmentReader	TokenNameIdentifier	 Segment Reader
sr	TokenNameIdentifier	 sr
,	TokenNameCOMMA	
boolean	TokenNameboolean	
drop	TokenNameIdentifier	 drop
)	TokenNameRPAREN	
throws	TokenNamethrows	
IOException	TokenNameIdentifier	 IO Exception
{	TokenNameLBRACE	
final	TokenNamefinal	
boolean	TokenNameboolean	
pooled	TokenNameIdentifier	 pooled
=	TokenNameEQUAL	
readerMap	TokenNameIdentifier	 reader Map
.	TokenNameDOT	
containsKey	TokenNameIdentifier	 contains Key
(	TokenNameLPAREN	
sr	TokenNameIdentifier	 sr
.	TokenNameDOT	
getSegmentInfo	TokenNameIdentifier	 get Segment Info
(	TokenNameLPAREN	
)	TokenNameRPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
assert	TokenNameassert	
!	TokenNameNOT	
pooled	TokenNameIdentifier	 pooled
||	TokenNameOR_OR	
readerMap	TokenNameIdentifier	 reader Map
.	TokenNameDOT	
get	TokenNameIdentifier	 get
(	TokenNameLPAREN	
sr	TokenNameIdentifier	 sr
.	TokenNameDOT	
getSegmentInfo	TokenNameIdentifier	 get Segment Info
(	TokenNameLPAREN	
)	TokenNameRPAREN	
)	TokenNameRPAREN	
==	TokenNameEQUAL_EQUAL	
sr	TokenNameIdentifier	 sr
;	TokenNameSEMICOLON	
// Drop caller's ref; for an external reader (not 	TokenNameCOMMENT_LINE	Drop caller's ref; for an external reader (not 
// pooled), this decRef will close it 	TokenNameCOMMENT_LINE	pooled), this decRef will close it 
sr	TokenNameIdentifier	 sr
.	TokenNameDOT	
decRef	TokenNameIdentifier	 dec Ref
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
if	TokenNameif	
(	TokenNameLPAREN	
pooled	TokenNameIdentifier	 pooled
&&	TokenNameAND_AND	
(	TokenNameLPAREN	
drop	TokenNameIdentifier	 drop
||	TokenNameOR_OR	
(	TokenNameLPAREN	
!	TokenNameNOT	
poolReaders	TokenNameIdentifier	 pool Readers
&&	TokenNameAND_AND	
sr	TokenNameIdentifier	 sr
.	TokenNameDOT	
getRefCount	TokenNameIdentifier	 get Ref Count
(	TokenNameLPAREN	
)	TokenNameRPAREN	
==	TokenNameEQUAL_EQUAL	
1	TokenNameIntegerLiteral	
)	TokenNameRPAREN	
)	TokenNameRPAREN	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
// We invoke deleter.checkpoint below, so we must be 	TokenNameCOMMENT_LINE	We invoke deleter.checkpoint below, so we must be 
// sync'd on IW if there are changes: 	TokenNameCOMMENT_LINE	sync'd on IW if there are changes: 
assert	TokenNameassert	
!	TokenNameNOT	
sr	TokenNameIdentifier	 sr
.	TokenNameDOT	
hasChanges	TokenNameIdentifier	 has Changes
||	TokenNameOR_OR	
Thread	TokenNameIdentifier	 Thread
.	TokenNameDOT	
holdsLock	TokenNameIdentifier	 holds Lock
(	TokenNameLPAREN	
IndexWriter	TokenNameIdentifier	 Index Writer
.	TokenNameDOT	
this	TokenNamethis	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
// Discard (don't save) changes when we are dropping 	TokenNameCOMMENT_LINE	Discard (don't save) changes when we are dropping 
// the reader; this is used only on the sub-readers 	TokenNameCOMMENT_LINE	the reader; this is used only on the sub-readers 
// after a successful merge. 	TokenNameCOMMENT_LINE	after a successful merge. 
sr	TokenNameIdentifier	 sr
.	TokenNameDOT	
hasChanges	TokenNameIdentifier	 has Changes
&=	TokenNameAND_EQUAL	
!	TokenNameNOT	
drop	TokenNameIdentifier	 drop
;	TokenNameSEMICOLON	
final	TokenNamefinal	
boolean	TokenNameboolean	
hasChanges	TokenNameIdentifier	 has Changes
=	TokenNameEQUAL	
sr	TokenNameIdentifier	 sr
.	TokenNameDOT	
hasChanges	TokenNameIdentifier	 has Changes
;	TokenNameSEMICOLON	
// Drop our ref -- this will commit any pending 	TokenNameCOMMENT_LINE	Drop our ref -- this will commit any pending 
// changes to the dir 	TokenNameCOMMENT_LINE	changes to the dir 
sr	TokenNameIdentifier	 sr
.	TokenNameDOT	
close	TokenNameIdentifier	 close
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
// We are the last ref to this reader; since we're 	TokenNameCOMMENT_LINE	We are the last ref to this reader; since we're 
// not pooling readers, we release it: 	TokenNameCOMMENT_LINE	not pooling readers, we release it: 
readerMap	TokenNameIdentifier	 reader Map
.	TokenNameDOT	
remove	TokenNameIdentifier	 remove
(	TokenNameLPAREN	
sr	TokenNameIdentifier	 sr
.	TokenNameDOT	
getSegmentInfo	TokenNameIdentifier	 get Segment Info
(	TokenNameLPAREN	
)	TokenNameRPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
return	TokenNamereturn	
hasChanges	TokenNameIdentifier	 has Changes
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
return	TokenNamereturn	
false	TokenNamefalse	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
public	TokenNamepublic	
synchronized	TokenNamesynchronized	
void	TokenNamevoid	
drop	TokenNameIdentifier	 drop
(	TokenNameLPAREN	
List	TokenNameIdentifier	 List
<	TokenNameLESS	
SegmentInfo	TokenNameIdentifier	 Segment Info
>	TokenNameGREATER	
infos	TokenNameIdentifier	 infos
)	TokenNameRPAREN	
throws	TokenNamethrows	
IOException	TokenNameIdentifier	 IO Exception
{	TokenNameLBRACE	
for	TokenNamefor	
(	TokenNameLPAREN	
SegmentInfo	TokenNameIdentifier	 Segment Info
info	TokenNameIdentifier	 info
:	TokenNameCOLON	
infos	TokenNameIdentifier	 infos
)	TokenNameRPAREN	
{	TokenNameLBRACE	
drop	TokenNameIdentifier	 drop
(	TokenNameLPAREN	
info	TokenNameIdentifier	 info
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
}	TokenNameRBRACE	
public	TokenNamepublic	
synchronized	TokenNamesynchronized	
void	TokenNamevoid	
drop	TokenNameIdentifier	 drop
(	TokenNameLPAREN	
SegmentInfo	TokenNameIdentifier	 Segment Info
info	TokenNameIdentifier	 info
)	TokenNameRPAREN	
throws	TokenNamethrows	
IOException	TokenNameIdentifier	 IO Exception
{	TokenNameLBRACE	
final	TokenNamefinal	
SegmentReader	TokenNameIdentifier	 Segment Reader
sr	TokenNameIdentifier	 sr
=	TokenNameEQUAL	
readerMap	TokenNameIdentifier	 reader Map
.	TokenNameDOT	
get	TokenNameIdentifier	 get
(	TokenNameLPAREN	
info	TokenNameIdentifier	 info
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
if	TokenNameif	
(	TokenNameLPAREN	
sr	TokenNameIdentifier	 sr
!=	TokenNameNOT_EQUAL	
null	TokenNamenull	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
sr	TokenNameIdentifier	 sr
.	TokenNameDOT	
hasChanges	TokenNameIdentifier	 has Changes
=	TokenNameEQUAL	
false	TokenNamefalse	
;	TokenNameSEMICOLON	
readerMap	TokenNameIdentifier	 reader Map
.	TokenNameDOT	
remove	TokenNameIdentifier	 remove
(	TokenNameLPAREN	
info	TokenNameIdentifier	 info
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
sr	TokenNameIdentifier	 sr
.	TokenNameDOT	
close	TokenNameIdentifier	 close
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
}	TokenNameRBRACE	
public	TokenNamepublic	
synchronized	TokenNamesynchronized	
void	TokenNamevoid	
dropAll	TokenNameIdentifier	 drop All
(	TokenNameLPAREN	
)	TokenNameRPAREN	
throws	TokenNamethrows	
IOException	TokenNameIdentifier	 IO Exception
{	TokenNameLBRACE	
for	TokenNamefor	
(	TokenNameLPAREN	
SegmentReader	TokenNameIdentifier	 Segment Reader
reader	TokenNameIdentifier	 reader
:	TokenNameCOLON	
readerMap	TokenNameIdentifier	 reader Map
.	TokenNameDOT	
values	TokenNameIdentifier	 values
(	TokenNameLPAREN	
)	TokenNameRPAREN	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
reader	TokenNameIdentifier	 reader
.	TokenNameDOT	
hasChanges	TokenNameIdentifier	 has Changes
=	TokenNameEQUAL	
false	TokenNamefalse	
;	TokenNameSEMICOLON	
// NOTE: it is allowed that this decRef does not 	TokenNameCOMMENT_LINE	NOTE: it is allowed that this decRef does not 
// actually close the SR; this can happen when a 	TokenNameCOMMENT_LINE	actually close the SR; this can happen when a 
// near real-time reader using this SR is still open 	TokenNameCOMMENT_LINE	near real-time reader using this SR is still open 
reader	TokenNameIdentifier	 reader
.	TokenNameDOT	
decRef	TokenNameIdentifier	 dec Ref
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
readerMap	TokenNameIdentifier	 reader Map
.	TokenNameDOT	
clear	TokenNameIdentifier	 clear
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
/** Remove all our references to readers, and commits * any pending changes. */	TokenNameCOMMENT_JAVADOC	 Remove all our references to readers, and commits any pending changes. 
synchronized	TokenNamesynchronized	
void	TokenNamevoid	
close	TokenNameIdentifier	 close
(	TokenNameLPAREN	
)	TokenNameRPAREN	
throws	TokenNamethrows	
IOException	TokenNameIdentifier	 IO Exception
{	TokenNameLBRACE	
// We invoke deleter.checkpoint below, so we must be 	TokenNameCOMMENT_LINE	We invoke deleter.checkpoint below, so we must be 
// sync'd on IW: 	TokenNameCOMMENT_LINE	sync'd on IW: 
assert	TokenNameassert	
Thread	TokenNameIdentifier	 Thread
.	TokenNameDOT	
holdsLock	TokenNameIdentifier	 holds Lock
(	TokenNameLPAREN	
IndexWriter	TokenNameIdentifier	 Index Writer
.	TokenNameDOT	
this	TokenNamethis	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
for	TokenNamefor	
(	TokenNameLPAREN	
Map	TokenNameIdentifier	 Map
.	TokenNameDOT	
Entry	TokenNameIdentifier	 Entry
<	TokenNameLESS	
SegmentInfo	TokenNameIdentifier	 Segment Info
,	TokenNameCOMMA	
SegmentReader	TokenNameIdentifier	 Segment Reader
>	TokenNameGREATER	
ent	TokenNameIdentifier	 ent
:	TokenNameCOLON	
readerMap	TokenNameIdentifier	 reader Map
.	TokenNameDOT	
entrySet	TokenNameIdentifier	 entry Set
(	TokenNameLPAREN	
)	TokenNameRPAREN	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
SegmentReader	TokenNameIdentifier	 Segment Reader
sr	TokenNameIdentifier	 sr
=	TokenNameEQUAL	
ent	TokenNameIdentifier	 ent
.	TokenNameDOT	
getValue	TokenNameIdentifier	 get Value
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
if	TokenNameif	
(	TokenNameLPAREN	
sr	TokenNameIdentifier	 sr
.	TokenNameDOT	
hasChanges	TokenNameIdentifier	 has Changes
)	TokenNameRPAREN	
{	TokenNameLBRACE	
assert	TokenNameassert	
infoIsLive	TokenNameIdentifier	 info Is Live
(	TokenNameLPAREN	
sr	TokenNameIdentifier	 sr
.	TokenNameDOT	
getSegmentInfo	TokenNameIdentifier	 get Segment Info
(	TokenNameLPAREN	
)	TokenNameRPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
sr	TokenNameIdentifier	 sr
.	TokenNameDOT	
doCommit	TokenNameIdentifier	 do Commit
(	TokenNameLPAREN	
null	TokenNamenull	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
// Must checkpoint w/ deleter, because this 	TokenNameCOMMENT_LINE	Must checkpoint w/ deleter, because this 
// segment reader will have created new _X_N.del 	TokenNameCOMMENT_LINE	segment reader will have created new _X_N.del 
// file. 	TokenNameCOMMENT_LINE	file. 
deleter	TokenNameIdentifier	 deleter
.	TokenNameDOT	
checkpoint	TokenNameIdentifier	 checkpoint
(	TokenNameLPAREN	
segmentInfos	TokenNameIdentifier	 segment Infos
,	TokenNameCOMMA	
false	TokenNamefalse	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
// NOTE: it is allowed that this decRef does not 	TokenNameCOMMENT_LINE	NOTE: it is allowed that this decRef does not 
// actually close the SR; this can happen when a 	TokenNameCOMMENT_LINE	actually close the SR; this can happen when a 
// near real-time reader is kept open after the 	TokenNameCOMMENT_LINE	near real-time reader is kept open after the 
// IndexWriter instance is closed 	TokenNameCOMMENT_LINE	IndexWriter instance is closed 
sr	TokenNameIdentifier	 sr
.	TokenNameDOT	
decRef	TokenNameIdentifier	 dec Ref
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
readerMap	TokenNameIdentifier	 reader Map
.	TokenNameDOT	
clear	TokenNameIdentifier	 clear
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
/** * Commit all segment reader in the pool. * @throws IOException */	TokenNameCOMMENT_JAVADOC	 Commit all segment reader in the pool. @throws IOException 
synchronized	TokenNamesynchronized	
void	TokenNamevoid	
commit	TokenNameIdentifier	 commit
(	TokenNameLPAREN	
SegmentInfos	TokenNameIdentifier	 Segment Infos
infos	TokenNameIdentifier	 infos
)	TokenNameRPAREN	
throws	TokenNamethrows	
IOException	TokenNameIdentifier	 IO Exception
{	TokenNameLBRACE	
// We invoke deleter.checkpoint below, so we must be 	TokenNameCOMMENT_LINE	We invoke deleter.checkpoint below, so we must be 
// sync'd on IW: 	TokenNameCOMMENT_LINE	sync'd on IW: 
assert	TokenNameassert	
Thread	TokenNameIdentifier	 Thread
.	TokenNameDOT	
holdsLock	TokenNameIdentifier	 holds Lock
(	TokenNameLPAREN	
IndexWriter	TokenNameIdentifier	 Index Writer
.	TokenNameDOT	
this	TokenNamethis	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
for	TokenNamefor	
(	TokenNameLPAREN	
SegmentInfo	TokenNameIdentifier	 Segment Info
info	TokenNameIdentifier	 info
:	TokenNameCOLON	
infos	TokenNameIdentifier	 infos
)	TokenNameRPAREN	
{	TokenNameLBRACE	
final	TokenNamefinal	
SegmentReader	TokenNameIdentifier	 Segment Reader
sr	TokenNameIdentifier	 sr
=	TokenNameEQUAL	
readerMap	TokenNameIdentifier	 reader Map
.	TokenNameDOT	
get	TokenNameIdentifier	 get
(	TokenNameLPAREN	
info	TokenNameIdentifier	 info
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
if	TokenNameif	
(	TokenNameLPAREN	
sr	TokenNameIdentifier	 sr
!=	TokenNameNOT_EQUAL	
null	TokenNamenull	
&&	TokenNameAND_AND	
sr	TokenNameIdentifier	 sr
.	TokenNameDOT	
hasChanges	TokenNameIdentifier	 has Changes
)	TokenNameRPAREN	
{	TokenNameLBRACE	
assert	TokenNameassert	
infoIsLive	TokenNameIdentifier	 info Is Live
(	TokenNameLPAREN	
info	TokenNameIdentifier	 info
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
sr	TokenNameIdentifier	 sr
.	TokenNameDOT	
doCommit	TokenNameIdentifier	 do Commit
(	TokenNameLPAREN	
null	TokenNamenull	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
// Must checkpoint w/ deleter, because this 	TokenNameCOMMENT_LINE	Must checkpoint w/ deleter, because this 
// segment reader will have created new _X_N.del 	TokenNameCOMMENT_LINE	segment reader will have created new _X_N.del 
// file. 	TokenNameCOMMENT_LINE	file. 
deleter	TokenNameIdentifier	 deleter
.	TokenNameDOT	
checkpoint	TokenNameIdentifier	 checkpoint
(	TokenNameLPAREN	
segmentInfos	TokenNameIdentifier	 segment Infos
,	TokenNameCOMMA	
false	TokenNamefalse	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
}	TokenNameRBRACE	
}	TokenNameRBRACE	
/** * Returns a ref to a clone. NOTE: this clone is not * enrolled in the pool, so you should simply close() * it when you're done (ie, do not call release()). */	TokenNameCOMMENT_JAVADOC	 Returns a ref to a clone. NOTE: this clone is not enrolled in the pool, so you should simply close() it when you're done (ie, do not call release()). 
public	TokenNamepublic	
synchronized	TokenNamesynchronized	
SegmentReader	TokenNameIdentifier	 Segment Reader
getReadOnlyClone	TokenNameIdentifier	 get Read Only Clone
(	TokenNameLPAREN	
SegmentInfo	TokenNameIdentifier	 Segment Info
info	TokenNameIdentifier	 info
,	TokenNameCOMMA	
boolean	TokenNameboolean	
doOpenStores	TokenNameIdentifier	 do Open Stores
,	TokenNameCOMMA	
int	TokenNameint	
termInfosIndexDivisor	TokenNameIdentifier	 term Infos Index Divisor
)	TokenNameRPAREN	
throws	TokenNamethrows	
IOException	TokenNameIdentifier	 IO Exception
{	TokenNameLBRACE	
SegmentReader	TokenNameIdentifier	 Segment Reader
sr	TokenNameIdentifier	 sr
=	TokenNameEQUAL	
get	TokenNameIdentifier	 get
(	TokenNameLPAREN	
info	TokenNameIdentifier	 info
,	TokenNameCOMMA	
doOpenStores	TokenNameIdentifier	 do Open Stores
,	TokenNameCOMMA	
BufferedIndexInput	TokenNameIdentifier	 Buffered Index Input
.	TokenNameDOT	
BUFFER_SIZE	TokenNameIdentifier	 BUFFER  SIZE
,	TokenNameCOMMA	
termInfosIndexDivisor	TokenNameIdentifier	 term Infos Index Divisor
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
try	TokenNametry	
{	TokenNameLBRACE	
return	TokenNamereturn	
(	TokenNameLPAREN	
SegmentReader	TokenNameIdentifier	 Segment Reader
)	TokenNameRPAREN	
sr	TokenNameIdentifier	 sr
.	TokenNameDOT	
clone	TokenNameIdentifier	 clone
(	TokenNameLPAREN	
true	TokenNametrue	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
finally	TokenNamefinally	
{	TokenNameLBRACE	
sr	TokenNameIdentifier	 sr
.	TokenNameDOT	
decRef	TokenNameIdentifier	 dec Ref
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
}	TokenNameRBRACE	
/** * Obtain a SegmentReader from the readerPool. The reader * must be returned by calling {@link #release(SegmentReader)} * @see #release(SegmentReader) * @param info * @param doOpenStores * @throws IOException */	TokenNameCOMMENT_JAVADOC	 Obtain a SegmentReader from the readerPool. The reader must be returned by calling {@link #release(SegmentReader)} @see #release(SegmentReader) @param info @param doOpenStores @throws IOException 
public	TokenNamepublic	
synchronized	TokenNamesynchronized	
SegmentReader	TokenNameIdentifier	 Segment Reader
get	TokenNameIdentifier	 get
(	TokenNameLPAREN	
SegmentInfo	TokenNameIdentifier	 Segment Info
info	TokenNameIdentifier	 info
,	TokenNameCOMMA	
boolean	TokenNameboolean	
doOpenStores	TokenNameIdentifier	 do Open Stores
)	TokenNameRPAREN	
throws	TokenNamethrows	
IOException	TokenNameIdentifier	 IO Exception
{	TokenNameLBRACE	
return	TokenNamereturn	
get	TokenNameIdentifier	 get
(	TokenNameLPAREN	
info	TokenNameIdentifier	 info
,	TokenNameCOMMA	
doOpenStores	TokenNameIdentifier	 do Open Stores
,	TokenNameCOMMA	
BufferedIndexInput	TokenNameIdentifier	 Buffered Index Input
.	TokenNameDOT	
BUFFER_SIZE	TokenNameIdentifier	 BUFFER  SIZE
,	TokenNameCOMMA	
config	TokenNameIdentifier	 config
.	TokenNameDOT	
getReaderTermsIndexDivisor	TokenNameIdentifier	 get Reader Terms Index Divisor
(	TokenNameLPAREN	
)	TokenNameRPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
/** * Obtain a SegmentReader from the readerPool. The reader * must be returned by calling {@link #release(SegmentReader)} * * @see #release(SegmentReader) * @param info * @param doOpenStores * @param readBufferSize * @param termsIndexDivisor * @throws IOException */	TokenNameCOMMENT_JAVADOC	 Obtain a SegmentReader from the readerPool. The reader must be returned by calling {@link #release(SegmentReader)} * @see #release(SegmentReader) @param info @param doOpenStores @param readBufferSize @param termsIndexDivisor @throws IOException 
public	TokenNamepublic	
synchronized	TokenNamesynchronized	
SegmentReader	TokenNameIdentifier	 Segment Reader
get	TokenNameIdentifier	 get
(	TokenNameLPAREN	
SegmentInfo	TokenNameIdentifier	 Segment Info
info	TokenNameIdentifier	 info
,	TokenNameCOMMA	
boolean	TokenNameboolean	
doOpenStores	TokenNameIdentifier	 do Open Stores
,	TokenNameCOMMA	
int	TokenNameint	
readBufferSize	TokenNameIdentifier	 read Buffer Size
,	TokenNameCOMMA	
int	TokenNameint	
termsIndexDivisor	TokenNameIdentifier	 terms Index Divisor
)	TokenNameRPAREN	
throws	TokenNamethrows	
IOException	TokenNameIdentifier	 IO Exception
{	TokenNameLBRACE	
if	TokenNameif	
(	TokenNameLPAREN	
poolReaders	TokenNameIdentifier	 pool Readers
)	TokenNameRPAREN	
{	TokenNameLBRACE	
readBufferSize	TokenNameIdentifier	 read Buffer Size
=	TokenNameEQUAL	
BufferedIndexInput	TokenNameIdentifier	 Buffered Index Input
.	TokenNameDOT	
BUFFER_SIZE	TokenNameIdentifier	 BUFFER  SIZE
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
SegmentReader	TokenNameIdentifier	 Segment Reader
sr	TokenNameIdentifier	 sr
=	TokenNameEQUAL	
readerMap	TokenNameIdentifier	 reader Map
.	TokenNameDOT	
get	TokenNameIdentifier	 get
(	TokenNameLPAREN	
info	TokenNameIdentifier	 info
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
if	TokenNameif	
(	TokenNameLPAREN	
sr	TokenNameIdentifier	 sr
==	TokenNameEQUAL_EQUAL	
null	TokenNamenull	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
// TODO: we may want to avoid doing this while 	TokenNameCOMMENT_LINE	TODO: we may want to avoid doing this while 
// synchronized 	TokenNameCOMMENT_LINE	synchronized 
// Returns a ref, which we xfer to readerMap: 	TokenNameCOMMENT_LINE	Returns a ref, which we xfer to readerMap: 
sr	TokenNameIdentifier	 sr
=	TokenNameEQUAL	
SegmentReader	TokenNameIdentifier	 Segment Reader
.	TokenNameDOT	
get	TokenNameIdentifier	 get
(	TokenNameLPAREN	
false	TokenNamefalse	
,	TokenNameCOMMA	
info	TokenNameIdentifier	 info
.	TokenNameDOT	
dir	TokenNameIdentifier	 dir
,	TokenNameCOMMA	
info	TokenNameIdentifier	 info
,	TokenNameCOMMA	
readBufferSize	TokenNameIdentifier	 read Buffer Size
,	TokenNameCOMMA	
doOpenStores	TokenNameIdentifier	 do Open Stores
,	TokenNameCOMMA	
termsIndexDivisor	TokenNameIdentifier	 terms Index Divisor
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
if	TokenNameif	
(	TokenNameLPAREN	
info	TokenNameIdentifier	 info
.	TokenNameDOT	
dir	TokenNameIdentifier	 dir
==	TokenNameEQUAL_EQUAL	
directory	TokenNameIdentifier	 directory
)	TokenNameRPAREN	
{	TokenNameLBRACE	
// Only pool if reader is not external 	TokenNameCOMMENT_LINE	Only pool if reader is not external 
readerMap	TokenNameIdentifier	 reader Map
.	TokenNameDOT	
put	TokenNameIdentifier	 put
(	TokenNameLPAREN	
info	TokenNameIdentifier	 info
,	TokenNameCOMMA	
sr	TokenNameIdentifier	 sr
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
}	TokenNameRBRACE	
else	TokenNameelse	
{	TokenNameLBRACE	
if	TokenNameif	
(	TokenNameLPAREN	
doOpenStores	TokenNameIdentifier	 do Open Stores
)	TokenNameRPAREN	
{	TokenNameLBRACE	
sr	TokenNameIdentifier	 sr
.	TokenNameDOT	
openDocStores	TokenNameIdentifier	 open Doc Stores
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
if	TokenNameif	
(	TokenNameLPAREN	
termsIndexDivisor	TokenNameIdentifier	 terms Index Divisor
!=	TokenNameNOT_EQUAL	
-	TokenNameMINUS	
1	TokenNameIntegerLiteral	
&&	TokenNameAND_AND	
!	TokenNameNOT	
sr	TokenNameIdentifier	 sr
.	TokenNameDOT	
termsIndexLoaded	TokenNameIdentifier	 terms Index Loaded
(	TokenNameLPAREN	
)	TokenNameRPAREN	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
// If this reader was originally opened because we 	TokenNameCOMMENT_LINE	If this reader was originally opened because we 
// needed to merge it, we didn't load the terms 	TokenNameCOMMENT_LINE	needed to merge it, we didn't load the terms 
// index. But now, if the caller wants the terms 	TokenNameCOMMENT_LINE	index. But now, if the caller wants the terms 
// index (eg because it's doing deletes, or an NRT 	TokenNameCOMMENT_LINE	index (eg because it's doing deletes, or an NRT 
// reader is being opened) we ask the reader to 	TokenNameCOMMENT_LINE	reader is being opened) we ask the reader to 
// load its terms index. 	TokenNameCOMMENT_LINE	load its terms index. 
sr	TokenNameIdentifier	 sr
.	TokenNameDOT	
loadTermsIndex	TokenNameIdentifier	 load Terms Index
(	TokenNameLPAREN	
termsIndexDivisor	TokenNameIdentifier	 terms Index Divisor
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
}	TokenNameRBRACE	
// Return a ref to our caller 	TokenNameCOMMENT_LINE	Return a ref to our caller 
if	TokenNameif	
(	TokenNameLPAREN	
info	TokenNameIdentifier	 info
.	TokenNameDOT	
dir	TokenNameIdentifier	 dir
==	TokenNameEQUAL_EQUAL	
directory	TokenNameIdentifier	 directory
)	TokenNameRPAREN	
{	TokenNameLBRACE	
// Only incRef if we pooled (reader is not external) 	TokenNameCOMMENT_LINE	Only incRef if we pooled (reader is not external) 
sr	TokenNameIdentifier	 sr
.	TokenNameDOT	
incRef	TokenNameIdentifier	 inc Ref
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
return	TokenNamereturn	
sr	TokenNameIdentifier	 sr
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
// Returns a ref 	TokenNameCOMMENT_LINE	Returns a ref 
public	TokenNamepublic	
synchronized	TokenNamesynchronized	
SegmentReader	TokenNameIdentifier	 Segment Reader
getIfExists	TokenNameIdentifier	 get If Exists
(	TokenNameLPAREN	
SegmentInfo	TokenNameIdentifier	 Segment Info
info	TokenNameIdentifier	 info
)	TokenNameRPAREN	
throws	TokenNamethrows	
IOException	TokenNameIdentifier	 IO Exception
{	TokenNameLBRACE	
SegmentReader	TokenNameIdentifier	 Segment Reader
sr	TokenNameIdentifier	 sr
=	TokenNameEQUAL	
readerMap	TokenNameIdentifier	 reader Map
.	TokenNameDOT	
get	TokenNameIdentifier	 get
(	TokenNameLPAREN	
info	TokenNameIdentifier	 info
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
if	TokenNameif	
(	TokenNameLPAREN	
sr	TokenNameIdentifier	 sr
!=	TokenNameNOT_EQUAL	
null	TokenNamenull	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
sr	TokenNameIdentifier	 sr
.	TokenNameDOT	
incRef	TokenNameIdentifier	 inc Ref
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
return	TokenNamereturn	
sr	TokenNameIdentifier	 sr
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
}	TokenNameRBRACE	
/** * Obtain the number of deleted docs for a pooled reader. * If the reader isn't being pooled, the segmentInfo's * delCount is returned. */	TokenNameCOMMENT_JAVADOC	 Obtain the number of deleted docs for a pooled reader. If the reader isn't being pooled, the segmentInfo's delCount is returned. 
public	TokenNamepublic	
int	TokenNameint	
numDeletedDocs	TokenNameIdentifier	 num Deleted Docs
(	TokenNameLPAREN	
SegmentInfo	TokenNameIdentifier	 Segment Info
info	TokenNameIdentifier	 info
)	TokenNameRPAREN	
throws	TokenNamethrows	
IOException	TokenNameIdentifier	 IO Exception
{	TokenNameLBRACE	
ensureOpen	TokenNameIdentifier	 ensure Open
(	TokenNameLPAREN	
false	TokenNamefalse	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
SegmentReader	TokenNameIdentifier	 Segment Reader
reader	TokenNameIdentifier	 reader
=	TokenNameEQUAL	
readerPool	TokenNameIdentifier	 reader Pool
.	TokenNameDOT	
getIfExists	TokenNameIdentifier	 get If Exists
(	TokenNameLPAREN	
info	TokenNameIdentifier	 info
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
try	TokenNametry	
{	TokenNameLBRACE	
if	TokenNameif	
(	TokenNameLPAREN	
reader	TokenNameIdentifier	 reader
!=	TokenNameNOT_EQUAL	
null	TokenNamenull	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
return	TokenNamereturn	
reader	TokenNameIdentifier	 reader
.	TokenNameDOT	
numDeletedDocs	TokenNameIdentifier	 num Deleted Docs
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
else	TokenNameelse	
{	TokenNameLBRACE	
return	TokenNamereturn	
info	TokenNameIdentifier	 info
.	TokenNameDOT	
getDelCount	TokenNameIdentifier	 get Del Count
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
}	TokenNameRBRACE	
finally	TokenNamefinally	
{	TokenNameLBRACE	
if	TokenNameif	
(	TokenNameLPAREN	
reader	TokenNameIdentifier	 reader
!=	TokenNameNOT_EQUAL	
null	TokenNamenull	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
readerPool	TokenNameIdentifier	 reader Pool
.	TokenNameDOT	
release	TokenNameIdentifier	 release
(	TokenNameLPAREN	
reader	TokenNameIdentifier	 reader
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
}	TokenNameRBRACE	
}	TokenNameRBRACE	
/** * Used internally to throw an {@link * AlreadyClosedException} if this IndexWriter has been * closed. * @throws AlreadyClosedException if this IndexWriter is closed */	TokenNameCOMMENT_JAVADOC	 Used internally to throw an {@link AlreadyClosedException} if this IndexWriter has been closed. @throws AlreadyClosedException if this IndexWriter is closed 
protected	TokenNameprotected	
final	TokenNamefinal	
void	TokenNamevoid	
ensureOpen	TokenNameIdentifier	 ensure Open
(	TokenNameLPAREN	
boolean	TokenNameboolean	
includePendingClose	TokenNameIdentifier	 include Pending Close
)	TokenNameRPAREN	
throws	TokenNamethrows	
AlreadyClosedException	TokenNameIdentifier	 Already Closed Exception
{	TokenNameLBRACE	
if	TokenNameif	
(	TokenNameLPAREN	
closed	TokenNameIdentifier	 closed
||	TokenNameOR_OR	
(	TokenNameLPAREN	
includePendingClose	TokenNameIdentifier	 include Pending Close
&&	TokenNameAND_AND	
closing	TokenNameIdentifier	 closing
)	TokenNameRPAREN	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
throw	TokenNamethrow	
new	TokenNamenew	
AlreadyClosedException	TokenNameIdentifier	 Already Closed Exception
(	TokenNameLPAREN	
"this IndexWriter is closed"	TokenNameStringLiteral	this IndexWriter is closed
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
}	TokenNameRBRACE	
protected	TokenNameprotected	
final	TokenNamefinal	
void	TokenNamevoid	
ensureOpen	TokenNameIdentifier	 ensure Open
(	TokenNameLPAREN	
)	TokenNameRPAREN	
throws	TokenNamethrows	
AlreadyClosedException	TokenNameIdentifier	 Already Closed Exception
{	TokenNameLBRACE	
ensureOpen	TokenNameIdentifier	 ensure Open
(	TokenNameLPAREN	
true	TokenNametrue	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
/** * Prints a message to the infoStream (if non-null), * prefixed with the identifying information for this * writer and the thread that's calling it. */	TokenNameCOMMENT_JAVADOC	 Prints a message to the infoStream (if non-null), prefixed with the identifying information for this writer and the thread that's calling it. 
public	TokenNamepublic	
void	TokenNamevoid	
message	TokenNameIdentifier	 message
(	TokenNameLPAREN	
String	TokenNameIdentifier	 String
message	TokenNameIdentifier	 message
)	TokenNameRPAREN	
{	TokenNameLBRACE	
if	TokenNameif	
(	TokenNameLPAREN	
infoStream	TokenNameIdentifier	 info Stream
!=	TokenNameNOT_EQUAL	
null	TokenNamenull	
)	TokenNameRPAREN	
infoStream	TokenNameIdentifier	 info Stream
.	TokenNameDOT	
println	TokenNameIdentifier	 println
(	TokenNameLPAREN	
"IW "	TokenNameStringLiteral	IW 
+	TokenNamePLUS	
messageID	TokenNameIdentifier	 message ID
+	TokenNamePLUS	
" ["	TokenNameStringLiteral	 [
+	TokenNamePLUS	
new	TokenNamenew	
Date	TokenNameIdentifier	 Date
(	TokenNameLPAREN	
)	TokenNameRPAREN	
+	TokenNamePLUS	
"; "	TokenNameStringLiteral	; 
+	TokenNamePLUS	
Thread	TokenNameIdentifier	 Thread
.	TokenNameDOT	
currentThread	TokenNameIdentifier	 current Thread
(	TokenNameLPAREN	
)	TokenNameRPAREN	
.	TokenNameDOT	
getName	TokenNameIdentifier	 get Name
(	TokenNameLPAREN	
)	TokenNameRPAREN	
+	TokenNamePLUS	
"]: "	TokenNameStringLiteral	]: 
+	TokenNamePLUS	
message	TokenNameIdentifier	 message
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
/** * Casts current mergePolicy to LogMergePolicy, and throws * an exception if the mergePolicy is not a LogMergePolicy. */	TokenNameCOMMENT_JAVADOC	 Casts current mergePolicy to LogMergePolicy, and throws an exception if the mergePolicy is not a LogMergePolicy. 
private	TokenNameprivate	
LogMergePolicy	TokenNameIdentifier	 Log Merge Policy
getLogMergePolicy	TokenNameIdentifier	 get Log Merge Policy
(	TokenNameLPAREN	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
if	TokenNameif	
(	TokenNameLPAREN	
mergePolicy	TokenNameIdentifier	 merge Policy
instanceof	TokenNameinstanceof	
LogMergePolicy	TokenNameIdentifier	 Log Merge Policy
)	TokenNameRPAREN	
return	TokenNamereturn	
(	TokenNameLPAREN	
LogMergePolicy	TokenNameIdentifier	 Log Merge Policy
)	TokenNameRPAREN	
mergePolicy	TokenNameIdentifier	 merge Policy
;	TokenNameSEMICOLON	
else	TokenNameelse	
throw	TokenNamethrow	
new	TokenNamenew	
IllegalArgumentException	TokenNameIdentifier	 Illegal Argument Exception
(	TokenNameLPAREN	
"this method can only be called when the merge policy is the default LogMergePolicy"	TokenNameStringLiteral	this method can only be called when the merge policy is the default LogMergePolicy
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
/** <p>Get the current setting of whether newly flushed * segments will use the compound file format. Note that * this just returns the value previously set with * setUseCompoundFile(boolean), or the default value * (true). You cannot use this to query the status of * previously flushed segments.</p> * * <p>Note that this method is a convenience method: it * just calls mergePolicy.getUseCompoundFile as long as * mergePolicy is an instance of {@link LogMergePolicy}. * Otherwise an IllegalArgumentException is thrown.</p> * * @see #setUseCompoundFile(boolean) * @deprecated use {@link LogMergePolicy#getUseCompoundFile()} */	TokenNameCOMMENT_JAVADOC	 <p>Get the current setting of whether newly flushed segments will use the compound file format. Note that this just returns the value previously set with setUseCompoundFile(boolean), or the default value (true). You cannot use this to query the status of previously flushed segments.</p> * <p>Note that this method is a convenience method: it just calls mergePolicy.getUseCompoundFile as long as mergePolicy is an instance of {@link LogMergePolicy}. Otherwise an IllegalArgumentException is thrown.</p> * @see #setUseCompoundFile(boolean) @deprecated use {@link LogMergePolicy#getUseCompoundFile()} 
@	TokenNameAT	
Deprecated	TokenNameIdentifier	 Deprecated
public	TokenNamepublic	
boolean	TokenNameboolean	
getUseCompoundFile	TokenNameIdentifier	 get Use Compound File
(	TokenNameLPAREN	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
return	TokenNamereturn	
getLogMergePolicy	TokenNameIdentifier	 get Log Merge Policy
(	TokenNameLPAREN	
)	TokenNameRPAREN	
.	TokenNameDOT	
getUseCompoundFile	TokenNameIdentifier	 get Use Compound File
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
/** * <p> * Setting to turn on usage of a compound file. When on, multiple files for * each segment are merged into a single file when a new segment is flushed. * </p> * * <p> * Note that this method is a convenience method: it just calls * mergePolicy.setUseCompoundFile as long as mergePolicy is an instance of * {@link LogMergePolicy}. Otherwise an IllegalArgumentException is thrown. * </p> * * @deprecated use {@link LogMergePolicy#setUseCompoundFile(boolean)}. */	TokenNameCOMMENT_JAVADOC	 <p> Setting to turn on usage of a compound file. When on, multiple files for each segment are merged into a single file when a new segment is flushed. </p> * <p> Note that this method is a convenience method: it just calls mergePolicy.setUseCompoundFile as long as mergePolicy is an instance of {@link LogMergePolicy}. Otherwise an IllegalArgumentException is thrown. </p> * @deprecated use {@link LogMergePolicy#setUseCompoundFile(boolean)}. 
@	TokenNameAT	
Deprecated	TokenNameIdentifier	 Deprecated
public	TokenNamepublic	
void	TokenNamevoid	
setUseCompoundFile	TokenNameIdentifier	 set Use Compound File
(	TokenNameLPAREN	
boolean	TokenNameboolean	
value	TokenNameIdentifier	 value
)	TokenNameRPAREN	
{	TokenNameLBRACE	
getLogMergePolicy	TokenNameIdentifier	 get Log Merge Policy
(	TokenNameLPAREN	
)	TokenNameRPAREN	
.	TokenNameDOT	
setUseCompoundFile	TokenNameIdentifier	 set Use Compound File
(	TokenNameLPAREN	
value	TokenNameIdentifier	 value
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
/** Expert: Set the Similarity implementation used by this IndexWriter. * * @see Similarity#setDefault(Similarity) * @deprecated use {@link IndexWriterConfig#setSimilarity(Similarity)} instead */	TokenNameCOMMENT_JAVADOC	 Expert: Set the Similarity implementation used by this IndexWriter. * @see Similarity#setDefault(Similarity) @deprecated use {@link IndexWriterConfig#setSimilarity(Similarity)} instead 
@	TokenNameAT	
Deprecated	TokenNameIdentifier	 Deprecated
public	TokenNamepublic	
void	TokenNamevoid	
setSimilarity	TokenNameIdentifier	 set Similarity
(	TokenNameLPAREN	
Similarity	TokenNameIdentifier	 Similarity
similarity	TokenNameIdentifier	 similarity
)	TokenNameRPAREN	
{	TokenNameLBRACE	
ensureOpen	TokenNameIdentifier	 ensure Open
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
this	TokenNamethis	
.	TokenNameDOT	
similarity	TokenNameIdentifier	 similarity
=	TokenNameEQUAL	
similarity	TokenNameIdentifier	 similarity
;	TokenNameSEMICOLON	
docWriter	TokenNameIdentifier	 doc Writer
.	TokenNameDOT	
setSimilarity	TokenNameIdentifier	 set Similarity
(	TokenNameLPAREN	
similarity	TokenNameIdentifier	 similarity
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
// Required so config.getSimilarity returns the right value. But this will 	TokenNameCOMMENT_LINE	Required so config.getSimilarity returns the right value. But this will 
// go away together with the method in 4.0. 	TokenNameCOMMENT_LINE	go away together with the method in 4.0. 
config	TokenNameIdentifier	 config
.	TokenNameDOT	
setSimilarity	TokenNameIdentifier	 set Similarity
(	TokenNameLPAREN	
similarity	TokenNameIdentifier	 similarity
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
/** Expert: Return the Similarity implementation used by this IndexWriter. * * <p>This defaults to the current value of {@link Similarity#getDefault()}. * @deprecated use {@link IndexWriterConfig#getSimilarity()} instead */	TokenNameCOMMENT_JAVADOC	 Expert: Return the Similarity implementation used by this IndexWriter. * <p>This defaults to the current value of {@link Similarity#getDefault()}. @deprecated use {@link IndexWriterConfig#getSimilarity()} instead 
@	TokenNameAT	
Deprecated	TokenNameIdentifier	 Deprecated
public	TokenNamepublic	
Similarity	TokenNameIdentifier	 Similarity
getSimilarity	TokenNameIdentifier	 get Similarity
(	TokenNameLPAREN	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
ensureOpen	TokenNameIdentifier	 ensure Open
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
return	TokenNamereturn	
similarity	TokenNameIdentifier	 similarity
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
/** Expert: Set the interval between indexed terms. Large values cause less * memory to be used by IndexReader, but slow random-access to terms. Small * values cause more memory to be used by an IndexReader, and speed * random-access to terms. * * This parameter determines the amount of computation required per query * term, regardless of the number of documents that contain that term. In * particular, it is the maximum number of other terms that must be * scanned before a term is located and its frequency and position information * may be processed. In a large index with user-entered query terms, query * processing time is likely to be dominated not by term lookup but rather * by the processing of frequency and positional data. In a small index * or when many uncommon query terms are generated (e.g., by wildcard * queries) term lookup may become a dominant cost. * * In particular, <code>numUniqueTerms/interval</code> terms are read into * memory by an IndexReader, and, on average, <code>interval/2</code> terms * must be scanned for each random term access. * * @see #DEFAULT_TERM_INDEX_INTERVAL * @deprecated use {@link IndexWriterConfig#setTermIndexInterval(int)} */	TokenNameCOMMENT_JAVADOC	 Expert: Set the interval between indexed terms. Large values cause less memory to be used by IndexReader, but slow random-access to terms. Small values cause more memory to be used by an IndexReader, and speed random-access to terms. * This parameter determines the amount of computation required per query term, regardless of the number of documents that contain that term. In particular, it is the maximum number of other terms that must be scanned before a term is located and its frequency and position information may be processed. In a large index with user-entered query terms, query processing time is likely to be dominated not by term lookup but rather by the processing of frequency and positional data. In a small index or when many uncommon query terms are generated (e.g., by wildcard queries) term lookup may become a dominant cost. * In particular, <code>numUniqueTerms/interval</code> terms are read into memory by an IndexReader, and, on average, <code>interval/2</code> terms must be scanned for each random term access. * @see #DEFAULT_TERM_INDEX_INTERVAL @deprecated use {@link IndexWriterConfig#setTermIndexInterval(int)} 
@	TokenNameAT	
Deprecated	TokenNameIdentifier	 Deprecated
public	TokenNamepublic	
void	TokenNamevoid	
setTermIndexInterval	TokenNameIdentifier	 set Term Index Interval
(	TokenNameLPAREN	
int	TokenNameint	
interval	TokenNameIdentifier	 interval
)	TokenNameRPAREN	
{	TokenNameLBRACE	
ensureOpen	TokenNameIdentifier	 ensure Open
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
config	TokenNameIdentifier	 config
.	TokenNameDOT	
setTermIndexInterval	TokenNameIdentifier	 set Term Index Interval
(	TokenNameLPAREN	
interval	TokenNameIdentifier	 interval
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
/** Expert: Return the interval between indexed terms. * * @see #setTermIndexInterval(int) * @deprecated use {@link IndexWriterConfig#getTermIndexInterval()} */	TokenNameCOMMENT_JAVADOC	 Expert: Return the interval between indexed terms. * @see #setTermIndexInterval(int) @deprecated use {@link IndexWriterConfig#getTermIndexInterval()} 
@	TokenNameAT	
Deprecated	TokenNameIdentifier	 Deprecated
public	TokenNamepublic	
int	TokenNameint	
getTermIndexInterval	TokenNameIdentifier	 get Term Index Interval
(	TokenNameLPAREN	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
// We pass false because this method is called by SegmentMerger while we are in the process of closing 	TokenNameCOMMENT_LINE	We pass false because this method is called by SegmentMerger while we are in the process of closing 
ensureOpen	TokenNameIdentifier	 ensure Open
(	TokenNameLPAREN	
false	TokenNamefalse	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
return	TokenNamereturn	
config	TokenNameIdentifier	 config
.	TokenNameDOT	
getTermIndexInterval	TokenNameIdentifier	 get Term Index Interval
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
/** * Constructs an IndexWriter for the index in <code>d</code>. * Text will be analyzed with <code>a</code>. If <code>create</code> * is true, then a new, empty index will be created in * <code>d</code>, replacing the index already there, if any. * * @param d the index directory * @param a the analyzer to use * @param create <code>true</code> to create the index or overwrite * the existing one; <code>false</code> to append to the existing * index * @param mfl Maximum field length in number of terms/tokens: LIMITED, UNLIMITED, or user-specified * via the MaxFieldLength constructor. * @throws CorruptIndexException if the index is corrupt * @throws LockObtainFailedException if another writer * has this index open (<code>write.lock</code> could not * be obtained) * @throws IOException if the directory cannot be read/written to, or * if it does not exist and <code>create</code> is * <code>false</code> or if there is any other low-level * IO error * @deprecated use {@link #IndexWriter(Directory, IndexWriterConfig)} instead */	TokenNameCOMMENT_JAVADOC	 Constructs an IndexWriter for the index in <code>d</code>. Text will be analyzed with <code>a</code>. If <code>create</code> is true, then a new, empty index will be created in <code>d</code>, replacing the index already there, if any. * @param d the index directory @param a the analyzer to use @param create <code>true</code> to create the index or overwrite the existing one; <code>false</code> to append to the existing index @param mfl Maximum field length in number of terms/tokens: LIMITED, UNLIMITED, or user-specified via the MaxFieldLength constructor. @throws CorruptIndexException if the index is corrupt @throws LockObtainFailedException if another writer has this index open (<code>write.lock</code> could not be obtained) @throws IOException if the directory cannot be read/written to, or if it does not exist and <code>create</code> is <code>false</code> or if there is any other low-level IO error @deprecated use {@link #IndexWriter(Directory, IndexWriterConfig)} instead 
@	TokenNameAT	
Deprecated	TokenNameIdentifier	 Deprecated
public	TokenNamepublic	
IndexWriter	TokenNameIdentifier	 Index Writer
(	TokenNameLPAREN	
Directory	TokenNameIdentifier	 Directory
d	TokenNameIdentifier	 d
,	TokenNameCOMMA	
Analyzer	TokenNameIdentifier	 Analyzer
a	TokenNameIdentifier	 a
,	TokenNameCOMMA	
boolean	TokenNameboolean	
create	TokenNameIdentifier	 create
,	TokenNameCOMMA	
MaxFieldLength	TokenNameIdentifier	 Max Field Length
mfl	TokenNameIdentifier	 mfl
)	TokenNameRPAREN	
throws	TokenNamethrows	
CorruptIndexException	TokenNameIdentifier	 Corrupt Index Exception
,	TokenNameCOMMA	
LockObtainFailedException	TokenNameIdentifier	 Lock Obtain Failed Exception
,	TokenNameCOMMA	
IOException	TokenNameIdentifier	 IO Exception
{	TokenNameLBRACE	
this	TokenNamethis	
(	TokenNameLPAREN	
d	TokenNameIdentifier	 d
,	TokenNameCOMMA	
new	TokenNamenew	
IndexWriterConfig	TokenNameIdentifier	 Index Writer Config
(	TokenNameLPAREN	
Version	TokenNameIdentifier	 Version
.	TokenNameDOT	
LUCENE_31	TokenNameIdentifier	 LUCENE 31
,	TokenNameCOMMA	
a	TokenNameIdentifier	 a
)	TokenNameRPAREN	
.	TokenNameDOT	
setOpenMode	TokenNameIdentifier	 set Open Mode
(	TokenNameLPAREN	
create	TokenNameIdentifier	 create
?	TokenNameQUESTION	
OpenMode	TokenNameIdentifier	 Open Mode
.	TokenNameDOT	
CREATE	TokenNameIdentifier	 CREATE
:	TokenNameCOLON	
OpenMode	TokenNameIdentifier	 Open Mode
.	TokenNameDOT	
APPEND	TokenNameIdentifier	 APPEND
)	TokenNameRPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
setMaxFieldLength	TokenNameIdentifier	 set Max Field Length
(	TokenNameLPAREN	
mfl	TokenNameIdentifier	 mfl
.	TokenNameDOT	
getLimit	TokenNameIdentifier	 get Limit
(	TokenNameLPAREN	
)	TokenNameRPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
/** * Constructs an IndexWriter for the index in * <code>d</code>, first creating it if it does not * already exist. Text will be analyzed with * <code>a</code>. * * @param d the index directory * @param a the analyzer to use * @param mfl Maximum field length in number of terms/tokens: LIMITED, UNLIMITED, or user-specified * via the MaxFieldLength constructor. * @throws CorruptIndexException if the index is corrupt * @throws LockObtainFailedException if another writer * has this index open (<code>write.lock</code> could not * be obtained) * @throws IOException if the directory cannot be * read/written to or if there is any other low-level * IO error * @deprecated use {@link #IndexWriter(Directory, IndexWriterConfig)} instead */	TokenNameCOMMENT_JAVADOC	 Constructs an IndexWriter for the index in <code>d</code>, first creating it if it does not already exist. Text will be analyzed with <code>a</code>. * @param d the index directory @param a the analyzer to use @param mfl Maximum field length in number of terms/tokens: LIMITED, UNLIMITED, or user-specified via the MaxFieldLength constructor. @throws CorruptIndexException if the index is corrupt @throws LockObtainFailedException if another writer has this index open (<code>write.lock</code> could not be obtained) @throws IOException if the directory cannot be read/written to or if there is any other low-level IO error @deprecated use {@link #IndexWriter(Directory, IndexWriterConfig)} instead 
@	TokenNameAT	
Deprecated	TokenNameIdentifier	 Deprecated
public	TokenNamepublic	
IndexWriter	TokenNameIdentifier	 Index Writer
(	TokenNameLPAREN	
Directory	TokenNameIdentifier	 Directory
d	TokenNameIdentifier	 d
,	TokenNameCOMMA	
Analyzer	TokenNameIdentifier	 Analyzer
a	TokenNameIdentifier	 a
,	TokenNameCOMMA	
MaxFieldLength	TokenNameIdentifier	 Max Field Length
mfl	TokenNameIdentifier	 mfl
)	TokenNameRPAREN	
throws	TokenNamethrows	
CorruptIndexException	TokenNameIdentifier	 Corrupt Index Exception
,	TokenNameCOMMA	
LockObtainFailedException	TokenNameIdentifier	 Lock Obtain Failed Exception
,	TokenNameCOMMA	
IOException	TokenNameIdentifier	 IO Exception
{	TokenNameLBRACE	
this	TokenNamethis	
(	TokenNameLPAREN	
d	TokenNameIdentifier	 d
,	TokenNameCOMMA	
new	TokenNamenew	
IndexWriterConfig	TokenNameIdentifier	 Index Writer Config
(	TokenNameLPAREN	
Version	TokenNameIdentifier	 Version
.	TokenNameDOT	
LUCENE_31	TokenNameIdentifier	 LUCENE 31
,	TokenNameCOMMA	
a	TokenNameIdentifier	 a
)	TokenNameRPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
setMaxFieldLength	TokenNameIdentifier	 set Max Field Length
(	TokenNameLPAREN	
mfl	TokenNameIdentifier	 mfl
.	TokenNameDOT	
getLimit	TokenNameIdentifier	 get Limit
(	TokenNameLPAREN	
)	TokenNameRPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
/** * Expert: constructs an IndexWriter with a custom {@link * IndexDeletionPolicy}, for the index in <code>d</code>, * first creating it if it does not already exist. Text * will be analyzed with <code>a</code>. * * @param d the index directory * @param a the analyzer to use * @param deletionPolicy see <a href="#deletionPolicy">above</a> * @param mfl whether or not to limit field lengths * @throws CorruptIndexException if the index is corrupt * @throws LockObtainFailedException if another writer * has this index open (<code>write.lock</code> could not * be obtained) * @throws IOException if the directory cannot be * read/written to or if there is any other low-level * IO error * @deprecated use {@link #IndexWriter(Directory, IndexWriterConfig)} instead */	TokenNameCOMMENT_JAVADOC	 Expert: constructs an IndexWriter with a custom {@link IndexDeletionPolicy}, for the index in <code>d</code>, first creating it if it does not already exist. Text will be analyzed with <code>a</code>. * @param d the index directory @param a the analyzer to use @param deletionPolicy see <a href="#deletionPolicy">above</a> @param mfl whether or not to limit field lengths @throws CorruptIndexException if the index is corrupt @throws LockObtainFailedException if another writer has this index open (<code>write.lock</code> could not be obtained) @throws IOException if the directory cannot be read/written to or if there is any other low-level IO error @deprecated use {@link #IndexWriter(Directory, IndexWriterConfig)} instead 
@	TokenNameAT	
Deprecated	TokenNameIdentifier	 Deprecated
public	TokenNamepublic	
IndexWriter	TokenNameIdentifier	 Index Writer
(	TokenNameLPAREN	
Directory	TokenNameIdentifier	 Directory
d	TokenNameIdentifier	 d
,	TokenNameCOMMA	
Analyzer	TokenNameIdentifier	 Analyzer
a	TokenNameIdentifier	 a
,	TokenNameCOMMA	
IndexDeletionPolicy	TokenNameIdentifier	 Index Deletion Policy
deletionPolicy	TokenNameIdentifier	 deletion Policy
,	TokenNameCOMMA	
MaxFieldLength	TokenNameIdentifier	 Max Field Length
mfl	TokenNameIdentifier	 mfl
)	TokenNameRPAREN	
throws	TokenNamethrows	
CorruptIndexException	TokenNameIdentifier	 Corrupt Index Exception
,	TokenNameCOMMA	
LockObtainFailedException	TokenNameIdentifier	 Lock Obtain Failed Exception
,	TokenNameCOMMA	
IOException	TokenNameIdentifier	 IO Exception
{	TokenNameLBRACE	
this	TokenNamethis	
(	TokenNameLPAREN	
d	TokenNameIdentifier	 d
,	TokenNameCOMMA	
new	TokenNamenew	
IndexWriterConfig	TokenNameIdentifier	 Index Writer Config
(	TokenNameLPAREN	
Version	TokenNameIdentifier	 Version
.	TokenNameDOT	
LUCENE_31	TokenNameIdentifier	 LUCENE 31
,	TokenNameCOMMA	
a	TokenNameIdentifier	 a
)	TokenNameRPAREN	
.	TokenNameDOT	
setIndexDeletionPolicy	TokenNameIdentifier	 set Index Deletion Policy
(	TokenNameLPAREN	
deletionPolicy	TokenNameIdentifier	 deletion Policy
)	TokenNameRPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
setMaxFieldLength	TokenNameIdentifier	 set Max Field Length
(	TokenNameLPAREN	
mfl	TokenNameIdentifier	 mfl
.	TokenNameDOT	
getLimit	TokenNameIdentifier	 get Limit
(	TokenNameLPAREN	
)	TokenNameRPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
/** * Expert: constructs an IndexWriter with a custom {@link * IndexDeletionPolicy}, for the index in <code>d</code>. * Text will be analyzed with <code>a</code>. If * <code>create</code> is true, then a new, empty index * will be created in <code>d</code>, replacing the index * already there, if any. * * @param d the index directory * @param a the analyzer to use * @param create <code>true</code> to create the index or overwrite * the existing one; <code>false</code> to append to the existing * index * @param deletionPolicy see <a href="#deletionPolicy">above</a> * @param mfl {@link org.apache.lucene.index.IndexWriter.MaxFieldLength}, whether or not to limit field lengths. Value is in number of terms/tokens * @throws CorruptIndexException if the index is corrupt * @throws LockObtainFailedException if another writer * has this index open (<code>write.lock</code> could not * be obtained) * @throws IOException if the directory cannot be read/written to, or * if it does not exist and <code>create</code> is * <code>false</code> or if there is any other low-level * IO error * @deprecated use {@link #IndexWriter(Directory, IndexWriterConfig)} instead */	TokenNameCOMMENT_JAVADOC	 Expert: constructs an IndexWriter with a custom {@link IndexDeletionPolicy}, for the index in <code>d</code>. Text will be analyzed with <code>a</code>. If <code>create</code> is true, then a new, empty index will be created in <code>d</code>, replacing the index already there, if any. * @param d the index directory @param a the analyzer to use @param create <code>true</code> to create the index or overwrite the existing one; <code>false</code> to append to the existing index @param deletionPolicy see <a href="#deletionPolicy">above</a> @param mfl {@link org.apache.lucene.index.IndexWriter.MaxFieldLength}, whether or not to limit field lengths. Value is in number of terms/tokens @throws CorruptIndexException if the index is corrupt @throws LockObtainFailedException if another writer has this index open (<code>write.lock</code> could not be obtained) @throws IOException if the directory cannot be read/written to, or if it does not exist and <code>create</code> is <code>false</code> or if there is any other low-level IO error @deprecated use {@link #IndexWriter(Directory, IndexWriterConfig)} instead 
@	TokenNameAT	
Deprecated	TokenNameIdentifier	 Deprecated
public	TokenNamepublic	
IndexWriter	TokenNameIdentifier	 Index Writer
(	TokenNameLPAREN	
Directory	TokenNameIdentifier	 Directory
d	TokenNameIdentifier	 d
,	TokenNameCOMMA	
Analyzer	TokenNameIdentifier	 Analyzer
a	TokenNameIdentifier	 a
,	TokenNameCOMMA	
boolean	TokenNameboolean	
create	TokenNameIdentifier	 create
,	TokenNameCOMMA	
IndexDeletionPolicy	TokenNameIdentifier	 Index Deletion Policy
deletionPolicy	TokenNameIdentifier	 deletion Policy
,	TokenNameCOMMA	
MaxFieldLength	TokenNameIdentifier	 Max Field Length
mfl	TokenNameIdentifier	 mfl
)	TokenNameRPAREN	
throws	TokenNamethrows	
CorruptIndexException	TokenNameIdentifier	 Corrupt Index Exception
,	TokenNameCOMMA	
LockObtainFailedException	TokenNameIdentifier	 Lock Obtain Failed Exception
,	TokenNameCOMMA	
IOException	TokenNameIdentifier	 IO Exception
{	TokenNameLBRACE	
this	TokenNamethis	
(	TokenNameLPAREN	
d	TokenNameIdentifier	 d
,	TokenNameCOMMA	
new	TokenNamenew	
IndexWriterConfig	TokenNameIdentifier	 Index Writer Config
(	TokenNameLPAREN	
Version	TokenNameIdentifier	 Version
.	TokenNameDOT	
LUCENE_31	TokenNameIdentifier	 LUCENE 31
,	TokenNameCOMMA	
a	TokenNameIdentifier	 a
)	TokenNameRPAREN	
.	TokenNameDOT	
setOpenMode	TokenNameIdentifier	 set Open Mode
(	TokenNameLPAREN	
create	TokenNameIdentifier	 create
?	TokenNameQUESTION	
OpenMode	TokenNameIdentifier	 Open Mode
.	TokenNameDOT	
CREATE	TokenNameIdentifier	 CREATE
:	TokenNameCOLON	
OpenMode	TokenNameIdentifier	 Open Mode
.	TokenNameDOT	
APPEND	TokenNameIdentifier	 APPEND
)	TokenNameRPAREN	
.	TokenNameDOT	
setIndexDeletionPolicy	TokenNameIdentifier	 set Index Deletion Policy
(	TokenNameLPAREN	
deletionPolicy	TokenNameIdentifier	 deletion Policy
)	TokenNameRPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
setMaxFieldLength	TokenNameIdentifier	 set Max Field Length
(	TokenNameLPAREN	
mfl	TokenNameIdentifier	 mfl
.	TokenNameDOT	
getLimit	TokenNameIdentifier	 get Limit
(	TokenNameLPAREN	
)	TokenNameRPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
/** * Expert: constructs an IndexWriter on specific commit * point, with a custom {@link IndexDeletionPolicy}, for * the index in <code>d</code>. Text will be analyzed * with <code>a</code>. * * <p> This is only meaningful if you've used a {@link * IndexDeletionPolicy} in that past that keeps more than * just the last commit. * * <p>This operation is similar to {@link #rollback()}, * except that method can only rollback what's been done * with the current instance of IndexWriter since its last * commit, whereas this method can rollback to an * arbitrary commit point from the past, assuming the * {@link IndexDeletionPolicy} has preserved past * commits. * * @param d the index directory * @param a the analyzer to use * @param deletionPolicy see <a href="#deletionPolicy">above</a> * @param mfl whether or not to limit field lengths, value is in number of terms/tokens. See {@link org.apache.lucene.index.IndexWriter.MaxFieldLength}. * @param commit which commit to open * @throws CorruptIndexException if the index is corrupt * @throws LockObtainFailedException if another writer * has this index open (<code>write.lock</code> could not * be obtained) * @throws IOException if the directory cannot be read/written to, or * if it does not exist and <code>create</code> is * <code>false</code> or if there is any other low-level * IO error * @deprecated use {@link #IndexWriter(Directory, IndexWriterConfig)} instead */	TokenNameCOMMENT_JAVADOC	 Expert: constructs an IndexWriter on specific commit point, with a custom {@link IndexDeletionPolicy}, for the index in <code>d</code>. Text will be analyzed with <code>a</code>. * <p> This is only meaningful if you've used a {@link IndexDeletionPolicy} in that past that keeps more than just the last commit. * <p>This operation is similar to {@link #rollback()}, except that method can only rollback what's been done with the current instance of IndexWriter since its last commit, whereas this method can rollback to an arbitrary commit point from the past, assuming the {@link IndexDeletionPolicy} has preserved past commits. * @param d the index directory @param a the analyzer to use @param deletionPolicy see <a href="#deletionPolicy">above</a> @param mfl whether or not to limit field lengths, value is in number of terms/tokens. See {@link org.apache.lucene.index.IndexWriter.MaxFieldLength}. @param commit which commit to open @throws CorruptIndexException if the index is corrupt @throws LockObtainFailedException if another writer has this index open (<code>write.lock</code> could not be obtained) @throws IOException if the directory cannot be read/written to, or if it does not exist and <code>create</code> is <code>false</code> or if there is any other low-level IO error @deprecated use {@link #IndexWriter(Directory, IndexWriterConfig)} instead 
@	TokenNameAT	
Deprecated	TokenNameIdentifier	 Deprecated
public	TokenNamepublic	
IndexWriter	TokenNameIdentifier	 Index Writer
(	TokenNameLPAREN	
Directory	TokenNameIdentifier	 Directory
d	TokenNameIdentifier	 d
,	TokenNameCOMMA	
Analyzer	TokenNameIdentifier	 Analyzer
a	TokenNameIdentifier	 a
,	TokenNameCOMMA	
IndexDeletionPolicy	TokenNameIdentifier	 Index Deletion Policy
deletionPolicy	TokenNameIdentifier	 deletion Policy
,	TokenNameCOMMA	
MaxFieldLength	TokenNameIdentifier	 Max Field Length
mfl	TokenNameIdentifier	 mfl
,	TokenNameCOMMA	
IndexCommit	TokenNameIdentifier	 Index Commit
commit	TokenNameIdentifier	 commit
)	TokenNameRPAREN	
throws	TokenNamethrows	
CorruptIndexException	TokenNameIdentifier	 Corrupt Index Exception
,	TokenNameCOMMA	
LockObtainFailedException	TokenNameIdentifier	 Lock Obtain Failed Exception
,	TokenNameCOMMA	
IOException	TokenNameIdentifier	 IO Exception
{	TokenNameLBRACE	
this	TokenNamethis	
(	TokenNameLPAREN	
d	TokenNameIdentifier	 d
,	TokenNameCOMMA	
new	TokenNamenew	
IndexWriterConfig	TokenNameIdentifier	 Index Writer Config
(	TokenNameLPAREN	
Version	TokenNameIdentifier	 Version
.	TokenNameDOT	
LUCENE_31	TokenNameIdentifier	 LUCENE 31
,	TokenNameCOMMA	
a	TokenNameIdentifier	 a
)	TokenNameRPAREN	
.	TokenNameDOT	
setOpenMode	TokenNameIdentifier	 set Open Mode
(	TokenNameLPAREN	
OpenMode	TokenNameIdentifier	 Open Mode
.	TokenNameDOT	
APPEND	TokenNameIdentifier	 APPEND
)	TokenNameRPAREN	
.	TokenNameDOT	
setIndexDeletionPolicy	TokenNameIdentifier	 set Index Deletion Policy
(	TokenNameLPAREN	
deletionPolicy	TokenNameIdentifier	 deletion Policy
)	TokenNameRPAREN	
.	TokenNameDOT	
setIndexCommit	TokenNameIdentifier	 set Index Commit
(	TokenNameLPAREN	
commit	TokenNameIdentifier	 commit
)	TokenNameRPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
setMaxFieldLength	TokenNameIdentifier	 set Max Field Length
(	TokenNameLPAREN	
mfl	TokenNameIdentifier	 mfl
.	TokenNameDOT	
getLimit	TokenNameIdentifier	 get Limit
(	TokenNameLPAREN	
)	TokenNameRPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
/** * Constructs a new IndexWriter per the settings given in <code>conf</code>. * Note that the passed in {@link IndexWriterConfig} is * privately cloned; if you need to make subsequent "live" * changes to the configuration use {@link #getConfig}. * <p> * * @param d * the index directory. The index is either created or appended * according <code>conf.getOpenMode()</code>. * @param conf * the configuration settings according to which IndexWriter should * be initialized. * @throws CorruptIndexException * if the index is corrupt * @throws LockObtainFailedException * if another writer has this index open (<code>write.lock</code> * could not be obtained) * @throws IOException * if the directory cannot be read/written to, or if it does not * exist and <code>conf.getOpenMode()</code> is * <code>OpenMode.APPEND</code> or if there is any other low-level * IO error */	TokenNameCOMMENT_JAVADOC	 Constructs a new IndexWriter per the settings given in <code>conf</code>. Note that the passed in {@link IndexWriterConfig} is privately cloned; if you need to make subsequent "live" changes to the configuration use {@link #getConfig}. <p> * @param d the index directory. The index is either created or appended according <code>conf.getOpenMode()</code>. @param conf the configuration settings according to which IndexWriter should be initialized. @throws CorruptIndexException if the index is corrupt @throws LockObtainFailedException if another writer has this index open (<code>write.lock</code> could not be obtained) @throws IOException if the directory cannot be read/written to, or if it does not exist and <code>conf.getOpenMode()</code> is <code>OpenMode.APPEND</code> or if there is any other low-level IO error 
public	TokenNamepublic	
IndexWriter	TokenNameIdentifier	 Index Writer
(	TokenNameLPAREN	
Directory	TokenNameIdentifier	 Directory
d	TokenNameIdentifier	 d
,	TokenNameCOMMA	
IndexWriterConfig	TokenNameIdentifier	 Index Writer Config
conf	TokenNameIdentifier	 conf
)	TokenNameRPAREN	
throws	TokenNamethrows	
CorruptIndexException	TokenNameIdentifier	 Corrupt Index Exception
,	TokenNameCOMMA	
LockObtainFailedException	TokenNameIdentifier	 Lock Obtain Failed Exception
,	TokenNameCOMMA	
IOException	TokenNameIdentifier	 IO Exception
{	TokenNameLBRACE	
config	TokenNameIdentifier	 config
=	TokenNameEQUAL	
(	TokenNameLPAREN	
IndexWriterConfig	TokenNameIdentifier	 Index Writer Config
)	TokenNameRPAREN	
conf	TokenNameIdentifier	 conf
.	TokenNameDOT	
clone	TokenNameIdentifier	 clone
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
directory	TokenNameIdentifier	 directory
=	TokenNameEQUAL	
d	TokenNameIdentifier	 d
;	TokenNameSEMICOLON	
analyzer	TokenNameIdentifier	 analyzer
=	TokenNameEQUAL	
conf	TokenNameIdentifier	 conf
.	TokenNameDOT	
getAnalyzer	TokenNameIdentifier	 get Analyzer
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
infoStream	TokenNameIdentifier	 info Stream
=	TokenNameEQUAL	
defaultInfoStream	TokenNameIdentifier	 default Info Stream
;	TokenNameSEMICOLON	
writeLockTimeout	TokenNameIdentifier	 write Lock Timeout
=	TokenNameEQUAL	
conf	TokenNameIdentifier	 conf
.	TokenNameDOT	
getWriteLockTimeout	TokenNameIdentifier	 get Write Lock Timeout
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
similarity	TokenNameIdentifier	 similarity
=	TokenNameEQUAL	
conf	TokenNameIdentifier	 conf
.	TokenNameDOT	
getSimilarity	TokenNameIdentifier	 get Similarity
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
mergePolicy	TokenNameIdentifier	 merge Policy
=	TokenNameEQUAL	
conf	TokenNameIdentifier	 conf
.	TokenNameDOT	
getMergePolicy	TokenNameIdentifier	 get Merge Policy
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
mergePolicy	TokenNameIdentifier	 merge Policy
.	TokenNameDOT	
setIndexWriter	TokenNameIdentifier	 set Index Writer
(	TokenNameLPAREN	
this	TokenNamethis	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
mergeScheduler	TokenNameIdentifier	 merge Scheduler
=	TokenNameEQUAL	
conf	TokenNameIdentifier	 conf
.	TokenNameDOT	
getMergeScheduler	TokenNameIdentifier	 get Merge Scheduler
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
bufferedDeletesStream	TokenNameIdentifier	 buffered Deletes Stream
=	TokenNameEQUAL	
new	TokenNamenew	
BufferedDeletesStream	TokenNameIdentifier	 Buffered Deletes Stream
(	TokenNameLPAREN	
messageID	TokenNameIdentifier	 message ID
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
bufferedDeletesStream	TokenNameIdentifier	 buffered Deletes Stream
.	TokenNameDOT	
setInfoStream	TokenNameIdentifier	 set Info Stream
(	TokenNameLPAREN	
infoStream	TokenNameIdentifier	 info Stream
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
poolReaders	TokenNameIdentifier	 pool Readers
=	TokenNameEQUAL	
conf	TokenNameIdentifier	 conf
.	TokenNameDOT	
getReaderPooling	TokenNameIdentifier	 get Reader Pooling
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
writeLock	TokenNameIdentifier	 write Lock
=	TokenNameEQUAL	
directory	TokenNameIdentifier	 directory
.	TokenNameDOT	
makeLock	TokenNameIdentifier	 make Lock
(	TokenNameLPAREN	
WRITE_LOCK_NAME	TokenNameIdentifier	 WRITE  LOCK  NAME
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
if	TokenNameif	
(	TokenNameLPAREN	
!	TokenNameNOT	
writeLock	TokenNameIdentifier	 write Lock
.	TokenNameDOT	
obtain	TokenNameIdentifier	 obtain
(	TokenNameLPAREN	
writeLockTimeout	TokenNameIdentifier	 write Lock Timeout
)	TokenNameRPAREN	
)	TokenNameRPAREN	
// obtain write lock 	TokenNameCOMMENT_LINE	obtain write lock 
throw	TokenNamethrow	
new	TokenNamenew	
LockObtainFailedException	TokenNameIdentifier	 Lock Obtain Failed Exception
(	TokenNameLPAREN	
"Index locked for write: "	TokenNameStringLiteral	Index locked for write: 
+	TokenNamePLUS	
writeLock	TokenNameIdentifier	 write Lock
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
boolean	TokenNameboolean	
success	TokenNameIdentifier	 success
=	TokenNameEQUAL	
false	TokenNamefalse	
;	TokenNameSEMICOLON	
try	TokenNametry	
{	TokenNameLBRACE	
OpenMode	TokenNameIdentifier	 Open Mode
mode	TokenNameIdentifier	 mode
=	TokenNameEQUAL	
conf	TokenNameIdentifier	 conf
.	TokenNameDOT	
getOpenMode	TokenNameIdentifier	 get Open Mode
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
boolean	TokenNameboolean	
create	TokenNameIdentifier	 create
;	TokenNameSEMICOLON	
if	TokenNameif	
(	TokenNameLPAREN	
mode	TokenNameIdentifier	 mode
==	TokenNameEQUAL_EQUAL	
OpenMode	TokenNameIdentifier	 Open Mode
.	TokenNameDOT	
CREATE	TokenNameIdentifier	 CREATE
)	TokenNameRPAREN	
{	TokenNameLBRACE	
create	TokenNameIdentifier	 create
=	TokenNameEQUAL	
true	TokenNametrue	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
else	TokenNameelse	
if	TokenNameif	
(	TokenNameLPAREN	
mode	TokenNameIdentifier	 mode
==	TokenNameEQUAL_EQUAL	
OpenMode	TokenNameIdentifier	 Open Mode
.	TokenNameDOT	
APPEND	TokenNameIdentifier	 APPEND
)	TokenNameRPAREN	
{	TokenNameLBRACE	
create	TokenNameIdentifier	 create
=	TokenNameEQUAL	
false	TokenNamefalse	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
else	TokenNameelse	
{	TokenNameLBRACE	
// CREATE_OR_APPEND - create only if an index does not exist 	TokenNameCOMMENT_LINE	CREATE_OR_APPEND - create only if an index does not exist 
create	TokenNameIdentifier	 create
=	TokenNameEQUAL	
!	TokenNameNOT	
IndexReader	TokenNameIdentifier	 Index Reader
.	TokenNameDOT	
indexExists	TokenNameIdentifier	 index Exists
(	TokenNameLPAREN	
directory	TokenNameIdentifier	 directory
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
// TODO: we should check whether this index is too old, 	TokenNameCOMMENT_LINE	TODO: we should check whether this index is too old, 
// and throw an IndexFormatTooOldExc up front, here, 	TokenNameCOMMENT_LINE	and throw an IndexFormatTooOldExc up front, here, 
// instead of later when merge, applyDeletes, getReader 	TokenNameCOMMENT_LINE	instead of later when merge, applyDeletes, getReader 
// is attempted. I think to do this we should store the 	TokenNameCOMMENT_LINE	is attempted. I think to do this we should store the 
// oldest segment's version in segments_N. 	TokenNameCOMMENT_LINE	oldest segment's version in segments_N. 
if	TokenNameif	
(	TokenNameLPAREN	
create	TokenNameIdentifier	 create
)	TokenNameRPAREN	
{	TokenNameLBRACE	
// Try to read first. This is to allow create 	TokenNameCOMMENT_LINE	Try to read first. This is to allow create 
// against an index that's currently open for 	TokenNameCOMMENT_LINE	against an index that's currently open for 
// searching. In this case we write the next 	TokenNameCOMMENT_LINE	searching. In this case we write the next 
// segments_N file with no segments: 	TokenNameCOMMENT_LINE	segments_N file with no segments: 
try	TokenNametry	
{	TokenNameLBRACE	
segmentInfos	TokenNameIdentifier	 segment Infos
.	TokenNameDOT	
read	TokenNameIdentifier	 read
(	TokenNameLPAREN	
directory	TokenNameIdentifier	 directory
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
segmentInfos	TokenNameIdentifier	 segment Infos
.	TokenNameDOT	
clear	TokenNameIdentifier	 clear
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
catch	TokenNamecatch	
(	TokenNameLPAREN	
IOException	TokenNameIdentifier	 IO Exception
e	TokenNameIdentifier	 e
)	TokenNameRPAREN	
{	TokenNameLBRACE	
// Likely this means it's a fresh directory 	TokenNameCOMMENT_LINE	Likely this means it's a fresh directory 
}	TokenNameRBRACE	
// Record that we have a change (zero out all 	TokenNameCOMMENT_LINE	Record that we have a change (zero out all 
// segments) pending: 	TokenNameCOMMENT_LINE	segments) pending: 
changeCount	TokenNameIdentifier	 change Count
++	TokenNamePLUS_PLUS	
;	TokenNameSEMICOLON	
segmentInfos	TokenNameIdentifier	 segment Infos
.	TokenNameDOT	
changed	TokenNameIdentifier	 changed
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
else	TokenNameelse	
{	TokenNameLBRACE	
segmentInfos	TokenNameIdentifier	 segment Infos
.	TokenNameDOT	
read	TokenNameIdentifier	 read
(	TokenNameLPAREN	
directory	TokenNameIdentifier	 directory
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
IndexCommit	TokenNameIdentifier	 Index Commit
commit	TokenNameIdentifier	 commit
=	TokenNameEQUAL	
conf	TokenNameIdentifier	 conf
.	TokenNameDOT	
getIndexCommit	TokenNameIdentifier	 get Index Commit
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
if	TokenNameif	
(	TokenNameLPAREN	
commit	TokenNameIdentifier	 commit
!=	TokenNameNOT_EQUAL	
null	TokenNamenull	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
// Swap out all segments, but, keep metadata in 	TokenNameCOMMENT_LINE	Swap out all segments, but, keep metadata in 
// SegmentInfos, like version & generation, to 	TokenNameCOMMENT_LINE	SegmentInfos, like version & generation, to 
// preserve write-once. This is important if 	TokenNameCOMMENT_LINE	preserve write-once. This is important if 
// readers are open against the future commit 	TokenNameCOMMENT_LINE	readers are open against the future commit 
// points. 	TokenNameCOMMENT_LINE	points. 
if	TokenNameif	
(	TokenNameLPAREN	
commit	TokenNameIdentifier	 commit
.	TokenNameDOT	
getDirectory	TokenNameIdentifier	 get Directory
(	TokenNameLPAREN	
)	TokenNameRPAREN	
!=	TokenNameNOT_EQUAL	
directory	TokenNameIdentifier	 directory
)	TokenNameRPAREN	
throw	TokenNamethrow	
new	TokenNamenew	
IllegalArgumentException	TokenNameIdentifier	 Illegal Argument Exception
(	TokenNameLPAREN	
"IndexCommit's directory doesn't match my directory"	TokenNameStringLiteral	IndexCommit's directory doesn't match my directory
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
SegmentInfos	TokenNameIdentifier	 Segment Infos
oldInfos	TokenNameIdentifier	 old Infos
=	TokenNameEQUAL	
new	TokenNamenew	
SegmentInfos	TokenNameIdentifier	 Segment Infos
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
oldInfos	TokenNameIdentifier	 old Infos
.	TokenNameDOT	
read	TokenNameIdentifier	 read
(	TokenNameLPAREN	
directory	TokenNameIdentifier	 directory
,	TokenNameCOMMA	
commit	TokenNameIdentifier	 commit
.	TokenNameDOT	
getSegmentsFileName	TokenNameIdentifier	 get Segments File Name
(	TokenNameLPAREN	
)	TokenNameRPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
segmentInfos	TokenNameIdentifier	 segment Infos
.	TokenNameDOT	
replace	TokenNameIdentifier	 replace
(	TokenNameLPAREN	
oldInfos	TokenNameIdentifier	 old Infos
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
changeCount	TokenNameIdentifier	 change Count
++	TokenNamePLUS_PLUS	
;	TokenNameSEMICOLON	
segmentInfos	TokenNameIdentifier	 segment Infos
.	TokenNameDOT	
changed	TokenNameIdentifier	 changed
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
if	TokenNameif	
(	TokenNameLPAREN	
infoStream	TokenNameIdentifier	 info Stream
!=	TokenNameNOT_EQUAL	
null	TokenNamenull	
)	TokenNameRPAREN	
message	TokenNameIdentifier	 message
(	TokenNameLPAREN	
"init: loaded commit ""	TokenNameStringLiteral	init: loaded commit "
+	TokenNamePLUS	
commit	TokenNameIdentifier	 commit
.	TokenNameDOT	
getSegmentsFileName	TokenNameIdentifier	 get Segments File Name
(	TokenNameLPAREN	
)	TokenNameRPAREN	
+	TokenNamePLUS	
"""	TokenNameStringLiteral	"
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
}	TokenNameRBRACE	
rollbackSegments	TokenNameIdentifier	 rollback Segments
=	TokenNameEQUAL	
segmentInfos	TokenNameIdentifier	 segment Infos
.	TokenNameDOT	
createBackupSegmentInfos	TokenNameIdentifier	 create Backup Segment Infos
(	TokenNameLPAREN	
true	TokenNametrue	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
docWriter	TokenNameIdentifier	 doc Writer
=	TokenNameEQUAL	
new	TokenNamenew	
DocumentsWriter	TokenNameIdentifier	 Documents Writer
(	TokenNameLPAREN	
config	TokenNameIdentifier	 config
,	TokenNameCOMMA	
directory	TokenNameIdentifier	 directory
,	TokenNameCOMMA	
this	TokenNamethis	
,	TokenNameCOMMA	
getCurrentFieldInfos	TokenNameIdentifier	 get Current Field Infos
(	TokenNameLPAREN	
)	TokenNameRPAREN	
,	TokenNameCOMMA	
bufferedDeletesStream	TokenNameIdentifier	 buffered Deletes Stream
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
docWriter	TokenNameIdentifier	 doc Writer
.	TokenNameDOT	
setInfoStream	TokenNameIdentifier	 set Info Stream
(	TokenNameLPAREN	
infoStream	TokenNameIdentifier	 info Stream
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
docWriter	TokenNameIdentifier	 doc Writer
.	TokenNameDOT	
setMaxFieldLength	TokenNameIdentifier	 set Max Field Length
(	TokenNameLPAREN	
maxFieldLength	TokenNameIdentifier	 max Field Length
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
// Default deleter (for backwards compatibility) is 	TokenNameCOMMENT_LINE	Default deleter (for backwards compatibility) is 
// KeepOnlyLastCommitDeleter: 	TokenNameCOMMENT_LINE	KeepOnlyLastCommitDeleter: 
synchronized	TokenNamesynchronized	
(	TokenNameLPAREN	
this	TokenNamethis	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
deleter	TokenNameIdentifier	 deleter
=	TokenNameEQUAL	
new	TokenNamenew	
IndexFileDeleter	TokenNameIdentifier	 Index File Deleter
(	TokenNameLPAREN	
directory	TokenNameIdentifier	 directory
,	TokenNameCOMMA	
conf	TokenNameIdentifier	 conf
.	TokenNameDOT	
getIndexDeletionPolicy	TokenNameIdentifier	 get Index Deletion Policy
(	TokenNameLPAREN	
)	TokenNameRPAREN	
,	TokenNameCOMMA	
segmentInfos	TokenNameIdentifier	 segment Infos
,	TokenNameCOMMA	
infoStream	TokenNameIdentifier	 info Stream
,	TokenNameCOMMA	
this	TokenNamethis	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
if	TokenNameif	
(	TokenNameLPAREN	
deleter	TokenNameIdentifier	 deleter
.	TokenNameDOT	
startingCommitDeleted	TokenNameIdentifier	 starting Commit Deleted
)	TokenNameRPAREN	
{	TokenNameLBRACE	
// Deletion policy deleted the "head" commit point. 	TokenNameCOMMENT_LINE	Deletion policy deleted the "head" commit point. 
// We have to mark ourself as changed so that if we 	TokenNameCOMMENT_LINE	We have to mark ourself as changed so that if we 
// are closed w/o any further changes we write a new 	TokenNameCOMMENT_LINE	are closed w/o any further changes we write a new 
// segments_N file. 	TokenNameCOMMENT_LINE	segments_N file. 
changeCount	TokenNameIdentifier	 change Count
++	TokenNamePLUS_PLUS	
;	TokenNameSEMICOLON	
segmentInfos	TokenNameIdentifier	 segment Infos
.	TokenNameDOT	
changed	TokenNameIdentifier	 changed
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
if	TokenNameif	
(	TokenNameLPAREN	
infoStream	TokenNameIdentifier	 info Stream
!=	TokenNameNOT_EQUAL	
null	TokenNamenull	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
messageState	TokenNameIdentifier	 message State
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
success	TokenNameIdentifier	 success
=	TokenNameEQUAL	
true	TokenNametrue	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
finally	TokenNamefinally	
{	TokenNameLBRACE	
if	TokenNameif	
(	TokenNameLPAREN	
!	TokenNameNOT	
success	TokenNameIdentifier	 success
)	TokenNameRPAREN	
{	TokenNameLBRACE	
if	TokenNameif	
(	TokenNameLPAREN	
infoStream	TokenNameIdentifier	 info Stream
!=	TokenNameNOT_EQUAL	
null	TokenNamenull	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
message	TokenNameIdentifier	 message
(	TokenNameLPAREN	
"init: hit exception on init; releasing write lock"	TokenNameStringLiteral	init: hit exception on init; releasing write lock
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
try	TokenNametry	
{	TokenNameLBRACE	
writeLock	TokenNameIdentifier	 write Lock
.	TokenNameDOT	
release	TokenNameIdentifier	 release
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
catch	TokenNamecatch	
(	TokenNameLPAREN	
Throwable	TokenNameIdentifier	 Throwable
t	TokenNameIdentifier	 t
)	TokenNameRPAREN	
{	TokenNameLBRACE	
// don't mask the original exception 	TokenNameCOMMENT_LINE	don't mask the original exception 
}	TokenNameRBRACE	
writeLock	TokenNameIdentifier	 write Lock
=	TokenNameEQUAL	
null	TokenNamenull	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
}	TokenNameRBRACE	
}	TokenNameRBRACE	
private	TokenNameprivate	
FieldInfos	TokenNameIdentifier	 Field Infos
getFieldInfos	TokenNameIdentifier	 get Field Infos
(	TokenNameLPAREN	
SegmentInfo	TokenNameIdentifier	 Segment Info
info	TokenNameIdentifier	 info
)	TokenNameRPAREN	
throws	TokenNamethrows	
IOException	TokenNameIdentifier	 IO Exception
{	TokenNameLBRACE	
Directory	TokenNameIdentifier	 Directory
cfsDir	TokenNameIdentifier	 cfs Dir
=	TokenNameEQUAL	
null	TokenNamenull	
;	TokenNameSEMICOLON	
try	TokenNametry	
{	TokenNameLBRACE	
if	TokenNameif	
(	TokenNameLPAREN	
info	TokenNameIdentifier	 info
.	TokenNameDOT	
getUseCompoundFile	TokenNameIdentifier	 get Use Compound File
(	TokenNameLPAREN	
)	TokenNameRPAREN	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
cfsDir	TokenNameIdentifier	 cfs Dir
=	TokenNameEQUAL	
new	TokenNamenew	
CompoundFileReader	TokenNameIdentifier	 Compound File Reader
(	TokenNameLPAREN	
directory	TokenNameIdentifier	 directory
,	TokenNameCOMMA	
IndexFileNames	TokenNameIdentifier	 Index File Names
.	TokenNameDOT	
segmentFileName	TokenNameIdentifier	 segment File Name
(	TokenNameLPAREN	
info	TokenNameIdentifier	 info
.	TokenNameDOT	
name	TokenNameIdentifier	 name
,	TokenNameCOMMA	
IndexFileNames	TokenNameIdentifier	 Index File Names
.	TokenNameDOT	
COMPOUND_FILE_EXTENSION	TokenNameIdentifier	 COMPOUND  FILE  EXTENSION
)	TokenNameRPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
else	TokenNameelse	
{	TokenNameLBRACE	
cfsDir	TokenNameIdentifier	 cfs Dir
=	TokenNameEQUAL	
directory	TokenNameIdentifier	 directory
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
return	TokenNamereturn	
new	TokenNamenew	
FieldInfos	TokenNameIdentifier	 Field Infos
(	TokenNameLPAREN	
cfsDir	TokenNameIdentifier	 cfs Dir
,	TokenNameCOMMA	
IndexFileNames	TokenNameIdentifier	 Index File Names
.	TokenNameDOT	
segmentFileName	TokenNameIdentifier	 segment File Name
(	TokenNameLPAREN	
info	TokenNameIdentifier	 info
.	TokenNameDOT	
name	TokenNameIdentifier	 name
,	TokenNameCOMMA	
IndexFileNames	TokenNameIdentifier	 Index File Names
.	TokenNameDOT	
FIELD_INFOS_EXTENSION	TokenNameIdentifier	 FIELD  INFOS  EXTENSION
)	TokenNameRPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
finally	TokenNamefinally	
{	TokenNameLBRACE	
if	TokenNameif	
(	TokenNameLPAREN	
info	TokenNameIdentifier	 info
.	TokenNameDOT	
getUseCompoundFile	TokenNameIdentifier	 get Use Compound File
(	TokenNameLPAREN	
)	TokenNameRPAREN	
&&	TokenNameAND_AND	
cfsDir	TokenNameIdentifier	 cfs Dir
!=	TokenNameNOT_EQUAL	
null	TokenNamenull	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
cfsDir	TokenNameIdentifier	 cfs Dir
.	TokenNameDOT	
close	TokenNameIdentifier	 close
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
}	TokenNameRBRACE	
}	TokenNameRBRACE	
private	TokenNameprivate	
FieldInfos	TokenNameIdentifier	 Field Infos
getCurrentFieldInfos	TokenNameIdentifier	 get Current Field Infos
(	TokenNameLPAREN	
)	TokenNameRPAREN	
throws	TokenNamethrows	
IOException	TokenNameIdentifier	 IO Exception
{	TokenNameLBRACE	
final	TokenNamefinal	
FieldInfos	TokenNameIdentifier	 Field Infos
fieldInfos	TokenNameIdentifier	 field Infos
;	TokenNameSEMICOLON	
if	TokenNameif	
(	TokenNameLPAREN	
segmentInfos	TokenNameIdentifier	 segment Infos
.	TokenNameDOT	
size	TokenNameIdentifier	 size
(	TokenNameLPAREN	
)	TokenNameRPAREN	
>	TokenNameGREATER	
0	TokenNameIntegerLiteral	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
if	TokenNameif	
(	TokenNameLPAREN	
segmentInfos	TokenNameIdentifier	 segment Infos
.	TokenNameDOT	
getFormat	TokenNameIdentifier	 get Format
(	TokenNameLPAREN	
)	TokenNameRPAREN	
>	TokenNameGREATER	
SegmentInfos	TokenNameIdentifier	 Segment Infos
.	TokenNameDOT	
FORMAT_DIAGNOSTICS	TokenNameIdentifier	 FORMAT  DIAGNOSTICS
)	TokenNameRPAREN	
{	TokenNameLBRACE	
// Pre-3.1 index. In this case we sweep all 	TokenNameCOMMENT_LINE	Pre-3.1 index. In this case we sweep all 
// segments, merging their FieldInfos: 	TokenNameCOMMENT_LINE	segments, merging their FieldInfos: 
fieldInfos	TokenNameIdentifier	 field Infos
=	TokenNameEQUAL	
new	TokenNamenew	
FieldInfos	TokenNameIdentifier	 Field Infos
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
for	TokenNamefor	
(	TokenNameLPAREN	
SegmentInfo	TokenNameIdentifier	 Segment Info
info	TokenNameIdentifier	 info
:	TokenNameCOLON	
segmentInfos	TokenNameIdentifier	 segment Infos
)	TokenNameRPAREN	
{	TokenNameLBRACE	
final	TokenNamefinal	
FieldInfos	TokenNameIdentifier	 Field Infos
segFieldInfos	TokenNameIdentifier	 seg Field Infos
=	TokenNameEQUAL	
getFieldInfos	TokenNameIdentifier	 get Field Infos
(	TokenNameLPAREN	
info	TokenNameIdentifier	 info
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
final	TokenNamefinal	
int	TokenNameint	
fieldCount	TokenNameIdentifier	 field Count
=	TokenNameEQUAL	
segFieldInfos	TokenNameIdentifier	 seg Field Infos
.	TokenNameDOT	
size	TokenNameIdentifier	 size
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
for	TokenNamefor	
(	TokenNameLPAREN	
int	TokenNameint	
fieldNumber	TokenNameIdentifier	 field Number
=	TokenNameEQUAL	
0	TokenNameIntegerLiteral	
;	TokenNameSEMICOLON	
fieldNumber	TokenNameIdentifier	 field Number
<	TokenNameLESS	
fieldCount	TokenNameIdentifier	 field Count
;	TokenNameSEMICOLON	
fieldNumber	TokenNameIdentifier	 field Number
++	TokenNamePLUS_PLUS	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
fieldInfos	TokenNameIdentifier	 field Infos
.	TokenNameDOT	
add	TokenNameIdentifier	 add
(	TokenNameLPAREN	
segFieldInfos	TokenNameIdentifier	 seg Field Infos
.	TokenNameDOT	
fieldInfo	TokenNameIdentifier	 field Info
(	TokenNameLPAREN	
fieldNumber	TokenNameIdentifier	 field Number
)	TokenNameRPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
}	TokenNameRBRACE	
}	TokenNameRBRACE	
else	TokenNameelse	
{	TokenNameLBRACE	
// Already a 3.1 index; just seed the FieldInfos 	TokenNameCOMMENT_LINE	Already a 3.1 index; just seed the FieldInfos 
// from the last segment 	TokenNameCOMMENT_LINE	from the last segment 
fieldInfos	TokenNameIdentifier	 field Infos
=	TokenNameEQUAL	
getFieldInfos	TokenNameIdentifier	 get Field Infos
(	TokenNameLPAREN	
segmentInfos	TokenNameIdentifier	 segment Infos
.	TokenNameDOT	
info	TokenNameIdentifier	 info
(	TokenNameLPAREN	
segmentInfos	TokenNameIdentifier	 segment Infos
.	TokenNameDOT	
size	TokenNameIdentifier	 size
(	TokenNameLPAREN	
)	TokenNameRPAREN	
-	TokenNameMINUS	
1	TokenNameIntegerLiteral	
)	TokenNameRPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
}	TokenNameRBRACE	
else	TokenNameelse	
{	TokenNameLBRACE	
fieldInfos	TokenNameIdentifier	 field Infos
=	TokenNameEQUAL	
new	TokenNamenew	
FieldInfos	TokenNameIdentifier	 Field Infos
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
return	TokenNamereturn	
fieldInfos	TokenNameIdentifier	 field Infos
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
/** * Returns the private {@link IndexWriterConfig}, cloned * from the {@link IndexWriterConfig} passed to * {@link #IndexWriter(Directory, IndexWriterConfig)}. * <p> * <b>NOTE:</b> some settings may be changed on the * returned {@link IndexWriterConfig}, and will take * effect in the current IndexWriter instance. See the * javadocs for the specific setters in {@link * IndexWriterConfig} for details. */	TokenNameCOMMENT_JAVADOC	 Returns the private {@link IndexWriterConfig}, cloned from the {@link IndexWriterConfig} passed to {@link #IndexWriter(Directory, IndexWriterConfig)}. <p> <b>NOTE:</b> some settings may be changed on the returned {@link IndexWriterConfig}, and will take effect in the current IndexWriter instance. See the javadocs for the specific setters in {@link IndexWriterConfig} for details. 
public	TokenNamepublic	
IndexWriterConfig	TokenNameIdentifier	 Index Writer Config
getConfig	TokenNameIdentifier	 get Config
(	TokenNameLPAREN	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
ensureOpen	TokenNameIdentifier	 ensure Open
(	TokenNameLPAREN	
false	TokenNamefalse	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
return	TokenNamereturn	
config	TokenNameIdentifier	 config
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
/** * Expert: set the merge policy used by this writer. * * @deprecated use {@link IndexWriterConfig#setMergePolicy(MergePolicy)} instead. */	TokenNameCOMMENT_JAVADOC	 Expert: set the merge policy used by this writer. * @deprecated use {@link IndexWriterConfig#setMergePolicy(MergePolicy)} instead. 
@	TokenNameAT	
Deprecated	TokenNameIdentifier	 Deprecated
public	TokenNamepublic	
void	TokenNamevoid	
setMergePolicy	TokenNameIdentifier	 set Merge Policy
(	TokenNameLPAREN	
MergePolicy	TokenNameIdentifier	 Merge Policy
mp	TokenNameIdentifier	 mp
)	TokenNameRPAREN	
{	TokenNameLBRACE	
ensureOpen	TokenNameIdentifier	 ensure Open
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
if	TokenNameif	
(	TokenNameLPAREN	
mp	TokenNameIdentifier	 mp
==	TokenNameEQUAL_EQUAL	
null	TokenNamenull	
)	TokenNameRPAREN	
throw	TokenNamethrow	
new	TokenNamenew	
NullPointerException	TokenNameIdentifier	 Null Pointer Exception
(	TokenNameLPAREN	
"MergePolicy must be non-null"	TokenNameStringLiteral	MergePolicy must be non-null
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
if	TokenNameif	
(	TokenNameLPAREN	
mergePolicy	TokenNameIdentifier	 merge Policy
!=	TokenNameNOT_EQUAL	
mp	TokenNameIdentifier	 mp
)	TokenNameRPAREN	
mergePolicy	TokenNameIdentifier	 merge Policy
.	TokenNameDOT	
close	TokenNameIdentifier	 close
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
mergePolicy	TokenNameIdentifier	 merge Policy
=	TokenNameEQUAL	
mp	TokenNameIdentifier	 mp
;	TokenNameSEMICOLON	
mergePolicy	TokenNameIdentifier	 merge Policy
.	TokenNameDOT	
setIndexWriter	TokenNameIdentifier	 set Index Writer
(	TokenNameLPAREN	
this	TokenNamethis	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
pushMaxBufferedDocs	TokenNameIdentifier	 push Max Buffered Docs
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
if	TokenNameif	
(	TokenNameLPAREN	
infoStream	TokenNameIdentifier	 info Stream
!=	TokenNameNOT_EQUAL	
null	TokenNamenull	
)	TokenNameRPAREN	
message	TokenNameIdentifier	 message
(	TokenNameLPAREN	
"setMergePolicy "	TokenNameStringLiteral	setMergePolicy 
+	TokenNamePLUS	
mp	TokenNameIdentifier	 mp
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
// Required so config.getMergePolicy returns the right value. But this will 	TokenNameCOMMENT_LINE	Required so config.getMergePolicy returns the right value. But this will 
// go away together with the method in 4.0. 	TokenNameCOMMENT_LINE	go away together with the method in 4.0. 
config	TokenNameIdentifier	 config
.	TokenNameDOT	
setMergePolicy	TokenNameIdentifier	 set Merge Policy
(	TokenNameLPAREN	
mp	TokenNameIdentifier	 mp
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
/** * Expert: returns the current MergePolicy in use by this writer. * @see #setMergePolicy * * @deprecated use {@link IndexWriterConfig#getMergePolicy()} instead */	TokenNameCOMMENT_JAVADOC	 Expert: returns the current MergePolicy in use by this writer. @see #setMergePolicy * @deprecated use {@link IndexWriterConfig#getMergePolicy()} instead 
@	TokenNameAT	
Deprecated	TokenNameIdentifier	 Deprecated
public	TokenNamepublic	
MergePolicy	TokenNameIdentifier	 Merge Policy
getMergePolicy	TokenNameIdentifier	 get Merge Policy
(	TokenNameLPAREN	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
ensureOpen	TokenNameIdentifier	 ensure Open
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
return	TokenNamereturn	
mergePolicy	TokenNameIdentifier	 merge Policy
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
/** * Expert: set the merge scheduler used by this writer. * @deprecated use {@link IndexWriterConfig#setMergeScheduler(MergeScheduler)} instead */	TokenNameCOMMENT_JAVADOC	 Expert: set the merge scheduler used by this writer. @deprecated use {@link IndexWriterConfig#setMergeScheduler(MergeScheduler)} instead 
@	TokenNameAT	
Deprecated	TokenNameIdentifier	 Deprecated
synchronized	TokenNamesynchronized	
public	TokenNamepublic	
void	TokenNamevoid	
setMergeScheduler	TokenNameIdentifier	 set Merge Scheduler
(	TokenNameLPAREN	
MergeScheduler	TokenNameIdentifier	 Merge Scheduler
mergeScheduler	TokenNameIdentifier	 merge Scheduler
)	TokenNameRPAREN	
throws	TokenNamethrows	
CorruptIndexException	TokenNameIdentifier	 Corrupt Index Exception
,	TokenNameCOMMA	
IOException	TokenNameIdentifier	 IO Exception
{	TokenNameLBRACE	
ensureOpen	TokenNameIdentifier	 ensure Open
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
if	TokenNameif	
(	TokenNameLPAREN	
mergeScheduler	TokenNameIdentifier	 merge Scheduler
==	TokenNameEQUAL_EQUAL	
null	TokenNamenull	
)	TokenNameRPAREN	
throw	TokenNamethrow	
new	TokenNamenew	
NullPointerException	TokenNameIdentifier	 Null Pointer Exception
(	TokenNameLPAREN	
"MergeScheduler must be non-null"	TokenNameStringLiteral	MergeScheduler must be non-null
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
if	TokenNameif	
(	TokenNameLPAREN	
this	TokenNamethis	
.	TokenNameDOT	
mergeScheduler	TokenNameIdentifier	 merge Scheduler
!=	TokenNameNOT_EQUAL	
mergeScheduler	TokenNameIdentifier	 merge Scheduler
)	TokenNameRPAREN	
{	TokenNameLBRACE	
finishMerges	TokenNameIdentifier	 finish Merges
(	TokenNameLPAREN	
true	TokenNametrue	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
this	TokenNamethis	
.	TokenNameDOT	
mergeScheduler	TokenNameIdentifier	 merge Scheduler
.	TokenNameDOT	
close	TokenNameIdentifier	 close
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
this	TokenNamethis	
.	TokenNameDOT	
mergeScheduler	TokenNameIdentifier	 merge Scheduler
=	TokenNameEQUAL	
mergeScheduler	TokenNameIdentifier	 merge Scheduler
;	TokenNameSEMICOLON	
if	TokenNameif	
(	TokenNameLPAREN	
infoStream	TokenNameIdentifier	 info Stream
!=	TokenNameNOT_EQUAL	
null	TokenNamenull	
)	TokenNameRPAREN	
message	TokenNameIdentifier	 message
(	TokenNameLPAREN	
"setMergeScheduler "	TokenNameStringLiteral	setMergeScheduler 
+	TokenNamePLUS	
mergeScheduler	TokenNameIdentifier	 merge Scheduler
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
// Required so config.getMergeScheduler returns the right value. But this will 	TokenNameCOMMENT_LINE	Required so config.getMergeScheduler returns the right value. But this will 
// go away together with the method in 4.0. 	TokenNameCOMMENT_LINE	go away together with the method in 4.0. 
config	TokenNameIdentifier	 config
.	TokenNameDOT	
setMergeScheduler	TokenNameIdentifier	 set Merge Scheduler
(	TokenNameLPAREN	
mergeScheduler	TokenNameIdentifier	 merge Scheduler
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
/** * Expert: returns the current MergeScheduler in use by this * writer. * @see #setMergeScheduler(MergeScheduler) * @deprecated use {@link IndexWriterConfig#getMergeScheduler()} instead */	TokenNameCOMMENT_JAVADOC	 Expert: returns the current MergeScheduler in use by this writer. @see #setMergeScheduler(MergeScheduler) @deprecated use {@link IndexWriterConfig#getMergeScheduler()} instead 
@	TokenNameAT	
Deprecated	TokenNameIdentifier	 Deprecated
public	TokenNamepublic	
MergeScheduler	TokenNameIdentifier	 Merge Scheduler
getMergeScheduler	TokenNameIdentifier	 get Merge Scheduler
(	TokenNameLPAREN	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
ensureOpen	TokenNameIdentifier	 ensure Open
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
return	TokenNamereturn	
mergeScheduler	TokenNameIdentifier	 merge Scheduler
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
/** <p>Determines the largest segment (measured by * document count) that may be merged with other segments. * Small values (e.g., less than 10,000) are best for * interactive indexing, as this limits the length of * pauses while indexing to a few seconds. Larger values * are best for batched indexing and speedier * searches.</p> * * <p>The default value is {@link Integer#MAX_VALUE}.</p> * * <p>Note that this method is a convenience method: it * just calls mergePolicy.setMaxMergeDocs as long as * mergePolicy is an instance of {@link LogMergePolicy}. * Otherwise an IllegalArgumentException is thrown.</p> * * <p>The default merge policy ({@link * LogByteSizeMergePolicy}) also allows you to set this * limit by net size (in MB) of the segment, using {@link * LogByteSizeMergePolicy#setMaxMergeMB}.</p> * @deprecated use {@link LogMergePolicy#setMaxMergeDocs(int)} directly. */	TokenNameCOMMENT_JAVADOC	 <p>Determines the largest segment (measured by document count) that may be merged with other segments. Small values (e.g., less than 10,000) are best for interactive indexing, as this limits the length of pauses while indexing to a few seconds. Larger values are best for batched indexing and speedier searches.</p> * <p>The default value is {@link Integer#MAX_VALUE}.</p> * <p>Note that this method is a convenience method: it just calls mergePolicy.setMaxMergeDocs as long as mergePolicy is an instance of {@link LogMergePolicy}. Otherwise an IllegalArgumentException is thrown.</p> * <p>The default merge policy ({@link LogByteSizeMergePolicy}) also allows you to set this limit by net size (in MB) of the segment, using {@link LogByteSizeMergePolicy#setMaxMergeMB}.</p> @deprecated use {@link LogMergePolicy#setMaxMergeDocs(int)} directly. 
@	TokenNameAT	
Deprecated	TokenNameIdentifier	 Deprecated
public	TokenNamepublic	
void	TokenNamevoid	
setMaxMergeDocs	TokenNameIdentifier	 set Max Merge Docs
(	TokenNameLPAREN	
int	TokenNameint	
maxMergeDocs	TokenNameIdentifier	 max Merge Docs
)	TokenNameRPAREN	
{	TokenNameLBRACE	
getLogMergePolicy	TokenNameIdentifier	 get Log Merge Policy
(	TokenNameLPAREN	
)	TokenNameRPAREN	
.	TokenNameDOT	
setMaxMergeDocs	TokenNameIdentifier	 set Max Merge Docs
(	TokenNameLPAREN	
maxMergeDocs	TokenNameIdentifier	 max Merge Docs
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
/** * <p>Returns the largest segment (measured by document * count) that may be merged with other segments.</p> * * <p>Note that this method is a convenience method: it * just calls mergePolicy.getMaxMergeDocs as long as * mergePolicy is an instance of {@link LogMergePolicy}. * Otherwise an IllegalArgumentException is thrown.</p> * * @see #setMaxMergeDocs * @deprecated use {@link LogMergePolicy#getMaxMergeDocs()} directly. */	TokenNameCOMMENT_JAVADOC	 <p>Returns the largest segment (measured by document count) that may be merged with other segments.</p> * <p>Note that this method is a convenience method: it just calls mergePolicy.getMaxMergeDocs as long as mergePolicy is an instance of {@link LogMergePolicy}. Otherwise an IllegalArgumentException is thrown.</p> * @see #setMaxMergeDocs @deprecated use {@link LogMergePolicy#getMaxMergeDocs()} directly. 
@	TokenNameAT	
Deprecated	TokenNameIdentifier	 Deprecated
public	TokenNamepublic	
int	TokenNameint	
getMaxMergeDocs	TokenNameIdentifier	 get Max Merge Docs
(	TokenNameLPAREN	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
return	TokenNamereturn	
getLogMergePolicy	TokenNameIdentifier	 get Log Merge Policy
(	TokenNameLPAREN	
)	TokenNameRPAREN	
.	TokenNameDOT	
getMaxMergeDocs	TokenNameIdentifier	 get Max Merge Docs
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
/** * The maximum number of terms that will be indexed for a single field in a * document. This limits the amount of memory required for indexing, so that * collections with very large files will not crash the indexing process by * running out of memory. This setting refers to the number of running terms, * not to the number of different terms. * <p/> * <strong>Note:</strong> this silently truncates large documents, excluding * from the index all terms that occur further in the document. If you know * your source documents are large, be sure to set this value high enough to * accomodate the expected size. If you set it to Integer.MAX_VALUE, then the * only limit is your memory, but you should anticipate an OutOfMemoryError. * <p/> * By default, no more than {@link #DEFAULT_MAX_FIELD_LENGTH} terms will be * indexed for a field. * * @deprecated use {@link LimitTokenCountAnalyzer} instead. Note that the * behvaior slightly changed - the analyzer limits the number of * tokens per token stream created, while this setting limits the * total number of tokens to index. This only matters if you index * many multi-valued fields though. */	TokenNameCOMMENT_JAVADOC	 The maximum number of terms that will be indexed for a single field in a document. This limits the amount of memory required for indexing, so that collections with very large files will not crash the indexing process by running out of memory. This setting refers to the number of running terms, not to the number of different terms. <p/> <strong>Note:</strong> this silently truncates large documents, excluding from the index all terms that occur further in the document. If you know your source documents are large, be sure to set this value high enough to accomodate the expected size. If you set it to Integer.MAX_VALUE, then the only limit is your memory, but you should anticipate an OutOfMemoryError. <p/> By default, no more than {@link #DEFAULT_MAX_FIELD_LENGTH} terms will be indexed for a field. * @deprecated use {@link LimitTokenCountAnalyzer} instead. Note that the behvaior slightly changed - the analyzer limits the number of tokens per token stream created, while this setting limits the total number of tokens to index. This only matters if you index many multi-valued fields though. 
@	TokenNameAT	
Deprecated	TokenNameIdentifier	 Deprecated
public	TokenNamepublic	
void	TokenNamevoid	
setMaxFieldLength	TokenNameIdentifier	 set Max Field Length
(	TokenNameLPAREN	
int	TokenNameint	
maxFieldLength	TokenNameIdentifier	 max Field Length
)	TokenNameRPAREN	
{	TokenNameLBRACE	
ensureOpen	TokenNameIdentifier	 ensure Open
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
this	TokenNamethis	
.	TokenNameDOT	
maxFieldLength	TokenNameIdentifier	 max Field Length
=	TokenNameEQUAL	
maxFieldLength	TokenNameIdentifier	 max Field Length
;	TokenNameSEMICOLON	
docWriter	TokenNameIdentifier	 doc Writer
.	TokenNameDOT	
setMaxFieldLength	TokenNameIdentifier	 set Max Field Length
(	TokenNameLPAREN	
maxFieldLength	TokenNameIdentifier	 max Field Length
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
if	TokenNameif	
(	TokenNameLPAREN	
infoStream	TokenNameIdentifier	 info Stream
!=	TokenNameNOT_EQUAL	
null	TokenNamenull	
)	TokenNameRPAREN	
message	TokenNameIdentifier	 message
(	TokenNameLPAREN	
"setMaxFieldLength "	TokenNameStringLiteral	setMaxFieldLength 
+	TokenNamePLUS	
maxFieldLength	TokenNameIdentifier	 max Field Length
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
/** * Returns the maximum number of terms that will be * indexed for a single field in a document. * @see #setMaxFieldLength * @deprecated use {@link LimitTokenCountAnalyzer} to limit number of tokens. */	TokenNameCOMMENT_JAVADOC	 Returns the maximum number of terms that will be indexed for a single field in a document. @see #setMaxFieldLength @deprecated use {@link LimitTokenCountAnalyzer} to limit number of tokens. 
@	TokenNameAT	
Deprecated	TokenNameIdentifier	 Deprecated
public	TokenNamepublic	
int	TokenNameint	
getMaxFieldLength	TokenNameIdentifier	 get Max Field Length
(	TokenNameLPAREN	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
ensureOpen	TokenNameIdentifier	 ensure Open
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
return	TokenNamereturn	
maxFieldLength	TokenNameIdentifier	 max Field Length
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
/** * @deprecated use {@link * IndexWriterConfig#setReaderTermsIndexDivisor} instead. */	TokenNameCOMMENT_JAVADOC	 @deprecated use {@link IndexWriterConfig#setReaderTermsIndexDivisor} instead. 
@	TokenNameAT	
Deprecated	TokenNameIdentifier	 Deprecated
public	TokenNamepublic	
void	TokenNamevoid	
setReaderTermsIndexDivisor	TokenNameIdentifier	 set Reader Terms Index Divisor
(	TokenNameLPAREN	
int	TokenNameint	
divisor	TokenNameIdentifier	 divisor
)	TokenNameRPAREN	
{	TokenNameLBRACE	
ensureOpen	TokenNameIdentifier	 ensure Open
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
config	TokenNameIdentifier	 config
.	TokenNameDOT	
setReaderTermsIndexDivisor	TokenNameIdentifier	 set Reader Terms Index Divisor
(	TokenNameLPAREN	
divisor	TokenNameIdentifier	 divisor
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
if	TokenNameif	
(	TokenNameLPAREN	
infoStream	TokenNameIdentifier	 info Stream
!=	TokenNameNOT_EQUAL	
null	TokenNamenull	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
message	TokenNameIdentifier	 message
(	TokenNameLPAREN	
"setReaderTermsIndexDivisor "	TokenNameStringLiteral	setReaderTermsIndexDivisor 
+	TokenNamePLUS	
divisor	TokenNameIdentifier	 divisor
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
}	TokenNameRBRACE	
/** * @deprecated use {@link * IndexWriterConfig#getReaderTermsIndexDivisor} instead. */	TokenNameCOMMENT_JAVADOC	 @deprecated use {@link IndexWriterConfig#getReaderTermsIndexDivisor} instead. 
@	TokenNameAT	
Deprecated	TokenNameIdentifier	 Deprecated
public	TokenNamepublic	
int	TokenNameint	
getReaderTermsIndexDivisor	TokenNameIdentifier	 get Reader Terms Index Divisor
(	TokenNameLPAREN	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
ensureOpen	TokenNameIdentifier	 ensure Open
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
return	TokenNamereturn	
config	TokenNameIdentifier	 config
.	TokenNameDOT	
getReaderTermsIndexDivisor	TokenNameIdentifier	 get Reader Terms Index Divisor
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
/** Determines the minimal number of documents required * before the buffered in-memory documents are flushed as * a new Segment. Large values generally gives faster * indexing. * * <p>When this is set, the writer will flush every * maxBufferedDocs added documents. Pass in {@link * #DISABLE_AUTO_FLUSH} to prevent triggering a flush due * to number of buffered documents. Note that if flushing * by RAM usage is also enabled, then the flush will be * triggered by whichever comes first.</p> * * <p>Disabled by default (writer flushes by RAM usage).</p> * * @throws IllegalArgumentException if maxBufferedDocs is * enabled but smaller than 2, or it disables maxBufferedDocs * when ramBufferSize is already disabled * @see #setRAMBufferSizeMB * @deprecated use {@link IndexWriterConfig#setMaxBufferedDocs(int)} instead. */	TokenNameCOMMENT_JAVADOC	 Determines the minimal number of documents required before the buffered in-memory documents are flushed as a new Segment. Large values generally gives faster indexing. * <p>When this is set, the writer will flush every maxBufferedDocs added documents. Pass in {@link #DISABLE_AUTO_FLUSH} to prevent triggering a flush due to number of buffered documents. Note that if flushing by RAM usage is also enabled, then the flush will be triggered by whichever comes first.</p> * <p>Disabled by default (writer flushes by RAM usage).</p> * @throws IllegalArgumentException if maxBufferedDocs is enabled but smaller than 2, or it disables maxBufferedDocs when ramBufferSize is already disabled @see #setRAMBufferSizeMB @deprecated use {@link IndexWriterConfig#setMaxBufferedDocs(int)} instead. 
@	TokenNameAT	
Deprecated	TokenNameIdentifier	 Deprecated
public	TokenNamepublic	
void	TokenNamevoid	
setMaxBufferedDocs	TokenNameIdentifier	 set Max Buffered Docs
(	TokenNameLPAREN	
int	TokenNameint	
maxBufferedDocs	TokenNameIdentifier	 max Buffered Docs
)	TokenNameRPAREN	
{	TokenNameLBRACE	
ensureOpen	TokenNameIdentifier	 ensure Open
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
pushMaxBufferedDocs	TokenNameIdentifier	 push Max Buffered Docs
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
if	TokenNameif	
(	TokenNameLPAREN	
infoStream	TokenNameIdentifier	 info Stream
!=	TokenNameNOT_EQUAL	
null	TokenNamenull	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
message	TokenNameIdentifier	 message
(	TokenNameLPAREN	
"setMaxBufferedDocs "	TokenNameStringLiteral	setMaxBufferedDocs 
+	TokenNamePLUS	
maxBufferedDocs	TokenNameIdentifier	 max Buffered Docs
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
// Required so config.getMaxBufferedDocs returns the right value. But this 	TokenNameCOMMENT_LINE	Required so config.getMaxBufferedDocs returns the right value. But this 
// will go away together with the method in 4.0. 	TokenNameCOMMENT_LINE	will go away together with the method in 4.0. 
config	TokenNameIdentifier	 config
.	TokenNameDOT	
setMaxBufferedDocs	TokenNameIdentifier	 set Max Buffered Docs
(	TokenNameLPAREN	
maxBufferedDocs	TokenNameIdentifier	 max Buffered Docs
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
/** * If we are flushing by doc count (not by RAM usage), and * using LogDocMergePolicy then push maxBufferedDocs down * as its minMergeDocs, to keep backwards compatibility. */	TokenNameCOMMENT_JAVADOC	 If we are flushing by doc count (not by RAM usage), and using LogDocMergePolicy then push maxBufferedDocs down as its minMergeDocs, to keep backwards compatibility. 
private	TokenNameprivate	
void	TokenNamevoid	
pushMaxBufferedDocs	TokenNameIdentifier	 push Max Buffered Docs
(	TokenNameLPAREN	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
if	TokenNameif	
(	TokenNameLPAREN	
config	TokenNameIdentifier	 config
.	TokenNameDOT	
getMaxBufferedDocs	TokenNameIdentifier	 get Max Buffered Docs
(	TokenNameLPAREN	
)	TokenNameRPAREN	
!=	TokenNameNOT_EQUAL	
DISABLE_AUTO_FLUSH	TokenNameIdentifier	 DISABLE  AUTO  FLUSH
)	TokenNameRPAREN	
{	TokenNameLBRACE	
final	TokenNamefinal	
MergePolicy	TokenNameIdentifier	 Merge Policy
mp	TokenNameIdentifier	 mp
=	TokenNameEQUAL	
mergePolicy	TokenNameIdentifier	 merge Policy
;	TokenNameSEMICOLON	
if	TokenNameif	
(	TokenNameLPAREN	
mp	TokenNameIdentifier	 mp
instanceof	TokenNameinstanceof	
LogDocMergePolicy	TokenNameIdentifier	 Log Doc Merge Policy
)	TokenNameRPAREN	
{	TokenNameLBRACE	
LogDocMergePolicy	TokenNameIdentifier	 Log Doc Merge Policy
lmp	TokenNameIdentifier	 lmp
=	TokenNameEQUAL	
(	TokenNameLPAREN	
LogDocMergePolicy	TokenNameIdentifier	 Log Doc Merge Policy
)	TokenNameRPAREN	
mp	TokenNameIdentifier	 mp
;	TokenNameSEMICOLON	
final	TokenNamefinal	
int	TokenNameint	
maxBufferedDocs	TokenNameIdentifier	 max Buffered Docs
=	TokenNameEQUAL	
config	TokenNameIdentifier	 config
.	TokenNameDOT	
getMaxBufferedDocs	TokenNameIdentifier	 get Max Buffered Docs
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
if	TokenNameif	
(	TokenNameLPAREN	
lmp	TokenNameIdentifier	 lmp
.	TokenNameDOT	
getMinMergeDocs	TokenNameIdentifier	 get Min Merge Docs
(	TokenNameLPAREN	
)	TokenNameRPAREN	
!=	TokenNameNOT_EQUAL	
maxBufferedDocs	TokenNameIdentifier	 max Buffered Docs
)	TokenNameRPAREN	
{	TokenNameLBRACE	
if	TokenNameif	
(	TokenNameLPAREN	
infoStream	TokenNameIdentifier	 info Stream
!=	TokenNameNOT_EQUAL	
null	TokenNamenull	
)	TokenNameRPAREN	
message	TokenNameIdentifier	 message
(	TokenNameLPAREN	
"now push maxBufferedDocs "	TokenNameStringLiteral	now push maxBufferedDocs 
+	TokenNamePLUS	
maxBufferedDocs	TokenNameIdentifier	 max Buffered Docs
+	TokenNamePLUS	
" to LogDocMergePolicy"	TokenNameStringLiteral	 to LogDocMergePolicy
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
lmp	TokenNameIdentifier	 lmp
.	TokenNameDOT	
setMinMergeDocs	TokenNameIdentifier	 set Min Merge Docs
(	TokenNameLPAREN	
maxBufferedDocs	TokenNameIdentifier	 max Buffered Docs
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
}	TokenNameRBRACE	
}	TokenNameRBRACE	
}	TokenNameRBRACE	
/** * Returns the number of buffered added documents that will * trigger a flush if enabled. * @see #setMaxBufferedDocs * @deprecated use {@link IndexWriterConfig#getMaxBufferedDocs()} instead. */	TokenNameCOMMENT_JAVADOC	 Returns the number of buffered added documents that will trigger a flush if enabled. @see #setMaxBufferedDocs @deprecated use {@link IndexWriterConfig#getMaxBufferedDocs()} instead. 
@	TokenNameAT	
Deprecated	TokenNameIdentifier	 Deprecated
public	TokenNamepublic	
int	TokenNameint	
getMaxBufferedDocs	TokenNameIdentifier	 get Max Buffered Docs
(	TokenNameLPAREN	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
ensureOpen	TokenNameIdentifier	 ensure Open
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
return	TokenNamereturn	
config	TokenNameIdentifier	 config
.	TokenNameDOT	
getMaxBufferedDocs	TokenNameIdentifier	 get Max Buffered Docs
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
/** Determines the amount of RAM that may be used for * buffering added documents and deletions before they are * flushed to the Directory. Generally for faster * indexing performance it's best to flush by RAM usage * instead of document count and use as large a RAM buffer * as you can. * * <p>When this is set, the writer will flush whenever * buffered documents and deletions use this much RAM. * Pass in {@link #DISABLE_AUTO_FLUSH} to prevent * triggering a flush due to RAM usage. Note that if * flushing by document count is also enabled, then the * flush will be triggered by whichever comes first.</p> * * <p> <b>NOTE</b>: the account of RAM usage for pending * deletions is only approximate. Specifically, if you * delete by Query, Lucene currently has no way to measure * the RAM usage if individual Queries so the accounting * will under-estimate and you should compensate by either * calling commit() periodically yourself, or by using * {@link #setMaxBufferedDeleteTerms} to flush by count * instead of RAM usage (each buffered delete Query counts * as one). * * <p> <b>NOTE</b>: because IndexWriter uses * <code>int</code>s when managing its internal storage, * the absolute maximum value for this setting is somewhat * less than 2048 MB. The precise limit depends on * various factors, such as how large your documents are, * how many fields have norms, etc., so it's best to set * this value comfortably under 2048.</p> * * <p> The default value is {@link #DEFAULT_RAM_BUFFER_SIZE_MB}.</p> * * @throws IllegalArgumentException if ramBufferSize is * enabled but non-positive, or it disables ramBufferSize * when maxBufferedDocs is already disabled * @deprecated use {@link IndexWriterConfig#setRAMBufferSizeMB(double)} instead. */	TokenNameCOMMENT_JAVADOC	 Determines the amount of RAM that may be used for buffering added documents and deletions before they are flushed to the Directory. Generally for faster indexing performance it's best to flush by RAM usage instead of document count and use as large a RAM buffer as you can. * <p>When this is set, the writer will flush whenever buffered documents and deletions use this much RAM. Pass in {@link #DISABLE_AUTO_FLUSH} to prevent triggering a flush due to RAM usage. Note that if flushing by document count is also enabled, then the flush will be triggered by whichever comes first.</p> * <p> <b>NOTE</b>: the account of RAM usage for pending deletions is only approximate. Specifically, if you delete by Query, Lucene currently has no way to measure the RAM usage if individual Queries so the accounting will under-estimate and you should compensate by either calling commit() periodically yourself, or by using {@link #setMaxBufferedDeleteTerms} to flush by count instead of RAM usage (each buffered delete Query counts as one). * <p> <b>NOTE</b>: because IndexWriter uses <code>int</code>s when managing its internal storage, the absolute maximum value for this setting is somewhat less than 2048 MB. The precise limit depends on various factors, such as how large your documents are, how many fields have norms, etc., so it's best to set this value comfortably under 2048.</p> * <p> The default value is {@link #DEFAULT_RAM_BUFFER_SIZE_MB}.</p> * @throws IllegalArgumentException if ramBufferSize is enabled but non-positive, or it disables ramBufferSize when maxBufferedDocs is already disabled @deprecated use {@link IndexWriterConfig#setRAMBufferSizeMB(double)} instead. 
@	TokenNameAT	
Deprecated	TokenNameIdentifier	 Deprecated
public	TokenNamepublic	
void	TokenNamevoid	
setRAMBufferSizeMB	TokenNameIdentifier	 set RAM Buffer Size MB
(	TokenNameLPAREN	
double	TokenNamedouble	
mb	TokenNameIdentifier	 mb
)	TokenNameRPAREN	
{	TokenNameLBRACE	
if	TokenNameif	
(	TokenNameLPAREN	
infoStream	TokenNameIdentifier	 info Stream
!=	TokenNameNOT_EQUAL	
null	TokenNamenull	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
message	TokenNameIdentifier	 message
(	TokenNameLPAREN	
"setRAMBufferSizeMB "	TokenNameStringLiteral	setRAMBufferSizeMB 
+	TokenNamePLUS	
mb	TokenNameIdentifier	 mb
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
// Required so config.getRAMBufferSizeMB returns the right value. But this 	TokenNameCOMMENT_LINE	Required so config.getRAMBufferSizeMB returns the right value. But this 
// will go away together with the method in 4.0. 	TokenNameCOMMENT_LINE	will go away together with the method in 4.0. 
config	TokenNameIdentifier	 config
.	TokenNameDOT	
setRAMBufferSizeMB	TokenNameIdentifier	 set RAM Buffer Size MB
(	TokenNameLPAREN	
mb	TokenNameIdentifier	 mb
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
/** * Returns the value set by {@link #setRAMBufferSizeMB} if enabled. * @deprecated use {@link IndexWriterConfig#getRAMBufferSizeMB()} instead. */	TokenNameCOMMENT_JAVADOC	 Returns the value set by {@link #setRAMBufferSizeMB} if enabled. @deprecated use {@link IndexWriterConfig#getRAMBufferSizeMB()} instead. 
@	TokenNameAT	
Deprecated	TokenNameIdentifier	 Deprecated
public	TokenNamepublic	
double	TokenNamedouble	
getRAMBufferSizeMB	TokenNameIdentifier	 get RAM Buffer Size MB
(	TokenNameLPAREN	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
return	TokenNamereturn	
config	TokenNameIdentifier	 config
.	TokenNameDOT	
getRAMBufferSizeMB	TokenNameIdentifier	 get RAM Buffer Size MB
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
/** * <p>Determines the minimal number of delete terms required before the buffered * in-memory delete terms are applied and flushed. If there are documents * buffered in memory at the time, they are merged and a new segment is * created.</p> * <p>Disabled by default (writer flushes by RAM usage).</p> * * @throws IllegalArgumentException if maxBufferedDeleteTerms * is enabled but smaller than 1 * @see #setRAMBufferSizeMB * @deprecated use {@link IndexWriterConfig#setMaxBufferedDeleteTerms(int)} instead. */	TokenNameCOMMENT_JAVADOC	 <p>Determines the minimal number of delete terms required before the buffered in-memory delete terms are applied and flushed. If there are documents buffered in memory at the time, they are merged and a new segment is created.</p> <p>Disabled by default (writer flushes by RAM usage).</p> * @throws IllegalArgumentException if maxBufferedDeleteTerms is enabled but smaller than 1 @see #setRAMBufferSizeMB @deprecated use {@link IndexWriterConfig#setMaxBufferedDeleteTerms(int)} instead. 
@	TokenNameAT	
Deprecated	TokenNameIdentifier	 Deprecated
public	TokenNamepublic	
void	TokenNamevoid	
setMaxBufferedDeleteTerms	TokenNameIdentifier	 set Max Buffered Delete Terms
(	TokenNameLPAREN	
int	TokenNameint	
maxBufferedDeleteTerms	TokenNameIdentifier	 max Buffered Delete Terms
)	TokenNameRPAREN	
{	TokenNameLBRACE	
ensureOpen	TokenNameIdentifier	 ensure Open
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
if	TokenNameif	
(	TokenNameLPAREN	
infoStream	TokenNameIdentifier	 info Stream
!=	TokenNameNOT_EQUAL	
null	TokenNamenull	
)	TokenNameRPAREN	
message	TokenNameIdentifier	 message
(	TokenNameLPAREN	
"setMaxBufferedDeleteTerms "	TokenNameStringLiteral	setMaxBufferedDeleteTerms 
+	TokenNamePLUS	
maxBufferedDeleteTerms	TokenNameIdentifier	 max Buffered Delete Terms
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
// Required so config.getMaxBufferedDeleteTerms returns the right value. But 	TokenNameCOMMENT_LINE	Required so config.getMaxBufferedDeleteTerms returns the right value. But 
// this will go away together with the method in 4.0. 	TokenNameCOMMENT_LINE	this will go away together with the method in 4.0. 
config	TokenNameIdentifier	 config
.	TokenNameDOT	
setMaxBufferedDeleteTerms	TokenNameIdentifier	 set Max Buffered Delete Terms
(	TokenNameLPAREN	
maxBufferedDeleteTerms	TokenNameIdentifier	 max Buffered Delete Terms
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
/** * Returns the number of buffered deleted terms that will * trigger a flush if enabled. * @see #setMaxBufferedDeleteTerms * @deprecated use {@link IndexWriterConfig#getMaxBufferedDeleteTerms()} instead */	TokenNameCOMMENT_JAVADOC	 Returns the number of buffered deleted terms that will trigger a flush if enabled. @see #setMaxBufferedDeleteTerms @deprecated use {@link IndexWriterConfig#getMaxBufferedDeleteTerms()} instead 
@	TokenNameAT	
Deprecated	TokenNameIdentifier	 Deprecated
public	TokenNamepublic	
int	TokenNameint	
getMaxBufferedDeleteTerms	TokenNameIdentifier	 get Max Buffered Delete Terms
(	TokenNameLPAREN	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
ensureOpen	TokenNameIdentifier	 ensure Open
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
return	TokenNamereturn	
config	TokenNameIdentifier	 config
.	TokenNameDOT	
getMaxBufferedDeleteTerms	TokenNameIdentifier	 get Max Buffered Delete Terms
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
/** Determines how often segment indices are merged by addDocument(). With * smaller values, less RAM is used while indexing, and searches on * unoptimized indices are faster, but indexing speed is slower. With larger * values, more RAM is used during indexing, and while searches on unoptimized * indices are slower, indexing is faster. Thus larger values (> 10) are best * for batch index creation, and smaller values (< 10) for indices that are * interactively maintained. * * <p>Note that this method is a convenience method: it * just calls mergePolicy.setMergeFactor as long as * mergePolicy is an instance of {@link LogMergePolicy}. * Otherwise an IllegalArgumentException is thrown.</p> * * <p>This must never be less than 2. The default value is 10. * @deprecated use {@link LogMergePolicy#setMergeFactor(int)} directly. */	TokenNameCOMMENT_JAVADOC	 Determines how often segment indices are merged by addDocument(). With smaller values, less RAM is used while indexing, and searches on unoptimized indices are faster, but indexing speed is slower. With larger values, more RAM is used during indexing, and while searches on unoptimized indices are slower, indexing is faster. Thus larger values (> 10) are best for batch index creation, and smaller values (< 10) for indices that are interactively maintained. * <p>Note that this method is a convenience method: it just calls mergePolicy.setMergeFactor as long as mergePolicy is an instance of {@link LogMergePolicy}. Otherwise an IllegalArgumentException is thrown.</p> * <p>This must never be less than 2. The default value is 10. @deprecated use {@link LogMergePolicy#setMergeFactor(int)} directly. 
@	TokenNameAT	
Deprecated	TokenNameIdentifier	 Deprecated
public	TokenNamepublic	
void	TokenNamevoid	
setMergeFactor	TokenNameIdentifier	 set Merge Factor
(	TokenNameLPAREN	
int	TokenNameint	
mergeFactor	TokenNameIdentifier	 merge Factor
)	TokenNameRPAREN	
{	TokenNameLBRACE	
getLogMergePolicy	TokenNameIdentifier	 get Log Merge Policy
(	TokenNameLPAREN	
)	TokenNameRPAREN	
.	TokenNameDOT	
setMergeFactor	TokenNameIdentifier	 set Merge Factor
(	TokenNameLPAREN	
mergeFactor	TokenNameIdentifier	 merge Factor
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
/** * <p>Returns the number of segments that are merged at * once and also controls the total number of segments * allowed to accumulate in the index.</p> * * <p>Note that this method is a convenience method: it * just calls mergePolicy.getMergeFactor as long as * mergePolicy is an instance of {@link LogMergePolicy}. * Otherwise an IllegalArgumentException is thrown.</p> * * @see #setMergeFactor * @deprecated use {@link LogMergePolicy#getMergeFactor()} directly. */	TokenNameCOMMENT_JAVADOC	 <p>Returns the number of segments that are merged at once and also controls the total number of segments allowed to accumulate in the index.</p> * <p>Note that this method is a convenience method: it just calls mergePolicy.getMergeFactor as long as mergePolicy is an instance of {@link LogMergePolicy}. Otherwise an IllegalArgumentException is thrown.</p> * @see #setMergeFactor @deprecated use {@link LogMergePolicy#getMergeFactor()} directly. 
@	TokenNameAT	
Deprecated	TokenNameIdentifier	 Deprecated
public	TokenNamepublic	
int	TokenNameint	
getMergeFactor	TokenNameIdentifier	 get Merge Factor
(	TokenNameLPAREN	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
return	TokenNamereturn	
getLogMergePolicy	TokenNameIdentifier	 get Log Merge Policy
(	TokenNameLPAREN	
)	TokenNameRPAREN	
.	TokenNameDOT	
getMergeFactor	TokenNameIdentifier	 get Merge Factor
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
/** If non-null, this will be the default infoStream used * by a newly instantiated IndexWriter. * @see #setInfoStream */	TokenNameCOMMENT_JAVADOC	 If non-null, this will be the default infoStream used by a newly instantiated IndexWriter. @see #setInfoStream 
public	TokenNamepublic	
static	TokenNamestatic	
void	TokenNamevoid	
setDefaultInfoStream	TokenNameIdentifier	 set Default Info Stream
(	TokenNameLPAREN	
PrintStream	TokenNameIdentifier	 Print Stream
infoStream	TokenNameIdentifier	 info Stream
)	TokenNameRPAREN	
{	TokenNameLBRACE	
IndexWriter	TokenNameIdentifier	 Index Writer
.	TokenNameDOT	
defaultInfoStream	TokenNameIdentifier	 default Info Stream
=	TokenNameEQUAL	
infoStream	TokenNameIdentifier	 info Stream
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
/** * Returns the current default infoStream for newly * instantiated IndexWriters. * @see #setDefaultInfoStream */	TokenNameCOMMENT_JAVADOC	 Returns the current default infoStream for newly instantiated IndexWriters. @see #setDefaultInfoStream 
public	TokenNamepublic	
static	TokenNamestatic	
PrintStream	TokenNameIdentifier	 Print Stream
getDefaultInfoStream	TokenNameIdentifier	 get Default Info Stream
(	TokenNameLPAREN	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
return	TokenNamereturn	
IndexWriter	TokenNameIdentifier	 Index Writer
.	TokenNameDOT	
defaultInfoStream	TokenNameIdentifier	 default Info Stream
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
/** If non-null, information about merges, deletes and a * message when maxFieldLength is reached will be printed * to this. */	TokenNameCOMMENT_JAVADOC	 If non-null, information about merges, deletes and a message when maxFieldLength is reached will be printed to this. 
public	TokenNamepublic	
void	TokenNamevoid	
setInfoStream	TokenNameIdentifier	 set Info Stream
(	TokenNameLPAREN	
PrintStream	TokenNameIdentifier	 Print Stream
infoStream	TokenNameIdentifier	 info Stream
)	TokenNameRPAREN	
throws	TokenNamethrows	
IOException	TokenNameIdentifier	 IO Exception
{	TokenNameLBRACE	
ensureOpen	TokenNameIdentifier	 ensure Open
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
this	TokenNamethis	
.	TokenNameDOT	
infoStream	TokenNameIdentifier	 info Stream
=	TokenNameEQUAL	
infoStream	TokenNameIdentifier	 info Stream
;	TokenNameSEMICOLON	
docWriter	TokenNameIdentifier	 doc Writer
.	TokenNameDOT	
setInfoStream	TokenNameIdentifier	 set Info Stream
(	TokenNameLPAREN	
infoStream	TokenNameIdentifier	 info Stream
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
deleter	TokenNameIdentifier	 deleter
.	TokenNameDOT	
setInfoStream	TokenNameIdentifier	 set Info Stream
(	TokenNameLPAREN	
infoStream	TokenNameIdentifier	 info Stream
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
bufferedDeletesStream	TokenNameIdentifier	 buffered Deletes Stream
.	TokenNameDOT	
setInfoStream	TokenNameIdentifier	 set Info Stream
(	TokenNameLPAREN	
infoStream	TokenNameIdentifier	 info Stream
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
if	TokenNameif	
(	TokenNameLPAREN	
infoStream	TokenNameIdentifier	 info Stream
!=	TokenNameNOT_EQUAL	
null	TokenNamenull	
)	TokenNameRPAREN	
messageState	TokenNameIdentifier	 message State
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
private	TokenNameprivate	
void	TokenNamevoid	
messageState	TokenNameIdentifier	 message State
(	TokenNameLPAREN	
)	TokenNameRPAREN	
throws	TokenNamethrows	
IOException	TokenNameIdentifier	 IO Exception
{	TokenNameLBRACE	
message	TokenNameIdentifier	 message
(	TokenNameLPAREN	
" dir="	TokenNameStringLiteral	 dir=
+	TokenNamePLUS	
directory	TokenNameIdentifier	 directory
+	TokenNamePLUS	
" "	TokenNameStringLiteral	 
+	TokenNamePLUS	
"index="	TokenNameStringLiteral	index=
+	TokenNamePLUS	
segString	TokenNameIdentifier	 seg String
(	TokenNameLPAREN	
)	TokenNameRPAREN	
+	TokenNamePLUS	
" "	TokenNameStringLiteral	 
+	TokenNamePLUS	
"version="	TokenNameStringLiteral	version=
+	TokenNamePLUS	
Constants	TokenNameIdentifier	 Constants
.	TokenNameDOT	
LUCENE_VERSION	TokenNameIdentifier	 LUCENE  VERSION
+	TokenNamePLUS	
" "	TokenNameStringLiteral	 
+	TokenNamePLUS	
config	TokenNameIdentifier	 config
.	TokenNameDOT	
toString	TokenNameIdentifier	 to String
(	TokenNameLPAREN	
)	TokenNameRPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
/** * Returns the current infoStream in use by this writer. * @see #setInfoStream */	TokenNameCOMMENT_JAVADOC	 Returns the current infoStream in use by this writer. @see #setInfoStream 
public	TokenNamepublic	
PrintStream	TokenNameIdentifier	 Print Stream
getInfoStream	TokenNameIdentifier	 get Info Stream
(	TokenNameLPAREN	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
ensureOpen	TokenNameIdentifier	 ensure Open
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
return	TokenNamereturn	
infoStream	TokenNameIdentifier	 info Stream
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
/** Returns true if verbosing is enabled (i.e., infoStream != null). */	TokenNameCOMMENT_JAVADOC	 Returns true if verbosing is enabled (i.e., infoStream != null). 
public	TokenNamepublic	
boolean	TokenNameboolean	
verbose	TokenNameIdentifier	 verbose
(	TokenNameLPAREN	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
return	TokenNamereturn	
infoStream	TokenNameIdentifier	 info Stream
!=	TokenNameNOT_EQUAL	
null	TokenNamenull	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
/** * Sets the maximum time to wait for a write lock (in milliseconds) for this instance of IndexWriter. @see * @see #setDefaultWriteLockTimeout to change the default value for all instances of IndexWriter. * @deprecated use {@link IndexWriterConfig#setWriteLockTimeout(long)} instead */	TokenNameCOMMENT_JAVADOC	 Sets the maximum time to wait for a write lock (in milliseconds) for this instance of IndexWriter. @see @see #setDefaultWriteLockTimeout to change the default value for all instances of IndexWriter. @deprecated use {@link IndexWriterConfig#setWriteLockTimeout(long)} instead 
@	TokenNameAT	
Deprecated	TokenNameIdentifier	 Deprecated
public	TokenNamepublic	
void	TokenNamevoid	
setWriteLockTimeout	TokenNameIdentifier	 set Write Lock Timeout
(	TokenNameLPAREN	
long	TokenNamelong	
writeLockTimeout	TokenNameIdentifier	 write Lock Timeout
)	TokenNameRPAREN	
{	TokenNameLBRACE	
ensureOpen	TokenNameIdentifier	 ensure Open
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
this	TokenNamethis	
.	TokenNameDOT	
writeLockTimeout	TokenNameIdentifier	 write Lock Timeout
=	TokenNameEQUAL	
writeLockTimeout	TokenNameIdentifier	 write Lock Timeout
;	TokenNameSEMICOLON	
// Required so config.getWriteLockTimeout returns the right value. But this 	TokenNameCOMMENT_LINE	Required so config.getWriteLockTimeout returns the right value. But this 
// will go away together with the method in 4.0. 	TokenNameCOMMENT_LINE	will go away together with the method in 4.0. 
config	TokenNameIdentifier	 config
.	TokenNameDOT	
setWriteLockTimeout	TokenNameIdentifier	 set Write Lock Timeout
(	TokenNameLPAREN	
writeLockTimeout	TokenNameIdentifier	 write Lock Timeout
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
/** * Returns allowed timeout when acquiring the write lock. * @see #setWriteLockTimeout * @deprecated use {@link IndexWriterConfig#getWriteLockTimeout()} */	TokenNameCOMMENT_JAVADOC	 Returns allowed timeout when acquiring the write lock. @see #setWriteLockTimeout @deprecated use {@link IndexWriterConfig#getWriteLockTimeout()} 
@	TokenNameAT	
Deprecated	TokenNameIdentifier	 Deprecated
public	TokenNamepublic	
long	TokenNamelong	
getWriteLockTimeout	TokenNameIdentifier	 get Write Lock Timeout
(	TokenNameLPAREN	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
ensureOpen	TokenNameIdentifier	 ensure Open
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
return	TokenNamereturn	
writeLockTimeout	TokenNameIdentifier	 write Lock Timeout
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
/** * Sets the default (for any instance of IndexWriter) maximum time to wait for a write lock (in * milliseconds). * @deprecated use {@link IndexWriterConfig#setDefaultWriteLockTimeout(long)} instead */	TokenNameCOMMENT_JAVADOC	 Sets the default (for any instance of IndexWriter) maximum time to wait for a write lock (in milliseconds). @deprecated use {@link IndexWriterConfig#setDefaultWriteLockTimeout(long)} instead 
@	TokenNameAT	
Deprecated	TokenNameIdentifier	 Deprecated
public	TokenNamepublic	
static	TokenNamestatic	
void	TokenNamevoid	
setDefaultWriteLockTimeout	TokenNameIdentifier	 set Default Write Lock Timeout
(	TokenNameLPAREN	
long	TokenNamelong	
writeLockTimeout	TokenNameIdentifier	 write Lock Timeout
)	TokenNameRPAREN	
{	TokenNameLBRACE	
IndexWriterConfig	TokenNameIdentifier	 Index Writer Config
.	TokenNameDOT	
setDefaultWriteLockTimeout	TokenNameIdentifier	 set Default Write Lock Timeout
(	TokenNameLPAREN	
writeLockTimeout	TokenNameIdentifier	 write Lock Timeout
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
/** * Returns default write lock timeout for newly * instantiated IndexWriters. * @see #setDefaultWriteLockTimeout * @deprecated use {@link IndexWriterConfig#getDefaultWriteLockTimeout()} instead */	TokenNameCOMMENT_JAVADOC	 Returns default write lock timeout for newly instantiated IndexWriters. @see #setDefaultWriteLockTimeout @deprecated use {@link IndexWriterConfig#getDefaultWriteLockTimeout()} instead 
@	TokenNameAT	
Deprecated	TokenNameIdentifier	 Deprecated
public	TokenNamepublic	
static	TokenNamestatic	
long	TokenNamelong	
getDefaultWriteLockTimeout	TokenNameIdentifier	 get Default Write Lock Timeout
(	TokenNameLPAREN	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
return	TokenNamereturn	
IndexWriterConfig	TokenNameIdentifier	 Index Writer Config
.	TokenNameDOT	
getDefaultWriteLockTimeout	TokenNameIdentifier	 get Default Write Lock Timeout
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
/** * Commits all changes to an index and closes all * associated files. Note that this may be a costly * operation, so, try to re-use a single writer instead of * closing and opening a new one. See {@link #commit()} for * caveats about write caching done by some IO devices. * * <p> If an Exception is hit during close, eg due to disk * full or some other reason, then both the on-disk index * and the internal state of the IndexWriter instance will * be consistent. However, the close will not be complete * even though part of it (flushing buffered documents) * may have succeeded, so the write lock will still be * held.</p> * * <p> If you can correct the underlying cause (eg free up * some disk space) then you can call close() again. * Failing that, if you want to force the write lock to be * released (dangerous, because you may then lose buffered * docs in the IndexWriter instance) then you can do * something like this:</p> * * <pre> * try { * writer.close(); * } finally { * if (IndexWriter.isLocked(directory)) { * IndexWriter.unlock(directory); * } * } * </pre> * * after which, you must be certain not to use the writer * instance anymore.</p> * * <p><b>NOTE</b>: if this method hits an OutOfMemoryError * you should immediately close the writer, again. See <a * href="#OOME">above</a> for details.</p> * * @throws CorruptIndexException if the index is corrupt * @throws IOException if there is a low-level IO error */	TokenNameCOMMENT_JAVADOC	 Commits all changes to an index and closes all associated files. Note that this may be a costly operation, so, try to re-use a single writer instead of closing and opening a new one. See {@link #commit()} for caveats about write caching done by some IO devices. * <p> If an Exception is hit during close, eg due to disk full or some other reason, then both the on-disk index and the internal state of the IndexWriter instance will be consistent. However, the close will not be complete even though part of it (flushing buffered documents) may have succeeded, so the write lock will still be held.</p> * <p> If you can correct the underlying cause (eg free up some disk space) then you can call close() again. Failing that, if you want to force the write lock to be released (dangerous, because you may then lose buffered docs in the IndexWriter instance) then you can do something like this:</p> * <pre> try { writer.close(); } finally { if (IndexWriter.isLocked(directory)) { IndexWriter.unlock(directory); } } </pre> * after which, you must be certain not to use the writer instance anymore.</p> * <p><b>NOTE</b>: if this method hits an OutOfMemoryError you should immediately close the writer, again. See <a href="#OOME">above</a> for details.</p> * @throws CorruptIndexException if the index is corrupt @throws IOException if there is a low-level IO error 
public	TokenNamepublic	
void	TokenNamevoid	
close	TokenNameIdentifier	 close
(	TokenNameLPAREN	
)	TokenNameRPAREN	
throws	TokenNamethrows	
CorruptIndexException	TokenNameIdentifier	 Corrupt Index Exception
,	TokenNameCOMMA	
IOException	TokenNameIdentifier	 IO Exception
{	TokenNameLBRACE	
close	TokenNameIdentifier	 close
(	TokenNameLPAREN	
true	TokenNametrue	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
/** * Closes the index with or without waiting for currently * running merges to finish. This is only meaningful when * using a MergeScheduler that runs merges in background * threads. * * <p><b>NOTE</b>: if this method hits an OutOfMemoryError * you should immediately close the writer, again. See <a * href="#OOME">above</a> for details.</p> * * <p><b>NOTE</b>: it is dangerous to always call * close(false), especially when IndexWriter is not open * for very long, because this can result in "merge * starvation" whereby long merges will never have a * chance to finish. This will cause too many segments in * your index over time.</p> * * @param waitForMerges if true, this call will block * until all merges complete; else, it will ask all * running merges to abort, wait until those merges have * finished (which should be at most a few seconds), and * then return. */	TokenNameCOMMENT_JAVADOC	 Closes the index with or without waiting for currently running merges to finish. This is only meaningful when using a MergeScheduler that runs merges in background threads. * <p><b>NOTE</b>: if this method hits an OutOfMemoryError you should immediately close the writer, again. See <a href="#OOME">above</a> for details.</p> * <p><b>NOTE</b>: it is dangerous to always call close(false), especially when IndexWriter is not open for very long, because this can result in "merge starvation" whereby long merges will never have a chance to finish. This will cause too many segments in your index over time.</p> * @param waitForMerges if true, this call will block until all merges complete; else, it will ask all running merges to abort, wait until those merges have finished (which should be at most a few seconds), and then return. 
public	TokenNamepublic	
void	TokenNamevoid	
close	TokenNameIdentifier	 close
(	TokenNameLPAREN	
boolean	TokenNameboolean	
waitForMerges	TokenNameIdentifier	 wait For Merges
)	TokenNameRPAREN	
throws	TokenNamethrows	
CorruptIndexException	TokenNameIdentifier	 Corrupt Index Exception
,	TokenNameCOMMA	
IOException	TokenNameIdentifier	 IO Exception
{	TokenNameLBRACE	
// Ensure that only one thread actually gets to do the closing: 	TokenNameCOMMENT_LINE	Ensure that only one thread actually gets to do the closing: 
if	TokenNameif	
(	TokenNameLPAREN	
shouldClose	TokenNameIdentifier	 should Close
(	TokenNameLPAREN	
)	TokenNameRPAREN	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
// If any methods have hit OutOfMemoryError, then abort 	TokenNameCOMMENT_LINE	If any methods have hit OutOfMemoryError, then abort 
// on close, in case the internal state of IndexWriter 	TokenNameCOMMENT_LINE	on close, in case the internal state of IndexWriter 
// or DocumentsWriter is corrupt 	TokenNameCOMMENT_LINE	or DocumentsWriter is corrupt 
if	TokenNameif	
(	TokenNameLPAREN	
hitOOM	TokenNameIdentifier	 hit OOM
)	TokenNameRPAREN	
rollbackInternal	TokenNameIdentifier	 rollback Internal
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
else	TokenNameelse	
closeInternal	TokenNameIdentifier	 close Internal
(	TokenNameLPAREN	
waitForMerges	TokenNameIdentifier	 wait For Merges
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
}	TokenNameRBRACE	
// Returns true if this thread should attempt to close, or 	TokenNameCOMMENT_LINE	Returns true if this thread should attempt to close, or 
// false if IndexWriter is now closed; else, waits until 	TokenNameCOMMENT_LINE	false if IndexWriter is now closed; else, waits until 
// another thread finishes closing 	TokenNameCOMMENT_LINE	another thread finishes closing 
synchronized	TokenNamesynchronized	
private	TokenNameprivate	
boolean	TokenNameboolean	
shouldClose	TokenNameIdentifier	 should Close
(	TokenNameLPAREN	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
while	TokenNamewhile	
(	TokenNameLPAREN	
true	TokenNametrue	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
if	TokenNameif	
(	TokenNameLPAREN	
!	TokenNameNOT	
closed	TokenNameIdentifier	 closed
)	TokenNameRPAREN	
{	TokenNameLBRACE	
if	TokenNameif	
(	TokenNameLPAREN	
!	TokenNameNOT	
closing	TokenNameIdentifier	 closing
)	TokenNameRPAREN	
{	TokenNameLBRACE	
closing	TokenNameIdentifier	 closing
=	TokenNameEQUAL	
true	TokenNametrue	
;	TokenNameSEMICOLON	
return	TokenNamereturn	
true	TokenNametrue	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
else	TokenNameelse	
{	TokenNameLBRACE	
// Another thread is presently trying to close; 	TokenNameCOMMENT_LINE	Another thread is presently trying to close; 
// wait until it finishes one way (closes 	TokenNameCOMMENT_LINE	wait until it finishes one way (closes 
// successfully) or another (fails to close) 	TokenNameCOMMENT_LINE	successfully) or another (fails to close) 
doWait	TokenNameIdentifier	 do Wait
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
}	TokenNameRBRACE	
else	TokenNameelse	
return	TokenNamereturn	
false	TokenNamefalse	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
}	TokenNameRBRACE	
private	TokenNameprivate	
void	TokenNamevoid	
closeInternal	TokenNameIdentifier	 close Internal
(	TokenNameLPAREN	
boolean	TokenNameboolean	
waitForMerges	TokenNameIdentifier	 wait For Merges
)	TokenNameRPAREN	
throws	TokenNamethrows	
CorruptIndexException	TokenNameIdentifier	 Corrupt Index Exception
,	TokenNameCOMMA	
IOException	TokenNameIdentifier	 IO Exception
{	TokenNameLBRACE	
try	TokenNametry	
{	TokenNameLBRACE	
if	TokenNameif	
(	TokenNameLPAREN	
pendingCommit	TokenNameIdentifier	 pending Commit
!=	TokenNameNOT_EQUAL	
null	TokenNamenull	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
throw	TokenNamethrow	
new	TokenNamenew	
IllegalStateException	TokenNameIdentifier	 Illegal State Exception
(	TokenNameLPAREN	
"cannot close: prepareCommit was already called with no corresponding call to commit"	TokenNameStringLiteral	cannot close: prepareCommit was already called with no corresponding call to commit
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
if	TokenNameif	
(	TokenNameLPAREN	
infoStream	TokenNameIdentifier	 info Stream
!=	TokenNameNOT_EQUAL	
null	TokenNamenull	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
message	TokenNameIdentifier	 message
(	TokenNameLPAREN	
"now flush at close waitForMerges="	TokenNameStringLiteral	now flush at close waitForMerges=
+	TokenNamePLUS	
waitForMerges	TokenNameIdentifier	 wait For Merges
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
docWriter	TokenNameIdentifier	 doc Writer
.	TokenNameDOT	
close	TokenNameIdentifier	 close
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
// Only allow a new merge to be triggered if we are 	TokenNameCOMMENT_LINE	Only allow a new merge to be triggered if we are 
// going to wait for merges: 	TokenNameCOMMENT_LINE	going to wait for merges: 
if	TokenNameif	
(	TokenNameLPAREN	
!	TokenNameNOT	
hitOOM	TokenNameIdentifier	 hit OOM
)	TokenNameRPAREN	
{	TokenNameLBRACE	
flush	TokenNameIdentifier	 flush
(	TokenNameLPAREN	
waitForMerges	TokenNameIdentifier	 wait For Merges
,	TokenNameCOMMA	
true	TokenNametrue	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
if	TokenNameif	
(	TokenNameLPAREN	
waitForMerges	TokenNameIdentifier	 wait For Merges
)	TokenNameRPAREN	
// Give merge scheduler last chance to run, in case 	TokenNameCOMMENT_LINE	Give merge scheduler last chance to run, in case 
// any pending merges are waiting: 	TokenNameCOMMENT_LINE	any pending merges are waiting: 
mergeScheduler	TokenNameIdentifier	 merge Scheduler
.	TokenNameDOT	
merge	TokenNameIdentifier	 merge
(	TokenNameLPAREN	
this	TokenNamethis	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
mergePolicy	TokenNameIdentifier	 merge Policy
.	TokenNameDOT	
close	TokenNameIdentifier	 close
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
synchronized	TokenNamesynchronized	
(	TokenNameLPAREN	
this	TokenNamethis	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
finishMerges	TokenNameIdentifier	 finish Merges
(	TokenNameLPAREN	
waitForMerges	TokenNameIdentifier	 wait For Merges
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
stopMerges	TokenNameIdentifier	 stop Merges
=	TokenNameEQUAL	
true	TokenNametrue	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
mergeScheduler	TokenNameIdentifier	 merge Scheduler
.	TokenNameDOT	
close	TokenNameIdentifier	 close
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
if	TokenNameif	
(	TokenNameLPAREN	
infoStream	TokenNameIdentifier	 info Stream
!=	TokenNameNOT_EQUAL	
null	TokenNamenull	
)	TokenNameRPAREN	
message	TokenNameIdentifier	 message
(	TokenNameLPAREN	
"now call final commit()"	TokenNameStringLiteral	now call final commit()
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
if	TokenNameif	
(	TokenNameLPAREN	
!	TokenNameNOT	
hitOOM	TokenNameIdentifier	 hit OOM
)	TokenNameRPAREN	
{	TokenNameLBRACE	
commitInternal	TokenNameIdentifier	 commit Internal
(	TokenNameLPAREN	
null	TokenNamenull	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
if	TokenNameif	
(	TokenNameLPAREN	
infoStream	TokenNameIdentifier	 info Stream
!=	TokenNameNOT_EQUAL	
null	TokenNamenull	
)	TokenNameRPAREN	
message	TokenNameIdentifier	 message
(	TokenNameLPAREN	
"at close: "	TokenNameStringLiteral	at close: 
+	TokenNamePLUS	
segString	TokenNameIdentifier	 seg String
(	TokenNameLPAREN	
)	TokenNameRPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
synchronized	TokenNamesynchronized	
(	TokenNameLPAREN	
this	TokenNamethis	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
readerPool	TokenNameIdentifier	 reader Pool
.	TokenNameDOT	
close	TokenNameIdentifier	 close
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
docWriter	TokenNameIdentifier	 doc Writer
=	TokenNameEQUAL	
null	TokenNamenull	
;	TokenNameSEMICOLON	
deleter	TokenNameIdentifier	 deleter
.	TokenNameDOT	
close	TokenNameIdentifier	 close
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
if	TokenNameif	
(	TokenNameLPAREN	
writeLock	TokenNameIdentifier	 write Lock
!=	TokenNameNOT_EQUAL	
null	TokenNamenull	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
writeLock	TokenNameIdentifier	 write Lock
.	TokenNameDOT	
release	TokenNameIdentifier	 release
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
// release write lock 	TokenNameCOMMENT_LINE	release write lock 
writeLock	TokenNameIdentifier	 write Lock
=	TokenNameEQUAL	
null	TokenNamenull	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
synchronized	TokenNamesynchronized	
(	TokenNameLPAREN	
this	TokenNamethis	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
closed	TokenNameIdentifier	 closed
=	TokenNameEQUAL	
true	TokenNametrue	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
}	TokenNameRBRACE	
catch	TokenNamecatch	
(	TokenNameLPAREN	
OutOfMemoryError	TokenNameIdentifier	 Out Of Memory Error
oom	TokenNameIdentifier	 oom
)	TokenNameRPAREN	
{	TokenNameLBRACE	
handleOOM	TokenNameIdentifier	 handle OOM
(	TokenNameLPAREN	
oom	TokenNameIdentifier	 oom
,	TokenNameCOMMA	
"closeInternal"	TokenNameStringLiteral	closeInternal
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
finally	TokenNamefinally	
{	TokenNameLBRACE	
synchronized	TokenNamesynchronized	
(	TokenNameLPAREN	
this	TokenNamethis	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
closing	TokenNameIdentifier	 closing
=	TokenNameEQUAL	
false	TokenNamefalse	
;	TokenNameSEMICOLON	
notifyAll	TokenNameIdentifier	 notify All
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
if	TokenNameif	
(	TokenNameLPAREN	
!	TokenNameNOT	
closed	TokenNameIdentifier	 closed
)	TokenNameRPAREN	
{	TokenNameLBRACE	
if	TokenNameif	
(	TokenNameLPAREN	
infoStream	TokenNameIdentifier	 info Stream
!=	TokenNameNOT_EQUAL	
null	TokenNamenull	
)	TokenNameRPAREN	
message	TokenNameIdentifier	 message
(	TokenNameLPAREN	
"hit exception while closing"	TokenNameStringLiteral	hit exception while closing
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
}	TokenNameRBRACE	
}	TokenNameRBRACE	
}	TokenNameRBRACE	
/** Returns the Directory used by this index. */	TokenNameCOMMENT_JAVADOC	 Returns the Directory used by this index. 
public	TokenNamepublic	
Directory	TokenNameIdentifier	 Directory
getDirectory	TokenNameIdentifier	 get Directory
(	TokenNameLPAREN	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
// Pass false because the flush during closing calls getDirectory 	TokenNameCOMMENT_LINE	Pass false because the flush during closing calls getDirectory 
ensureOpen	TokenNameIdentifier	 ensure Open
(	TokenNameLPAREN	
false	TokenNamefalse	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
return	TokenNamereturn	
directory	TokenNameIdentifier	 directory
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
/** Returns the analyzer used by this index. */	TokenNameCOMMENT_JAVADOC	 Returns the analyzer used by this index. 
public	TokenNamepublic	
Analyzer	TokenNameIdentifier	 Analyzer
getAnalyzer	TokenNameIdentifier	 get Analyzer
(	TokenNameLPAREN	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
ensureOpen	TokenNameIdentifier	 ensure Open
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
return	TokenNamereturn	
analyzer	TokenNameIdentifier	 analyzer
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
/** Returns total number of docs in this index, including * docs not yet flushed (still in the RAM buffer), * not counting deletions. * @see #numDocs */	TokenNameCOMMENT_JAVADOC	 Returns total number of docs in this index, including docs not yet flushed (still in the RAM buffer), not counting deletions. @see #numDocs 
public	TokenNamepublic	
synchronized	TokenNamesynchronized	
int	TokenNameint	
maxDoc	TokenNameIdentifier	 max Doc
(	TokenNameLPAREN	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
ensureOpen	TokenNameIdentifier	 ensure Open
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
int	TokenNameint	
count	TokenNameIdentifier	 count
;	TokenNameSEMICOLON	
if	TokenNameif	
(	TokenNameLPAREN	
docWriter	TokenNameIdentifier	 doc Writer
!=	TokenNameNOT_EQUAL	
null	TokenNamenull	
)	TokenNameRPAREN	
count	TokenNameIdentifier	 count
=	TokenNameEQUAL	
docWriter	TokenNameIdentifier	 doc Writer
.	TokenNameDOT	
getNumDocs	TokenNameIdentifier	 get Num Docs
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
else	TokenNameelse	
count	TokenNameIdentifier	 count
=	TokenNameEQUAL	
0	TokenNameIntegerLiteral	
;	TokenNameSEMICOLON	
count	TokenNameIdentifier	 count
+=	TokenNamePLUS_EQUAL	
segmentInfos	TokenNameIdentifier	 segment Infos
.	TokenNameDOT	
totalDocCount	TokenNameIdentifier	 total Doc Count
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
return	TokenNamereturn	
count	TokenNameIdentifier	 count
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
/** Returns total number of docs in this index, including * docs not yet flushed (still in the RAM buffer), and * including deletions. <b>NOTE:</b> buffered deletions * are not counted. If you really need these to be * counted you should call {@link #commit()} first. * @see #numDocs */	TokenNameCOMMENT_JAVADOC	 Returns total number of docs in this index, including docs not yet flushed (still in the RAM buffer), and including deletions. <b>NOTE:</b> buffered deletions are not counted. If you really need these to be counted you should call {@link #commit()} first. @see #numDocs 
public	TokenNamepublic	
synchronized	TokenNamesynchronized	
int	TokenNameint	
numDocs	TokenNameIdentifier	 num Docs
(	TokenNameLPAREN	
)	TokenNameRPAREN	
throws	TokenNamethrows	
IOException	TokenNameIdentifier	 IO Exception
{	TokenNameLBRACE	
ensureOpen	TokenNameIdentifier	 ensure Open
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
int	TokenNameint	
count	TokenNameIdentifier	 count
;	TokenNameSEMICOLON	
if	TokenNameif	
(	TokenNameLPAREN	
docWriter	TokenNameIdentifier	 doc Writer
!=	TokenNameNOT_EQUAL	
null	TokenNamenull	
)	TokenNameRPAREN	
count	TokenNameIdentifier	 count
=	TokenNameEQUAL	
docWriter	TokenNameIdentifier	 doc Writer
.	TokenNameDOT	
getNumDocs	TokenNameIdentifier	 get Num Docs
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
else	TokenNameelse	
count	TokenNameIdentifier	 count
=	TokenNameEQUAL	
0	TokenNameIntegerLiteral	
;	TokenNameSEMICOLON	
for	TokenNamefor	
(	TokenNameLPAREN	
final	TokenNamefinal	
SegmentInfo	TokenNameIdentifier	 Segment Info
info	TokenNameIdentifier	 info
:	TokenNameCOLON	
segmentInfos	TokenNameIdentifier	 segment Infos
)	TokenNameRPAREN	
{	TokenNameLBRACE	
count	TokenNameIdentifier	 count
+=	TokenNamePLUS_EQUAL	
info	TokenNameIdentifier	 info
.	TokenNameDOT	
docCount	TokenNameIdentifier	 doc Count
-	TokenNameMINUS	
numDeletedDocs	TokenNameIdentifier	 num Deleted Docs
(	TokenNameLPAREN	
info	TokenNameIdentifier	 info
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
return	TokenNamereturn	
count	TokenNameIdentifier	 count
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
public	TokenNamepublic	
synchronized	TokenNamesynchronized	
boolean	TokenNameboolean	
hasDeletions	TokenNameIdentifier	 has Deletions
(	TokenNameLPAREN	
)	TokenNameRPAREN	
throws	TokenNamethrows	
IOException	TokenNameIdentifier	 IO Exception
{	TokenNameLBRACE	
ensureOpen	TokenNameIdentifier	 ensure Open
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
if	TokenNameif	
(	TokenNameLPAREN	
bufferedDeletesStream	TokenNameIdentifier	 buffered Deletes Stream
.	TokenNameDOT	
any	TokenNameIdentifier	 any
(	TokenNameLPAREN	
)	TokenNameRPAREN	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
return	TokenNamereturn	
true	TokenNametrue	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
if	TokenNameif	
(	TokenNameLPAREN	
docWriter	TokenNameIdentifier	 doc Writer
.	TokenNameDOT	
anyDeletions	TokenNameIdentifier	 any Deletions
(	TokenNameLPAREN	
)	TokenNameRPAREN	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
return	TokenNamereturn	
true	TokenNametrue	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
for	TokenNamefor	
(	TokenNameLPAREN	
final	TokenNamefinal	
SegmentInfo	TokenNameIdentifier	 Segment Info
info	TokenNameIdentifier	 info
:	TokenNameCOLON	
segmentInfos	TokenNameIdentifier	 segment Infos
)	TokenNameRPAREN	
{	TokenNameLBRACE	
if	TokenNameif	
(	TokenNameLPAREN	
info	TokenNameIdentifier	 info
.	TokenNameDOT	
hasDeletions	TokenNameIdentifier	 has Deletions
(	TokenNameLPAREN	
)	TokenNameRPAREN	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
return	TokenNamereturn	
true	TokenNametrue	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
}	TokenNameRBRACE	
return	TokenNamereturn	
false	TokenNamefalse	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
/** * The maximum number of terms that will be indexed for a single field in a * document. This limits the amount of memory required for indexing, so that * collections with very large files will not crash the indexing process by * running out of memory.<p/> * Note that this effectively truncates large documents, excluding from the * index terms that occur further in the document. If you know your source * documents are large, be sure to set this value high enough to accommodate * the expected size. If you set it to Integer.MAX_VALUE, then the only limit * is your memory, but you should anticipate an OutOfMemoryError.<p/> * By default, no more than 10,000 terms will be indexed for a field. * * @see MaxFieldLength * @deprecated remove in 4.0 */	TokenNameCOMMENT_JAVADOC	 The maximum number of terms that will be indexed for a single field in a document. This limits the amount of memory required for indexing, so that collections with very large files will not crash the indexing process by running out of memory.<p/> Note that this effectively truncates large documents, excluding from the index terms that occur further in the document. If you know your source documents are large, be sure to set this value high enough to accommodate the expected size. If you set it to Integer.MAX_VALUE, then the only limit is your memory, but you should anticipate an OutOfMemoryError.<p/> By default, no more than 10,000 terms will be indexed for a field. * @see MaxFieldLength @deprecated remove in 4.0 
@	TokenNameAT	
Deprecated	TokenNameIdentifier	 Deprecated
private	TokenNameprivate	
int	TokenNameint	
maxFieldLength	TokenNameIdentifier	 max Field Length
=	TokenNameEQUAL	
DEFAULT_MAX_FIELD_LENGTH	TokenNameIdentifier	 DEFAULT  MAX  FIELD  LENGTH
;	TokenNameSEMICOLON	
/** * Adds a document to this index. If the document contains more than * {@link #setMaxFieldLength(int)} terms for a given field, the remainder are * discarded. * * <p> Note that if an Exception is hit (for example disk full) * then the index will be consistent, but this document * may not have been added. Furthermore, it's possible * the index will have one segment in non-compound format * even when using compound files (when a merge has * partially succeeded).</p> * * <p> This method periodically flushes pending documents * to the Directory (see <a href="#flush">above</a>), and * also periodically triggers segment merges in the index * according to the {@link MergePolicy} in use.</p> * * <p>Merges temporarily consume space in the * directory. The amount of space required is up to 1X the * size of all segments being merged, when no * readers/searchers are open against the index, and up to * 2X the size of all segments being merged when * readers/searchers are open against the index (see * {@link #forceMerge(int)} for details). The sequence of * primitive merge operations performed is governed by the * merge policy. * * <p>Note that each term in the document can be no longer * than 16383 characters, otherwise an * IllegalArgumentException will be thrown.</p> * * <p>Note that it's possible to create an invalid Unicode * string in java if a UTF16 surrogate pair is malformed. * In this case, the invalid characters are silently * replaced with the Unicode replacement character * U+FFFD.</p> * * <p><b>NOTE</b>: if this method hits an OutOfMemoryError * you should immediately close the writer. See <a * href="#OOME">above</a> for details.</p> * * @throws CorruptIndexException if the index is corrupt * @throws IOException if there is a low-level IO error */	TokenNameCOMMENT_JAVADOC	 Adds a document to this index. If the document contains more than {@link #setMaxFieldLength(int)} terms for a given field, the remainder are discarded. * <p> Note that if an Exception is hit (for example disk full) then the index will be consistent, but this document may not have been added. Furthermore, it's possible the index will have one segment in non-compound format even when using compound files (when a merge has partially succeeded).</p> * <p> This method periodically flushes pending documents to the Directory (see <a href="#flush">above</a>), and also periodically triggers segment merges in the index according to the {@link MergePolicy} in use.</p> * <p>Merges temporarily consume space in the directory. The amount of space required is up to 1X the size of all segments being merged, when no readers/searchers are open against the index, and up to 2X the size of all segments being merged when readers/searchers are open against the index (see {@link #forceMerge(int)} for details). The sequence of primitive merge operations performed is governed by the merge policy. * <p>Note that each term in the document can be no longer than 16383 characters, otherwise an IllegalArgumentException will be thrown.</p> * <p>Note that it's possible to create an invalid Unicode string in java if a UTF16 surrogate pair is malformed. In this case, the invalid characters are silently replaced with the Unicode replacement character U+FFFD.</p> * <p><b>NOTE</b>: if this method hits an OutOfMemoryError you should immediately close the writer. See <a href="#OOME">above</a> for details.</p> * @throws CorruptIndexException if the index is corrupt @throws IOException if there is a low-level IO error 
public	TokenNamepublic	
void	TokenNamevoid	
addDocument	TokenNameIdentifier	 add Document
(	TokenNameLPAREN	
Document	TokenNameIdentifier	 Document
doc	TokenNameIdentifier	 doc
)	TokenNameRPAREN	
throws	TokenNamethrows	
CorruptIndexException	TokenNameIdentifier	 Corrupt Index Exception
,	TokenNameCOMMA	
IOException	TokenNameIdentifier	 IO Exception
{	TokenNameLBRACE	
addDocument	TokenNameIdentifier	 add Document
(	TokenNameLPAREN	
doc	TokenNameIdentifier	 doc
,	TokenNameCOMMA	
analyzer	TokenNameIdentifier	 analyzer
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
/** * Adds a document to this index, using the provided analyzer instead of the * value of {@link #getAnalyzer()}. If the document contains more than * {@link #setMaxFieldLength(int)} terms for a given field, the remainder are * discarded. * * <p>See {@link #addDocument(Document)} for details on * index and IndexWriter state after an Exception, and * flushing/merging temporary free space requirements.</p> * * <p><b>NOTE</b>: if this method hits an OutOfMemoryError * you should immediately close the writer. See <a * href="#OOME">above</a> for details.</p> * * @throws CorruptIndexException if the index is corrupt * @throws IOException if there is a low-level IO error */	TokenNameCOMMENT_JAVADOC	 Adds a document to this index, using the provided analyzer instead of the value of {@link #getAnalyzer()}. If the document contains more than {@link #setMaxFieldLength(int)} terms for a given field, the remainder are discarded. * <p>See {@link #addDocument(Document)} for details on index and IndexWriter state after an Exception, and flushing/merging temporary free space requirements.</p> * <p><b>NOTE</b>: if this method hits an OutOfMemoryError you should immediately close the writer. See <a href="#OOME">above</a> for details.</p> * @throws CorruptIndexException if the index is corrupt @throws IOException if there is a low-level IO error 
public	TokenNamepublic	
void	TokenNamevoid	
addDocument	TokenNameIdentifier	 add Document
(	TokenNameLPAREN	
Document	TokenNameIdentifier	 Document
doc	TokenNameIdentifier	 doc
,	TokenNameCOMMA	
Analyzer	TokenNameIdentifier	 Analyzer
analyzer	TokenNameIdentifier	 analyzer
)	TokenNameRPAREN	
throws	TokenNamethrows	
CorruptIndexException	TokenNameIdentifier	 Corrupt Index Exception
,	TokenNameCOMMA	
IOException	TokenNameIdentifier	 IO Exception
{	TokenNameLBRACE	
ensureOpen	TokenNameIdentifier	 ensure Open
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
boolean	TokenNameboolean	
doFlush	TokenNameIdentifier	 do Flush
=	TokenNameEQUAL	
false	TokenNamefalse	
;	TokenNameSEMICOLON	
boolean	TokenNameboolean	
success	TokenNameIdentifier	 success
=	TokenNameEQUAL	
false	TokenNamefalse	
;	TokenNameSEMICOLON	
try	TokenNametry	
{	TokenNameLBRACE	
try	TokenNametry	
{	TokenNameLBRACE	
doFlush	TokenNameIdentifier	 do Flush
=	TokenNameEQUAL	
docWriter	TokenNameIdentifier	 doc Writer
.	TokenNameDOT	
updateDocument	TokenNameIdentifier	 update Document
(	TokenNameLPAREN	
doc	TokenNameIdentifier	 doc
,	TokenNameCOMMA	
analyzer	TokenNameIdentifier	 analyzer
,	TokenNameCOMMA	
null	TokenNamenull	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
success	TokenNameIdentifier	 success
=	TokenNameEQUAL	
true	TokenNametrue	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
finally	TokenNamefinally	
{	TokenNameLBRACE	
if	TokenNameif	
(	TokenNameLPAREN	
!	TokenNameNOT	
success	TokenNameIdentifier	 success
&&	TokenNameAND_AND	
infoStream	TokenNameIdentifier	 info Stream
!=	TokenNameNOT_EQUAL	
null	TokenNamenull	
)	TokenNameRPAREN	
message	TokenNameIdentifier	 message
(	TokenNameLPAREN	
"hit exception adding document"	TokenNameStringLiteral	hit exception adding document
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
if	TokenNameif	
(	TokenNameLPAREN	
doFlush	TokenNameIdentifier	 do Flush
)	TokenNameRPAREN	
flush	TokenNameIdentifier	 flush
(	TokenNameLPAREN	
true	TokenNametrue	
,	TokenNameCOMMA	
false	TokenNamefalse	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
catch	TokenNamecatch	
(	TokenNameLPAREN	
OutOfMemoryError	TokenNameIdentifier	 Out Of Memory Error
oom	TokenNameIdentifier	 oom
)	TokenNameRPAREN	
{	TokenNameLBRACE	
handleOOM	TokenNameIdentifier	 handle OOM
(	TokenNameLPAREN	
oom	TokenNameIdentifier	 oom
,	TokenNameCOMMA	
"addDocument"	TokenNameStringLiteral	addDocument
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
}	TokenNameRBRACE	
/** * Atomically adds a block of documents with sequentially * assigned document IDs, such that an external reader * will see all or none of the documents. * * <p><b>WARNING</b>: the index does not currently record * which documents were added as a block. Today this is * fine, because merging will preserve a block. The order of * documents within a segment will be preserved, even when child * documents within a block are deleted. Most search features * (like result grouping and block joining) require you to * mark documents; when these documents are deleted these * search features will not work as expected. Obviously adding * documents to an existing block will require you the reindex * the entire block. * * <p>However it's possible that in the future Lucene may * merge more aggressively re-order documents (for example, * perhaps to obtain better index compression), in which case * you may need to fully re-index your documents at that time. * * <p>See {@link #addDocument(Document)} for details on * index and IndexWriter state after an Exception, and * flushing/merging temporary free space requirements.</p> * * <p><b>NOTE</b>: tools that do offline splitting of an index * (for example, IndexSplitter in contrib) or * re-sorting of documents (for example, IndexSorter in * contrib) are not aware of these atomically added documents * and will likely break them up. Use such tools at your * own risk! * * <p><b>NOTE</b>: if this method hits an OutOfMemoryError * you should immediately close the writer. See <a * href="#OOME">above</a> for details.</p> * * @throws CorruptIndexException if the index is corrupt * @throws IOException if there is a low-level IO error * * @lucene.experimental */	TokenNameCOMMENT_JAVADOC	 Atomically adds a block of documents with sequentially assigned document IDs, such that an external reader will see all or none of the documents. * <p><b>WARNING</b>: the index does not currently record which documents were added as a block. Today this is fine, because merging will preserve a block. The order of documents within a segment will be preserved, even when child documents within a block are deleted. Most search features (like result grouping and block joining) require you to mark documents; when these documents are deleted these search features will not work as expected. Obviously adding documents to an existing block will require you the reindex the entire block. * <p>However it's possible that in the future Lucene may merge more aggressively re-order documents (for example, perhaps to obtain better index compression), in which case you may need to fully re-index your documents at that time. * <p>See {@link #addDocument(Document)} for details on index and IndexWriter state after an Exception, and flushing/merging temporary free space requirements.</p> * <p><b>NOTE</b>: tools that do offline splitting of an index (for example, IndexSplitter in contrib) or re-sorting of documents (for example, IndexSorter in contrib) are not aware of these atomically added documents and will likely break them up. Use such tools at your own risk! * <p><b>NOTE</b>: if this method hits an OutOfMemoryError you should immediately close the writer. See <a href="#OOME">above</a> for details.</p> * @throws CorruptIndexException if the index is corrupt @throws IOException if there is a low-level IO error * @lucene.experimental 
public	TokenNamepublic	
void	TokenNamevoid	
addDocuments	TokenNameIdentifier	 add Documents
(	TokenNameLPAREN	
Collection	TokenNameIdentifier	 Collection
<	TokenNameLESS	
Document	TokenNameIdentifier	 Document
>	TokenNameGREATER	
docs	TokenNameIdentifier	 docs
)	TokenNameRPAREN	
throws	TokenNamethrows	
CorruptIndexException	TokenNameIdentifier	 Corrupt Index Exception
,	TokenNameCOMMA	
IOException	TokenNameIdentifier	 IO Exception
{	TokenNameLBRACE	
// TODO: if we backport DWPT we should change arg to Iterable<Document> 	TokenNameCOMMENT_LINE	TODO: if we backport DWPT we should change arg to Iterable<Document> 
addDocuments	TokenNameIdentifier	 add Documents
(	TokenNameLPAREN	
docs	TokenNameIdentifier	 docs
,	TokenNameCOMMA	
analyzer	TokenNameIdentifier	 analyzer
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
/** * Atomically adds a block of documents, analyzed using the * provided analyzer, with sequentially assigned document * IDs, such that an external reader will see all or none * of the documents. * * @throws CorruptIndexException if the index is corrupt * @throws IOException if there is a low-level IO error * * @lucene.experimental */	TokenNameCOMMENT_JAVADOC	 Atomically adds a block of documents, analyzed using the provided analyzer, with sequentially assigned document IDs, such that an external reader will see all or none of the documents. * @throws CorruptIndexException if the index is corrupt @throws IOException if there is a low-level IO error * @lucene.experimental 
public	TokenNamepublic	
void	TokenNamevoid	
addDocuments	TokenNameIdentifier	 add Documents
(	TokenNameLPAREN	
Collection	TokenNameIdentifier	 Collection
<	TokenNameLESS	
Document	TokenNameIdentifier	 Document
>	TokenNameGREATER	
docs	TokenNameIdentifier	 docs
,	TokenNameCOMMA	
Analyzer	TokenNameIdentifier	 Analyzer
analyzer	TokenNameIdentifier	 analyzer
)	TokenNameRPAREN	
throws	TokenNamethrows	
CorruptIndexException	TokenNameIdentifier	 Corrupt Index Exception
,	TokenNameCOMMA	
IOException	TokenNameIdentifier	 IO Exception
{	TokenNameLBRACE	
// TODO: if we backport DWPT we should change arg to Iterable<Document> 	TokenNameCOMMENT_LINE	TODO: if we backport DWPT we should change arg to Iterable<Document> 
updateDocuments	TokenNameIdentifier	 update Documents
(	TokenNameLPAREN	
null	TokenNamenull	
,	TokenNameCOMMA	
docs	TokenNameIdentifier	 docs
,	TokenNameCOMMA	
analyzer	TokenNameIdentifier	 analyzer
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
/** * Atomically deletes documents matching the provided * delTerm and adds a block of documents with sequentially * assigned document IDs, such that an external reader * will see all or none of the documents. * * See {@link #addDocuments(Collection)}. * * @throws CorruptIndexException if the index is corrupt * @throws IOException if there is a low-level IO error * * @lucene.experimental */	TokenNameCOMMENT_JAVADOC	 Atomically deletes documents matching the provided delTerm and adds a block of documents with sequentially assigned document IDs, such that an external reader will see all or none of the documents. * See {@link #addDocuments(Collection)}. * @throws CorruptIndexException if the index is corrupt @throws IOException if there is a low-level IO error * @lucene.experimental 
public	TokenNamepublic	
void	TokenNamevoid	
updateDocuments	TokenNameIdentifier	 update Documents
(	TokenNameLPAREN	
Term	TokenNameIdentifier	 Term
delTerm	TokenNameIdentifier	 del Term
,	TokenNameCOMMA	
Collection	TokenNameIdentifier	 Collection
<	TokenNameLESS	
Document	TokenNameIdentifier	 Document
>	TokenNameGREATER	
docs	TokenNameIdentifier	 docs
)	TokenNameRPAREN	
throws	TokenNamethrows	
CorruptIndexException	TokenNameIdentifier	 Corrupt Index Exception
,	TokenNameCOMMA	
IOException	TokenNameIdentifier	 IO Exception
{	TokenNameLBRACE	
// TODO: if we backport DWPT we should change arg to Iterable<Document> 	TokenNameCOMMENT_LINE	TODO: if we backport DWPT we should change arg to Iterable<Document> 
updateDocuments	TokenNameIdentifier	 update Documents
(	TokenNameLPAREN	
delTerm	TokenNameIdentifier	 del Term
,	TokenNameCOMMA	
docs	TokenNameIdentifier	 docs
,	TokenNameCOMMA	
analyzer	TokenNameIdentifier	 analyzer
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
/** * Atomically deletes documents matching the provided * delTerm and adds a block of documents, analyzed using * the provided analyzer, with sequentially * assigned document IDs, such that an external reader * will see all or none of the documents. * * See {@link #addDocuments(Collection)}. * * @throws CorruptIndexException if the index is corrupt * @throws IOException if there is a low-level IO error * * @lucene.experimental */	TokenNameCOMMENT_JAVADOC	 Atomically deletes documents matching the provided delTerm and adds a block of documents, analyzed using the provided analyzer, with sequentially assigned document IDs, such that an external reader will see all or none of the documents. * See {@link #addDocuments(Collection)}. * @throws CorruptIndexException if the index is corrupt @throws IOException if there is a low-level IO error * @lucene.experimental 
public	TokenNamepublic	
void	TokenNamevoid	
updateDocuments	TokenNameIdentifier	 update Documents
(	TokenNameLPAREN	
Term	TokenNameIdentifier	 Term
delTerm	TokenNameIdentifier	 del Term
,	TokenNameCOMMA	
Collection	TokenNameIdentifier	 Collection
<	TokenNameLESS	
Document	TokenNameIdentifier	 Document
>	TokenNameGREATER	
docs	TokenNameIdentifier	 docs
,	TokenNameCOMMA	
Analyzer	TokenNameIdentifier	 Analyzer
analyzer	TokenNameIdentifier	 analyzer
)	TokenNameRPAREN	
throws	TokenNamethrows	
CorruptIndexException	TokenNameIdentifier	 Corrupt Index Exception
,	TokenNameCOMMA	
IOException	TokenNameIdentifier	 IO Exception
{	TokenNameLBRACE	
// TODO: if we backport DWPT we should change arg to Iterable<Document> 	TokenNameCOMMENT_LINE	TODO: if we backport DWPT we should change arg to Iterable<Document> 
ensureOpen	TokenNameIdentifier	 ensure Open
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
try	TokenNametry	
{	TokenNameLBRACE	
boolean	TokenNameboolean	
success	TokenNameIdentifier	 success
=	TokenNameEQUAL	
false	TokenNamefalse	
;	TokenNameSEMICOLON	
boolean	TokenNameboolean	
doFlush	TokenNameIdentifier	 do Flush
=	TokenNameEQUAL	
false	TokenNamefalse	
;	TokenNameSEMICOLON	
try	TokenNametry	
{	TokenNameLBRACE	
doFlush	TokenNameIdentifier	 do Flush
=	TokenNameEQUAL	
docWriter	TokenNameIdentifier	 doc Writer
.	TokenNameDOT	
updateDocuments	TokenNameIdentifier	 update Documents
(	TokenNameLPAREN	
docs	TokenNameIdentifier	 docs
,	TokenNameCOMMA	
analyzer	TokenNameIdentifier	 analyzer
,	TokenNameCOMMA	
delTerm	TokenNameIdentifier	 del Term
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
success	TokenNameIdentifier	 success
=	TokenNameEQUAL	
true	TokenNametrue	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
finally	TokenNamefinally	
{	TokenNameLBRACE	
if	TokenNameif	
(	TokenNameLPAREN	
!	TokenNameNOT	
success	TokenNameIdentifier	 success
&&	TokenNameAND_AND	
infoStream	TokenNameIdentifier	 info Stream
!=	TokenNameNOT_EQUAL	
null	TokenNamenull	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
message	TokenNameIdentifier	 message
(	TokenNameLPAREN	
"hit exception updating document"	TokenNameStringLiteral	hit exception updating document
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
}	TokenNameRBRACE	
if	TokenNameif	
(	TokenNameLPAREN	
doFlush	TokenNameIdentifier	 do Flush
)	TokenNameRPAREN	
{	TokenNameLBRACE	
flush	TokenNameIdentifier	 flush
(	TokenNameLPAREN	
true	TokenNametrue	
,	TokenNameCOMMA	
false	TokenNamefalse	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
}	TokenNameRBRACE	
catch	TokenNamecatch	
(	TokenNameLPAREN	
OutOfMemoryError	TokenNameIdentifier	 Out Of Memory Error
oom	TokenNameIdentifier	 oom
)	TokenNameRPAREN	
{	TokenNameLBRACE	
handleOOM	TokenNameIdentifier	 handle OOM
(	TokenNameLPAREN	
oom	TokenNameIdentifier	 oom
,	TokenNameCOMMA	
"updateDocuments"	TokenNameStringLiteral	updateDocuments
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
}	TokenNameRBRACE	
/** * Deletes the document(s) containing <code>term</code>. * * <p><b>NOTE</b>: if this method hits an OutOfMemoryError * you should immediately close the writer. See <a * href="#OOME">above</a> for details.</p> * * @param term the term to identify the documents to be deleted * @throws CorruptIndexException if the index is corrupt * @throws IOException if there is a low-level IO error */	TokenNameCOMMENT_JAVADOC	 Deletes the document(s) containing <code>term</code>. * <p><b>NOTE</b>: if this method hits an OutOfMemoryError you should immediately close the writer. See <a href="#OOME">above</a> for details.</p> * @param term the term to identify the documents to be deleted @throws CorruptIndexException if the index is corrupt @throws IOException if there is a low-level IO error 
public	TokenNamepublic	
void	TokenNamevoid	
deleteDocuments	TokenNameIdentifier	 delete Documents
(	TokenNameLPAREN	
Term	TokenNameIdentifier	 Term
term	TokenNameIdentifier	 term
)	TokenNameRPAREN	
throws	TokenNamethrows	
CorruptIndexException	TokenNameIdentifier	 Corrupt Index Exception
,	TokenNameCOMMA	
IOException	TokenNameIdentifier	 IO Exception
{	TokenNameLBRACE	
ensureOpen	TokenNameIdentifier	 ensure Open
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
try	TokenNametry	
{	TokenNameLBRACE	
if	TokenNameif	
(	TokenNameLPAREN	
docWriter	TokenNameIdentifier	 doc Writer
.	TokenNameDOT	
deleteTerm	TokenNameIdentifier	 delete Term
(	TokenNameLPAREN	
term	TokenNameIdentifier	 term
,	TokenNameCOMMA	
false	TokenNamefalse	
)	TokenNameRPAREN	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
flush	TokenNameIdentifier	 flush
(	TokenNameLPAREN	
true	TokenNametrue	
,	TokenNameCOMMA	
false	TokenNamefalse	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
}	TokenNameRBRACE	
catch	TokenNamecatch	
(	TokenNameLPAREN	
OutOfMemoryError	TokenNameIdentifier	 Out Of Memory Error
oom	TokenNameIdentifier	 oom
)	TokenNameRPAREN	
{	TokenNameLBRACE	
handleOOM	TokenNameIdentifier	 handle OOM
(	TokenNameLPAREN	
oom	TokenNameIdentifier	 oom
,	TokenNameCOMMA	
"deleteDocuments(Term)"	TokenNameStringLiteral	deleteDocuments(Term)
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
}	TokenNameRBRACE	
/** * Deletes the document(s) containing any of the * terms. All deletes are flushed at the same time. * * <p><b>NOTE</b>: if this method hits an OutOfMemoryError * you should immediately close the writer. See <a * href="#OOME">above</a> for details.</p> * * @param terms array of terms to identify the documents * to be deleted * @throws CorruptIndexException if the index is corrupt * @throws IOException if there is a low-level IO error */	TokenNameCOMMENT_JAVADOC	 Deletes the document(s) containing any of the terms. All deletes are flushed at the same time. * <p><b>NOTE</b>: if this method hits an OutOfMemoryError you should immediately close the writer. See <a href="#OOME">above</a> for details.</p> * @param terms array of terms to identify the documents to be deleted @throws CorruptIndexException if the index is corrupt @throws IOException if there is a low-level IO error 
public	TokenNamepublic	
void	TokenNamevoid	
deleteDocuments	TokenNameIdentifier	 delete Documents
(	TokenNameLPAREN	
Term	TokenNameIdentifier	 Term
...	TokenNameELLIPSIS	
terms	TokenNameIdentifier	 terms
)	TokenNameRPAREN	
throws	TokenNamethrows	
CorruptIndexException	TokenNameIdentifier	 Corrupt Index Exception
,	TokenNameCOMMA	
IOException	TokenNameIdentifier	 IO Exception
{	TokenNameLBRACE	
ensureOpen	TokenNameIdentifier	 ensure Open
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
try	TokenNametry	
{	TokenNameLBRACE	
if	TokenNameif	
(	TokenNameLPAREN	
docWriter	TokenNameIdentifier	 doc Writer
.	TokenNameDOT	
deleteTerms	TokenNameIdentifier	 delete Terms
(	TokenNameLPAREN	
terms	TokenNameIdentifier	 terms
)	TokenNameRPAREN	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
flush	TokenNameIdentifier	 flush
(	TokenNameLPAREN	
true	TokenNametrue	
,	TokenNameCOMMA	
false	TokenNamefalse	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
}	TokenNameRBRACE	
catch	TokenNamecatch	
(	TokenNameLPAREN	
OutOfMemoryError	TokenNameIdentifier	 Out Of Memory Error
oom	TokenNameIdentifier	 oom
)	TokenNameRPAREN	
{	TokenNameLBRACE	
handleOOM	TokenNameIdentifier	 handle OOM
(	TokenNameLPAREN	
oom	TokenNameIdentifier	 oom
,	TokenNameCOMMA	
"deleteDocuments(Term..)"	TokenNameStringLiteral	deleteDocuments(Term..)
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
}	TokenNameRBRACE	
/** * Deletes the document(s) matching the provided query. * * <p><b>NOTE</b>: if this method hits an OutOfMemoryError * you should immediately close the writer. See <a * href="#OOME">above</a> for details.</p> * * @param query the query to identify the documents to be deleted * @throws CorruptIndexException if the index is corrupt * @throws IOException if there is a low-level IO error */	TokenNameCOMMENT_JAVADOC	 Deletes the document(s) matching the provided query. * <p><b>NOTE</b>: if this method hits an OutOfMemoryError you should immediately close the writer. See <a href="#OOME">above</a> for details.</p> * @param query the query to identify the documents to be deleted @throws CorruptIndexException if the index is corrupt @throws IOException if there is a low-level IO error 
public	TokenNamepublic	
void	TokenNamevoid	
deleteDocuments	TokenNameIdentifier	 delete Documents
(	TokenNameLPAREN	
Query	TokenNameIdentifier	 Query
query	TokenNameIdentifier	 query
)	TokenNameRPAREN	
throws	TokenNamethrows	
CorruptIndexException	TokenNameIdentifier	 Corrupt Index Exception
,	TokenNameCOMMA	
IOException	TokenNameIdentifier	 IO Exception
{	TokenNameLBRACE	
ensureOpen	TokenNameIdentifier	 ensure Open
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
try	TokenNametry	
{	TokenNameLBRACE	
if	TokenNameif	
(	TokenNameLPAREN	
docWriter	TokenNameIdentifier	 doc Writer
.	TokenNameDOT	
deleteQuery	TokenNameIdentifier	 delete Query
(	TokenNameLPAREN	
query	TokenNameIdentifier	 query
)	TokenNameRPAREN	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
flush	TokenNameIdentifier	 flush
(	TokenNameLPAREN	
true	TokenNametrue	
,	TokenNameCOMMA	
false	TokenNamefalse	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
}	TokenNameRBRACE	
catch	TokenNamecatch	
(	TokenNameLPAREN	
OutOfMemoryError	TokenNameIdentifier	 Out Of Memory Error
oom	TokenNameIdentifier	 oom
)	TokenNameRPAREN	
{	TokenNameLBRACE	
handleOOM	TokenNameIdentifier	 handle OOM
(	TokenNameLPAREN	
oom	TokenNameIdentifier	 oom
,	TokenNameCOMMA	
"deleteDocuments(Query)"	TokenNameStringLiteral	deleteDocuments(Query)
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
}	TokenNameRBRACE	
/** * Deletes the document(s) matching any of the provided queries. * All deletes are flushed at the same time. * * <p><b>NOTE</b>: if this method hits an OutOfMemoryError * you should immediately close the writer. See <a * href="#OOME">above</a> for details.</p> * * @param queries array of queries to identify the documents * to be deleted * @throws CorruptIndexException if the index is corrupt * @throws IOException if there is a low-level IO error */	TokenNameCOMMENT_JAVADOC	 Deletes the document(s) matching any of the provided queries. All deletes are flushed at the same time. * <p><b>NOTE</b>: if this method hits an OutOfMemoryError you should immediately close the writer. See <a href="#OOME">above</a> for details.</p> * @param queries array of queries to identify the documents to be deleted @throws CorruptIndexException if the index is corrupt @throws IOException if there is a low-level IO error 
public	TokenNamepublic	
void	TokenNamevoid	
deleteDocuments	TokenNameIdentifier	 delete Documents
(	TokenNameLPAREN	
Query	TokenNameIdentifier	 Query
...	TokenNameELLIPSIS	
queries	TokenNameIdentifier	 queries
)	TokenNameRPAREN	
throws	TokenNamethrows	
CorruptIndexException	TokenNameIdentifier	 Corrupt Index Exception
,	TokenNameCOMMA	
IOException	TokenNameIdentifier	 IO Exception
{	TokenNameLBRACE	
ensureOpen	TokenNameIdentifier	 ensure Open
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
try	TokenNametry	
{	TokenNameLBRACE	
if	TokenNameif	
(	TokenNameLPAREN	
docWriter	TokenNameIdentifier	 doc Writer
.	TokenNameDOT	
deleteQueries	TokenNameIdentifier	 delete Queries
(	TokenNameLPAREN	
queries	TokenNameIdentifier	 queries
)	TokenNameRPAREN	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
flush	TokenNameIdentifier	 flush
(	TokenNameLPAREN	
true	TokenNametrue	
,	TokenNameCOMMA	
false	TokenNamefalse	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
}	TokenNameRBRACE	
catch	TokenNamecatch	
(	TokenNameLPAREN	
OutOfMemoryError	TokenNameIdentifier	 Out Of Memory Error
oom	TokenNameIdentifier	 oom
)	TokenNameRPAREN	
{	TokenNameLBRACE	
handleOOM	TokenNameIdentifier	 handle OOM
(	TokenNameLPAREN	
oom	TokenNameIdentifier	 oom
,	TokenNameCOMMA	
"deleteDocuments(Query..)"	TokenNameStringLiteral	deleteDocuments(Query..)
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
}	TokenNameRBRACE	
/** * Updates a document by first deleting the document(s) * containing <code>term</code> and then adding the new * document. The delete and then add are atomic as seen * by a reader on the same index (flush may happen only after * the add). * * <p><b>NOTE</b>: if this method hits an OutOfMemoryError * you should immediately close the writer. See <a * href="#OOME">above</a> for details.</p> * * @param term the term to identify the document(s) to be * deleted * @param doc the document to be added * @throws CorruptIndexException if the index is corrupt * @throws IOException if there is a low-level IO error */	TokenNameCOMMENT_JAVADOC	 Updates a document by first deleting the document(s) containing <code>term</code> and then adding the new document. The delete and then add are atomic as seen by a reader on the same index (flush may happen only after the add). * <p><b>NOTE</b>: if this method hits an OutOfMemoryError you should immediately close the writer. See <a href="#OOME">above</a> for details.</p> * @param term the term to identify the document(s) to be deleted @param doc the document to be added @throws CorruptIndexException if the index is corrupt @throws IOException if there is a low-level IO error 
public	TokenNamepublic	
void	TokenNamevoid	
updateDocument	TokenNameIdentifier	 update Document
(	TokenNameLPAREN	
Term	TokenNameIdentifier	 Term
term	TokenNameIdentifier	 term
,	TokenNameCOMMA	
Document	TokenNameIdentifier	 Document
doc	TokenNameIdentifier	 doc
)	TokenNameRPAREN	
throws	TokenNamethrows	
CorruptIndexException	TokenNameIdentifier	 Corrupt Index Exception
,	TokenNameCOMMA	
IOException	TokenNameIdentifier	 IO Exception
{	TokenNameLBRACE	
ensureOpen	TokenNameIdentifier	 ensure Open
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
updateDocument	TokenNameIdentifier	 update Document
(	TokenNameLPAREN	
term	TokenNameIdentifier	 term
,	TokenNameCOMMA	
doc	TokenNameIdentifier	 doc
,	TokenNameCOMMA	
getAnalyzer	TokenNameIdentifier	 get Analyzer
(	TokenNameLPAREN	
)	TokenNameRPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
/** * Updates a document by first deleting the document(s) * containing <code>term</code> and then adding the new * document. The delete and then add are atomic as seen * by a reader on the same index (flush may happen only after * the add). * * <p><b>NOTE</b>: if this method hits an OutOfMemoryError * you should immediately close the writer. See <a * href="#OOME">above</a> for details.</p> * * @param term the term to identify the document(s) to be * deleted * @param doc the document to be added * @param analyzer the analyzer to use when analyzing the document * @throws CorruptIndexException if the index is corrupt * @throws IOException if there is a low-level IO error */	TokenNameCOMMENT_JAVADOC	 Updates a document by first deleting the document(s) containing <code>term</code> and then adding the new document. The delete and then add are atomic as seen by a reader on the same index (flush may happen only after the add). * <p><b>NOTE</b>: if this method hits an OutOfMemoryError you should immediately close the writer. See <a href="#OOME">above</a> for details.</p> * @param term the term to identify the document(s) to be deleted @param doc the document to be added @param analyzer the analyzer to use when analyzing the document @throws CorruptIndexException if the index is corrupt @throws IOException if there is a low-level IO error 
public	TokenNamepublic	
void	TokenNamevoid	
updateDocument	TokenNameIdentifier	 update Document
(	TokenNameLPAREN	
Term	TokenNameIdentifier	 Term
term	TokenNameIdentifier	 term
,	TokenNameCOMMA	
Document	TokenNameIdentifier	 Document
doc	TokenNameIdentifier	 doc
,	TokenNameCOMMA	
Analyzer	TokenNameIdentifier	 Analyzer
analyzer	TokenNameIdentifier	 analyzer
)	TokenNameRPAREN	
throws	TokenNamethrows	
CorruptIndexException	TokenNameIdentifier	 Corrupt Index Exception
,	TokenNameCOMMA	
IOException	TokenNameIdentifier	 IO Exception
{	TokenNameLBRACE	
ensureOpen	TokenNameIdentifier	 ensure Open
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
try	TokenNametry	
{	TokenNameLBRACE	
boolean	TokenNameboolean	
doFlush	TokenNameIdentifier	 do Flush
=	TokenNameEQUAL	
false	TokenNamefalse	
;	TokenNameSEMICOLON	
boolean	TokenNameboolean	
success	TokenNameIdentifier	 success
=	TokenNameEQUAL	
false	TokenNamefalse	
;	TokenNameSEMICOLON	
try	TokenNametry	
{	TokenNameLBRACE	
doFlush	TokenNameIdentifier	 do Flush
=	TokenNameEQUAL	
docWriter	TokenNameIdentifier	 doc Writer
.	TokenNameDOT	
updateDocument	TokenNameIdentifier	 update Document
(	TokenNameLPAREN	
doc	TokenNameIdentifier	 doc
,	TokenNameCOMMA	
analyzer	TokenNameIdentifier	 analyzer
,	TokenNameCOMMA	
term	TokenNameIdentifier	 term
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
success	TokenNameIdentifier	 success
=	TokenNameEQUAL	
true	TokenNametrue	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
finally	TokenNamefinally	
{	TokenNameLBRACE	
if	TokenNameif	
(	TokenNameLPAREN	
!	TokenNameNOT	
success	TokenNameIdentifier	 success
&&	TokenNameAND_AND	
infoStream	TokenNameIdentifier	 info Stream
!=	TokenNameNOT_EQUAL	
null	TokenNamenull	
)	TokenNameRPAREN	
message	TokenNameIdentifier	 message
(	TokenNameLPAREN	
"hit exception updating document"	TokenNameStringLiteral	hit exception updating document
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
if	TokenNameif	
(	TokenNameLPAREN	
doFlush	TokenNameIdentifier	 do Flush
)	TokenNameRPAREN	
{	TokenNameLBRACE	
flush	TokenNameIdentifier	 flush
(	TokenNameLPAREN	
true	TokenNametrue	
,	TokenNameCOMMA	
false	TokenNamefalse	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
}	TokenNameRBRACE	
catch	TokenNamecatch	
(	TokenNameLPAREN	
OutOfMemoryError	TokenNameIdentifier	 Out Of Memory Error
oom	TokenNameIdentifier	 oom
)	TokenNameRPAREN	
{	TokenNameLBRACE	
handleOOM	TokenNameIdentifier	 handle OOM
(	TokenNameLPAREN	
oom	TokenNameIdentifier	 oom
,	TokenNameCOMMA	
"updateDocument"	TokenNameStringLiteral	updateDocument
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
}	TokenNameRBRACE	
// for test purpose 	TokenNameCOMMENT_LINE	for test purpose 
final	TokenNamefinal	
synchronized	TokenNamesynchronized	
int	TokenNameint	
getSegmentCount	TokenNameIdentifier	 get Segment Count
(	TokenNameLPAREN	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
return	TokenNamereturn	
segmentInfos	TokenNameIdentifier	 segment Infos
.	TokenNameDOT	
size	TokenNameIdentifier	 size
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
// for test purpose 	TokenNameCOMMENT_LINE	for test purpose 
final	TokenNamefinal	
synchronized	TokenNamesynchronized	
int	TokenNameint	
getNumBufferedDocuments	TokenNameIdentifier	 get Num Buffered Documents
(	TokenNameLPAREN	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
return	TokenNamereturn	
docWriter	TokenNameIdentifier	 doc Writer
.	TokenNameDOT	
getNumDocs	TokenNameIdentifier	 get Num Docs
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
// for test purpose 	TokenNameCOMMENT_LINE	for test purpose 
final	TokenNamefinal	
synchronized	TokenNamesynchronized	
int	TokenNameint	
getDocCount	TokenNameIdentifier	 get Doc Count
(	TokenNameLPAREN	
int	TokenNameint	
i	TokenNameIdentifier	 i
)	TokenNameRPAREN	
{	TokenNameLBRACE	
if	TokenNameif	
(	TokenNameLPAREN	
i	TokenNameIdentifier	 i
>=	TokenNameGREATER_EQUAL	
0	TokenNameIntegerLiteral	
&&	TokenNameAND_AND	
i	TokenNameIdentifier	 i
<	TokenNameLESS	
segmentInfos	TokenNameIdentifier	 segment Infos
.	TokenNameDOT	
size	TokenNameIdentifier	 size
(	TokenNameLPAREN	
)	TokenNameRPAREN	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
return	TokenNamereturn	
segmentInfos	TokenNameIdentifier	 segment Infos
.	TokenNameDOT	
info	TokenNameIdentifier	 info
(	TokenNameLPAREN	
i	TokenNameIdentifier	 i
)	TokenNameRPAREN	
.	TokenNameDOT	
docCount	TokenNameIdentifier	 doc Count
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
else	TokenNameelse	
{	TokenNameLBRACE	
return	TokenNamereturn	
-	TokenNameMINUS	
1	TokenNameIntegerLiteral	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
}	TokenNameRBRACE	
// for test purpose 	TokenNameCOMMENT_LINE	for test purpose 
final	TokenNamefinal	
int	TokenNameint	
getFlushCount	TokenNameIdentifier	 get Flush Count
(	TokenNameLPAREN	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
return	TokenNamereturn	
flushCount	TokenNameIdentifier	 flush Count
.	TokenNameDOT	
get	TokenNameIdentifier	 get
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
// for test purpose 	TokenNameCOMMENT_LINE	for test purpose 
final	TokenNamefinal	
int	TokenNameint	
getFlushDeletesCount	TokenNameIdentifier	 get Flush Deletes Count
(	TokenNameLPAREN	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
return	TokenNamereturn	
flushDeletesCount	TokenNameIdentifier	 flush Deletes Count
.	TokenNameDOT	
get	TokenNameIdentifier	 get
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
final	TokenNamefinal	
String	TokenNameIdentifier	 String
newSegmentName	TokenNameIdentifier	 new Segment Name
(	TokenNameLPAREN	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
// Cannot synchronize on IndexWriter because that causes 	TokenNameCOMMENT_LINE	Cannot synchronize on IndexWriter because that causes 
// deadlock 	TokenNameCOMMENT_LINE	deadlock 
synchronized	TokenNamesynchronized	
(	TokenNameLPAREN	
segmentInfos	TokenNameIdentifier	 segment Infos
)	TokenNameRPAREN	
{	TokenNameLBRACE	
// Important to increment changeCount so that the 	TokenNameCOMMENT_LINE	Important to increment changeCount so that the 
// segmentInfos is written on close. Otherwise we 	TokenNameCOMMENT_LINE	segmentInfos is written on close. Otherwise we 
// could close, re-open and re-return the same segment 	TokenNameCOMMENT_LINE	could close, re-open and re-return the same segment 
// name that was previously returned which can cause 	TokenNameCOMMENT_LINE	name that was previously returned which can cause 
// problems at least with ConcurrentMergeScheduler. 	TokenNameCOMMENT_LINE	problems at least with ConcurrentMergeScheduler. 
changeCount	TokenNameIdentifier	 change Count
++	TokenNamePLUS_PLUS	
;	TokenNameSEMICOLON	
segmentInfos	TokenNameIdentifier	 segment Infos
.	TokenNameDOT	
changed	TokenNameIdentifier	 changed
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
return	TokenNamereturn	
"_"	TokenNameStringLiteral	_
+	TokenNamePLUS	
Integer	TokenNameIdentifier	 Integer
.	TokenNameDOT	
toString	TokenNameIdentifier	 to String
(	TokenNameLPAREN	
segmentInfos	TokenNameIdentifier	 segment Infos
.	TokenNameDOT	
counter	TokenNameIdentifier	 counter
++	TokenNamePLUS_PLUS	
,	TokenNameCOMMA	
Character	TokenNameIdentifier	 Character
.	TokenNameDOT	
MAX_RADIX	TokenNameIdentifier	 MAX  RADIX
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
}	TokenNameRBRACE	
/** If non-null, information about merges will be printed to this. */	TokenNameCOMMENT_JAVADOC	 If non-null, information about merges will be printed to this. 
private	TokenNameprivate	
PrintStream	TokenNameIdentifier	 Print Stream
infoStream	TokenNameIdentifier	 info Stream
;	TokenNameSEMICOLON	
private	TokenNameprivate	
static	TokenNamestatic	
PrintStream	TokenNameIdentifier	 Print Stream
defaultInfoStream	TokenNameIdentifier	 default Info Stream
;	TokenNameSEMICOLON	
/** This method has been deprecated, as it is horribly * inefficient and very rarely justified. Lucene's * multi-segment search performance has improved over * time, and the default TieredMergePolicy now targets * segments with deletions. * * @deprecated */	TokenNameCOMMENT_JAVADOC	 This method has been deprecated, as it is horribly inefficient and very rarely justified. Lucene's multi-segment search performance has improved over time, and the default TieredMergePolicy now targets segments with deletions. * @deprecated 
@	TokenNameAT	
Deprecated	TokenNameIdentifier	 Deprecated
public	TokenNamepublic	
void	TokenNamevoid	
optimize	TokenNameIdentifier	 optimize
(	TokenNameLPAREN	
)	TokenNameRPAREN	
throws	TokenNamethrows	
CorruptIndexException	TokenNameIdentifier	 Corrupt Index Exception
,	TokenNameCOMMA	
IOException	TokenNameIdentifier	 IO Exception
{	TokenNameLBRACE	
forceMerge	TokenNameIdentifier	 force Merge
(	TokenNameLPAREN	
1	TokenNameIntegerLiteral	
,	TokenNameCOMMA	
true	TokenNametrue	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
/** This method has been deprecated, as it is horribly * inefficient and very rarely justified. Lucene's * multi-segment search performance has improved over * time, and the default TieredMergePolicy now targets * segments with deletions. * * @deprecated */	TokenNameCOMMENT_JAVADOC	 This method has been deprecated, as it is horribly inefficient and very rarely justified. Lucene's multi-segment search performance has improved over time, and the default TieredMergePolicy now targets segments with deletions. * @deprecated 
@	TokenNameAT	
Deprecated	TokenNameIdentifier	 Deprecated
public	TokenNamepublic	
void	TokenNamevoid	
optimize	TokenNameIdentifier	 optimize
(	TokenNameLPAREN	
int	TokenNameint	
maxNumSegments	TokenNameIdentifier	 max Num Segments
)	TokenNameRPAREN	
throws	TokenNamethrows	
CorruptIndexException	TokenNameIdentifier	 Corrupt Index Exception
,	TokenNameCOMMA	
IOException	TokenNameIdentifier	 IO Exception
{	TokenNameLBRACE	
forceMerge	TokenNameIdentifier	 force Merge
(	TokenNameLPAREN	
maxNumSegments	TokenNameIdentifier	 max Num Segments
,	TokenNameCOMMA	
true	TokenNametrue	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
/** This method has been deprecated, as it is horribly * inefficient and very rarely justified. Lucene's * multi-segment search performance has improved over * time, and the default TieredMergePolicy now targets * segments with deletions. * * @deprecated */	TokenNameCOMMENT_JAVADOC	 This method has been deprecated, as it is horribly inefficient and very rarely justified. Lucene's multi-segment search performance has improved over time, and the default TieredMergePolicy now targets segments with deletions. * @deprecated 
@	TokenNameAT	
Deprecated	TokenNameIdentifier	 Deprecated
public	TokenNamepublic	
void	TokenNamevoid	
optimize	TokenNameIdentifier	 optimize
(	TokenNameLPAREN	
boolean	TokenNameboolean	
doWait	TokenNameIdentifier	 do Wait
)	TokenNameRPAREN	
throws	TokenNamethrows	
CorruptIndexException	TokenNameIdentifier	 Corrupt Index Exception
,	TokenNameCOMMA	
IOException	TokenNameIdentifier	 IO Exception
{	TokenNameLBRACE	
forceMerge	TokenNameIdentifier	 force Merge
(	TokenNameLPAREN	
1	TokenNameIntegerLiteral	
,	TokenNameCOMMA	
doWait	TokenNameIdentifier	 do Wait
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
/** * Forces merge policy to merge segments until there's <= * maxNumSegments. The actual merges to be * executed are determined by the {@link MergePolicy}. * * <p>This is a horribly costly operation, especially when * you pass a small {@code maxNumSegments}; usually you * should only call this if the index is static (will no * longer be changed).</p> * * <p>Note that this requires up to 2X the index size free * space in your Directory (3X if you're using compound * file format). For example, if your index size is 10 MB * then you need up to 20 MB free for this to complete (30 * MB if you're using compound file format). Also, * it's best to call {@link #commit()} afterwards, * to allow IndexWriter to free up disk space.</p> * * <p>If some but not all readers re-open while merging * is underway, this will cause > 2X temporary * space to be consumed as those new readers will then * hold open the temporary segments at that time. It is * best not to re-open readers while merging is running.</p> * * <p>The actual temporary usage could be much less than * these figures (it depends on many factors).</p> * * <p>In general, once the this completes, the total size of the * index will be less than the size of the starting index. * It could be quite a bit smaller (if there were many * pending deletes) or just slightly smaller.</p> * * <p>If an Exception is hit, for example * due to disk full, the index will not be corrupt and no * documents will have been lost. However, it may have * been partially merged (some segments were merged but * not all), and it's possible that one of the segments in * the index will be in non-compound format even when * using compound file format. This will occur when the * Exception is hit during conversion of the segment into * compound format.</p> * * <p>This call will merge those segments present in * the index when the call started. If other threads are * still adding documents and flushing segments, those * newly created segments will not be merged unless you * call forceMerge again.</p> * * <p><b>NOTE</b>: if this method hits an OutOfMemoryError * you should immediately close the writer. See <a * href="#OOME">above</a> for details.</p> * * <p><b>NOTE</b>: if you call {@link #close(boolean)} * with <tt>false</tt>, which aborts all running merges, * then any thread still running this method might hit a * {@link MergePolicy.MergeAbortedException}. * * @throws CorruptIndexException if the index is corrupt * @throws IOException if there is a low-level IO error * @see MergePolicy#findMerges * * @param maxNumSegments maximum number of segments left * in the index after merging finishes */	TokenNameCOMMENT_JAVADOC	 Forces merge policy to merge segments until there's <= maxNumSegments. The actual merges to be executed are determined by the {@link MergePolicy}. * <p>This is a horribly costly operation, especially when you pass a small {@code maxNumSegments}; usually you should only call this if the index is static (will no longer be changed).</p> * <p>Note that this requires up to 2X the index size free space in your Directory (3X if you're using compound file format). For example, if your index size is 10 MB then you need up to 20 MB free for this to complete (30 MB if you're using compound file format). Also, it's best to call {@link #commit()} afterwards, to allow IndexWriter to free up disk space.</p> * <p>If some but not all readers re-open while merging is underway, this will cause > 2X temporary space to be consumed as those new readers will then hold open the temporary segments at that time. It is best not to re-open readers while merging is running.</p> * <p>The actual temporary usage could be much less than these figures (it depends on many factors).</p> * <p>In general, once the this completes, the total size of the index will be less than the size of the starting index. It could be quite a bit smaller (if there were many pending deletes) or just slightly smaller.</p> * <p>If an Exception is hit, for example due to disk full, the index will not be corrupt and no documents will have been lost. However, it may have been partially merged (some segments were merged but not all), and it's possible that one of the segments in the index will be in non-compound format even when using compound file format. This will occur when the Exception is hit during conversion of the segment into compound format.</p> * <p>This call will merge those segments present in the index when the call started. If other threads are still adding documents and flushing segments, those newly created segments will not be merged unless you call forceMerge again.</p> * <p><b>NOTE</b>: if this method hits an OutOfMemoryError you should immediately close the writer. See <a href="#OOME">above</a> for details.</p> * <p><b>NOTE</b>: if you call {@link #close(boolean)} with <tt>false</tt>, which aborts all running merges, then any thread still running this method might hit a {@link MergePolicy.MergeAbortedException}. * @throws CorruptIndexException if the index is corrupt @throws IOException if there is a low-level IO error @see MergePolicy#findMerges * @param maxNumSegments maximum number of segments left in the index after merging finishes 
public	TokenNamepublic	
void	TokenNamevoid	
forceMerge	TokenNameIdentifier	 force Merge
(	TokenNameLPAREN	
int	TokenNameint	
maxNumSegments	TokenNameIdentifier	 max Num Segments
)	TokenNameRPAREN	
throws	TokenNamethrows	
CorruptIndexException	TokenNameIdentifier	 Corrupt Index Exception
,	TokenNameCOMMA	
IOException	TokenNameIdentifier	 IO Exception
{	TokenNameLBRACE	
forceMerge	TokenNameIdentifier	 force Merge
(	TokenNameLPAREN	
maxNumSegments	TokenNameIdentifier	 max Num Segments
,	TokenNameCOMMA	
true	TokenNametrue	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
/** Just like {@link #forceMerge(int)}, except you can * specify whether the call should block until * all merging completes. This is only meaningful with a * {@link MergeScheduler} that is able to run merges in * background threads. * * <p><b>NOTE</b>: if this method hits an OutOfMemoryError * you should immediately close the writer. See <a * href="#OOME">above</a> for details.</p> */	TokenNameCOMMENT_JAVADOC	 Just like {@link #forceMerge(int)}, except you can specify whether the call should block until all merging completes. This is only meaningful with a {@link MergeScheduler} that is able to run merges in background threads. * <p><b>NOTE</b>: if this method hits an OutOfMemoryError you should immediately close the writer. See <a href="#OOME">above</a> for details.</p> 
public	TokenNamepublic	
void	TokenNamevoid	
forceMerge	TokenNameIdentifier	 force Merge
(	TokenNameLPAREN	
int	TokenNameint	
maxNumSegments	TokenNameIdentifier	 max Num Segments
,	TokenNameCOMMA	
boolean	TokenNameboolean	
doWait	TokenNameIdentifier	 do Wait
)	TokenNameRPAREN	
throws	TokenNamethrows	
CorruptIndexException	TokenNameIdentifier	 Corrupt Index Exception
,	TokenNameCOMMA	
IOException	TokenNameIdentifier	 IO Exception
{	TokenNameLBRACE	
ensureOpen	TokenNameIdentifier	 ensure Open
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
if	TokenNameif	
(	TokenNameLPAREN	
maxNumSegments	TokenNameIdentifier	 max Num Segments
<	TokenNameLESS	
1	TokenNameIntegerLiteral	
)	TokenNameRPAREN	
throw	TokenNamethrow	
new	TokenNamenew	
IllegalArgumentException	TokenNameIdentifier	 Illegal Argument Exception
(	TokenNameLPAREN	
"maxNumSegments must be >= 1; got "	TokenNameStringLiteral	maxNumSegments must be >= 1; got 
+	TokenNamePLUS	
maxNumSegments	TokenNameIdentifier	 max Num Segments
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
if	TokenNameif	
(	TokenNameLPAREN	
infoStream	TokenNameIdentifier	 info Stream
!=	TokenNameNOT_EQUAL	
null	TokenNamenull	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
message	TokenNameIdentifier	 message
(	TokenNameLPAREN	
"forceMerge: index now "	TokenNameStringLiteral	forceMerge: index now 
+	TokenNamePLUS	
segString	TokenNameIdentifier	 seg String
(	TokenNameLPAREN	
)	TokenNameRPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
message	TokenNameIdentifier	 message
(	TokenNameLPAREN	
"now flush at forceMerge"	TokenNameStringLiteral	now flush at forceMerge
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
flush	TokenNameIdentifier	 flush
(	TokenNameLPAREN	
true	TokenNametrue	
,	TokenNameCOMMA	
true	TokenNametrue	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
synchronized	TokenNamesynchronized	
(	TokenNameLPAREN	
this	TokenNamethis	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
resetMergeExceptions	TokenNameIdentifier	 reset Merge Exceptions
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
segmentsToMerge	TokenNameIdentifier	 segments To Merge
.	TokenNameDOT	
clear	TokenNameIdentifier	 clear
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
for	TokenNamefor	
(	TokenNameLPAREN	
SegmentInfo	TokenNameIdentifier	 Segment Info
info	TokenNameIdentifier	 info
:	TokenNameCOLON	
segmentInfos	TokenNameIdentifier	 segment Infos
)	TokenNameRPAREN	
{	TokenNameLBRACE	
segmentsToMerge	TokenNameIdentifier	 segments To Merge
.	TokenNameDOT	
put	TokenNameIdentifier	 put
(	TokenNameLPAREN	
info	TokenNameIdentifier	 info
,	TokenNameCOMMA	
Boolean	TokenNameIdentifier	 Boolean
.	TokenNameDOT	
TRUE	TokenNameIdentifier	 TRUE
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
mergeMaxNumSegments	TokenNameIdentifier	 merge Max Num Segments
=	TokenNameEQUAL	
maxNumSegments	TokenNameIdentifier	 max Num Segments
;	TokenNameSEMICOLON	
// Now mark all pending & running merges as isMaxNumSegments: 	TokenNameCOMMENT_LINE	Now mark all pending & running merges as isMaxNumSegments: 
for	TokenNamefor	
(	TokenNameLPAREN	
final	TokenNamefinal	
MergePolicy	TokenNameIdentifier	 Merge Policy
.	TokenNameDOT	
OneMerge	TokenNameIdentifier	 One Merge
merge	TokenNameIdentifier	 merge
:	TokenNameCOLON	
pendingMerges	TokenNameIdentifier	 pending Merges
)	TokenNameRPAREN	
{	TokenNameLBRACE	
merge	TokenNameIdentifier	 merge
.	TokenNameDOT	
maxNumSegments	TokenNameIdentifier	 max Num Segments
=	TokenNameEQUAL	
maxNumSegments	TokenNameIdentifier	 max Num Segments
;	TokenNameSEMICOLON	
segmentsToMerge	TokenNameIdentifier	 segments To Merge
.	TokenNameDOT	
put	TokenNameIdentifier	 put
(	TokenNameLPAREN	
merge	TokenNameIdentifier	 merge
.	TokenNameDOT	
info	TokenNameIdentifier	 info
,	TokenNameCOMMA	
Boolean	TokenNameIdentifier	 Boolean
.	TokenNameDOT	
TRUE	TokenNameIdentifier	 TRUE
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
for	TokenNamefor	
(	TokenNameLPAREN	
final	TokenNamefinal	
MergePolicy	TokenNameIdentifier	 Merge Policy
.	TokenNameDOT	
OneMerge	TokenNameIdentifier	 One Merge
merge	TokenNameIdentifier	 merge
:	TokenNameCOLON	
runningMerges	TokenNameIdentifier	 running Merges
)	TokenNameRPAREN	
{	TokenNameLBRACE	
merge	TokenNameIdentifier	 merge
.	TokenNameDOT	
maxNumSegments	TokenNameIdentifier	 max Num Segments
=	TokenNameEQUAL	
maxNumSegments	TokenNameIdentifier	 max Num Segments
;	TokenNameSEMICOLON	
segmentsToMerge	TokenNameIdentifier	 segments To Merge
.	TokenNameDOT	
put	TokenNameIdentifier	 put
(	TokenNameLPAREN	
merge	TokenNameIdentifier	 merge
.	TokenNameDOT	
info	TokenNameIdentifier	 info
,	TokenNameCOMMA	
Boolean	TokenNameIdentifier	 Boolean
.	TokenNameDOT	
TRUE	TokenNameIdentifier	 TRUE
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
}	TokenNameRBRACE	
maybeMerge	TokenNameIdentifier	 maybe Merge
(	TokenNameLPAREN	
maxNumSegments	TokenNameIdentifier	 max Num Segments
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
if	TokenNameif	
(	TokenNameLPAREN	
doWait	TokenNameIdentifier	 do Wait
)	TokenNameRPAREN	
{	TokenNameLBRACE	
synchronized	TokenNamesynchronized	
(	TokenNameLPAREN	
this	TokenNamethis	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
while	TokenNamewhile	
(	TokenNameLPAREN	
true	TokenNametrue	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
if	TokenNameif	
(	TokenNameLPAREN	
hitOOM	TokenNameIdentifier	 hit OOM
)	TokenNameRPAREN	
{	TokenNameLBRACE	
throw	TokenNamethrow	
new	TokenNamenew	
IllegalStateException	TokenNameIdentifier	 Illegal State Exception
(	TokenNameLPAREN	
"this writer hit an OutOfMemoryError; cannot complete forceMerge"	TokenNameStringLiteral	this writer hit an OutOfMemoryError; cannot complete forceMerge
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
if	TokenNameif	
(	TokenNameLPAREN	
mergeExceptions	TokenNameIdentifier	 merge Exceptions
.	TokenNameDOT	
size	TokenNameIdentifier	 size
(	TokenNameLPAREN	
)	TokenNameRPAREN	
>	TokenNameGREATER	
0	TokenNameIntegerLiteral	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
// Forward any exceptions in background merge 	TokenNameCOMMENT_LINE	Forward any exceptions in background merge 
// threads to the current thread: 	TokenNameCOMMENT_LINE	threads to the current thread: 
final	TokenNamefinal	
int	TokenNameint	
size	TokenNameIdentifier	 size
=	TokenNameEQUAL	
mergeExceptions	TokenNameIdentifier	 merge Exceptions
.	TokenNameDOT	
size	TokenNameIdentifier	 size
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
for	TokenNamefor	
(	TokenNameLPAREN	
int	TokenNameint	
i	TokenNameIdentifier	 i
=	TokenNameEQUAL	
0	TokenNameIntegerLiteral	
;	TokenNameSEMICOLON	
i	TokenNameIdentifier	 i
<	TokenNameLESS	
size	TokenNameIdentifier	 size
;	TokenNameSEMICOLON	
i	TokenNameIdentifier	 i
++	TokenNamePLUS_PLUS	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
final	TokenNamefinal	
MergePolicy	TokenNameIdentifier	 Merge Policy
.	TokenNameDOT	
OneMerge	TokenNameIdentifier	 One Merge
merge	TokenNameIdentifier	 merge
=	TokenNameEQUAL	
mergeExceptions	TokenNameIdentifier	 merge Exceptions
.	TokenNameDOT	
get	TokenNameIdentifier	 get
(	TokenNameLPAREN	
i	TokenNameIdentifier	 i
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
if	TokenNameif	
(	TokenNameLPAREN	
merge	TokenNameIdentifier	 merge
.	TokenNameDOT	
maxNumSegments	TokenNameIdentifier	 max Num Segments
!=	TokenNameNOT_EQUAL	
-	TokenNameMINUS	
1	TokenNameIntegerLiteral	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
IOException	TokenNameIdentifier	 IO Exception
err	TokenNameIdentifier	 err
=	TokenNameEQUAL	
new	TokenNamenew	
IOException	TokenNameIdentifier	 IO Exception
(	TokenNameLPAREN	
"background merge hit exception: "	TokenNameStringLiteral	background merge hit exception: 
+	TokenNamePLUS	
merge	TokenNameIdentifier	 merge
.	TokenNameDOT	
segString	TokenNameIdentifier	 seg String
(	TokenNameLPAREN	
directory	TokenNameIdentifier	 directory
)	TokenNameRPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
final	TokenNamefinal	
Throwable	TokenNameIdentifier	 Throwable
t	TokenNameIdentifier	 t
=	TokenNameEQUAL	
merge	TokenNameIdentifier	 merge
.	TokenNameDOT	
getException	TokenNameIdentifier	 get Exception
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
if	TokenNameif	
(	TokenNameLPAREN	
t	TokenNameIdentifier	 t
!=	TokenNameNOT_EQUAL	
null	TokenNamenull	
)	TokenNameRPAREN	
err	TokenNameIdentifier	 err
.	TokenNameDOT	
initCause	TokenNameIdentifier	 init Cause
(	TokenNameLPAREN	
t	TokenNameIdentifier	 t
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
throw	TokenNamethrow	
err	TokenNameIdentifier	 err
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
}	TokenNameRBRACE	
}	TokenNameRBRACE	
if	TokenNameif	
(	TokenNameLPAREN	
maxNumSegmentsMergesPending	TokenNameIdentifier	 max Num Segments Merges Pending
(	TokenNameLPAREN	
)	TokenNameRPAREN	
)	TokenNameRPAREN	
doWait	TokenNameIdentifier	 do Wait
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
else	TokenNameelse	
break	TokenNamebreak	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
}	TokenNameRBRACE	
// If close is called while we are still 	TokenNameCOMMENT_LINE	If close is called while we are still 
// running, throw an exception so the calling 	TokenNameCOMMENT_LINE	running, throw an exception so the calling 
// thread will know merging did not 	TokenNameCOMMENT_LINE	thread will know merging did not 
// complete 	TokenNameCOMMENT_LINE	complete 
ensureOpen	TokenNameIdentifier	 ensure Open
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
// NOTE: in the ConcurrentMergeScheduler case, when 	TokenNameCOMMENT_LINE	NOTE: in the ConcurrentMergeScheduler case, when 
// doWait is false, we can return immediately while 	TokenNameCOMMENT_LINE	doWait is false, we can return immediately while 
// background threads accomplish the merging 	TokenNameCOMMENT_LINE	background threads accomplish the merging 
}	TokenNameRBRACE	
/** Returns true if any merges in pendingMerges or * runningMerges are maxNumSegments merges. */	TokenNameCOMMENT_JAVADOC	 Returns true if any merges in pendingMerges or runningMerges are maxNumSegments merges. 
private	TokenNameprivate	
synchronized	TokenNamesynchronized	
boolean	TokenNameboolean	
maxNumSegmentsMergesPending	TokenNameIdentifier	 max Num Segments Merges Pending
(	TokenNameLPAREN	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
for	TokenNamefor	
(	TokenNameLPAREN	
final	TokenNamefinal	
MergePolicy	TokenNameIdentifier	 Merge Policy
.	TokenNameDOT	
OneMerge	TokenNameIdentifier	 One Merge
merge	TokenNameIdentifier	 merge
:	TokenNameCOLON	
pendingMerges	TokenNameIdentifier	 pending Merges
)	TokenNameRPAREN	
{	TokenNameLBRACE	
if	TokenNameif	
(	TokenNameLPAREN	
merge	TokenNameIdentifier	 merge
.	TokenNameDOT	
maxNumSegments	TokenNameIdentifier	 max Num Segments
!=	TokenNameNOT_EQUAL	
-	TokenNameMINUS	
1	TokenNameIntegerLiteral	
)	TokenNameRPAREN	
return	TokenNamereturn	
true	TokenNametrue	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
for	TokenNamefor	
(	TokenNameLPAREN	
final	TokenNamefinal	
MergePolicy	TokenNameIdentifier	 Merge Policy
.	TokenNameDOT	
OneMerge	TokenNameIdentifier	 One Merge
merge	TokenNameIdentifier	 merge
:	TokenNameCOLON	
runningMerges	TokenNameIdentifier	 running Merges
)	TokenNameRPAREN	
{	TokenNameLBRACE	
if	TokenNameif	
(	TokenNameLPAREN	
merge	TokenNameIdentifier	 merge
.	TokenNameDOT	
maxNumSegments	TokenNameIdentifier	 max Num Segments
!=	TokenNameNOT_EQUAL	
-	TokenNameMINUS	
1	TokenNameIntegerLiteral	
)	TokenNameRPAREN	
return	TokenNamereturn	
true	TokenNametrue	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
return	TokenNamereturn	
false	TokenNamefalse	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
/** This method has been deprecated, as it is horribly * inefficient and very rarely justified. Lucene's * multi-segment search performance has improved over * time, and the default TieredMergePolicy now targets * segments with deletions. * * @deprecated */	TokenNameCOMMENT_JAVADOC	 This method has been deprecated, as it is horribly inefficient and very rarely justified. Lucene's multi-segment search performance has improved over time, and the default TieredMergePolicy now targets segments with deletions. * @deprecated 
@	TokenNameAT	
Deprecated	TokenNameIdentifier	 Deprecated
public	TokenNamepublic	
void	TokenNamevoid	
expungeDeletes	TokenNameIdentifier	 expunge Deletes
(	TokenNameLPAREN	
boolean	TokenNameboolean	
doWait	TokenNameIdentifier	 do Wait
)	TokenNameRPAREN	
throws	TokenNamethrows	
CorruptIndexException	TokenNameIdentifier	 Corrupt Index Exception
,	TokenNameCOMMA	
IOException	TokenNameIdentifier	 IO Exception
{	TokenNameLBRACE	
forceMergeDeletes	TokenNameIdentifier	 force Merge Deletes
(	TokenNameLPAREN	
doWait	TokenNameIdentifier	 do Wait
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
/** Just like {@link #forceMergeDeletes()}, except you can * specify whether the call should block until the * operation completes. This is only meaningful with a * {@link MergeScheduler} that is able to run merges in * background threads. * * <p><b>NOTE</b>: if this method hits an OutOfMemoryError * you should immediately close the writer. See <a * href="#OOME">above</a> for details.</p> * * <p><b>NOTE</b>: if you call {@link #close(boolean)} * with <tt>false</tt>, which aborts all running merges, * then any thread still running this method might hit a * {@link MergePolicy.MergeAbortedException}. */	TokenNameCOMMENT_JAVADOC	 Just like {@link #forceMergeDeletes()}, except you can specify whether the call should block until the operation completes. This is only meaningful with a {@link MergeScheduler} that is able to run merges in background threads. * <p><b>NOTE</b>: if this method hits an OutOfMemoryError you should immediately close the writer. See <a href="#OOME">above</a> for details.</p> * <p><b>NOTE</b>: if you call {@link #close(boolean)} with <tt>false</tt>, which aborts all running merges, then any thread still running this method might hit a {@link MergePolicy.MergeAbortedException}. 
public	TokenNamepublic	
void	TokenNamevoid	
forceMergeDeletes	TokenNameIdentifier	 force Merge Deletes
(	TokenNameLPAREN	
boolean	TokenNameboolean	
doWait	TokenNameIdentifier	 do Wait
)	TokenNameRPAREN	
throws	TokenNamethrows	
CorruptIndexException	TokenNameIdentifier	 Corrupt Index Exception
,	TokenNameCOMMA	
IOException	TokenNameIdentifier	 IO Exception
{	TokenNameLBRACE	
ensureOpen	TokenNameIdentifier	 ensure Open
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
flush	TokenNameIdentifier	 flush
(	TokenNameLPAREN	
true	TokenNametrue	
,	TokenNameCOMMA	
true	TokenNametrue	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
if	TokenNameif	
(	TokenNameLPAREN	
infoStream	TokenNameIdentifier	 info Stream
!=	TokenNameNOT_EQUAL	
null	TokenNamenull	
)	TokenNameRPAREN	
message	TokenNameIdentifier	 message
(	TokenNameLPAREN	
"forceMergeDeletes: index now "	TokenNameStringLiteral	forceMergeDeletes: index now 
+	TokenNamePLUS	
segString	TokenNameIdentifier	 seg String
(	TokenNameLPAREN	
)	TokenNameRPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
MergePolicy	TokenNameIdentifier	 Merge Policy
.	TokenNameDOT	
MergeSpecification	TokenNameIdentifier	 Merge Specification
spec	TokenNameIdentifier	 spec
;	TokenNameSEMICOLON	
synchronized	TokenNamesynchronized	
(	TokenNameLPAREN	
this	TokenNamethis	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
spec	TokenNameIdentifier	 spec
=	TokenNameEQUAL	
mergePolicy	TokenNameIdentifier	 merge Policy
.	TokenNameDOT	
findForcedDeletesMerges	TokenNameIdentifier	 find Forced Deletes Merges
(	TokenNameLPAREN	
segmentInfos	TokenNameIdentifier	 segment Infos
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
if	TokenNameif	
(	TokenNameLPAREN	
spec	TokenNameIdentifier	 spec
!=	TokenNameNOT_EQUAL	
null	TokenNamenull	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
final	TokenNamefinal	
int	TokenNameint	
numMerges	TokenNameIdentifier	 num Merges
=	TokenNameEQUAL	
spec	TokenNameIdentifier	 spec
.	TokenNameDOT	
merges	TokenNameIdentifier	 merges
.	TokenNameDOT	
size	TokenNameIdentifier	 size
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
for	TokenNamefor	
(	TokenNameLPAREN	
int	TokenNameint	
i	TokenNameIdentifier	 i
=	TokenNameEQUAL	
0	TokenNameIntegerLiteral	
;	TokenNameSEMICOLON	
i	TokenNameIdentifier	 i
<	TokenNameLESS	
numMerges	TokenNameIdentifier	 num Merges
;	TokenNameSEMICOLON	
i	TokenNameIdentifier	 i
++	TokenNamePLUS_PLUS	
)	TokenNameRPAREN	
registerMerge	TokenNameIdentifier	 register Merge
(	TokenNameLPAREN	
spec	TokenNameIdentifier	 spec
.	TokenNameDOT	
merges	TokenNameIdentifier	 merges
.	TokenNameDOT	
get	TokenNameIdentifier	 get
(	TokenNameLPAREN	
i	TokenNameIdentifier	 i
)	TokenNameRPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
}	TokenNameRBRACE	
mergeScheduler	TokenNameIdentifier	 merge Scheduler
.	TokenNameDOT	
merge	TokenNameIdentifier	 merge
(	TokenNameLPAREN	
this	TokenNamethis	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
if	TokenNameif	
(	TokenNameLPAREN	
spec	TokenNameIdentifier	 spec
!=	TokenNameNOT_EQUAL	
null	TokenNamenull	
&&	TokenNameAND_AND	
doWait	TokenNameIdentifier	 do Wait
)	TokenNameRPAREN	
{	TokenNameLBRACE	
final	TokenNamefinal	
int	TokenNameint	
numMerges	TokenNameIdentifier	 num Merges
=	TokenNameEQUAL	
spec	TokenNameIdentifier	 spec
.	TokenNameDOT	
merges	TokenNameIdentifier	 merges
.	TokenNameDOT	
size	TokenNameIdentifier	 size
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
synchronized	TokenNamesynchronized	
(	TokenNameLPAREN	
this	TokenNamethis	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
boolean	TokenNameboolean	
running	TokenNameIdentifier	 running
=	TokenNameEQUAL	
true	TokenNametrue	
;	TokenNameSEMICOLON	
while	TokenNamewhile	
(	TokenNameLPAREN	
running	TokenNameIdentifier	 running
)	TokenNameRPAREN	
{	TokenNameLBRACE	
if	TokenNameif	
(	TokenNameLPAREN	
hitOOM	TokenNameIdentifier	 hit OOM
)	TokenNameRPAREN	
{	TokenNameLBRACE	
throw	TokenNamethrow	
new	TokenNamenew	
IllegalStateException	TokenNameIdentifier	 Illegal State Exception
(	TokenNameLPAREN	
"this writer hit an OutOfMemoryError; cannot complete forceMergeDeletes"	TokenNameStringLiteral	this writer hit an OutOfMemoryError; cannot complete forceMergeDeletes
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
// Check each merge that MergePolicy asked us to 	TokenNameCOMMENT_LINE	Check each merge that MergePolicy asked us to 
// do, to see if any of them are still running and 	TokenNameCOMMENT_LINE	do, to see if any of them are still running and 
// if any of them have hit an exception. 	TokenNameCOMMENT_LINE	if any of them have hit an exception. 
running	TokenNameIdentifier	 running
=	TokenNameEQUAL	
false	TokenNamefalse	
;	TokenNameSEMICOLON	
for	TokenNamefor	
(	TokenNameLPAREN	
int	TokenNameint	
i	TokenNameIdentifier	 i
=	TokenNameEQUAL	
0	TokenNameIntegerLiteral	
;	TokenNameSEMICOLON	
i	TokenNameIdentifier	 i
<	TokenNameLESS	
numMerges	TokenNameIdentifier	 num Merges
;	TokenNameSEMICOLON	
i	TokenNameIdentifier	 i
++	TokenNamePLUS_PLUS	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
final	TokenNamefinal	
MergePolicy	TokenNameIdentifier	 Merge Policy
.	TokenNameDOT	
OneMerge	TokenNameIdentifier	 One Merge
merge	TokenNameIdentifier	 merge
=	TokenNameEQUAL	
spec	TokenNameIdentifier	 spec
.	TokenNameDOT	
merges	TokenNameIdentifier	 merges
.	TokenNameDOT	
get	TokenNameIdentifier	 get
(	TokenNameLPAREN	
i	TokenNameIdentifier	 i
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
if	TokenNameif	
(	TokenNameLPAREN	
pendingMerges	TokenNameIdentifier	 pending Merges
.	TokenNameDOT	
contains	TokenNameIdentifier	 contains
(	TokenNameLPAREN	
merge	TokenNameIdentifier	 merge
)	TokenNameRPAREN	
||	TokenNameOR_OR	
runningMerges	TokenNameIdentifier	 running Merges
.	TokenNameDOT	
contains	TokenNameIdentifier	 contains
(	TokenNameLPAREN	
merge	TokenNameIdentifier	 merge
)	TokenNameRPAREN	
)	TokenNameRPAREN	
running	TokenNameIdentifier	 running
=	TokenNameEQUAL	
true	TokenNametrue	
;	TokenNameSEMICOLON	
Throwable	TokenNameIdentifier	 Throwable
t	TokenNameIdentifier	 t
=	TokenNameEQUAL	
merge	TokenNameIdentifier	 merge
.	TokenNameDOT	
getException	TokenNameIdentifier	 get Exception
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
if	TokenNameif	
(	TokenNameLPAREN	
t	TokenNameIdentifier	 t
!=	TokenNameNOT_EQUAL	
null	TokenNamenull	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
IOException	TokenNameIdentifier	 IO Exception
ioe	TokenNameIdentifier	 ioe
=	TokenNameEQUAL	
new	TokenNamenew	
IOException	TokenNameIdentifier	 IO Exception
(	TokenNameLPAREN	
"background merge hit exception: "	TokenNameStringLiteral	background merge hit exception: 
+	TokenNamePLUS	
merge	TokenNameIdentifier	 merge
.	TokenNameDOT	
segString	TokenNameIdentifier	 seg String
(	TokenNameLPAREN	
directory	TokenNameIdentifier	 directory
)	TokenNameRPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
ioe	TokenNameIdentifier	 ioe
.	TokenNameDOT	
initCause	TokenNameIdentifier	 init Cause
(	TokenNameLPAREN	
t	TokenNameIdentifier	 t
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
throw	TokenNamethrow	
ioe	TokenNameIdentifier	 ioe
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
}	TokenNameRBRACE	
// If any of our merges are still running, wait: 	TokenNameCOMMENT_LINE	If any of our merges are still running, wait: 
if	TokenNameif	
(	TokenNameLPAREN	
running	TokenNameIdentifier	 running
)	TokenNameRPAREN	
doWait	TokenNameIdentifier	 do Wait
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
}	TokenNameRBRACE	
}	TokenNameRBRACE	
// NOTE: in the ConcurrentMergeScheduler case, when 	TokenNameCOMMENT_LINE	NOTE: in the ConcurrentMergeScheduler case, when 
// doWait is false, we can return immediately while 	TokenNameCOMMENT_LINE	doWait is false, we can return immediately while 
// background threads accomplish the merging 	TokenNameCOMMENT_LINE	background threads accomplish the merging 
}	TokenNameRBRACE	
/** This method has been deprecated, as it is horribly * inefficient and very rarely justified. Lucene's * multi-segment search performance has improved over * time, and the default TieredMergePolicy now targets * segments with deletions. * * @deprecated */	TokenNameCOMMENT_JAVADOC	 This method has been deprecated, as it is horribly inefficient and very rarely justified. Lucene's multi-segment search performance has improved over time, and the default TieredMergePolicy now targets segments with deletions. * @deprecated 
@	TokenNameAT	
Deprecated	TokenNameIdentifier	 Deprecated
public	TokenNamepublic	
void	TokenNamevoid	
expungeDeletes	TokenNameIdentifier	 expunge Deletes
(	TokenNameLPAREN	
)	TokenNameRPAREN	
throws	TokenNamethrows	
CorruptIndexException	TokenNameIdentifier	 Corrupt Index Exception
,	TokenNameCOMMA	
IOException	TokenNameIdentifier	 IO Exception
{	TokenNameLBRACE	
forceMergeDeletes	TokenNameIdentifier	 force Merge Deletes
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
/** * Forces merging of all segments that have deleted * documents. The actual merges to be executed are * determined by the {@link MergePolicy}. For example, * the default {@link TieredMergePolicy} will only * pick a segment if the percentage of * deleted docs is over 10%. * * <p>This is often a horribly costly operation; rarely * is it warranted.</p> * * <p>To see how * many deletions you have pending in your index, call * {@link IndexReader#numDeletedDocs}.</p> * * <p><b>NOTE</b>: this method first flushes a new * segment (if there are indexed documents), and applies * all buffered deletes. * * <p><b>NOTE</b>: if this method hits an OutOfMemoryError * you should immediately close the writer. See <a * href="#OOME">above</a> for details.</p> */	TokenNameCOMMENT_JAVADOC	 Forces merging of all segments that have deleted documents. The actual merges to be executed are determined by the {@link MergePolicy}. For example, the default {@link TieredMergePolicy} will only pick a segment if the percentage of deleted docs is over 10%. * <p>This is often a horribly costly operation; rarely is it warranted.</p> * <p>To see how many deletions you have pending in your index, call {@link IndexReader#numDeletedDocs}.</p> * <p><b>NOTE</b>: this method first flushes a new segment (if there are indexed documents), and applies all buffered deletes. * <p><b>NOTE</b>: if this method hits an OutOfMemoryError you should immediately close the writer. See <a href="#OOME">above</a> for details.</p> 
public	TokenNamepublic	
void	TokenNamevoid	
forceMergeDeletes	TokenNameIdentifier	 force Merge Deletes
(	TokenNameLPAREN	
)	TokenNameRPAREN	
throws	TokenNamethrows	
CorruptIndexException	TokenNameIdentifier	 Corrupt Index Exception
,	TokenNameCOMMA	
IOException	TokenNameIdentifier	 IO Exception
{	TokenNameLBRACE	
forceMergeDeletes	TokenNameIdentifier	 force Merge Deletes
(	TokenNameLPAREN	
true	TokenNametrue	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
/** * Expert: asks the mergePolicy whether any merges are * necessary now and if so, runs the requested merges and * then iterate (test again if merges are needed) until no * more merges are returned by the mergePolicy. * * Explicit calls to maybeMerge() are usually not * necessary. The most common case is when merge policy * parameters have changed. * * <p><b>NOTE</b>: if this method hits an OutOfMemoryError * you should immediately close the writer. See <a * href="#OOME">above</a> for details.</p> */	TokenNameCOMMENT_JAVADOC	 Expert: asks the mergePolicy whether any merges are necessary now and if so, runs the requested merges and then iterate (test again if merges are needed) until no more merges are returned by the mergePolicy. * Explicit calls to maybeMerge() are usually not necessary. The most common case is when merge policy parameters have changed. * <p><b>NOTE</b>: if this method hits an OutOfMemoryError you should immediately close the writer. See <a href="#OOME">above</a> for details.</p> 
public	TokenNamepublic	
final	TokenNamefinal	
void	TokenNamevoid	
maybeMerge	TokenNameIdentifier	 maybe Merge
(	TokenNameLPAREN	
)	TokenNameRPAREN	
throws	TokenNamethrows	
CorruptIndexException	TokenNameIdentifier	 Corrupt Index Exception
,	TokenNameCOMMA	
IOException	TokenNameIdentifier	 IO Exception
{	TokenNameLBRACE	
maybeMerge	TokenNameIdentifier	 maybe Merge
(	TokenNameLPAREN	
-	TokenNameMINUS	
1	TokenNameIntegerLiteral	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
private	TokenNameprivate	
final	TokenNamefinal	
void	TokenNamevoid	
maybeMerge	TokenNameIdentifier	 maybe Merge
(	TokenNameLPAREN	
int	TokenNameint	
maxNumSegments	TokenNameIdentifier	 max Num Segments
)	TokenNameRPAREN	
throws	TokenNamethrows	
CorruptIndexException	TokenNameIdentifier	 Corrupt Index Exception
,	TokenNameCOMMA	
IOException	TokenNameIdentifier	 IO Exception
{	TokenNameLBRACE	
ensureOpen	TokenNameIdentifier	 ensure Open
(	TokenNameLPAREN	
false	TokenNamefalse	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
updatePendingMerges	TokenNameIdentifier	 update Pending Merges
(	TokenNameLPAREN	
maxNumSegments	TokenNameIdentifier	 max Num Segments
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
mergeScheduler	TokenNameIdentifier	 merge Scheduler
.	TokenNameDOT	
merge	TokenNameIdentifier	 merge
(	TokenNameLPAREN	
this	TokenNamethis	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
private	TokenNameprivate	
synchronized	TokenNamesynchronized	
void	TokenNamevoid	
updatePendingMerges	TokenNameIdentifier	 update Pending Merges
(	TokenNameLPAREN	
int	TokenNameint	
maxNumSegments	TokenNameIdentifier	 max Num Segments
)	TokenNameRPAREN	
throws	TokenNamethrows	
CorruptIndexException	TokenNameIdentifier	 Corrupt Index Exception
,	TokenNameCOMMA	
IOException	TokenNameIdentifier	 IO Exception
{	TokenNameLBRACE	
assert	TokenNameassert	
maxNumSegments	TokenNameIdentifier	 max Num Segments
==	TokenNameEQUAL_EQUAL	
-	TokenNameMINUS	
1	TokenNameIntegerLiteral	
||	TokenNameOR_OR	
maxNumSegments	TokenNameIdentifier	 max Num Segments
>	TokenNameGREATER	
0	TokenNameIntegerLiteral	
;	TokenNameSEMICOLON	
if	TokenNameif	
(	TokenNameLPAREN	
stopMerges	TokenNameIdentifier	 stop Merges
)	TokenNameRPAREN	
{	TokenNameLBRACE	
return	TokenNamereturn	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
// Do not start new merges if we've hit OOME 	TokenNameCOMMENT_LINE	Do not start new merges if we've hit OOME 
if	TokenNameif	
(	TokenNameLPAREN	
hitOOM	TokenNameIdentifier	 hit OOM
)	TokenNameRPAREN	
{	TokenNameLBRACE	
return	TokenNamereturn	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
final	TokenNamefinal	
MergePolicy	TokenNameIdentifier	 Merge Policy
.	TokenNameDOT	
MergeSpecification	TokenNameIdentifier	 Merge Specification
spec	TokenNameIdentifier	 spec
;	TokenNameSEMICOLON	
if	TokenNameif	
(	TokenNameLPAREN	
maxNumSegments	TokenNameIdentifier	 max Num Segments
!=	TokenNameNOT_EQUAL	
-	TokenNameMINUS	
1	TokenNameIntegerLiteral	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
spec	TokenNameIdentifier	 spec
=	TokenNameEQUAL	
mergePolicy	TokenNameIdentifier	 merge Policy
.	TokenNameDOT	
findForcedMerges	TokenNameIdentifier	 find Forced Merges
(	TokenNameLPAREN	
segmentInfos	TokenNameIdentifier	 segment Infos
,	TokenNameCOMMA	
maxNumSegments	TokenNameIdentifier	 max Num Segments
,	TokenNameCOMMA	
Collections	TokenNameIdentifier	 Collections
.	TokenNameDOT	
unmodifiableMap	TokenNameIdentifier	 unmodifiable Map
(	TokenNameLPAREN	
segmentsToMerge	TokenNameIdentifier	 segments To Merge
)	TokenNameRPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
if	TokenNameif	
(	TokenNameLPAREN	
spec	TokenNameIdentifier	 spec
!=	TokenNameNOT_EQUAL	
null	TokenNamenull	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
final	TokenNamefinal	
int	TokenNameint	
numMerges	TokenNameIdentifier	 num Merges
=	TokenNameEQUAL	
spec	TokenNameIdentifier	 spec
.	TokenNameDOT	
merges	TokenNameIdentifier	 merges
.	TokenNameDOT	
size	TokenNameIdentifier	 size
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
for	TokenNamefor	
(	TokenNameLPAREN	
int	TokenNameint	
i	TokenNameIdentifier	 i
=	TokenNameEQUAL	
0	TokenNameIntegerLiteral	
;	TokenNameSEMICOLON	
i	TokenNameIdentifier	 i
<	TokenNameLESS	
numMerges	TokenNameIdentifier	 num Merges
;	TokenNameSEMICOLON	
i	TokenNameIdentifier	 i
++	TokenNamePLUS_PLUS	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
final	TokenNamefinal	
MergePolicy	TokenNameIdentifier	 Merge Policy
.	TokenNameDOT	
OneMerge	TokenNameIdentifier	 One Merge
merge	TokenNameIdentifier	 merge
=	TokenNameEQUAL	
spec	TokenNameIdentifier	 spec
.	TokenNameDOT	
merges	TokenNameIdentifier	 merges
.	TokenNameDOT	
get	TokenNameIdentifier	 get
(	TokenNameLPAREN	
i	TokenNameIdentifier	 i
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
merge	TokenNameIdentifier	 merge
.	TokenNameDOT	
maxNumSegments	TokenNameIdentifier	 max Num Segments
=	TokenNameEQUAL	
maxNumSegments	TokenNameIdentifier	 max Num Segments
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
}	TokenNameRBRACE	
}	TokenNameRBRACE	
else	TokenNameelse	
{	TokenNameLBRACE	
spec	TokenNameIdentifier	 spec
=	TokenNameEQUAL	
mergePolicy	TokenNameIdentifier	 merge Policy
.	TokenNameDOT	
findMerges	TokenNameIdentifier	 find Merges
(	TokenNameLPAREN	
segmentInfos	TokenNameIdentifier	 segment Infos
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
if	TokenNameif	
(	TokenNameLPAREN	
spec	TokenNameIdentifier	 spec
!=	TokenNameNOT_EQUAL	
null	TokenNamenull	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
final	TokenNamefinal	
int	TokenNameint	
numMerges	TokenNameIdentifier	 num Merges
=	TokenNameEQUAL	
spec	TokenNameIdentifier	 spec
.	TokenNameDOT	
merges	TokenNameIdentifier	 merges
.	TokenNameDOT	
size	TokenNameIdentifier	 size
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
for	TokenNamefor	
(	TokenNameLPAREN	
int	TokenNameint	
i	TokenNameIdentifier	 i
=	TokenNameEQUAL	
0	TokenNameIntegerLiteral	
;	TokenNameSEMICOLON	
i	TokenNameIdentifier	 i
<	TokenNameLESS	
numMerges	TokenNameIdentifier	 num Merges
;	TokenNameSEMICOLON	
i	TokenNameIdentifier	 i
++	TokenNamePLUS_PLUS	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
registerMerge	TokenNameIdentifier	 register Merge
(	TokenNameLPAREN	
spec	TokenNameIdentifier	 spec
.	TokenNameDOT	
merges	TokenNameIdentifier	 merges
.	TokenNameDOT	
get	TokenNameIdentifier	 get
(	TokenNameLPAREN	
i	TokenNameIdentifier	 i
)	TokenNameRPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
}	TokenNameRBRACE	
}	TokenNameRBRACE	
/** Expert: to be used by a {@link MergePolicy} to avoid * selecting merges for segments already being merged. * The returned collection is not cloned, and thus is * only safe to access if you hold IndexWriter's lock * (which you do when IndexWriter invokes the * MergePolicy). * * <p>Do not alter the returned collection! */	TokenNameCOMMENT_JAVADOC	 Expert: to be used by a {@link MergePolicy} to avoid selecting merges for segments already being merged. The returned collection is not cloned, and thus is only safe to access if you hold IndexWriter's lock (which you do when IndexWriter invokes the MergePolicy). * <p>Do not alter the returned collection! 
public	TokenNamepublic	
synchronized	TokenNamesynchronized	
Collection	TokenNameIdentifier	 Collection
<	TokenNameLESS	
SegmentInfo	TokenNameIdentifier	 Segment Info
>	TokenNameGREATER	
getMergingSegments	TokenNameIdentifier	 get Merging Segments
(	TokenNameLPAREN	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
return	TokenNamereturn	
mergingSegments	TokenNameIdentifier	 merging Segments
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
/** Expert: the {@link MergeScheduler} calls this method * to retrieve the next merge requested by the * MergePolicy * * @lucene.experimental */	TokenNameCOMMENT_JAVADOC	 Expert: the {@link MergeScheduler} calls this method to retrieve the next merge requested by the MergePolicy * @lucene.experimental 
public	TokenNamepublic	
synchronized	TokenNamesynchronized	
MergePolicy	TokenNameIdentifier	 Merge Policy
.	TokenNameDOT	
OneMerge	TokenNameIdentifier	 One Merge
getNextMerge	TokenNameIdentifier	 get Next Merge
(	TokenNameLPAREN	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
if	TokenNameif	
(	TokenNameLPAREN	
pendingMerges	TokenNameIdentifier	 pending Merges
.	TokenNameDOT	
size	TokenNameIdentifier	 size
(	TokenNameLPAREN	
)	TokenNameRPAREN	
==	TokenNameEQUAL_EQUAL	
0	TokenNameIntegerLiteral	
)	TokenNameRPAREN	
return	TokenNamereturn	
null	TokenNamenull	
;	TokenNameSEMICOLON	
else	TokenNameelse	
{	TokenNameLBRACE	
// Advance the merge from pending to running 	TokenNameCOMMENT_LINE	Advance the merge from pending to running 
MergePolicy	TokenNameIdentifier	 Merge Policy
.	TokenNameDOT	
OneMerge	TokenNameIdentifier	 One Merge
merge	TokenNameIdentifier	 merge
=	TokenNameEQUAL	
pendingMerges	TokenNameIdentifier	 pending Merges
.	TokenNameDOT	
removeFirst	TokenNameIdentifier	 remove First
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
runningMerges	TokenNameIdentifier	 running Merges
.	TokenNameDOT	
add	TokenNameIdentifier	 add
(	TokenNameLPAREN	
merge	TokenNameIdentifier	 merge
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
return	TokenNamereturn	
merge	TokenNameIdentifier	 merge
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
}	TokenNameRBRACE	
/** * Close the <code>IndexWriter</code> without committing * any changes that have occurred since the last commit * (or since it was opened, if commit hasn't been called). * This removes any temporary files that had been created, * after which the state of the index will be the same as * it was when commit() was last called or when this * writer was first opened. This also clears a previous * call to {@link #prepareCommit}. * @throws IOException if there is a low-level IO error */	TokenNameCOMMENT_JAVADOC	 Close the <code>IndexWriter</code> without committing any changes that have occurred since the last commit (or since it was opened, if commit hasn't been called). This removes any temporary files that had been created, after which the state of the index will be the same as it was when commit() was last called or when this writer was first opened. This also clears a previous call to {@link #prepareCommit}. @throws IOException if there is a low-level IO error 
public	TokenNamepublic	
void	TokenNamevoid	
rollback	TokenNameIdentifier	 rollback
(	TokenNameLPAREN	
)	TokenNameRPAREN	
throws	TokenNamethrows	
IOException	TokenNameIdentifier	 IO Exception
{	TokenNameLBRACE	
ensureOpen	TokenNameIdentifier	 ensure Open
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
// Ensure that only one thread actually gets to do the closing: 	TokenNameCOMMENT_LINE	Ensure that only one thread actually gets to do the closing: 
if	TokenNameif	
(	TokenNameLPAREN	
shouldClose	TokenNameIdentifier	 should Close
(	TokenNameLPAREN	
)	TokenNameRPAREN	
)	TokenNameRPAREN	
rollbackInternal	TokenNameIdentifier	 rollback Internal
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
private	TokenNameprivate	
void	TokenNamevoid	
rollbackInternal	TokenNameIdentifier	 rollback Internal
(	TokenNameLPAREN	
)	TokenNameRPAREN	
throws	TokenNamethrows	
IOException	TokenNameIdentifier	 IO Exception
{	TokenNameLBRACE	
boolean	TokenNameboolean	
success	TokenNameIdentifier	 success
=	TokenNameEQUAL	
false	TokenNamefalse	
;	TokenNameSEMICOLON	
if	TokenNameif	
(	TokenNameLPAREN	
infoStream	TokenNameIdentifier	 info Stream
!=	TokenNameNOT_EQUAL	
null	TokenNamenull	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
message	TokenNameIdentifier	 message
(	TokenNameLPAREN	
"rollback"	TokenNameStringLiteral	rollback
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
try	TokenNametry	
{	TokenNameLBRACE	
synchronized	TokenNamesynchronized	
(	TokenNameLPAREN	
this	TokenNamethis	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
finishMerges	TokenNameIdentifier	 finish Merges
(	TokenNameLPAREN	
false	TokenNamefalse	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
stopMerges	TokenNameIdentifier	 stop Merges
=	TokenNameEQUAL	
true	TokenNametrue	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
if	TokenNameif	
(	TokenNameLPAREN	
infoStream	TokenNameIdentifier	 info Stream
!=	TokenNameNOT_EQUAL	
null	TokenNamenull	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
message	TokenNameIdentifier	 message
(	TokenNameLPAREN	
"rollback: done finish merges"	TokenNameStringLiteral	rollback: done finish merges
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
// Must pre-close these two, in case they increment 	TokenNameCOMMENT_LINE	Must pre-close these two, in case they increment 
// changeCount so that we can then set it to false 	TokenNameCOMMENT_LINE	changeCount so that we can then set it to false 
// before calling closeInternal 	TokenNameCOMMENT_LINE	before calling closeInternal 
mergePolicy	TokenNameIdentifier	 merge Policy
.	TokenNameDOT	
close	TokenNameIdentifier	 close
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
mergeScheduler	TokenNameIdentifier	 merge Scheduler
.	TokenNameDOT	
close	TokenNameIdentifier	 close
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
bufferedDeletesStream	TokenNameIdentifier	 buffered Deletes Stream
.	TokenNameDOT	
clear	TokenNameIdentifier	 clear
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
synchronized	TokenNamesynchronized	
(	TokenNameLPAREN	
this	TokenNamethis	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
if	TokenNameif	
(	TokenNameLPAREN	
pendingCommit	TokenNameIdentifier	 pending Commit
!=	TokenNameNOT_EQUAL	
null	TokenNamenull	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
pendingCommit	TokenNameIdentifier	 pending Commit
.	TokenNameDOT	
rollbackCommit	TokenNameIdentifier	 rollback Commit
(	TokenNameLPAREN	
directory	TokenNameIdentifier	 directory
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
deleter	TokenNameIdentifier	 deleter
.	TokenNameDOT	
decRef	TokenNameIdentifier	 dec Ref
(	TokenNameLPAREN	
pendingCommit	TokenNameIdentifier	 pending Commit
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
pendingCommit	TokenNameIdentifier	 pending Commit
=	TokenNameEQUAL	
null	TokenNamenull	
;	TokenNameSEMICOLON	
notifyAll	TokenNameIdentifier	 notify All
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
// Keep the same segmentInfos instance but replace all 	TokenNameCOMMENT_LINE	Keep the same segmentInfos instance but replace all 
// of its SegmentInfo instances. This is so the next 	TokenNameCOMMENT_LINE	of its SegmentInfo instances. This is so the next 
// attempt to commit using this instance of IndexWriter 	TokenNameCOMMENT_LINE	attempt to commit using this instance of IndexWriter 
// will always write to a new generation ("write 	TokenNameCOMMENT_LINE	will always write to a new generation ("write 
// once"). 	TokenNameCOMMENT_LINE	once"). 
segmentInfos	TokenNameIdentifier	 segment Infos
.	TokenNameDOT	
rollbackSegmentInfos	TokenNameIdentifier	 rollback Segment Infos
(	TokenNameLPAREN	
rollbackSegments	TokenNameIdentifier	 rollback Segments
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
if	TokenNameif	
(	TokenNameLPAREN	
infoStream	TokenNameIdentifier	 info Stream
!=	TokenNameNOT_EQUAL	
null	TokenNamenull	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
message	TokenNameIdentifier	 message
(	TokenNameLPAREN	
"rollback: infos="	TokenNameStringLiteral	rollback: infos=
+	TokenNamePLUS	
segString	TokenNameIdentifier	 seg String
(	TokenNameLPAREN	
segmentInfos	TokenNameIdentifier	 segment Infos
)	TokenNameRPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
docWriter	TokenNameIdentifier	 doc Writer
.	TokenNameDOT	
abort	TokenNameIdentifier	 abort
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
assert	TokenNameassert	
testPoint	TokenNameIdentifier	 test Point
(	TokenNameLPAREN	
"rollback before checkpoint"	TokenNameStringLiteral	rollback before checkpoint
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
// Ask deleter to locate unreferenced files & remove 	TokenNameCOMMENT_LINE	Ask deleter to locate unreferenced files & remove 
// them: 	TokenNameCOMMENT_LINE	them: 
deleter	TokenNameIdentifier	 deleter
.	TokenNameDOT	
checkpoint	TokenNameIdentifier	 checkpoint
(	TokenNameLPAREN	
segmentInfos	TokenNameIdentifier	 segment Infos
,	TokenNameCOMMA	
false	TokenNamefalse	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
deleter	TokenNameIdentifier	 deleter
.	TokenNameDOT	
refresh	TokenNameIdentifier	 refresh
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
// Don't bother saving any changes in our segmentInfos 	TokenNameCOMMENT_LINE	Don't bother saving any changes in our segmentInfos 
readerPool	TokenNameIdentifier	 reader Pool
.	TokenNameDOT	
clear	TokenNameIdentifier	 clear
(	TokenNameLPAREN	
null	TokenNamenull	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
lastCommitChangeCount	TokenNameIdentifier	 last Commit Change Count
=	TokenNameEQUAL	
changeCount	TokenNameIdentifier	 change Count
;	TokenNameSEMICOLON	
success	TokenNameIdentifier	 success
=	TokenNameEQUAL	
true	TokenNametrue	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
catch	TokenNamecatch	
(	TokenNameLPAREN	
OutOfMemoryError	TokenNameIdentifier	 Out Of Memory Error
oom	TokenNameIdentifier	 oom
)	TokenNameRPAREN	
{	TokenNameLBRACE	
handleOOM	TokenNameIdentifier	 handle OOM
(	TokenNameLPAREN	
oom	TokenNameIdentifier	 oom
,	TokenNameCOMMA	
"rollbackInternal"	TokenNameStringLiteral	rollbackInternal
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
finally	TokenNamefinally	
{	TokenNameLBRACE	
synchronized	TokenNamesynchronized	
(	TokenNameLPAREN	
this	TokenNamethis	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
if	TokenNameif	
(	TokenNameLPAREN	
!	TokenNameNOT	
success	TokenNameIdentifier	 success
)	TokenNameRPAREN	
{	TokenNameLBRACE	
closing	TokenNameIdentifier	 closing
=	TokenNameEQUAL	
false	TokenNamefalse	
;	TokenNameSEMICOLON	
notifyAll	TokenNameIdentifier	 notify All
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
if	TokenNameif	
(	TokenNameLPAREN	
infoStream	TokenNameIdentifier	 info Stream
!=	TokenNameNOT_EQUAL	
null	TokenNamenull	
)	TokenNameRPAREN	
message	TokenNameIdentifier	 message
(	TokenNameLPAREN	
"hit exception during rollback"	TokenNameStringLiteral	hit exception during rollback
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
}	TokenNameRBRACE	
}	TokenNameRBRACE	
closeInternal	TokenNameIdentifier	 close Internal
(	TokenNameLPAREN	
false	TokenNamefalse	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
/** * Delete all documents in the index. * * <p>This method will drop all buffered documents and will * remove all segments from the index. This change will not be * visible until a {@link #commit()} has been called. This method * can be rolled back using {@link #rollback()}.</p> * * <p>NOTE: this method is much faster than using deleteDocuments( new MatchAllDocsQuery() ).</p> * * <p>NOTE: this method will forcefully abort all merges * in progress. If other threads are running {@link * #forceMerge}, {@link #addIndexes(IndexReader[])} or * {@link #forceMergeDeletes} methods, they may receive * {@link MergePolicy.MergeAbortedException}s. */	TokenNameCOMMENT_JAVADOC	 Delete all documents in the index. * <p>This method will drop all buffered documents and will remove all segments from the index. This change will not be visible until a {@link #commit()} has been called. This method can be rolled back using {@link #rollback()}.</p> * <p>NOTE: this method is much faster than using deleteDocuments( new MatchAllDocsQuery() ).</p> * <p>NOTE: this method will forcefully abort all merges in progress. If other threads are running {@link #forceMerge}, {@link #addIndexes(IndexReader[])} or {@link #forceMergeDeletes} methods, they may receive {@link MergePolicy.MergeAbortedException}s. 
public	TokenNamepublic	
synchronized	TokenNamesynchronized	
void	TokenNamevoid	
deleteAll	TokenNameIdentifier	 delete All
(	TokenNameLPAREN	
)	TokenNameRPAREN	
throws	TokenNamethrows	
IOException	TokenNameIdentifier	 IO Exception
{	TokenNameLBRACE	
ensureOpen	TokenNameIdentifier	 ensure Open
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
try	TokenNametry	
{	TokenNameLBRACE	
// Abort any running merges 	TokenNameCOMMENT_LINE	Abort any running merges 
finishMerges	TokenNameIdentifier	 finish Merges
(	TokenNameLPAREN	
false	TokenNamefalse	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
// Remove any buffered docs 	TokenNameCOMMENT_LINE	Remove any buffered docs 
docWriter	TokenNameIdentifier	 doc Writer
.	TokenNameDOT	
abort	TokenNameIdentifier	 abort
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
// Remove all segments 	TokenNameCOMMENT_LINE	Remove all segments 
segmentInfos	TokenNameIdentifier	 segment Infos
.	TokenNameDOT	
clear	TokenNameIdentifier	 clear
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
// Ask deleter to locate unreferenced files & remove them: 	TokenNameCOMMENT_LINE	Ask deleter to locate unreferenced files & remove them: 
deleter	TokenNameIdentifier	 deleter
.	TokenNameDOT	
checkpoint	TokenNameIdentifier	 checkpoint
(	TokenNameLPAREN	
segmentInfos	TokenNameIdentifier	 segment Infos
,	TokenNameCOMMA	
false	TokenNamefalse	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
deleter	TokenNameIdentifier	 deleter
.	TokenNameDOT	
refresh	TokenNameIdentifier	 refresh
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
// Don't bother saving any changes in our segmentInfos 	TokenNameCOMMENT_LINE	Don't bother saving any changes in our segmentInfos 
readerPool	TokenNameIdentifier	 reader Pool
.	TokenNameDOT	
dropAll	TokenNameIdentifier	 drop All
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
// Mark that the index has changed 	TokenNameCOMMENT_LINE	Mark that the index has changed 
++	TokenNamePLUS_PLUS	
changeCount	TokenNameIdentifier	 change Count
;	TokenNameSEMICOLON	
segmentInfos	TokenNameIdentifier	 segment Infos
.	TokenNameDOT	
changed	TokenNameIdentifier	 changed
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
catch	TokenNamecatch	
(	TokenNameLPAREN	
OutOfMemoryError	TokenNameIdentifier	 Out Of Memory Error
oom	TokenNameIdentifier	 oom
)	TokenNameRPAREN	
{	TokenNameLBRACE	
handleOOM	TokenNameIdentifier	 handle OOM
(	TokenNameLPAREN	
oom	TokenNameIdentifier	 oom
,	TokenNameCOMMA	
"deleteAll"	TokenNameStringLiteral	deleteAll
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
finally	TokenNamefinally	
{	TokenNameLBRACE	
if	TokenNameif	
(	TokenNameLPAREN	
infoStream	TokenNameIdentifier	 info Stream
!=	TokenNameNOT_EQUAL	
null	TokenNamenull	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
message	TokenNameIdentifier	 message
(	TokenNameLPAREN	
"hit exception during deleteAll"	TokenNameStringLiteral	hit exception during deleteAll
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
}	TokenNameRBRACE	
}	TokenNameRBRACE	
private	TokenNameprivate	
synchronized	TokenNamesynchronized	
void	TokenNamevoid	
finishMerges	TokenNameIdentifier	 finish Merges
(	TokenNameLPAREN	
boolean	TokenNameboolean	
waitForMerges	TokenNameIdentifier	 wait For Merges
)	TokenNameRPAREN	
throws	TokenNamethrows	
IOException	TokenNameIdentifier	 IO Exception
{	TokenNameLBRACE	
if	TokenNameif	
(	TokenNameLPAREN	
!	TokenNameNOT	
waitForMerges	TokenNameIdentifier	 wait For Merges
)	TokenNameRPAREN	
{	TokenNameLBRACE	
stopMerges	TokenNameIdentifier	 stop Merges
=	TokenNameEQUAL	
true	TokenNametrue	
;	TokenNameSEMICOLON	
// Abort all pending & running merges: 	TokenNameCOMMENT_LINE	Abort all pending & running merges: 
for	TokenNamefor	
(	TokenNameLPAREN	
final	TokenNamefinal	
MergePolicy	TokenNameIdentifier	 Merge Policy
.	TokenNameDOT	
OneMerge	TokenNameIdentifier	 One Merge
merge	TokenNameIdentifier	 merge
:	TokenNameCOLON	
pendingMerges	TokenNameIdentifier	 pending Merges
)	TokenNameRPAREN	
{	TokenNameLBRACE	
if	TokenNameif	
(	TokenNameLPAREN	
infoStream	TokenNameIdentifier	 info Stream
!=	TokenNameNOT_EQUAL	
null	TokenNamenull	
)	TokenNameRPAREN	
message	TokenNameIdentifier	 message
(	TokenNameLPAREN	
"now abort pending merge "	TokenNameStringLiteral	now abort pending merge 
+	TokenNamePLUS	
merge	TokenNameIdentifier	 merge
.	TokenNameDOT	
segString	TokenNameIdentifier	 seg String
(	TokenNameLPAREN	
directory	TokenNameIdentifier	 directory
)	TokenNameRPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
merge	TokenNameIdentifier	 merge
.	TokenNameDOT	
abort	TokenNameIdentifier	 abort
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
mergeFinish	TokenNameIdentifier	 merge Finish
(	TokenNameLPAREN	
merge	TokenNameIdentifier	 merge
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
pendingMerges	TokenNameIdentifier	 pending Merges
.	TokenNameDOT	
clear	TokenNameIdentifier	 clear
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
for	TokenNamefor	
(	TokenNameLPAREN	
final	TokenNamefinal	
MergePolicy	TokenNameIdentifier	 Merge Policy
.	TokenNameDOT	
OneMerge	TokenNameIdentifier	 One Merge
merge	TokenNameIdentifier	 merge
:	TokenNameCOLON	
runningMerges	TokenNameIdentifier	 running Merges
)	TokenNameRPAREN	
{	TokenNameLBRACE	
if	TokenNameif	
(	TokenNameLPAREN	
infoStream	TokenNameIdentifier	 info Stream
!=	TokenNameNOT_EQUAL	
null	TokenNamenull	
)	TokenNameRPAREN	
message	TokenNameIdentifier	 message
(	TokenNameLPAREN	
"now abort running merge "	TokenNameStringLiteral	now abort running merge 
+	TokenNamePLUS	
merge	TokenNameIdentifier	 merge
.	TokenNameDOT	
segString	TokenNameIdentifier	 seg String
(	TokenNameLPAREN	
directory	TokenNameIdentifier	 directory
)	TokenNameRPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
merge	TokenNameIdentifier	 merge
.	TokenNameDOT	
abort	TokenNameIdentifier	 abort
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
// These merges periodically check whether they have 	TokenNameCOMMENT_LINE	These merges periodically check whether they have 
// been aborted, and stop if so. We wait here to make 	TokenNameCOMMENT_LINE	been aborted, and stop if so. We wait here to make 
// sure they all stop. It should not take very long 	TokenNameCOMMENT_LINE	sure they all stop. It should not take very long 
// because the merge threads periodically check if 	TokenNameCOMMENT_LINE	because the merge threads periodically check if 
// they are aborted. 	TokenNameCOMMENT_LINE	they are aborted. 
while	TokenNamewhile	
(	TokenNameLPAREN	
runningMerges	TokenNameIdentifier	 running Merges
.	TokenNameDOT	
size	TokenNameIdentifier	 size
(	TokenNameLPAREN	
)	TokenNameRPAREN	
>	TokenNameGREATER	
0	TokenNameIntegerLiteral	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
if	TokenNameif	
(	TokenNameLPAREN	
infoStream	TokenNameIdentifier	 info Stream
!=	TokenNameNOT_EQUAL	
null	TokenNamenull	
)	TokenNameRPAREN	
message	TokenNameIdentifier	 message
(	TokenNameLPAREN	
"now wait for "	TokenNameStringLiteral	now wait for 
+	TokenNamePLUS	
runningMerges	TokenNameIdentifier	 running Merges
.	TokenNameDOT	
size	TokenNameIdentifier	 size
(	TokenNameLPAREN	
)	TokenNameRPAREN	
+	TokenNamePLUS	
" running merge to abort"	TokenNameStringLiteral	 running merge to abort
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
doWait	TokenNameIdentifier	 do Wait
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
stopMerges	TokenNameIdentifier	 stop Merges
=	TokenNameEQUAL	
false	TokenNamefalse	
;	TokenNameSEMICOLON	
notifyAll	TokenNameIdentifier	 notify All
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
assert	TokenNameassert	
0	TokenNameIntegerLiteral	
==	TokenNameEQUAL_EQUAL	
mergingSegments	TokenNameIdentifier	 merging Segments
.	TokenNameDOT	
size	TokenNameIdentifier	 size
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
if	TokenNameif	
(	TokenNameLPAREN	
infoStream	TokenNameIdentifier	 info Stream
!=	TokenNameNOT_EQUAL	
null	TokenNamenull	
)	TokenNameRPAREN	
message	TokenNameIdentifier	 message
(	TokenNameLPAREN	
"all running merges have aborted"	TokenNameStringLiteral	all running merges have aborted
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
else	TokenNameelse	
{	TokenNameLBRACE	
// waitForMerges() will ensure any running addIndexes finishes. 	TokenNameCOMMENT_LINE	waitForMerges() will ensure any running addIndexes finishes. 
// It's fine if a new one attempts to start because from our 	TokenNameCOMMENT_LINE	It's fine if a new one attempts to start because from our 
// caller above the call will see that we are in the 	TokenNameCOMMENT_LINE	caller above the call will see that we are in the 
// process of closing, and will throw an 	TokenNameCOMMENT_LINE	process of closing, and will throw an 
// AlreadyClosedException. 	TokenNameCOMMENT_LINE	AlreadyClosedException. 
waitForMerges	TokenNameIdentifier	 wait For Merges
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
}	TokenNameRBRACE	
/** * Wait for any currently outstanding merges to finish. * * <p>It is guaranteed that any merges started prior to calling this method * will have completed once this method completes.</p> */	TokenNameCOMMENT_JAVADOC	 Wait for any currently outstanding merges to finish. * <p>It is guaranteed that any merges started prior to calling this method will have completed once this method completes.</p> 
public	TokenNamepublic	
synchronized	TokenNamesynchronized	
void	TokenNamevoid	
waitForMerges	TokenNameIdentifier	 wait For Merges
(	TokenNameLPAREN	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
ensureOpen	TokenNameIdentifier	 ensure Open
(	TokenNameLPAREN	
false	TokenNamefalse	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
if	TokenNameif	
(	TokenNameLPAREN	
infoStream	TokenNameIdentifier	 info Stream
!=	TokenNameNOT_EQUAL	
null	TokenNamenull	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
message	TokenNameIdentifier	 message
(	TokenNameLPAREN	
"waitForMerges"	TokenNameStringLiteral	waitForMerges
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
while	TokenNamewhile	
(	TokenNameLPAREN	
pendingMerges	TokenNameIdentifier	 pending Merges
.	TokenNameDOT	
size	TokenNameIdentifier	 size
(	TokenNameLPAREN	
)	TokenNameRPAREN	
>	TokenNameGREATER	
0	TokenNameIntegerLiteral	
||	TokenNameOR_OR	
runningMerges	TokenNameIdentifier	 running Merges
.	TokenNameDOT	
size	TokenNameIdentifier	 size
(	TokenNameLPAREN	
)	TokenNameRPAREN	
>	TokenNameGREATER	
0	TokenNameIntegerLiteral	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
doWait	TokenNameIdentifier	 do Wait
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
// sanity check 	TokenNameCOMMENT_LINE	sanity check 
assert	TokenNameassert	
0	TokenNameIntegerLiteral	
==	TokenNameEQUAL_EQUAL	
mergingSegments	TokenNameIdentifier	 merging Segments
.	TokenNameDOT	
size	TokenNameIdentifier	 size
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
if	TokenNameif	
(	TokenNameLPAREN	
infoStream	TokenNameIdentifier	 info Stream
!=	TokenNameNOT_EQUAL	
null	TokenNamenull	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
message	TokenNameIdentifier	 message
(	TokenNameLPAREN	
"waitForMerges done"	TokenNameStringLiteral	waitForMerges done
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
}	TokenNameRBRACE	
/** * Called whenever the SegmentInfos has been updated and * the index files referenced exist (correctly) in the * index directory. */	TokenNameCOMMENT_JAVADOC	 Called whenever the SegmentInfos has been updated and the index files referenced exist (correctly) in the index directory. 
synchronized	TokenNamesynchronized	
void	TokenNamevoid	
checkpoint	TokenNameIdentifier	 checkpoint
(	TokenNameLPAREN	
)	TokenNameRPAREN	
throws	TokenNamethrows	
IOException	TokenNameIdentifier	 IO Exception
{	TokenNameLBRACE	
changeCount	TokenNameIdentifier	 change Count
++	TokenNamePLUS_PLUS	
;	TokenNameSEMICOLON	
segmentInfos	TokenNameIdentifier	 segment Infos
.	TokenNameDOT	
changed	TokenNameIdentifier	 changed
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
deleter	TokenNameIdentifier	 deleter
.	TokenNameDOT	
checkpoint	TokenNameIdentifier	 checkpoint
(	TokenNameLPAREN	
segmentInfos	TokenNameIdentifier	 segment Infos
,	TokenNameCOMMA	
false	TokenNamefalse	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
private	TokenNameprivate	
synchronized	TokenNamesynchronized	
void	TokenNamevoid	
resetMergeExceptions	TokenNameIdentifier	 reset Merge Exceptions
(	TokenNameLPAREN	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
mergeExceptions	TokenNameIdentifier	 merge Exceptions
=	TokenNameEQUAL	
new	TokenNamenew	
ArrayList	TokenNameIdentifier	 Array List
<	TokenNameLESS	
MergePolicy	TokenNameIdentifier	 Merge Policy
.	TokenNameDOT	
OneMerge	TokenNameIdentifier	 One Merge
>	TokenNameGREATER	
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
mergeGen	TokenNameIdentifier	 merge Gen
++	TokenNamePLUS_PLUS	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
private	TokenNameprivate	
void	TokenNamevoid	
noDupDirs	TokenNameIdentifier	 no Dup Dirs
(	TokenNameLPAREN	
Directory	TokenNameIdentifier	 Directory
...	TokenNameELLIPSIS	
dirs	TokenNameIdentifier	 dirs
)	TokenNameRPAREN	
{	TokenNameLBRACE	
HashSet	TokenNameIdentifier	 Hash Set
<	TokenNameLESS	
Directory	TokenNameIdentifier	 Directory
>	TokenNameGREATER	
dups	TokenNameIdentifier	 dups
=	TokenNameEQUAL	
new	TokenNamenew	
HashSet	TokenNameIdentifier	 Hash Set
<	TokenNameLESS	
Directory	TokenNameIdentifier	 Directory
>	TokenNameGREATER	
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
for	TokenNamefor	
(	TokenNameLPAREN	
Directory	TokenNameIdentifier	 Directory
dir	TokenNameIdentifier	 dir
:	TokenNameCOLON	
dirs	TokenNameIdentifier	 dirs
)	TokenNameRPAREN	
{	TokenNameLBRACE	
if	TokenNameif	
(	TokenNameLPAREN	
dups	TokenNameIdentifier	 dups
.	TokenNameDOT	
contains	TokenNameIdentifier	 contains
(	TokenNameLPAREN	
dir	TokenNameIdentifier	 dir
)	TokenNameRPAREN	
)	TokenNameRPAREN	
throw	TokenNamethrow	
new	TokenNamenew	
IllegalArgumentException	TokenNameIdentifier	 Illegal Argument Exception
(	TokenNameLPAREN	
"Directory "	TokenNameStringLiteral	Directory 
+	TokenNamePLUS	
dir	TokenNameIdentifier	 dir
+	TokenNamePLUS	
" appears more than once"	TokenNameStringLiteral	 appears more than once
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
if	TokenNameif	
(	TokenNameLPAREN	
dir	TokenNameIdentifier	 dir
==	TokenNameEQUAL_EQUAL	
directory	TokenNameIdentifier	 directory
)	TokenNameRPAREN	
throw	TokenNamethrow	
new	TokenNamenew	
IllegalArgumentException	TokenNameIdentifier	 Illegal Argument Exception
(	TokenNameLPAREN	
"Cannot add directory to itself"	TokenNameStringLiteral	Cannot add directory to itself
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
dups	TokenNameIdentifier	 dups
.	TokenNameDOT	
add	TokenNameIdentifier	 add
(	TokenNameLPAREN	
dir	TokenNameIdentifier	 dir
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
}	TokenNameRBRACE	
/** * @deprecated use {@link #addIndexes(Directory...)} instead */	TokenNameCOMMENT_JAVADOC	 @deprecated use {@link #addIndexes(Directory...)} instead 
@	TokenNameAT	
Deprecated	TokenNameIdentifier	 Deprecated
public	TokenNamepublic	
void	TokenNamevoid	
addIndexesNoOptimize	TokenNameIdentifier	 add Indexes No Optimize
(	TokenNameLPAREN	
Directory	TokenNameIdentifier	 Directory
...	TokenNameELLIPSIS	
dirs	TokenNameIdentifier	 dirs
)	TokenNameRPAREN	
throws	TokenNamethrows	
CorruptIndexException	TokenNameIdentifier	 Corrupt Index Exception
,	TokenNameCOMMA	
IOException	TokenNameIdentifier	 IO Exception
{	TokenNameLBRACE	
addIndexes	TokenNameIdentifier	 add Indexes
(	TokenNameLPAREN	
dirs	TokenNameIdentifier	 dirs
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
/** * Adds all segments from an array of indexes into this index. * * <p>This may be used to parallelize batch indexing. A large document * collection can be broken into sub-collections. Each sub-collection can be * indexed in parallel, on a different thread, process or machine. The * complete index can then be created by merging sub-collection indexes * with this method. * * <p> * <b>NOTE:</b> the index in each {@link Directory} must not be * changed (opened by a writer) while this method is * running. This method does not acquire a write lock in * each input Directory, so it is up to the caller to * enforce this. * * <p>This method is transactional in how Exceptions are * handled: it does not commit a new segments_N file until * all indexes are added. This means if an Exception * occurs (for example disk full), then either no indexes * will have been added or they all will have been. * * <p>Note that this requires temporary free space in the * {@link Directory} up to 2X the sum of all input indexes * (including the starting index). If readers/searchers * are open against the starting index, then temporary * free space required will be higher by the size of the * starting index (see {@link #forceMerge(int)} for details). * * <p> * <b>NOTE:</b> this method only copies the segments of the incomning indexes * and does not merge them. Therefore deleted documents are not removed and * the new segments are not merged with the existing ones. * * <p> * <p>This requires this index not be among those to be added. * * <p> * <b>NOTE</b>: if this method hits an OutOfMemoryError * you should immediately close the writer. See <a * href="#OOME">above</a> for details. * * @throws CorruptIndexException if the index is corrupt * @throws IOException if there is a low-level IO error */	TokenNameCOMMENT_JAVADOC	 Adds all segments from an array of indexes into this index. * <p>This may be used to parallelize batch indexing. A large document collection can be broken into sub-collections. Each sub-collection can be indexed in parallel, on a different thread, process or machine. The complete index can then be created by merging sub-collection indexes with this method. * <p> <b>NOTE:</b> the index in each {@link Directory} must not be changed (opened by a writer) while this method is running. This method does not acquire a write lock in each input Directory, so it is up to the caller to enforce this. * <p>This method is transactional in how Exceptions are handled: it does not commit a new segments_N file until all indexes are added. This means if an Exception occurs (for example disk full), then either no indexes will have been added or they all will have been. * <p>Note that this requires temporary free space in the {@link Directory} up to 2X the sum of all input indexes (including the starting index). If readers/searchers are open against the starting index, then temporary free space required will be higher by the size of the starting index (see {@link #forceMerge(int)} for details). * <p> <b>NOTE:</b> this method only copies the segments of the incomning indexes and does not merge them. Therefore deleted documents are not removed and the new segments are not merged with the existing ones. * <p> <p>This requires this index not be among those to be added. * <p> <b>NOTE</b>: if this method hits an OutOfMemoryError you should immediately close the writer. See <a href="#OOME">above</a> for details. * @throws CorruptIndexException if the index is corrupt @throws IOException if there is a low-level IO error 
public	TokenNamepublic	
void	TokenNamevoid	
addIndexes	TokenNameIdentifier	 add Indexes
(	TokenNameLPAREN	
Directory	TokenNameIdentifier	 Directory
...	TokenNameELLIPSIS	
dirs	TokenNameIdentifier	 dirs
)	TokenNameRPAREN	
throws	TokenNamethrows	
CorruptIndexException	TokenNameIdentifier	 Corrupt Index Exception
,	TokenNameCOMMA	
IOException	TokenNameIdentifier	 IO Exception
{	TokenNameLBRACE	
ensureOpen	TokenNameIdentifier	 ensure Open
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
noDupDirs	TokenNameIdentifier	 no Dup Dirs
(	TokenNameLPAREN	
dirs	TokenNameIdentifier	 dirs
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
try	TokenNametry	
{	TokenNameLBRACE	
if	TokenNameif	
(	TokenNameLPAREN	
infoStream	TokenNameIdentifier	 info Stream
!=	TokenNameNOT_EQUAL	
null	TokenNamenull	
)	TokenNameRPAREN	
message	TokenNameIdentifier	 message
(	TokenNameLPAREN	
"flush at addIndexes(Directory...)"	TokenNameStringLiteral	flush at addIndexes(Directory...)
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
flush	TokenNameIdentifier	 flush
(	TokenNameLPAREN	
false	TokenNamefalse	
,	TokenNameCOMMA	
true	TokenNametrue	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
List	TokenNameIdentifier	 List
<	TokenNameLESS	
SegmentInfo	TokenNameIdentifier	 Segment Info
>	TokenNameGREATER	
infos	TokenNameIdentifier	 infos
=	TokenNameEQUAL	
new	TokenNamenew	
ArrayList	TokenNameIdentifier	 Array List
<	TokenNameLESS	
SegmentInfo	TokenNameIdentifier	 Segment Info
>	TokenNameGREATER	
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
Comparator	TokenNameIdentifier	 Comparator
<	TokenNameLESS	
String	TokenNameIdentifier	 String
>	TokenNameGREATER	
versionComparator	TokenNameIdentifier	 version Comparator
=	TokenNameEQUAL	
StringHelper	TokenNameIdentifier	 String Helper
.	TokenNameDOT	
getVersionComparator	TokenNameIdentifier	 get Version Comparator
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
for	TokenNamefor	
(	TokenNameLPAREN	
Directory	TokenNameIdentifier	 Directory
dir	TokenNameIdentifier	 dir
:	TokenNameCOLON	
dirs	TokenNameIdentifier	 dirs
)	TokenNameRPAREN	
{	TokenNameLBRACE	
if	TokenNameif	
(	TokenNameLPAREN	
infoStream	TokenNameIdentifier	 info Stream
!=	TokenNameNOT_EQUAL	
null	TokenNamenull	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
message	TokenNameIdentifier	 message
(	TokenNameLPAREN	
"addIndexes: process directory "	TokenNameStringLiteral	addIndexes: process directory 
+	TokenNamePLUS	
dir	TokenNameIdentifier	 dir
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
SegmentInfos	TokenNameIdentifier	 Segment Infos
sis	TokenNameIdentifier	 sis
=	TokenNameEQUAL	
new	TokenNamenew	
SegmentInfos	TokenNameIdentifier	 Segment Infos
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
// read infos from dir 	TokenNameCOMMENT_LINE	read infos from dir 
sis	TokenNameIdentifier	 sis
.	TokenNameDOT	
read	TokenNameIdentifier	 read
(	TokenNameLPAREN	
dir	TokenNameIdentifier	 dir
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
final	TokenNamefinal	
Set	TokenNameIdentifier	 Set
<	TokenNameLESS	
String	TokenNameIdentifier	 String
>	TokenNameGREATER	
dsFilesCopied	TokenNameIdentifier	 ds Files Copied
=	TokenNameEQUAL	
new	TokenNamenew	
HashSet	TokenNameIdentifier	 Hash Set
<	TokenNameLESS	
String	TokenNameIdentifier	 String
>	TokenNameGREATER	
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
final	TokenNamefinal	
Map	TokenNameIdentifier	 Map
<	TokenNameLESS	
String	TokenNameIdentifier	 String
,	TokenNameCOMMA	
String	TokenNameIdentifier	 String
>	TokenNameGREATER	
dsNames	TokenNameIdentifier	 ds Names
=	TokenNameEQUAL	
new	TokenNamenew	
HashMap	TokenNameIdentifier	 Hash Map
<	TokenNameLESS	
String	TokenNameIdentifier	 String
,	TokenNameCOMMA	
String	TokenNameIdentifier	 String
>	TokenNameGREATER	
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
for	TokenNamefor	
(	TokenNameLPAREN	
SegmentInfo	TokenNameIdentifier	 Segment Info
info	TokenNameIdentifier	 info
:	TokenNameCOLON	
sis	TokenNameIdentifier	 sis
)	TokenNameRPAREN	
{	TokenNameLBRACE	
assert	TokenNameassert	
!	TokenNameNOT	
infos	TokenNameIdentifier	 infos
.	TokenNameDOT	
contains	TokenNameIdentifier	 contains
(	TokenNameLPAREN	
info	TokenNameIdentifier	 info
)	TokenNameRPAREN	
:	TokenNameCOLON	
"dup info dir="	TokenNameStringLiteral	dup info dir=
+	TokenNamePLUS	
info	TokenNameIdentifier	 info
.	TokenNameDOT	
dir	TokenNameIdentifier	 dir
+	TokenNamePLUS	
" name="	TokenNameStringLiteral	 name=
+	TokenNamePLUS	
info	TokenNameIdentifier	 info
.	TokenNameDOT	
name	TokenNameIdentifier	 name
;	TokenNameSEMICOLON	
String	TokenNameIdentifier	 String
newSegName	TokenNameIdentifier	 new Seg Name
=	TokenNameEQUAL	
newSegmentName	TokenNameIdentifier	 new Segment Name
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
String	TokenNameIdentifier	 String
dsName	TokenNameIdentifier	 ds Name
=	TokenNameEQUAL	
info	TokenNameIdentifier	 info
.	TokenNameDOT	
getDocStoreSegment	TokenNameIdentifier	 get Doc Store Segment
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
if	TokenNameif	
(	TokenNameLPAREN	
infoStream	TokenNameIdentifier	 info Stream
!=	TokenNameNOT_EQUAL	
null	TokenNamenull	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
message	TokenNameIdentifier	 message
(	TokenNameLPAREN	
"addIndexes: process segment origName="	TokenNameStringLiteral	addIndexes: process segment origName=
+	TokenNamePLUS	
info	TokenNameIdentifier	 info
.	TokenNameDOT	
name	TokenNameIdentifier	 name
+	TokenNamePLUS	
" newName="	TokenNameStringLiteral	 newName=
+	TokenNamePLUS	
newSegName	TokenNameIdentifier	 new Seg Name
+	TokenNamePLUS	
" dsName="	TokenNameStringLiteral	 dsName=
+	TokenNamePLUS	
dsName	TokenNameIdentifier	 ds Name
+	TokenNamePLUS	
" info="	TokenNameStringLiteral	 info=
+	TokenNamePLUS	
info	TokenNameIdentifier	 info
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
copySegmentAsIs	TokenNameIdentifier	 copy Segment As Is
(	TokenNameLPAREN	
info	TokenNameIdentifier	 info
,	TokenNameCOMMA	
newSegName	TokenNameIdentifier	 new Seg Name
,	TokenNameCOMMA	
dsNames	TokenNameIdentifier	 ds Names
,	TokenNameCOMMA	
dsFilesCopied	TokenNameIdentifier	 ds Files Copied
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
infos	TokenNameIdentifier	 infos
.	TokenNameDOT	
add	TokenNameIdentifier	 add
(	TokenNameLPAREN	
info	TokenNameIdentifier	 info
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
}	TokenNameRBRACE	
synchronized	TokenNamesynchronized	
(	TokenNameLPAREN	
this	TokenNamethis	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
ensureOpen	TokenNameIdentifier	 ensure Open
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
segmentInfos	TokenNameIdentifier	 segment Infos
.	TokenNameDOT	
addAll	TokenNameIdentifier	 add All
(	TokenNameLPAREN	
infos	TokenNameIdentifier	 infos
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
checkpoint	TokenNameIdentifier	 checkpoint
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
}	TokenNameRBRACE	
catch	TokenNamecatch	
(	TokenNameLPAREN	
OutOfMemoryError	TokenNameIdentifier	 Out Of Memory Error
oom	TokenNameIdentifier	 oom
)	TokenNameRPAREN	
{	TokenNameLBRACE	
handleOOM	TokenNameIdentifier	 handle OOM
(	TokenNameLPAREN	
oom	TokenNameIdentifier	 oom
,	TokenNameCOMMA	
"addIndexes(Directory...)"	TokenNameStringLiteral	addIndexes(Directory...)
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
}	TokenNameRBRACE	
/** * Merges the provided indexes into this index. This method is useful * if you use extensions of {@link IndexReader}. Otherwise, using * {@link #addIndexes(Directory...)} is highly recommended for performance * reasons. It uses the {@link MergeScheduler} and {@link MergePolicy} set * on this writer, which may perform merges in parallel. * * <p>The provided IndexReaders are not closed. * * <p><b>NOTE:</b> this method does not merge the current segments, * only the incoming ones. * * <p>See {@link #addIndexes(Directory...)} for details on transactional * semantics, temporary free space required in the Directory, * and non-CFS segments on an Exception. * * <p><b>NOTE</b>: if this method hits an OutOfMemoryError * you should immediately close the writer. See <a * href="#OOME">above</a> for details. * * <p><b>NOTE</b>: if you call {@link #close(boolean)} * with <tt>false</tt>, which aborts all running merges, * then any thread still running this method might hit a * {@link MergePolicy.MergeAbortedException}. * * @throws CorruptIndexException if the index is corrupt * @throws IOException if there is a low-level IO error */	TokenNameCOMMENT_JAVADOC	 Merges the provided indexes into this index. This method is useful if you use extensions of {@link IndexReader}. Otherwise, using {@link #addIndexes(Directory...)} is highly recommended for performance reasons. It uses the {@link MergeScheduler} and {@link MergePolicy} set on this writer, which may perform merges in parallel. * <p>The provided IndexReaders are not closed. * <p><b>NOTE:</b> this method does not merge the current segments, only the incoming ones. * <p>See {@link #addIndexes(Directory...)} for details on transactional semantics, temporary free space required in the Directory, and non-CFS segments on an Exception. * <p><b>NOTE</b>: if this method hits an OutOfMemoryError you should immediately close the writer. See <a href="#OOME">above</a> for details. * <p><b>NOTE</b>: if you call {@link #close(boolean)} with <tt>false</tt>, which aborts all running merges, then any thread still running this method might hit a {@link MergePolicy.MergeAbortedException}. * @throws CorruptIndexException if the index is corrupt @throws IOException if there is a low-level IO error 
public	TokenNamepublic	
void	TokenNamevoid	
addIndexes	TokenNameIdentifier	 add Indexes
(	TokenNameLPAREN	
IndexReader	TokenNameIdentifier	 Index Reader
...	TokenNameELLIPSIS	
readers	TokenNameIdentifier	 readers
)	TokenNameRPAREN	
throws	TokenNamethrows	
CorruptIndexException	TokenNameIdentifier	 Corrupt Index Exception
,	TokenNameCOMMA	
IOException	TokenNameIdentifier	 IO Exception
{	TokenNameLBRACE	
ensureOpen	TokenNameIdentifier	 ensure Open
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
try	TokenNametry	
{	TokenNameLBRACE	
if	TokenNameif	
(	TokenNameLPAREN	
infoStream	TokenNameIdentifier	 info Stream
!=	TokenNameNOT_EQUAL	
null	TokenNamenull	
)	TokenNameRPAREN	
message	TokenNameIdentifier	 message
(	TokenNameLPAREN	
"flush at addIndexes(IndexReader...)"	TokenNameStringLiteral	flush at addIndexes(IndexReader...)
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
flush	TokenNameIdentifier	 flush
(	TokenNameLPAREN	
false	TokenNamefalse	
,	TokenNameCOMMA	
true	TokenNametrue	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
String	TokenNameIdentifier	 String
mergedName	TokenNameIdentifier	 merged Name
=	TokenNameEQUAL	
newSegmentName	TokenNameIdentifier	 new Segment Name
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
// TODO: somehow we should fix this merge so it's 	TokenNameCOMMENT_LINE	TODO: somehow we should fix this merge so it's 
// abortable so that IW.close(false) is able to stop it 	TokenNameCOMMENT_LINE	abortable so that IW.close(false) is able to stop it 
SegmentMerger	TokenNameIdentifier	 Segment Merger
merger	TokenNameIdentifier	 merger
=	TokenNameEQUAL	
new	TokenNamenew	
SegmentMerger	TokenNameIdentifier	 Segment Merger
(	TokenNameLPAREN	
directory	TokenNameIdentifier	 directory
,	TokenNameCOMMA	
config	TokenNameIdentifier	 config
.	TokenNameDOT	
getTermIndexInterval	TokenNameIdentifier	 get Term Index Interval
(	TokenNameLPAREN	
)	TokenNameRPAREN	
,	TokenNameCOMMA	
mergedName	TokenNameIdentifier	 merged Name
,	TokenNameCOMMA	
null	TokenNamenull	
,	TokenNameCOMMA	
payloadProcessorProvider	TokenNameIdentifier	 payload Processor Provider
,	TokenNameCOMMA	
(	TokenNameLPAREN	
(	TokenNameLPAREN	
FieldInfos	TokenNameIdentifier	 Field Infos
)	TokenNameRPAREN	
docWriter	TokenNameIdentifier	 doc Writer
.	TokenNameDOT	
getFieldInfos	TokenNameIdentifier	 get Field Infos
(	TokenNameLPAREN	
)	TokenNameRPAREN	
.	TokenNameDOT	
clone	TokenNameIdentifier	 clone
(	TokenNameLPAREN	
)	TokenNameRPAREN	
)	TokenNameRPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
for	TokenNamefor	
(	TokenNameLPAREN	
IndexReader	TokenNameIdentifier	 Index Reader
reader	TokenNameIdentifier	 reader
:	TokenNameCOLON	
readers	TokenNameIdentifier	 readers
)	TokenNameRPAREN	
// add new indexes 	TokenNameCOMMENT_LINE	add new indexes 
merger	TokenNameIdentifier	 merger
.	TokenNameDOT	
add	TokenNameIdentifier	 add
(	TokenNameLPAREN	
reader	TokenNameIdentifier	 reader
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
int	TokenNameint	
docCount	TokenNameIdentifier	 doc Count
=	TokenNameEQUAL	
merger	TokenNameIdentifier	 merger
.	TokenNameDOT	
merge	TokenNameIdentifier	 merge
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
// merge 'em 	TokenNameCOMMENT_LINE	merge 'em 
SegmentInfo	TokenNameIdentifier	 Segment Info
info	TokenNameIdentifier	 info
=	TokenNameEQUAL	
new	TokenNamenew	
SegmentInfo	TokenNameIdentifier	 Segment Info
(	TokenNameLPAREN	
mergedName	TokenNameIdentifier	 merged Name
,	TokenNameCOMMA	
docCount	TokenNameIdentifier	 doc Count
,	TokenNameCOMMA	
directory	TokenNameIdentifier	 directory
,	TokenNameCOMMA	
false	TokenNamefalse	
,	TokenNameCOMMA	
true	TokenNametrue	
,	TokenNameCOMMA	
merger	TokenNameIdentifier	 merger
.	TokenNameDOT	
fieldInfos	TokenNameIdentifier	 field Infos
(	TokenNameLPAREN	
)	TokenNameRPAREN	
.	TokenNameDOT	
hasProx	TokenNameIdentifier	 has Prox
(	TokenNameLPAREN	
)	TokenNameRPAREN	
,	TokenNameCOMMA	
merger	TokenNameIdentifier	 merger
.	TokenNameDOT	
fieldInfos	TokenNameIdentifier	 field Infos
(	TokenNameLPAREN	
)	TokenNameRPAREN	
.	TokenNameDOT	
hasVectors	TokenNameIdentifier	 has Vectors
(	TokenNameLPAREN	
)	TokenNameRPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
setDiagnostics	TokenNameIdentifier	 set Diagnostics
(	TokenNameLPAREN	
info	TokenNameIdentifier	 info
,	TokenNameCOMMA	
"addIndexes(IndexReader...)"	TokenNameStringLiteral	addIndexes(IndexReader...)
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
boolean	TokenNameboolean	
useCompoundFile	TokenNameIdentifier	 use Compound File
;	TokenNameSEMICOLON	
synchronized	TokenNamesynchronized	
(	TokenNameLPAREN	
this	TokenNamethis	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
// Guard segmentInfos 	TokenNameCOMMENT_LINE	Guard segmentInfos 
if	TokenNameif	
(	TokenNameLPAREN	
stopMerges	TokenNameIdentifier	 stop Merges
)	TokenNameRPAREN	
{	TokenNameLBRACE	
deleter	TokenNameIdentifier	 deleter
.	TokenNameDOT	
deleteNewFiles	TokenNameIdentifier	 delete New Files
(	TokenNameLPAREN	
info	TokenNameIdentifier	 info
.	TokenNameDOT	
files	TokenNameIdentifier	 files
(	TokenNameLPAREN	
)	TokenNameRPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
return	TokenNamereturn	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
ensureOpen	TokenNameIdentifier	 ensure Open
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
useCompoundFile	TokenNameIdentifier	 use Compound File
=	TokenNameEQUAL	
mergePolicy	TokenNameIdentifier	 merge Policy
.	TokenNameDOT	
useCompoundFile	TokenNameIdentifier	 use Compound File
(	TokenNameLPAREN	
segmentInfos	TokenNameIdentifier	 segment Infos
,	TokenNameCOMMA	
info	TokenNameIdentifier	 info
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
// Now create the compound file if needed 	TokenNameCOMMENT_LINE	Now create the compound file if needed 
if	TokenNameif	
(	TokenNameLPAREN	
useCompoundFile	TokenNameIdentifier	 use Compound File
)	TokenNameRPAREN	
{	TokenNameLBRACE	
merger	TokenNameIdentifier	 merger
.	TokenNameDOT	
createCompoundFile	TokenNameIdentifier	 create Compound File
(	TokenNameLPAREN	
mergedName	TokenNameIdentifier	 merged Name
+	TokenNamePLUS	
".cfs"	TokenNameStringLiteral	.cfs
,	TokenNameCOMMA	
info	TokenNameIdentifier	 info
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
// delete new non cfs files directly: they were never 	TokenNameCOMMENT_LINE	delete new non cfs files directly: they were never 
// registered with IFD 	TokenNameCOMMENT_LINE	registered with IFD 
synchronized	TokenNamesynchronized	
(	TokenNameLPAREN	
this	TokenNamethis	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
deleter	TokenNameIdentifier	 deleter
.	TokenNameDOT	
deleteNewFiles	TokenNameIdentifier	 delete New Files
(	TokenNameLPAREN	
info	TokenNameIdentifier	 info
.	TokenNameDOT	
files	TokenNameIdentifier	 files
(	TokenNameLPAREN	
)	TokenNameRPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
info	TokenNameIdentifier	 info
.	TokenNameDOT	
setUseCompoundFile	TokenNameIdentifier	 set Use Compound File
(	TokenNameLPAREN	
true	TokenNametrue	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
// Register the new segment 	TokenNameCOMMENT_LINE	Register the new segment 
synchronized	TokenNamesynchronized	
(	TokenNameLPAREN	
this	TokenNamethis	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
if	TokenNameif	
(	TokenNameLPAREN	
stopMerges	TokenNameIdentifier	 stop Merges
)	TokenNameRPAREN	
{	TokenNameLBRACE	
deleter	TokenNameIdentifier	 deleter
.	TokenNameDOT	
deleteNewFiles	TokenNameIdentifier	 delete New Files
(	TokenNameLPAREN	
info	TokenNameIdentifier	 info
.	TokenNameDOT	
files	TokenNameIdentifier	 files
(	TokenNameLPAREN	
)	TokenNameRPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
return	TokenNamereturn	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
ensureOpen	TokenNameIdentifier	 ensure Open
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
segmentInfos	TokenNameIdentifier	 segment Infos
.	TokenNameDOT	
add	TokenNameIdentifier	 add
(	TokenNameLPAREN	
info	TokenNameIdentifier	 info
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
checkpoint	TokenNameIdentifier	 checkpoint
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
}	TokenNameRBRACE	
catch	TokenNamecatch	
(	TokenNameLPAREN	
OutOfMemoryError	TokenNameIdentifier	 Out Of Memory Error
oom	TokenNameIdentifier	 oom
)	TokenNameRPAREN	
{	TokenNameLBRACE	
handleOOM	TokenNameIdentifier	 handle OOM
(	TokenNameLPAREN	
oom	TokenNameIdentifier	 oom
,	TokenNameCOMMA	
"addIndexes(IndexReader...)"	TokenNameStringLiteral	addIndexes(IndexReader...)
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
}	TokenNameRBRACE	
/** Copies the segment files as-is into the IndexWriter's directory. */	TokenNameCOMMENT_JAVADOC	 Copies the segment files as-is into the IndexWriter's directory. 
private	TokenNameprivate	
void	TokenNamevoid	
copySegmentAsIs	TokenNameIdentifier	 copy Segment As Is
(	TokenNameLPAREN	
SegmentInfo	TokenNameIdentifier	 Segment Info
info	TokenNameIdentifier	 info
,	TokenNameCOMMA	
String	TokenNameIdentifier	 String
segName	TokenNameIdentifier	 seg Name
,	TokenNameCOMMA	
Map	TokenNameIdentifier	 Map
<	TokenNameLESS	
String	TokenNameIdentifier	 String
,	TokenNameCOMMA	
String	TokenNameIdentifier	 String
>	TokenNameGREATER	
dsNames	TokenNameIdentifier	 ds Names
,	TokenNameCOMMA	
Set	TokenNameIdentifier	 Set
<	TokenNameLESS	
String	TokenNameIdentifier	 String
>	TokenNameGREATER	
dsFilesCopied	TokenNameIdentifier	 ds Files Copied
)	TokenNameRPAREN	
throws	TokenNamethrows	
IOException	TokenNameIdentifier	 IO Exception
{	TokenNameLBRACE	
// Determine if the doc store of this segment needs to be copied. It's 	TokenNameCOMMENT_LINE	Determine if the doc store of this segment needs to be copied. It's 
// only relevant for segments that share doc store with others, 	TokenNameCOMMENT_LINE	only relevant for segments that share doc store with others, 
// because the DS might have been copied already, in which case we 	TokenNameCOMMENT_LINE	because the DS might have been copied already, in which case we 
// just want to update the DS name of this SegmentInfo. 	TokenNameCOMMENT_LINE	just want to update the DS name of this SegmentInfo. 
// NOTE: pre-3x segments include a null DSName if they don't share doc 	TokenNameCOMMENT_LINE	NOTE: pre-3x segments include a null DSName if they don't share doc 
// store. The following code ensures we don't accidentally insert 	TokenNameCOMMENT_LINE	store. The following code ensures we don't accidentally insert 
// 'null' to the map. 	TokenNameCOMMENT_LINE	'null' to the map. 
String	TokenNameIdentifier	 String
dsName	TokenNameIdentifier	 ds Name
=	TokenNameEQUAL	
info	TokenNameIdentifier	 info
.	TokenNameDOT	
getDocStoreSegment	TokenNameIdentifier	 get Doc Store Segment
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
final	TokenNamefinal	
String	TokenNameIdentifier	 String
newDsName	TokenNameIdentifier	 new Ds Name
;	TokenNameSEMICOLON	
if	TokenNameif	
(	TokenNameLPAREN	
dsName	TokenNameIdentifier	 ds Name
!=	TokenNameNOT_EQUAL	
null	TokenNamenull	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
if	TokenNameif	
(	TokenNameLPAREN	
dsNames	TokenNameIdentifier	 ds Names
.	TokenNameDOT	
containsKey	TokenNameIdentifier	 contains Key
(	TokenNameLPAREN	
dsName	TokenNameIdentifier	 ds Name
)	TokenNameRPAREN	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
newDsName	TokenNameIdentifier	 new Ds Name
=	TokenNameEQUAL	
dsNames	TokenNameIdentifier	 ds Names
.	TokenNameDOT	
get	TokenNameIdentifier	 get
(	TokenNameLPAREN	
dsName	TokenNameIdentifier	 ds Name
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
else	TokenNameelse	
{	TokenNameLBRACE	
dsNames	TokenNameIdentifier	 ds Names
.	TokenNameDOT	
put	TokenNameIdentifier	 put
(	TokenNameLPAREN	
dsName	TokenNameIdentifier	 ds Name
,	TokenNameCOMMA	
segName	TokenNameIdentifier	 seg Name
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
newDsName	TokenNameIdentifier	 new Ds Name
=	TokenNameEQUAL	
segName	TokenNameIdentifier	 seg Name
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
}	TokenNameRBRACE	
else	TokenNameelse	
{	TokenNameLBRACE	
newDsName	TokenNameIdentifier	 new Ds Name
=	TokenNameEQUAL	
segName	TokenNameIdentifier	 seg Name
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
// Copy the segment files 	TokenNameCOMMENT_LINE	Copy the segment files 
for	TokenNamefor	
(	TokenNameLPAREN	
String	TokenNameIdentifier	 String
file	TokenNameIdentifier	 file
:	TokenNameCOLON	
info	TokenNameIdentifier	 info
.	TokenNameDOT	
files	TokenNameIdentifier	 files
(	TokenNameLPAREN	
)	TokenNameRPAREN	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
final	TokenNamefinal	
String	TokenNameIdentifier	 String
newFileName	TokenNameIdentifier	 new File Name
;	TokenNameSEMICOLON	
if	TokenNameif	
(	TokenNameLPAREN	
IndexFileNames	TokenNameIdentifier	 Index File Names
.	TokenNameDOT	
isDocStoreFile	TokenNameIdentifier	 is Doc Store File
(	TokenNameLPAREN	
file	TokenNameIdentifier	 file
)	TokenNameRPAREN	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
newFileName	TokenNameIdentifier	 new File Name
=	TokenNameEQUAL	
newDsName	TokenNameIdentifier	 new Ds Name
+	TokenNamePLUS	
IndexFileNames	TokenNameIdentifier	 Index File Names
.	TokenNameDOT	
stripSegmentName	TokenNameIdentifier	 strip Segment Name
(	TokenNameLPAREN	
file	TokenNameIdentifier	 file
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
if	TokenNameif	
(	TokenNameLPAREN	
dsFilesCopied	TokenNameIdentifier	 ds Files Copied
.	TokenNameDOT	
contains	TokenNameIdentifier	 contains
(	TokenNameLPAREN	
newFileName	TokenNameIdentifier	 new File Name
)	TokenNameRPAREN	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
continue	TokenNamecontinue	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
dsFilesCopied	TokenNameIdentifier	 ds Files Copied
.	TokenNameDOT	
add	TokenNameIdentifier	 add
(	TokenNameLPAREN	
newFileName	TokenNameIdentifier	 new File Name
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
else	TokenNameelse	
{	TokenNameLBRACE	
newFileName	TokenNameIdentifier	 new File Name
=	TokenNameEQUAL	
segName	TokenNameIdentifier	 seg Name
+	TokenNamePLUS	
IndexFileNames	TokenNameIdentifier	 Index File Names
.	TokenNameDOT	
stripSegmentName	TokenNameIdentifier	 strip Segment Name
(	TokenNameLPAREN	
file	TokenNameIdentifier	 file
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
assert	TokenNameassert	
!	TokenNameNOT	
directory	TokenNameIdentifier	 directory
.	TokenNameDOT	
fileExists	TokenNameIdentifier	 file Exists
(	TokenNameLPAREN	
newFileName	TokenNameIdentifier	 new File Name
)	TokenNameRPAREN	
:	TokenNameCOLON	
"file ""	TokenNameStringLiteral	file "
+	TokenNamePLUS	
newFileName	TokenNameIdentifier	 new File Name
+	TokenNamePLUS	
"" already exists"	TokenNameStringLiteral	" already exists
;	TokenNameSEMICOLON	
info	TokenNameIdentifier	 info
.	TokenNameDOT	
dir	TokenNameIdentifier	 dir
.	TokenNameDOT	
copy	TokenNameIdentifier	 copy
(	TokenNameLPAREN	
directory	TokenNameIdentifier	 directory
,	TokenNameCOMMA	
file	TokenNameIdentifier	 file
,	TokenNameCOMMA	
newFileName	TokenNameIdentifier	 new File Name
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
info	TokenNameIdentifier	 info
.	TokenNameDOT	
setDocStore	TokenNameIdentifier	 set Doc Store
(	TokenNameLPAREN	
info	TokenNameIdentifier	 info
.	TokenNameDOT	
getDocStoreOffset	TokenNameIdentifier	 get Doc Store Offset
(	TokenNameLPAREN	
)	TokenNameRPAREN	
,	TokenNameCOMMA	
newDsName	TokenNameIdentifier	 new Ds Name
,	TokenNameCOMMA	
info	TokenNameIdentifier	 info
.	TokenNameDOT	
getDocStoreIsCompoundFile	TokenNameIdentifier	 get Doc Store Is Compound File
(	TokenNameLPAREN	
)	TokenNameRPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
info	TokenNameIdentifier	 info
.	TokenNameDOT	
dir	TokenNameIdentifier	 dir
=	TokenNameEQUAL	
directory	TokenNameIdentifier	 directory
;	TokenNameSEMICOLON	
info	TokenNameIdentifier	 info
.	TokenNameDOT	
name	TokenNameIdentifier	 name
=	TokenNameEQUAL	
segName	TokenNameIdentifier	 seg Name
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
/** * A hook for extending classes to execute operations after pending added and * deleted documents have been flushed to the Directory but before the change * is committed (new segments_N file written). */	TokenNameCOMMENT_JAVADOC	 A hook for extending classes to execute operations after pending added and deleted documents have been flushed to the Directory but before the change is committed (new segments_N file written). 
protected	TokenNameprotected	
void	TokenNamevoid	
doAfterFlush	TokenNameIdentifier	 do After Flush
(	TokenNameLPAREN	
)	TokenNameRPAREN	
throws	TokenNamethrows	
IOException	TokenNameIdentifier	 IO Exception
{	TokenNameLBRACE	
}	TokenNameRBRACE	
/** * A hook for extending classes to execute operations before pending added and * deleted documents are flushed to the Directory. */	TokenNameCOMMENT_JAVADOC	 A hook for extending classes to execute operations before pending added and deleted documents are flushed to the Directory. 
protected	TokenNameprotected	
void	TokenNamevoid	
doBeforeFlush	TokenNameIdentifier	 do Before Flush
(	TokenNameLPAREN	
)	TokenNameRPAREN	
throws	TokenNamethrows	
IOException	TokenNameIdentifier	 IO Exception
{	TokenNameLBRACE	
}	TokenNameRBRACE	
/** Expert: prepare for commit. * * <p><b>NOTE</b>: if this method hits an OutOfMemoryError * you should immediately close the writer. See <a * href="#OOME">above</a> for details.</p> * * @see #prepareCommit(Map) */	TokenNameCOMMENT_JAVADOC	 Expert: prepare for commit. * <p><b>NOTE</b>: if this method hits an OutOfMemoryError you should immediately close the writer. See <a href="#OOME">above</a> for details.</p> * @see #prepareCommit(Map) 
public	TokenNamepublic	
final	TokenNamefinal	
void	TokenNamevoid	
prepareCommit	TokenNameIdentifier	 prepare Commit
(	TokenNameLPAREN	
)	TokenNameRPAREN	
throws	TokenNamethrows	
CorruptIndexException	TokenNameIdentifier	 Corrupt Index Exception
,	TokenNameCOMMA	
IOException	TokenNameIdentifier	 IO Exception
{	TokenNameLBRACE	
ensureOpen	TokenNameIdentifier	 ensure Open
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
prepareCommit	TokenNameIdentifier	 prepare Commit
(	TokenNameLPAREN	
null	TokenNamenull	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
/** <p>Expert: prepare for commit, specifying * commitUserData Map (String -> String). This does the * first phase of 2-phase commit. This method does all * steps necessary to commit changes since this writer * was opened: flushes pending added and deleted docs, * syncs the index files, writes most of next segments_N * file. After calling this you must call either {@link * #commit()} to finish the commit, or {@link * #rollback()} to revert the commit and undo all changes * done since the writer was opened.</p> * * <p>You can also just call {@link #commit(Map)} directly * without prepareCommit first in which case that method * will internally call prepareCommit. * * <p><b>NOTE</b>: if this method hits an OutOfMemoryError * you should immediately close the writer. See <a * href="#OOME">above</a> for details.</p> * * @param commitUserData Opaque Map (String->String) * that's recorded into the segments file in the index, * and retrievable by {@link * IndexCommit#getUserData}. Note that when * IndexWriter commits itself during {@link #close}, the * commitUserData is unchanged (just carried over from * the prior commit). If this is null then the previous * commitUserData is kept. Also, the commitUserData will * only "stick" if there are actually changes in the * index to commit. */	TokenNameCOMMENT_JAVADOC	 <p>Expert: prepare for commit, specifying commitUserData Map (String -> String). This does the first phase of 2-phase commit. This method does all steps necessary to commit changes since this writer was opened: flushes pending added and deleted docs, syncs the index files, writes most of next segments_N file. After calling this you must call either {@link #commit()} to finish the commit, or {@link #rollback()} to revert the commit and undo all changes done since the writer was opened.</p> * <p>You can also just call {@link #commit(Map)} directly without prepareCommit first in which case that method will internally call prepareCommit. * <p><b>NOTE</b>: if this method hits an OutOfMemoryError you should immediately close the writer. See <a href="#OOME">above</a> for details.</p> * @param commitUserData Opaque Map (String->String) that's recorded into the segments file in the index, and retrievable by {@link IndexCommit#getUserData}. Note that when IndexWriter commits itself during {@link #close}, the commitUserData is unchanged (just carried over from the prior commit). If this is null then the previous commitUserData is kept. Also, the commitUserData will only "stick" if there are actually changes in the index to commit. 
public	TokenNamepublic	
final	TokenNamefinal	
void	TokenNamevoid	
prepareCommit	TokenNameIdentifier	 prepare Commit
(	TokenNameLPAREN	
Map	TokenNameIdentifier	 Map
<	TokenNameLESS	
String	TokenNameIdentifier	 String
,	TokenNameCOMMA	
String	TokenNameIdentifier	 String
>	TokenNameGREATER	
commitUserData	TokenNameIdentifier	 commit User Data
)	TokenNameRPAREN	
throws	TokenNamethrows	
CorruptIndexException	TokenNameIdentifier	 Corrupt Index Exception
,	TokenNameCOMMA	
IOException	TokenNameIdentifier	 IO Exception
{	TokenNameLBRACE	
ensureOpen	TokenNameIdentifier	 ensure Open
(	TokenNameLPAREN	
false	TokenNamefalse	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
if	TokenNameif	
(	TokenNameLPAREN	
hitOOM	TokenNameIdentifier	 hit OOM
)	TokenNameRPAREN	
{	TokenNameLBRACE	
throw	TokenNamethrow	
new	TokenNamenew	
IllegalStateException	TokenNameIdentifier	 Illegal State Exception
(	TokenNameLPAREN	
"this writer hit an OutOfMemoryError; cannot commit"	TokenNameStringLiteral	this writer hit an OutOfMemoryError; cannot commit
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
if	TokenNameif	
(	TokenNameLPAREN	
pendingCommit	TokenNameIdentifier	 pending Commit
!=	TokenNameNOT_EQUAL	
null	TokenNamenull	
)	TokenNameRPAREN	
throw	TokenNamethrow	
new	TokenNamenew	
IllegalStateException	TokenNameIdentifier	 Illegal State Exception
(	TokenNameLPAREN	
"prepareCommit was already called with no corresponding call to commit"	TokenNameStringLiteral	prepareCommit was already called with no corresponding call to commit
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
if	TokenNameif	
(	TokenNameLPAREN	
infoStream	TokenNameIdentifier	 info Stream
!=	TokenNameNOT_EQUAL	
null	TokenNamenull	
)	TokenNameRPAREN	
message	TokenNameIdentifier	 message
(	TokenNameLPAREN	
"prepareCommit: flush"	TokenNameStringLiteral	prepareCommit: flush
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
ensureOpen	TokenNameIdentifier	 ensure Open
(	TokenNameLPAREN	
false	TokenNamefalse	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
boolean	TokenNameboolean	
anySegmentsFlushed	TokenNameIdentifier	 any Segments Flushed
=	TokenNameEQUAL	
false	TokenNamefalse	
;	TokenNameSEMICOLON	
SegmentInfos	TokenNameIdentifier	 Segment Infos
toCommit	TokenNameIdentifier	 to Commit
=	TokenNameEQUAL	
null	TokenNamenull	
;	TokenNameSEMICOLON	
boolean	TokenNameboolean	
success	TokenNameIdentifier	 success
=	TokenNameEQUAL	
false	TokenNamefalse	
;	TokenNameSEMICOLON	
try	TokenNametry	
{	TokenNameLBRACE	
try	TokenNametry	
{	TokenNameLBRACE	
synchronized	TokenNamesynchronized	
(	TokenNameLPAREN	
this	TokenNamethis	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
anySegmentsFlushed	TokenNameIdentifier	 any Segments Flushed
=	TokenNameEQUAL	
doFlush	TokenNameIdentifier	 do Flush
(	TokenNameLPAREN	
true	TokenNametrue	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
readerPool	TokenNameIdentifier	 reader Pool
.	TokenNameDOT	
commit	TokenNameIdentifier	 commit
(	TokenNameLPAREN	
segmentInfos	TokenNameIdentifier	 segment Infos
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
toCommit	TokenNameIdentifier	 to Commit
=	TokenNameEQUAL	
(	TokenNameLPAREN	
SegmentInfos	TokenNameIdentifier	 Segment Infos
)	TokenNameRPAREN	
segmentInfos	TokenNameIdentifier	 segment Infos
.	TokenNameDOT	
clone	TokenNameIdentifier	 clone
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
pendingCommitChangeCount	TokenNameIdentifier	 pending Commit Change Count
=	TokenNameEQUAL	
changeCount	TokenNameIdentifier	 change Count
;	TokenNameSEMICOLON	
// This protects the segmentInfos we are now going 	TokenNameCOMMENT_LINE	This protects the segmentInfos we are now going 
// to commit. This is important in case, eg, while 	TokenNameCOMMENT_LINE	to commit. This is important in case, eg, while 
// we are trying to sync all referenced files, a 	TokenNameCOMMENT_LINE	we are trying to sync all referenced files, a 
// merge completes which would otherwise have 	TokenNameCOMMENT_LINE	merge completes which would otherwise have 
// removed the files we are now syncing. 	TokenNameCOMMENT_LINE	removed the files we are now syncing. 
filesToCommit	TokenNameIdentifier	 files To Commit
=	TokenNameEQUAL	
toCommit	TokenNameIdentifier	 to Commit
.	TokenNameDOT	
files	TokenNameIdentifier	 files
(	TokenNameLPAREN	
directory	TokenNameIdentifier	 directory
,	TokenNameCOMMA	
false	TokenNamefalse	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
deleter	TokenNameIdentifier	 deleter
.	TokenNameDOT	
incRef	TokenNameIdentifier	 inc Ref
(	TokenNameLPAREN	
filesToCommit	TokenNameIdentifier	 files To Commit
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
success	TokenNameIdentifier	 success
=	TokenNameEQUAL	
true	TokenNametrue	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
finally	TokenNamefinally	
{	TokenNameLBRACE	
if	TokenNameif	
(	TokenNameLPAREN	
!	TokenNameNOT	
success	TokenNameIdentifier	 success
&&	TokenNameAND_AND	
infoStream	TokenNameIdentifier	 info Stream
!=	TokenNameNOT_EQUAL	
null	TokenNamenull	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
message	TokenNameIdentifier	 message
(	TokenNameLPAREN	
"hit exception during prepareCommit"	TokenNameStringLiteral	hit exception during prepareCommit
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
doAfterFlush	TokenNameIdentifier	 do After Flush
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
}	TokenNameRBRACE	
catch	TokenNamecatch	
(	TokenNameLPAREN	
OutOfMemoryError	TokenNameIdentifier	 Out Of Memory Error
oom	TokenNameIdentifier	 oom
)	TokenNameRPAREN	
{	TokenNameLBRACE	
handleOOM	TokenNameIdentifier	 handle OOM
(	TokenNameLPAREN	
oom	TokenNameIdentifier	 oom
,	TokenNameCOMMA	
"prepareCommit"	TokenNameStringLiteral	prepareCommit
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
success	TokenNameIdentifier	 success
=	TokenNameEQUAL	
false	TokenNamefalse	
;	TokenNameSEMICOLON	
try	TokenNametry	
{	TokenNameLBRACE	
if	TokenNameif	
(	TokenNameLPAREN	
anySegmentsFlushed	TokenNameIdentifier	 any Segments Flushed
)	TokenNameRPAREN	
{	TokenNameLBRACE	
maybeMerge	TokenNameIdentifier	 maybe Merge
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
success	TokenNameIdentifier	 success
=	TokenNameEQUAL	
true	TokenNametrue	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
finally	TokenNamefinally	
{	TokenNameLBRACE	
if	TokenNameif	
(	TokenNameLPAREN	
!	TokenNameNOT	
success	TokenNameIdentifier	 success
)	TokenNameRPAREN	
{	TokenNameLBRACE	
synchronized	TokenNamesynchronized	
(	TokenNameLPAREN	
this	TokenNamethis	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
deleter	TokenNameIdentifier	 deleter
.	TokenNameDOT	
decRef	TokenNameIdentifier	 dec Ref
(	TokenNameLPAREN	
filesToCommit	TokenNameIdentifier	 files To Commit
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
filesToCommit	TokenNameIdentifier	 files To Commit
=	TokenNameEQUAL	
null	TokenNamenull	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
}	TokenNameRBRACE	
}	TokenNameRBRACE	
startCommit	TokenNameIdentifier	 start Commit
(	TokenNameLPAREN	
toCommit	TokenNameIdentifier	 to Commit
,	TokenNameCOMMA	
commitUserData	TokenNameIdentifier	 commit User Data
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
// Used only by commit, below; lock order is commitLock -> IW 	TokenNameCOMMENT_LINE	Used only by commit, below; lock order is commitLock -> IW 
private	TokenNameprivate	
final	TokenNamefinal	
Object	TokenNameIdentifier	 Object
commitLock	TokenNameIdentifier	 commit Lock
=	TokenNameEQUAL	
new	TokenNamenew	
Object	TokenNameIdentifier	 Object
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
/** * <p>Commits all pending changes (added & deleted * documents, segment merges, added * indexes, etc.) to the index, and syncs all referenced * index files, such that a reader will see the changes * and the index updates will survive an OS or machine * crash or power loss. Note that this does not wait for * any running background merges to finish. This may be a * costly operation, so you should test the cost in your * application and do it only when really necessary.</p> * * <p> Note that this operation calls Directory.sync on * the index files. That call should not return until the * file contents & metadata are on stable storage. For * FSDirectory, this calls the OS's fsync. But, beware: * some hardware devices may in fact cache writes even * during fsync, and return before the bits are actually * on stable storage, to give the appearance of faster * performance. If you have such a device, and it does * not have a battery backup (for example) then on power * loss it may still lose data. Lucene cannot guarantee * consistency on such devices. </p> * * <p><b>NOTE</b>: if this method hits an OutOfMemoryError * you should immediately close the writer. See <a * href="#OOME">above</a> for details.</p> * * @see #prepareCommit * @see #commit(Map) */	TokenNameCOMMENT_JAVADOC	 <p>Commits all pending changes (added & deleted documents, segment merges, added indexes, etc.) to the index, and syncs all referenced index files, such that a reader will see the changes and the index updates will survive an OS or machine crash or power loss. Note that this does not wait for any running background merges to finish. This may be a costly operation, so you should test the cost in your application and do it only when really necessary.</p> * <p> Note that this operation calls Directory.sync on the index files. That call should not return until the file contents & metadata are on stable storage. For FSDirectory, this calls the OS's fsync. But, beware: some hardware devices may in fact cache writes even during fsync, and return before the bits are actually on stable storage, to give the appearance of faster performance. If you have such a device, and it does not have a battery backup (for example) then on power loss it may still lose data. Lucene cannot guarantee consistency on such devices. </p> * <p><b>NOTE</b>: if this method hits an OutOfMemoryError you should immediately close the writer. See <a href="#OOME">above</a> for details.</p> * @see #prepareCommit @see #commit(Map) 
public	TokenNamepublic	
final	TokenNamefinal	
void	TokenNamevoid	
commit	TokenNameIdentifier	 commit
(	TokenNameLPAREN	
)	TokenNameRPAREN	
throws	TokenNamethrows	
CorruptIndexException	TokenNameIdentifier	 Corrupt Index Exception
,	TokenNameCOMMA	
IOException	TokenNameIdentifier	 IO Exception
{	TokenNameLBRACE	
commit	TokenNameIdentifier	 commit
(	TokenNameLPAREN	
null	TokenNamenull	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
/** Commits all changes to the index, specifying a * commitUserData Map (String -> String). This just * calls {@link #prepareCommit(Map)} (if you didn't * already call it) and then {@link #finishCommit}. * * <p><b>NOTE</b>: if this method hits an OutOfMemoryError * you should immediately close the writer. See <a * href="#OOME">above</a> for details.</p> */	TokenNameCOMMENT_JAVADOC	 Commits all changes to the index, specifying a commitUserData Map (String -> String). This just calls {@link #prepareCommit(Map)} (if you didn't already call it) and then {@link #finishCommit}. * <p><b>NOTE</b>: if this method hits an OutOfMemoryError you should immediately close the writer. See <a href="#OOME">above</a> for details.</p> 
public	TokenNamepublic	
final	TokenNamefinal	
void	TokenNamevoid	
commit	TokenNameIdentifier	 commit
(	TokenNameLPAREN	
Map	TokenNameIdentifier	 Map
<	TokenNameLESS	
String	TokenNameIdentifier	 String
,	TokenNameCOMMA	
String	TokenNameIdentifier	 String
>	TokenNameGREATER	
commitUserData	TokenNameIdentifier	 commit User Data
)	TokenNameRPAREN	
throws	TokenNamethrows	
CorruptIndexException	TokenNameIdentifier	 Corrupt Index Exception
,	TokenNameCOMMA	
IOException	TokenNameIdentifier	 IO Exception
{	TokenNameLBRACE	
ensureOpen	TokenNameIdentifier	 ensure Open
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
commitInternal	TokenNameIdentifier	 commit Internal
(	TokenNameLPAREN	
commitUserData	TokenNameIdentifier	 commit User Data
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
private	TokenNameprivate	
final	TokenNamefinal	
void	TokenNamevoid	
commitInternal	TokenNameIdentifier	 commit Internal
(	TokenNameLPAREN	
Map	TokenNameIdentifier	 Map
<	TokenNameLESS	
String	TokenNameIdentifier	 String
,	TokenNameCOMMA	
String	TokenNameIdentifier	 String
>	TokenNameGREATER	
commitUserData	TokenNameIdentifier	 commit User Data
)	TokenNameRPAREN	
throws	TokenNamethrows	
CorruptIndexException	TokenNameIdentifier	 Corrupt Index Exception
,	TokenNameCOMMA	
IOException	TokenNameIdentifier	 IO Exception
{	TokenNameLBRACE	
if	TokenNameif	
(	TokenNameLPAREN	
infoStream	TokenNameIdentifier	 info Stream
!=	TokenNameNOT_EQUAL	
null	TokenNamenull	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
message	TokenNameIdentifier	 message
(	TokenNameLPAREN	
"commit: start"	TokenNameStringLiteral	commit: start
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
synchronized	TokenNamesynchronized	
(	TokenNameLPAREN	
commitLock	TokenNameIdentifier	 commit Lock
)	TokenNameRPAREN	
{	TokenNameLBRACE	
if	TokenNameif	
(	TokenNameLPAREN	
infoStream	TokenNameIdentifier	 info Stream
!=	TokenNameNOT_EQUAL	
null	TokenNamenull	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
message	TokenNameIdentifier	 message
(	TokenNameLPAREN	
"commit: enter lock"	TokenNameStringLiteral	commit: enter lock
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
if	TokenNameif	
(	TokenNameLPAREN	
pendingCommit	TokenNameIdentifier	 pending Commit
==	TokenNameEQUAL_EQUAL	
null	TokenNamenull	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
if	TokenNameif	
(	TokenNameLPAREN	
infoStream	TokenNameIdentifier	 info Stream
!=	TokenNameNOT_EQUAL	
null	TokenNamenull	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
message	TokenNameIdentifier	 message
(	TokenNameLPAREN	
"commit: now prepare"	TokenNameStringLiteral	commit: now prepare
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
prepareCommit	TokenNameIdentifier	 prepare Commit
(	TokenNameLPAREN	
commitUserData	TokenNameIdentifier	 commit User Data
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
else	TokenNameelse	
if	TokenNameif	
(	TokenNameLPAREN	
infoStream	TokenNameIdentifier	 info Stream
!=	TokenNameNOT_EQUAL	
null	TokenNamenull	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
message	TokenNameIdentifier	 message
(	TokenNameLPAREN	
"commit: already prepared"	TokenNameStringLiteral	commit: already prepared
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
finishCommit	TokenNameIdentifier	 finish Commit
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
}	TokenNameRBRACE	
private	TokenNameprivate	
synchronized	TokenNamesynchronized	
final	TokenNamefinal	
void	TokenNamevoid	
finishCommit	TokenNameIdentifier	 finish Commit
(	TokenNameLPAREN	
)	TokenNameRPAREN	
throws	TokenNamethrows	
CorruptIndexException	TokenNameIdentifier	 Corrupt Index Exception
,	TokenNameCOMMA	
IOException	TokenNameIdentifier	 IO Exception
{	TokenNameLBRACE	
if	TokenNameif	
(	TokenNameLPAREN	
pendingCommit	TokenNameIdentifier	 pending Commit
!=	TokenNameNOT_EQUAL	
null	TokenNamenull	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
try	TokenNametry	
{	TokenNameLBRACE	
if	TokenNameif	
(	TokenNameLPAREN	
infoStream	TokenNameIdentifier	 info Stream
!=	TokenNameNOT_EQUAL	
null	TokenNamenull	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
message	TokenNameIdentifier	 message
(	TokenNameLPAREN	
"commit: pendingCommit != null"	TokenNameStringLiteral	commit: pendingCommit != null
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
pendingCommit	TokenNameIdentifier	 pending Commit
.	TokenNameDOT	
finishCommit	TokenNameIdentifier	 finish Commit
(	TokenNameLPAREN	
directory	TokenNameIdentifier	 directory
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
if	TokenNameif	
(	TokenNameLPAREN	
infoStream	TokenNameIdentifier	 info Stream
!=	TokenNameNOT_EQUAL	
null	TokenNamenull	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
message	TokenNameIdentifier	 message
(	TokenNameLPAREN	
"commit: wrote segments file ""	TokenNameStringLiteral	commit: wrote segments file "
+	TokenNamePLUS	
pendingCommit	TokenNameIdentifier	 pending Commit
.	TokenNameDOT	
getSegmentsFileName	TokenNameIdentifier	 get Segments File Name
(	TokenNameLPAREN	
)	TokenNameRPAREN	
+	TokenNamePLUS	
"""	TokenNameStringLiteral	"
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
lastCommitChangeCount	TokenNameIdentifier	 last Commit Change Count
=	TokenNameEQUAL	
pendingCommitChangeCount	TokenNameIdentifier	 pending Commit Change Count
;	TokenNameSEMICOLON	
segmentInfos	TokenNameIdentifier	 segment Infos
.	TokenNameDOT	
updateGeneration	TokenNameIdentifier	 update Generation
(	TokenNameLPAREN	
pendingCommit	TokenNameIdentifier	 pending Commit
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
segmentInfos	TokenNameIdentifier	 segment Infos
.	TokenNameDOT	
setUserData	TokenNameIdentifier	 set User Data
(	TokenNameLPAREN	
pendingCommit	TokenNameIdentifier	 pending Commit
.	TokenNameDOT	
getUserData	TokenNameIdentifier	 get User Data
(	TokenNameLPAREN	
)	TokenNameRPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
rollbackSegments	TokenNameIdentifier	 rollback Segments
=	TokenNameEQUAL	
pendingCommit	TokenNameIdentifier	 pending Commit
.	TokenNameDOT	
createBackupSegmentInfos	TokenNameIdentifier	 create Backup Segment Infos
(	TokenNameLPAREN	
true	TokenNametrue	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
deleter	TokenNameIdentifier	 deleter
.	TokenNameDOT	
checkpoint	TokenNameIdentifier	 checkpoint
(	TokenNameLPAREN	
pendingCommit	TokenNameIdentifier	 pending Commit
,	TokenNameCOMMA	
true	TokenNametrue	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
finally	TokenNamefinally	
{	TokenNameLBRACE	
// Matches the incRef done in prepareCommit: 	TokenNameCOMMENT_LINE	Matches the incRef done in prepareCommit: 
deleter	TokenNameIdentifier	 deleter
.	TokenNameDOT	
decRef	TokenNameIdentifier	 dec Ref
(	TokenNameLPAREN	
filesToCommit	TokenNameIdentifier	 files To Commit
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
filesToCommit	TokenNameIdentifier	 files To Commit
=	TokenNameEQUAL	
null	TokenNamenull	
;	TokenNameSEMICOLON	
pendingCommit	TokenNameIdentifier	 pending Commit
=	TokenNameEQUAL	
null	TokenNamenull	
;	TokenNameSEMICOLON	
notifyAll	TokenNameIdentifier	 notify All
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
}	TokenNameRBRACE	
else	TokenNameelse	
if	TokenNameif	
(	TokenNameLPAREN	
infoStream	TokenNameIdentifier	 info Stream
!=	TokenNameNOT_EQUAL	
null	TokenNamenull	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
message	TokenNameIdentifier	 message
(	TokenNameLPAREN	
"commit: pendingCommit == null; skip"	TokenNameStringLiteral	commit: pendingCommit == null; skip
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
if	TokenNameif	
(	TokenNameLPAREN	
infoStream	TokenNameIdentifier	 info Stream
!=	TokenNameNOT_EQUAL	
null	TokenNamenull	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
message	TokenNameIdentifier	 message
(	TokenNameLPAREN	
"commit: done"	TokenNameStringLiteral	commit: done
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
}	TokenNameRBRACE	
/** NOTE: flushDocStores is ignored now (hardwired to * true); this method is only here for backwards * compatibility */	TokenNameCOMMENT_JAVADOC	 NOTE: flushDocStores is ignored now (hardwired to true); this method is only here for backwards compatibility 
protected	TokenNameprotected	
final	TokenNamefinal	
void	TokenNamevoid	
flush	TokenNameIdentifier	 flush
(	TokenNameLPAREN	
boolean	TokenNameboolean	
triggerMerge	TokenNameIdentifier	 trigger Merge
,	TokenNameCOMMA	
boolean	TokenNameboolean	
flushDocStores	TokenNameIdentifier	 flush Doc Stores
,	TokenNameCOMMA	
boolean	TokenNameboolean	
flushDeletes	TokenNameIdentifier	 flush Deletes
)	TokenNameRPAREN	
throws	TokenNamethrows	
CorruptIndexException	TokenNameIdentifier	 Corrupt Index Exception
,	TokenNameCOMMA	
IOException	TokenNameIdentifier	 IO Exception
{	TokenNameLBRACE	
flush	TokenNameIdentifier	 flush
(	TokenNameLPAREN	
triggerMerge	TokenNameIdentifier	 trigger Merge
,	TokenNameCOMMA	
flushDeletes	TokenNameIdentifier	 flush Deletes
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
/** * Flush all in-memory buffered updates (adds and deletes) * to the Directory. * @param triggerMerge if true, we may merge segments (if * deletes or docs were flushed) if necessary * @param applyAllDeletes whether pending deletes should also */	TokenNameCOMMENT_JAVADOC	 Flush all in-memory buffered updates (adds and deletes) to the Directory. @param triggerMerge if true, we may merge segments (if deletes or docs were flushed) if necessary @param applyAllDeletes whether pending deletes should also 
protected	TokenNameprotected	
final	TokenNamefinal	
void	TokenNamevoid	
flush	TokenNameIdentifier	 flush
(	TokenNameLPAREN	
boolean	TokenNameboolean	
triggerMerge	TokenNameIdentifier	 trigger Merge
,	TokenNameCOMMA	
boolean	TokenNameboolean	
applyAllDeletes	TokenNameIdentifier	 apply All Deletes
)	TokenNameRPAREN	
throws	TokenNamethrows	
CorruptIndexException	TokenNameIdentifier	 Corrupt Index Exception
,	TokenNameCOMMA	
IOException	TokenNameIdentifier	 IO Exception
{	TokenNameLBRACE	
// NOTE: this method cannot be sync'd because 	TokenNameCOMMENT_LINE	NOTE: this method cannot be sync'd because 
// maybeMerge() in turn calls mergeScheduler.merge which 	TokenNameCOMMENT_LINE	maybeMerge() in turn calls mergeScheduler.merge which 
// in turn can take a long time to run and we don't want 	TokenNameCOMMENT_LINE	in turn can take a long time to run and we don't want 
// to hold the lock for that. In the case of 	TokenNameCOMMENT_LINE	to hold the lock for that. In the case of 
// ConcurrentMergeScheduler this can lead to deadlock 	TokenNameCOMMENT_LINE	ConcurrentMergeScheduler this can lead to deadlock 
// when it stalls due to too many running merges. 	TokenNameCOMMENT_LINE	when it stalls due to too many running merges. 
// We can be called during close, when closing==true, so we must pass false to ensureOpen: 	TokenNameCOMMENT_LINE	We can be called during close, when closing==true, so we must pass false to ensureOpen: 
ensureOpen	TokenNameIdentifier	 ensure Open
(	TokenNameLPAREN	
false	TokenNamefalse	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
if	TokenNameif	
(	TokenNameLPAREN	
doFlush	TokenNameIdentifier	 do Flush
(	TokenNameLPAREN	
applyAllDeletes	TokenNameIdentifier	 apply All Deletes
)	TokenNameRPAREN	
&&	TokenNameAND_AND	
triggerMerge	TokenNameIdentifier	 trigger Merge
)	TokenNameRPAREN	
{	TokenNameLBRACE	
maybeMerge	TokenNameIdentifier	 maybe Merge
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
}	TokenNameRBRACE	
// TODO: this method should not have to be entirely 	TokenNameCOMMENT_LINE	TODO: this method should not have to be entirely 
// synchronized, ie, merges should be allowed to commit 	TokenNameCOMMENT_LINE	synchronized, ie, merges should be allowed to commit 
// even while a flush is happening 	TokenNameCOMMENT_LINE	even while a flush is happening 
private	TokenNameprivate	
synchronized	TokenNamesynchronized	
boolean	TokenNameboolean	
doFlush	TokenNameIdentifier	 do Flush
(	TokenNameLPAREN	
boolean	TokenNameboolean	
applyAllDeletes	TokenNameIdentifier	 apply All Deletes
)	TokenNameRPAREN	
throws	TokenNamethrows	
CorruptIndexException	TokenNameIdentifier	 Corrupt Index Exception
,	TokenNameCOMMA	
IOException	TokenNameIdentifier	 IO Exception
{	TokenNameLBRACE	
if	TokenNameif	
(	TokenNameLPAREN	
hitOOM	TokenNameIdentifier	 hit OOM
)	TokenNameRPAREN	
{	TokenNameLBRACE	
throw	TokenNamethrow	
new	TokenNamenew	
IllegalStateException	TokenNameIdentifier	 Illegal State Exception
(	TokenNameLPAREN	
"this writer hit an OutOfMemoryError; cannot flush"	TokenNameStringLiteral	this writer hit an OutOfMemoryError; cannot flush
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
doBeforeFlush	TokenNameIdentifier	 do Before Flush
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
assert	TokenNameassert	
testPoint	TokenNameIdentifier	 test Point
(	TokenNameLPAREN	
"startDoFlush"	TokenNameStringLiteral	startDoFlush
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
// We may be flushing because it was triggered by doc 	TokenNameCOMMENT_LINE	We may be flushing because it was triggered by doc 
// count, del count, ram usage (in which case flush 	TokenNameCOMMENT_LINE	count, del count, ram usage (in which case flush 
// pending is already set), or we may be flushing 	TokenNameCOMMENT_LINE	pending is already set), or we may be flushing 
// due to external event eg getReader or commit is 	TokenNameCOMMENT_LINE	due to external event eg getReader or commit is 
// called (in which case we now set it, and this will 	TokenNameCOMMENT_LINE	called (in which case we now set it, and this will 
// pause all threads): 	TokenNameCOMMENT_LINE	pause all threads): 
flushControl	TokenNameIdentifier	 flush Control
.	TokenNameDOT	
setFlushPendingNoWait	TokenNameIdentifier	 set Flush Pending No Wait
(	TokenNameLPAREN	
"explicit flush"	TokenNameStringLiteral	explicit flush
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
boolean	TokenNameboolean	
success	TokenNameIdentifier	 success
=	TokenNameEQUAL	
false	TokenNamefalse	
;	TokenNameSEMICOLON	
try	TokenNametry	
{	TokenNameLBRACE	
if	TokenNameif	
(	TokenNameLPAREN	
infoStream	TokenNameIdentifier	 info Stream
!=	TokenNameNOT_EQUAL	
null	TokenNamenull	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
message	TokenNameIdentifier	 message
(	TokenNameLPAREN	
" start flush: applyAllDeletes="	TokenNameStringLiteral	 start flush: applyAllDeletes=
+	TokenNamePLUS	
applyAllDeletes	TokenNameIdentifier	 apply All Deletes
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
message	TokenNameIdentifier	 message
(	TokenNameLPAREN	
" index before flush "	TokenNameStringLiteral	 index before flush 
+	TokenNamePLUS	
segString	TokenNameIdentifier	 seg String
(	TokenNameLPAREN	
)	TokenNameRPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
final	TokenNamefinal	
SegmentInfo	TokenNameIdentifier	 Segment Info
newSegment	TokenNameIdentifier	 new Segment
=	TokenNameEQUAL	
docWriter	TokenNameIdentifier	 doc Writer
.	TokenNameDOT	
flush	TokenNameIdentifier	 flush
(	TokenNameLPAREN	
this	TokenNamethis	
,	TokenNameCOMMA	
deleter	TokenNameIdentifier	 deleter
,	TokenNameCOMMA	
mergePolicy	TokenNameIdentifier	 merge Policy
,	TokenNameCOMMA	
segmentInfos	TokenNameIdentifier	 segment Infos
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
if	TokenNameif	
(	TokenNameLPAREN	
newSegment	TokenNameIdentifier	 new Segment
!=	TokenNameNOT_EQUAL	
null	TokenNamenull	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
setDiagnostics	TokenNameIdentifier	 set Diagnostics
(	TokenNameLPAREN	
newSegment	TokenNameIdentifier	 new Segment
,	TokenNameCOMMA	
"flush"	TokenNameStringLiteral	flush
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
segmentInfos	TokenNameIdentifier	 segment Infos
.	TokenNameDOT	
add	TokenNameIdentifier	 add
(	TokenNameLPAREN	
newSegment	TokenNameIdentifier	 new Segment
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
checkpoint	TokenNameIdentifier	 checkpoint
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
if	TokenNameif	
(	TokenNameLPAREN	
!	TokenNameNOT	
applyAllDeletes	TokenNameIdentifier	 apply All Deletes
)	TokenNameRPAREN	
{	TokenNameLBRACE	
// If deletes alone are consuming > 1/2 our RAM 	TokenNameCOMMENT_LINE	If deletes alone are consuming > 1/2 our RAM 
// buffer, force them all to apply now. This is to 	TokenNameCOMMENT_LINE	buffer, force them all to apply now. This is to 
// prevent too-frequent flushing of a long tail of 	TokenNameCOMMENT_LINE	prevent too-frequent flushing of a long tail of 
// tiny segments: 	TokenNameCOMMENT_LINE	tiny segments: 
if	TokenNameif	
(	TokenNameLPAREN	
flushControl	TokenNameIdentifier	 flush Control
.	TokenNameDOT	
getFlushDeletes	TokenNameIdentifier	 get Flush Deletes
(	TokenNameLPAREN	
)	TokenNameRPAREN	
||	TokenNameOR_OR	
(	TokenNameLPAREN	
config	TokenNameIdentifier	 config
.	TokenNameDOT	
getRAMBufferSizeMB	TokenNameIdentifier	 get RAM Buffer Size MB
(	TokenNameLPAREN	
)	TokenNameRPAREN	
!=	TokenNameNOT_EQUAL	
IndexWriterConfig	TokenNameIdentifier	 Index Writer Config
.	TokenNameDOT	
DISABLE_AUTO_FLUSH	TokenNameIdentifier	 DISABLE  AUTO  FLUSH
&&	TokenNameAND_AND	
bufferedDeletesStream	TokenNameIdentifier	 buffered Deletes Stream
.	TokenNameDOT	
bytesUsed	TokenNameIdentifier	 bytes Used
(	TokenNameLPAREN	
)	TokenNameRPAREN	
>	TokenNameGREATER	
(	TokenNameLPAREN	
1024	TokenNameIntegerLiteral	
*	TokenNameMULTIPLY	
1024	TokenNameIntegerLiteral	
*	TokenNameMULTIPLY	
config	TokenNameIdentifier	 config
.	TokenNameDOT	
getRAMBufferSizeMB	TokenNameIdentifier	 get RAM Buffer Size MB
(	TokenNameLPAREN	
)	TokenNameRPAREN	
/	TokenNameDIVIDE	
2	TokenNameIntegerLiteral	
)	TokenNameRPAREN	
)	TokenNameRPAREN	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
applyAllDeletes	TokenNameIdentifier	 apply All Deletes
=	TokenNameEQUAL	
true	TokenNametrue	
;	TokenNameSEMICOLON	
if	TokenNameif	
(	TokenNameLPAREN	
infoStream	TokenNameIdentifier	 info Stream
!=	TokenNameNOT_EQUAL	
null	TokenNamenull	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
message	TokenNameIdentifier	 message
(	TokenNameLPAREN	
"force apply deletes bytesUsed="	TokenNameStringLiteral	force apply deletes bytesUsed=
+	TokenNamePLUS	
bufferedDeletesStream	TokenNameIdentifier	 buffered Deletes Stream
.	TokenNameDOT	
bytesUsed	TokenNameIdentifier	 bytes Used
(	TokenNameLPAREN	
)	TokenNameRPAREN	
+	TokenNamePLUS	
" vs ramBuffer="	TokenNameStringLiteral	 vs ramBuffer=
+	TokenNamePLUS	
(	TokenNameLPAREN	
1024	TokenNameIntegerLiteral	
*	TokenNameMULTIPLY	
1024	TokenNameIntegerLiteral	
*	TokenNameMULTIPLY	
config	TokenNameIdentifier	 config
.	TokenNameDOT	
getRAMBufferSizeMB	TokenNameIdentifier	 get RAM Buffer Size MB
(	TokenNameLPAREN	
)	TokenNameRPAREN	
)	TokenNameRPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
}	TokenNameRBRACE	
}	TokenNameRBRACE	
if	TokenNameif	
(	TokenNameLPAREN	
applyAllDeletes	TokenNameIdentifier	 apply All Deletes
)	TokenNameRPAREN	
{	TokenNameLBRACE	
if	TokenNameif	
(	TokenNameLPAREN	
infoStream	TokenNameIdentifier	 info Stream
!=	TokenNameNOT_EQUAL	
null	TokenNamenull	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
message	TokenNameIdentifier	 message
(	TokenNameLPAREN	
"apply all deletes during flush"	TokenNameStringLiteral	apply all deletes during flush
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
flushDeletesCount	TokenNameIdentifier	 flush Deletes Count
.	TokenNameDOT	
incrementAndGet	TokenNameIdentifier	 increment And Get
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
final	TokenNamefinal	
BufferedDeletesStream	TokenNameIdentifier	 Buffered Deletes Stream
.	TokenNameDOT	
ApplyDeletesResult	TokenNameIdentifier	 Apply Deletes Result
result	TokenNameIdentifier	 result
=	TokenNameEQUAL	
bufferedDeletesStream	TokenNameIdentifier	 buffered Deletes Stream
.	TokenNameDOT	
applyDeletes	TokenNameIdentifier	 apply Deletes
(	TokenNameLPAREN	
readerPool	TokenNameIdentifier	 reader Pool
,	TokenNameCOMMA	
segmentInfos	TokenNameIdentifier	 segment Infos
.	TokenNameDOT	
asList	TokenNameIdentifier	 as List
(	TokenNameLPAREN	
)	TokenNameRPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
if	TokenNameif	
(	TokenNameLPAREN	
result	TokenNameIdentifier	 result
.	TokenNameDOT	
anyDeletes	TokenNameIdentifier	 any Deletes
)	TokenNameRPAREN	
{	TokenNameLBRACE	
checkpoint	TokenNameIdentifier	 checkpoint
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
if	TokenNameif	
(	TokenNameLPAREN	
!	TokenNameNOT	
keepFullyDeletedSegments	TokenNameIdentifier	 keep Fully Deleted Segments
&&	TokenNameAND_AND	
result	TokenNameIdentifier	 result
.	TokenNameDOT	
allDeleted	TokenNameIdentifier	 all Deleted
!=	TokenNameNOT_EQUAL	
null	TokenNamenull	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
if	TokenNameif	
(	TokenNameLPAREN	
infoStream	TokenNameIdentifier	 info Stream
!=	TokenNameNOT_EQUAL	
null	TokenNamenull	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
message	TokenNameIdentifier	 message
(	TokenNameLPAREN	
"drop 100% deleted segments: "	TokenNameStringLiteral	drop 100% deleted segments: 
+	TokenNamePLUS	
result	TokenNameIdentifier	 result
.	TokenNameDOT	
allDeleted	TokenNameIdentifier	 all Deleted
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
for	TokenNamefor	
(	TokenNameLPAREN	
SegmentInfo	TokenNameIdentifier	 Segment Info
info	TokenNameIdentifier	 info
:	TokenNameCOLON	
result	TokenNameIdentifier	 result
.	TokenNameDOT	
allDeleted	TokenNameIdentifier	 all Deleted
)	TokenNameRPAREN	
{	TokenNameLBRACE	
// If a merge has already registered for this 	TokenNameCOMMENT_LINE	If a merge has already registered for this 
// segment, we leave it in the readerPool; the 	TokenNameCOMMENT_LINE	segment, we leave it in the readerPool; the 
// merge will skip merging it and will then drop 	TokenNameCOMMENT_LINE	merge will skip merging it and will then drop 
// it once it's done: 	TokenNameCOMMENT_LINE	it once it's done: 
if	TokenNameif	
(	TokenNameLPAREN	
!	TokenNameNOT	
mergingSegments	TokenNameIdentifier	 merging Segments
.	TokenNameDOT	
contains	TokenNameIdentifier	 contains
(	TokenNameLPAREN	
info	TokenNameIdentifier	 info
)	TokenNameRPAREN	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
segmentInfos	TokenNameIdentifier	 segment Infos
.	TokenNameDOT	
remove	TokenNameIdentifier	 remove
(	TokenNameLPAREN	
info	TokenNameIdentifier	 info
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
if	TokenNameif	
(	TokenNameLPAREN	
readerPool	TokenNameIdentifier	 reader Pool
!=	TokenNameNOT_EQUAL	
null	TokenNamenull	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
readerPool	TokenNameIdentifier	 reader Pool
.	TokenNameDOT	
drop	TokenNameIdentifier	 drop
(	TokenNameLPAREN	
info	TokenNameIdentifier	 info
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
}	TokenNameRBRACE	
}	TokenNameRBRACE	
checkpoint	TokenNameIdentifier	 checkpoint
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
bufferedDeletesStream	TokenNameIdentifier	 buffered Deletes Stream
.	TokenNameDOT	
prune	TokenNameIdentifier	 prune
(	TokenNameLPAREN	
segmentInfos	TokenNameIdentifier	 segment Infos
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
assert	TokenNameassert	
!	TokenNameNOT	
bufferedDeletesStream	TokenNameIdentifier	 buffered Deletes Stream
.	TokenNameDOT	
any	TokenNameIdentifier	 any
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
flushControl	TokenNameIdentifier	 flush Control
.	TokenNameDOT	
clearDeletes	TokenNameIdentifier	 clear Deletes
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
else	TokenNameelse	
if	TokenNameif	
(	TokenNameLPAREN	
infoStream	TokenNameIdentifier	 info Stream
!=	TokenNameNOT_EQUAL	
null	TokenNamenull	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
message	TokenNameIdentifier	 message
(	TokenNameLPAREN	
"don't apply deletes now delTermCount="	TokenNameStringLiteral	don't apply deletes now delTermCount=
+	TokenNamePLUS	
bufferedDeletesStream	TokenNameIdentifier	 buffered Deletes Stream
.	TokenNameDOT	
numTerms	TokenNameIdentifier	 num Terms
(	TokenNameLPAREN	
)	TokenNameRPAREN	
+	TokenNamePLUS	
" bytesUsed="	TokenNameStringLiteral	 bytesUsed=
+	TokenNamePLUS	
bufferedDeletesStream	TokenNameIdentifier	 buffered Deletes Stream
.	TokenNameDOT	
bytesUsed	TokenNameIdentifier	 bytes Used
(	TokenNameLPAREN	
)	TokenNameRPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
doAfterFlush	TokenNameIdentifier	 do After Flush
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
flushCount	TokenNameIdentifier	 flush Count
.	TokenNameDOT	
incrementAndGet	TokenNameIdentifier	 increment And Get
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
success	TokenNameIdentifier	 success
=	TokenNameEQUAL	
true	TokenNametrue	
;	TokenNameSEMICOLON	
return	TokenNamereturn	
newSegment	TokenNameIdentifier	 new Segment
!=	TokenNameNOT_EQUAL	
null	TokenNamenull	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
catch	TokenNamecatch	
(	TokenNameLPAREN	
OutOfMemoryError	TokenNameIdentifier	 Out Of Memory Error
oom	TokenNameIdentifier	 oom
)	TokenNameRPAREN	
{	TokenNameLBRACE	
handleOOM	TokenNameIdentifier	 handle OOM
(	TokenNameLPAREN	
oom	TokenNameIdentifier	 oom
,	TokenNameCOMMA	
"doFlush"	TokenNameStringLiteral	doFlush
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
// never hit 	TokenNameCOMMENT_LINE	never hit 
return	TokenNamereturn	
false	TokenNamefalse	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
finally	TokenNamefinally	
{	TokenNameLBRACE	
flushControl	TokenNameIdentifier	 flush Control
.	TokenNameDOT	
clearFlushPending	TokenNameIdentifier	 clear Flush Pending
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
if	TokenNameif	
(	TokenNameLPAREN	
!	TokenNameNOT	
success	TokenNameIdentifier	 success
&&	TokenNameAND_AND	
infoStream	TokenNameIdentifier	 info Stream
!=	TokenNameNOT_EQUAL	
null	TokenNamenull	
)	TokenNameRPAREN	
message	TokenNameIdentifier	 message
(	TokenNameLPAREN	
"hit exception during flush"	TokenNameStringLiteral	hit exception during flush
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
}	TokenNameRBRACE	
/** Expert: Return the total size of all index files currently cached in memory. * Useful for size management with flushRamDocs() */	TokenNameCOMMENT_JAVADOC	 Expert: Return the total size of all index files currently cached in memory. Useful for size management with flushRamDocs() 
public	TokenNamepublic	
final	TokenNamefinal	
long	TokenNamelong	
ramSizeInBytes	TokenNameIdentifier	 ram Size In Bytes
(	TokenNameLPAREN	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
ensureOpen	TokenNameIdentifier	 ensure Open
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
return	TokenNamereturn	
docWriter	TokenNameIdentifier	 doc Writer
.	TokenNameDOT	
bytesUsed	TokenNameIdentifier	 bytes Used
(	TokenNameLPAREN	
)	TokenNameRPAREN	
+	TokenNamePLUS	
bufferedDeletesStream	TokenNameIdentifier	 buffered Deletes Stream
.	TokenNameDOT	
bytesUsed	TokenNameIdentifier	 bytes Used
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
/** Expert: Return the number of documents currently * buffered in RAM. */	TokenNameCOMMENT_JAVADOC	 Expert: Return the number of documents currently buffered in RAM. 
public	TokenNamepublic	
final	TokenNamefinal	
synchronized	TokenNamesynchronized	
int	TokenNameint	
numRamDocs	TokenNameIdentifier	 num Ram Docs
(	TokenNameLPAREN	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
ensureOpen	TokenNameIdentifier	 ensure Open
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
return	TokenNamereturn	
docWriter	TokenNameIdentifier	 doc Writer
.	TokenNameDOT	
getNumDocs	TokenNameIdentifier	 get Num Docs
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
private	TokenNameprivate	
void	TokenNamevoid	
ensureValidMerge	TokenNameIdentifier	 ensure Valid Merge
(	TokenNameLPAREN	
MergePolicy	TokenNameIdentifier	 Merge Policy
.	TokenNameDOT	
OneMerge	TokenNameIdentifier	 One Merge
merge	TokenNameIdentifier	 merge
)	TokenNameRPAREN	
throws	TokenNamethrows	
IOException	TokenNameIdentifier	 IO Exception
{	TokenNameLBRACE	
for	TokenNamefor	
(	TokenNameLPAREN	
SegmentInfo	TokenNameIdentifier	 Segment Info
info	TokenNameIdentifier	 info
:	TokenNameCOLON	
merge	TokenNameIdentifier	 merge
.	TokenNameDOT	
segments	TokenNameIdentifier	 segments
)	TokenNameRPAREN	
{	TokenNameLBRACE	
if	TokenNameif	
(	TokenNameLPAREN	
!	TokenNameNOT	
segmentInfos	TokenNameIdentifier	 segment Infos
.	TokenNameDOT	
contains	TokenNameIdentifier	 contains
(	TokenNameLPAREN	
info	TokenNameIdentifier	 info
)	TokenNameRPAREN	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
throw	TokenNamethrow	
new	TokenNamenew	
MergePolicy	TokenNameIdentifier	 Merge Policy
.	TokenNameDOT	
MergeException	TokenNameIdentifier	 Merge Exception
(	TokenNameLPAREN	
"MergePolicy selected a segment ("	TokenNameStringLiteral	MergePolicy selected a segment (
+	TokenNamePLUS	
info	TokenNameIdentifier	 info
.	TokenNameDOT	
name	TokenNameIdentifier	 name
+	TokenNamePLUS	
") that is not in the current index "	TokenNameStringLiteral	) that is not in the current index 
+	TokenNamePLUS	
segString	TokenNameIdentifier	 seg String
(	TokenNameLPAREN	
)	TokenNameRPAREN	
,	TokenNameCOMMA	
directory	TokenNameIdentifier	 directory
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
}	TokenNameRBRACE	
}	TokenNameRBRACE	
/** Carefully merges deletes for the segments we just * merged. This is tricky because, although merging will * clear all deletes (compacts the documents), new * deletes may have been flushed to the segments since * the merge was started. This method "carries over" * such new deletes onto the newly merged segment, and * saves the resulting deletes file (incrementing the * delete generation for merge.info). If no deletes were * flushed, no new deletes file is saved. */	TokenNameCOMMENT_JAVADOC	 Carefully merges deletes for the segments we just merged. This is tricky because, although merging will clear all deletes (compacts the documents), new deletes may have been flushed to the segments since the merge was started. This method "carries over" such new deletes onto the newly merged segment, and saves the resulting deletes file (incrementing the delete generation for merge.info). If no deletes were flushed, no new deletes file is saved. 
synchronized	TokenNamesynchronized	
private	TokenNameprivate	
void	TokenNamevoid	
commitMergedDeletes	TokenNameIdentifier	 commit Merged Deletes
(	TokenNameLPAREN	
MergePolicy	TokenNameIdentifier	 Merge Policy
.	TokenNameDOT	
OneMerge	TokenNameIdentifier	 One Merge
merge	TokenNameIdentifier	 merge
,	TokenNameCOMMA	
SegmentReader	TokenNameIdentifier	 Segment Reader
mergedReader	TokenNameIdentifier	 merged Reader
)	TokenNameRPAREN	
throws	TokenNamethrows	
IOException	TokenNameIdentifier	 IO Exception
{	TokenNameLBRACE	
assert	TokenNameassert	
testPoint	TokenNameIdentifier	 test Point
(	TokenNameLPAREN	
"startCommitMergeDeletes"	TokenNameStringLiteral	startCommitMergeDeletes
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
final	TokenNamefinal	
List	TokenNameIdentifier	 List
<	TokenNameLESS	
SegmentInfo	TokenNameIdentifier	 Segment Info
>	TokenNameGREATER	
sourceSegments	TokenNameIdentifier	 source Segments
=	TokenNameEQUAL	
merge	TokenNameIdentifier	 merge
.	TokenNameDOT	
segments	TokenNameIdentifier	 segments
;	TokenNameSEMICOLON	
if	TokenNameif	
(	TokenNameLPAREN	
infoStream	TokenNameIdentifier	 info Stream
!=	TokenNameNOT_EQUAL	
null	TokenNamenull	
)	TokenNameRPAREN	
message	TokenNameIdentifier	 message
(	TokenNameLPAREN	
"commitMergeDeletes "	TokenNameStringLiteral	commitMergeDeletes 
+	TokenNamePLUS	
merge	TokenNameIdentifier	 merge
.	TokenNameDOT	
segString	TokenNameIdentifier	 seg String
(	TokenNameLPAREN	
directory	TokenNameIdentifier	 directory
)	TokenNameRPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
// Carefully merge deletes that occurred after we 	TokenNameCOMMENT_LINE	Carefully merge deletes that occurred after we 
// started merging: 	TokenNameCOMMENT_LINE	started merging: 
int	TokenNameint	
docUpto	TokenNameIdentifier	 doc Upto
=	TokenNameEQUAL	
0	TokenNameIntegerLiteral	
;	TokenNameSEMICOLON	
int	TokenNameint	
delCount	TokenNameIdentifier	 del Count
=	TokenNameEQUAL	
0	TokenNameIntegerLiteral	
;	TokenNameSEMICOLON	
long	TokenNamelong	
minGen	TokenNameIdentifier	 min Gen
=	TokenNameEQUAL	
Long	TokenNameIdentifier	 Long
.	TokenNameDOT	
MAX_VALUE	TokenNameIdentifier	 MAX  VALUE
;	TokenNameSEMICOLON	
for	TokenNamefor	
(	TokenNameLPAREN	
int	TokenNameint	
i	TokenNameIdentifier	 i
=	TokenNameEQUAL	
0	TokenNameIntegerLiteral	
;	TokenNameSEMICOLON	
i	TokenNameIdentifier	 i
<	TokenNameLESS	
sourceSegments	TokenNameIdentifier	 source Segments
.	TokenNameDOT	
size	TokenNameIdentifier	 size
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
i	TokenNameIdentifier	 i
++	TokenNamePLUS_PLUS	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
SegmentInfo	TokenNameIdentifier	 Segment Info
info	TokenNameIdentifier	 info
=	TokenNameEQUAL	
sourceSegments	TokenNameIdentifier	 source Segments
.	TokenNameDOT	
get	TokenNameIdentifier	 get
(	TokenNameLPAREN	
i	TokenNameIdentifier	 i
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
minGen	TokenNameIdentifier	 min Gen
=	TokenNameEQUAL	
Math	TokenNameIdentifier	 Math
.	TokenNameDOT	
min	TokenNameIdentifier	 min
(	TokenNameLPAREN	
info	TokenNameIdentifier	 info
.	TokenNameDOT	
getBufferedDeletesGen	TokenNameIdentifier	 get Buffered Deletes Gen
(	TokenNameLPAREN	
)	TokenNameRPAREN	
,	TokenNameCOMMA	
minGen	TokenNameIdentifier	 min Gen
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
int	TokenNameint	
docCount	TokenNameIdentifier	 doc Count
=	TokenNameEQUAL	
info	TokenNameIdentifier	 info
.	TokenNameDOT	
docCount	TokenNameIdentifier	 doc Count
;	TokenNameSEMICOLON	
final	TokenNamefinal	
SegmentReader	TokenNameIdentifier	 Segment Reader
previousReader	TokenNameIdentifier	 previous Reader
=	TokenNameEQUAL	
merge	TokenNameIdentifier	 merge
.	TokenNameDOT	
readerClones	TokenNameIdentifier	 reader Clones
.	TokenNameDOT	
get	TokenNameIdentifier	 get
(	TokenNameLPAREN	
i	TokenNameIdentifier	 i
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
if	TokenNameif	
(	TokenNameLPAREN	
previousReader	TokenNameIdentifier	 previous Reader
==	TokenNameEQUAL_EQUAL	
null	TokenNamenull	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
// Reader was skipped because it was 100% deletions 	TokenNameCOMMENT_LINE	Reader was skipped because it was 100% deletions 
continue	TokenNamecontinue	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
final	TokenNamefinal	
SegmentReader	TokenNameIdentifier	 Segment Reader
currentReader	TokenNameIdentifier	 current Reader
=	TokenNameEQUAL	
merge	TokenNameIdentifier	 merge
.	TokenNameDOT	
readers	TokenNameIdentifier	 readers
.	TokenNameDOT	
get	TokenNameIdentifier	 get
(	TokenNameLPAREN	
i	TokenNameIdentifier	 i
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
if	TokenNameif	
(	TokenNameLPAREN	
previousReader	TokenNameIdentifier	 previous Reader
.	TokenNameDOT	
hasDeletions	TokenNameIdentifier	 has Deletions
(	TokenNameLPAREN	
)	TokenNameRPAREN	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
// There were deletes on this segment when the merge 	TokenNameCOMMENT_LINE	There were deletes on this segment when the merge 
// started. The merge has collapsed away those 	TokenNameCOMMENT_LINE	started. The merge has collapsed away those 
// deletes, but, if new deletes were flushed since 	TokenNameCOMMENT_LINE	deletes, but, if new deletes were flushed since 
// the merge started, we must now carefully keep any 	TokenNameCOMMENT_LINE	the merge started, we must now carefully keep any 
// newly flushed deletes but mapping them to the new 	TokenNameCOMMENT_LINE	newly flushed deletes but mapping them to the new 
// docIDs. 	TokenNameCOMMENT_LINE	docIDs. 
if	TokenNameif	
(	TokenNameLPAREN	
currentReader	TokenNameIdentifier	 current Reader
.	TokenNameDOT	
numDeletedDocs	TokenNameIdentifier	 num Deleted Docs
(	TokenNameLPAREN	
)	TokenNameRPAREN	
>	TokenNameGREATER	
previousReader	TokenNameIdentifier	 previous Reader
.	TokenNameDOT	
numDeletedDocs	TokenNameIdentifier	 num Deleted Docs
(	TokenNameLPAREN	
)	TokenNameRPAREN	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
// This means this segment has had new deletes 	TokenNameCOMMENT_LINE	This means this segment has had new deletes 
// committed since we started the merge, so we 	TokenNameCOMMENT_LINE	committed since we started the merge, so we 
// must merge them: 	TokenNameCOMMENT_LINE	must merge them: 
for	TokenNamefor	
(	TokenNameLPAREN	
int	TokenNameint	
j	TokenNameIdentifier	 j
=	TokenNameEQUAL	
0	TokenNameIntegerLiteral	
;	TokenNameSEMICOLON	
j	TokenNameIdentifier	 j
<	TokenNameLESS	
docCount	TokenNameIdentifier	 doc Count
;	TokenNameSEMICOLON	
j	TokenNameIdentifier	 j
++	TokenNamePLUS_PLUS	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
if	TokenNameif	
(	TokenNameLPAREN	
previousReader	TokenNameIdentifier	 previous Reader
.	TokenNameDOT	
isDeleted	TokenNameIdentifier	 is Deleted
(	TokenNameLPAREN	
j	TokenNameIdentifier	 j
)	TokenNameRPAREN	
)	TokenNameRPAREN	
assert	TokenNameassert	
currentReader	TokenNameIdentifier	 current Reader
.	TokenNameDOT	
isDeleted	TokenNameIdentifier	 is Deleted
(	TokenNameLPAREN	
j	TokenNameIdentifier	 j
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
else	TokenNameelse	
{	TokenNameLBRACE	
if	TokenNameif	
(	TokenNameLPAREN	
currentReader	TokenNameIdentifier	 current Reader
.	TokenNameDOT	
isDeleted	TokenNameIdentifier	 is Deleted
(	TokenNameLPAREN	
j	TokenNameIdentifier	 j
)	TokenNameRPAREN	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
mergedReader	TokenNameIdentifier	 merged Reader
.	TokenNameDOT	
doDelete	TokenNameIdentifier	 do Delete
(	TokenNameLPAREN	
docUpto	TokenNameIdentifier	 doc Upto
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
delCount	TokenNameIdentifier	 del Count
++	TokenNamePLUS_PLUS	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
docUpto	TokenNameIdentifier	 doc Upto
++	TokenNamePLUS_PLUS	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
}	TokenNameRBRACE	
}	TokenNameRBRACE	
else	TokenNameelse	
{	TokenNameLBRACE	
docUpto	TokenNameIdentifier	 doc Upto
+=	TokenNamePLUS_EQUAL	
docCount	TokenNameIdentifier	 doc Count
-	TokenNameMINUS	
previousReader	TokenNameIdentifier	 previous Reader
.	TokenNameDOT	
numDeletedDocs	TokenNameIdentifier	 num Deleted Docs
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
}	TokenNameRBRACE	
else	TokenNameelse	
if	TokenNameif	
(	TokenNameLPAREN	
currentReader	TokenNameIdentifier	 current Reader
.	TokenNameDOT	
hasDeletions	TokenNameIdentifier	 has Deletions
(	TokenNameLPAREN	
)	TokenNameRPAREN	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
// This segment had no deletes before but now it 	TokenNameCOMMENT_LINE	This segment had no deletes before but now it 
// does: 	TokenNameCOMMENT_LINE	does: 
for	TokenNamefor	
(	TokenNameLPAREN	
int	TokenNameint	
j	TokenNameIdentifier	 j
=	TokenNameEQUAL	
0	TokenNameIntegerLiteral	
;	TokenNameSEMICOLON	
j	TokenNameIdentifier	 j
<	TokenNameLESS	
docCount	TokenNameIdentifier	 doc Count
;	TokenNameSEMICOLON	
j	TokenNameIdentifier	 j
++	TokenNamePLUS_PLUS	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
if	TokenNameif	
(	TokenNameLPAREN	
currentReader	TokenNameIdentifier	 current Reader
.	TokenNameDOT	
isDeleted	TokenNameIdentifier	 is Deleted
(	TokenNameLPAREN	
j	TokenNameIdentifier	 j
)	TokenNameRPAREN	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
mergedReader	TokenNameIdentifier	 merged Reader
.	TokenNameDOT	
doDelete	TokenNameIdentifier	 do Delete
(	TokenNameLPAREN	
docUpto	TokenNameIdentifier	 doc Upto
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
delCount	TokenNameIdentifier	 del Count
++	TokenNamePLUS_PLUS	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
docUpto	TokenNameIdentifier	 doc Upto
++	TokenNamePLUS_PLUS	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
}	TokenNameRBRACE	
else	TokenNameelse	
// No deletes before or after 	TokenNameCOMMENT_LINE	No deletes before or after 
docUpto	TokenNameIdentifier	 doc Upto
+=	TokenNamePLUS_EQUAL	
info	TokenNameIdentifier	 info
.	TokenNameDOT	
docCount	TokenNameIdentifier	 doc Count
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
assert	TokenNameassert	
mergedReader	TokenNameIdentifier	 merged Reader
.	TokenNameDOT	
numDeletedDocs	TokenNameIdentifier	 num Deleted Docs
(	TokenNameLPAREN	
)	TokenNameRPAREN	
==	TokenNameEQUAL_EQUAL	
delCount	TokenNameIdentifier	 del Count
;	TokenNameSEMICOLON	
mergedReader	TokenNameIdentifier	 merged Reader
.	TokenNameDOT	
hasChanges	TokenNameIdentifier	 has Changes
=	TokenNameEQUAL	
delCount	TokenNameIdentifier	 del Count
>	TokenNameGREATER	
0	TokenNameIntegerLiteral	
;	TokenNameSEMICOLON	
// If new deletes were applied while we were merging 	TokenNameCOMMENT_LINE	If new deletes were applied while we were merging 
// (which happens if eg commit() or getReader() is 	TokenNameCOMMENT_LINE	(which happens if eg commit() or getReader() is 
// called during our merge), then it better be the case 	TokenNameCOMMENT_LINE	called during our merge), then it better be the case 
// that the delGen has increased for all our merged 	TokenNameCOMMENT_LINE	that the delGen has increased for all our merged 
// segments: 	TokenNameCOMMENT_LINE	segments: 
assert	TokenNameassert	
!	TokenNameNOT	
mergedReader	TokenNameIdentifier	 merged Reader
.	TokenNameDOT	
hasChanges	TokenNameIdentifier	 has Changes
||	TokenNameOR_OR	
minGen	TokenNameIdentifier	 min Gen
>	TokenNameGREATER	
mergedReader	TokenNameIdentifier	 merged Reader
.	TokenNameDOT	
getSegmentInfo	TokenNameIdentifier	 get Segment Info
(	TokenNameLPAREN	
)	TokenNameRPAREN	
.	TokenNameDOT	
getBufferedDeletesGen	TokenNameIdentifier	 get Buffered Deletes Gen
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
mergedReader	TokenNameIdentifier	 merged Reader
.	TokenNameDOT	
getSegmentInfo	TokenNameIdentifier	 get Segment Info
(	TokenNameLPAREN	
)	TokenNameRPAREN	
.	TokenNameDOT	
setBufferedDeletesGen	TokenNameIdentifier	 set Buffered Deletes Gen
(	TokenNameLPAREN	
minGen	TokenNameIdentifier	 min Gen
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
synchronized	TokenNamesynchronized	
private	TokenNameprivate	
boolean	TokenNameboolean	
commitMerge	TokenNameIdentifier	 commit Merge
(	TokenNameLPAREN	
MergePolicy	TokenNameIdentifier	 Merge Policy
.	TokenNameDOT	
OneMerge	TokenNameIdentifier	 One Merge
merge	TokenNameIdentifier	 merge
,	TokenNameCOMMA	
SegmentReader	TokenNameIdentifier	 Segment Reader
mergedReader	TokenNameIdentifier	 merged Reader
)	TokenNameRPAREN	
throws	TokenNamethrows	
IOException	TokenNameIdentifier	 IO Exception
{	TokenNameLBRACE	
assert	TokenNameassert	
testPoint	TokenNameIdentifier	 test Point
(	TokenNameLPAREN	
"startCommitMerge"	TokenNameStringLiteral	startCommitMerge
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
if	TokenNameif	
(	TokenNameLPAREN	
hitOOM	TokenNameIdentifier	 hit OOM
)	TokenNameRPAREN	
{	TokenNameLBRACE	
throw	TokenNamethrow	
new	TokenNamenew	
IllegalStateException	TokenNameIdentifier	 Illegal State Exception
(	TokenNameLPAREN	
"this writer hit an OutOfMemoryError; cannot complete merge"	TokenNameStringLiteral	this writer hit an OutOfMemoryError; cannot complete merge
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
if	TokenNameif	
(	TokenNameLPAREN	
infoStream	TokenNameIdentifier	 info Stream
!=	TokenNameNOT_EQUAL	
null	TokenNamenull	
)	TokenNameRPAREN	
message	TokenNameIdentifier	 message
(	TokenNameLPAREN	
"commitMerge: "	TokenNameStringLiteral	commitMerge: 
+	TokenNamePLUS	
merge	TokenNameIdentifier	 merge
.	TokenNameDOT	
segString	TokenNameIdentifier	 seg String
(	TokenNameLPAREN	
directory	TokenNameIdentifier	 directory
)	TokenNameRPAREN	
+	TokenNamePLUS	
" index="	TokenNameStringLiteral	 index=
+	TokenNamePLUS	
segString	TokenNameIdentifier	 seg String
(	TokenNameLPAREN	
)	TokenNameRPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
assert	TokenNameassert	
merge	TokenNameIdentifier	 merge
.	TokenNameDOT	
registerDone	TokenNameIdentifier	 register Done
;	TokenNameSEMICOLON	
// If merge was explicitly aborted, or, if rollback() or 	TokenNameCOMMENT_LINE	If merge was explicitly aborted, or, if rollback() or 
// rollbackTransaction() had been called since our merge 	TokenNameCOMMENT_LINE	rollbackTransaction() had been called since our merge 
// started (which results in an unqualified 	TokenNameCOMMENT_LINE	started (which results in an unqualified 
// deleter.refresh() call that will remove any index 	TokenNameCOMMENT_LINE	deleter.refresh() call that will remove any index 
// file that current segments does not reference), we 	TokenNameCOMMENT_LINE	file that current segments does not reference), we 
// abort this merge 	TokenNameCOMMENT_LINE	abort this merge 
if	TokenNameif	
(	TokenNameLPAREN	
merge	TokenNameIdentifier	 merge
.	TokenNameDOT	
isAborted	TokenNameIdentifier	 is Aborted
(	TokenNameLPAREN	
)	TokenNameRPAREN	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
if	TokenNameif	
(	TokenNameLPAREN	
infoStream	TokenNameIdentifier	 info Stream
!=	TokenNameNOT_EQUAL	
null	TokenNamenull	
)	TokenNameRPAREN	
message	TokenNameIdentifier	 message
(	TokenNameLPAREN	
"commitMerge: skipping merge "	TokenNameStringLiteral	commitMerge: skipping merge 
+	TokenNamePLUS	
merge	TokenNameIdentifier	 merge
.	TokenNameDOT	
segString	TokenNameIdentifier	 seg String
(	TokenNameLPAREN	
directory	TokenNameIdentifier	 directory
)	TokenNameRPAREN	
+	TokenNamePLUS	
": it was aborted"	TokenNameStringLiteral	: it was aborted
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
return	TokenNamereturn	
false	TokenNamefalse	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
if	TokenNameif	
(	TokenNameLPAREN	
merge	TokenNameIdentifier	 merge
.	TokenNameDOT	
info	TokenNameIdentifier	 info
.	TokenNameDOT	
docCount	TokenNameIdentifier	 doc Count
>	TokenNameGREATER	
0	TokenNameIntegerLiteral	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
commitMergedDeletes	TokenNameIdentifier	 commit Merged Deletes
(	TokenNameLPAREN	
merge	TokenNameIdentifier	 merge
,	TokenNameCOMMA	
mergedReader	TokenNameIdentifier	 merged Reader
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
// If the doc store we are using has been closed and 	TokenNameCOMMENT_LINE	If the doc store we are using has been closed and 
// is in now compound format (but wasn't when we 	TokenNameCOMMENT_LINE	is in now compound format (but wasn't when we 
// started), then we will switch to the compound 	TokenNameCOMMENT_LINE	started), then we will switch to the compound 
// format as well: 	TokenNameCOMMENT_LINE	format as well: 
assert	TokenNameassert	
!	TokenNameNOT	
segmentInfos	TokenNameIdentifier	 segment Infos
.	TokenNameDOT	
contains	TokenNameIdentifier	 contains
(	TokenNameLPAREN	
merge	TokenNameIdentifier	 merge
.	TokenNameDOT	
info	TokenNameIdentifier	 info
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
final	TokenNamefinal	
boolean	TokenNameboolean	
allDeleted	TokenNameIdentifier	 all Deleted
=	TokenNameEQUAL	
mergedReader	TokenNameIdentifier	 merged Reader
.	TokenNameDOT	
numDocs	TokenNameIdentifier	 num Docs
(	TokenNameLPAREN	
)	TokenNameRPAREN	
==	TokenNameEQUAL_EQUAL	
0	TokenNameIntegerLiteral	
;	TokenNameSEMICOLON	
if	TokenNameif	
(	TokenNameLPAREN	
infoStream	TokenNameIdentifier	 info Stream
!=	TokenNameNOT_EQUAL	
null	TokenNamenull	
&&	TokenNameAND_AND	
allDeleted	TokenNameIdentifier	 all Deleted
)	TokenNameRPAREN	
{	TokenNameLBRACE	
message	TokenNameIdentifier	 message
(	TokenNameLPAREN	
"merged segment "	TokenNameStringLiteral	merged segment 
+	TokenNamePLUS	
merge	TokenNameIdentifier	 merge
.	TokenNameDOT	
info	TokenNameIdentifier	 info
+	TokenNamePLUS	
" is 100% deleted"	TokenNameStringLiteral	 is 100% deleted
+	TokenNamePLUS	
(	TokenNameLPAREN	
keepFullyDeletedSegments	TokenNameIdentifier	 keep Fully Deleted Segments
?	TokenNameQUESTION	
""	TokenNameStringLiteral	 
:	TokenNameCOLON	
"; skipping insert"	TokenNameStringLiteral	; skipping insert
)	TokenNameRPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
final	TokenNamefinal	
boolean	TokenNameboolean	
dropSegment	TokenNameIdentifier	 drop Segment
=	TokenNameEQUAL	
allDeleted	TokenNameIdentifier	 all Deleted
&&	TokenNameAND_AND	
!	TokenNameNOT	
keepFullyDeletedSegments	TokenNameIdentifier	 keep Fully Deleted Segments
;	TokenNameSEMICOLON	
segmentInfos	TokenNameIdentifier	 segment Infos
.	TokenNameDOT	
applyMergeChanges	TokenNameIdentifier	 apply Merge Changes
(	TokenNameLPAREN	
merge	TokenNameIdentifier	 merge
,	TokenNameCOMMA	
dropSegment	TokenNameIdentifier	 drop Segment
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
if	TokenNameif	
(	TokenNameLPAREN	
dropSegment	TokenNameIdentifier	 drop Segment
)	TokenNameRPAREN	
{	TokenNameLBRACE	
readerPool	TokenNameIdentifier	 reader Pool
.	TokenNameDOT	
drop	TokenNameIdentifier	 drop
(	TokenNameLPAREN	
merge	TokenNameIdentifier	 merge
.	TokenNameDOT	
info	TokenNameIdentifier	 info
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
deleter	TokenNameIdentifier	 deleter
.	TokenNameDOT	
deleteNewFiles	TokenNameIdentifier	 delete New Files
(	TokenNameLPAREN	
merge	TokenNameIdentifier	 merge
.	TokenNameDOT	
info	TokenNameIdentifier	 info
.	TokenNameDOT	
files	TokenNameIdentifier	 files
(	TokenNameLPAREN	
)	TokenNameRPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
assert	TokenNameassert	
!	TokenNameNOT	
segmentInfos	TokenNameIdentifier	 segment Infos
.	TokenNameDOT	
contains	TokenNameIdentifier	 contains
(	TokenNameLPAREN	
merge	TokenNameIdentifier	 merge
.	TokenNameDOT	
info	TokenNameIdentifier	 info
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
if	TokenNameif	
(	TokenNameLPAREN	
infoStream	TokenNameIdentifier	 info Stream
!=	TokenNameNOT_EQUAL	
null	TokenNamenull	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
message	TokenNameIdentifier	 message
(	TokenNameLPAREN	
"after commit: "	TokenNameStringLiteral	after commit: 
+	TokenNamePLUS	
segString	TokenNameIdentifier	 seg String
(	TokenNameLPAREN	
)	TokenNameRPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
closeMergeReaders	TokenNameIdentifier	 close Merge Readers
(	TokenNameLPAREN	
merge	TokenNameIdentifier	 merge
,	TokenNameCOMMA	
false	TokenNamefalse	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
// Must note the change to segmentInfos so any commits 	TokenNameCOMMENT_LINE	Must note the change to segmentInfos so any commits 
// in-flight don't lose it: 	TokenNameCOMMENT_LINE	in-flight don't lose it: 
checkpoint	TokenNameIdentifier	 checkpoint
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
// If the merged segments had pending changes, clear 	TokenNameCOMMENT_LINE	If the merged segments had pending changes, clear 
// them so that they don't bother writing them to 	TokenNameCOMMENT_LINE	them so that they don't bother writing them to 
// disk, updating SegmentInfo, etc.: 	TokenNameCOMMENT_LINE	disk, updating SegmentInfo, etc.: 
readerPool	TokenNameIdentifier	 reader Pool
.	TokenNameDOT	
clear	TokenNameIdentifier	 clear
(	TokenNameLPAREN	
merge	TokenNameIdentifier	 merge
.	TokenNameDOT	
segments	TokenNameIdentifier	 segments
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
if	TokenNameif	
(	TokenNameLPAREN	
merge	TokenNameIdentifier	 merge
.	TokenNameDOT	
maxNumSegments	TokenNameIdentifier	 max Num Segments
!=	TokenNameNOT_EQUAL	
-	TokenNameMINUS	
1	TokenNameIntegerLiteral	
&&	TokenNameAND_AND	
!	TokenNameNOT	
dropSegment	TokenNameIdentifier	 drop Segment
)	TokenNameRPAREN	
{	TokenNameLBRACE	
// cascade the forceMerge: 	TokenNameCOMMENT_LINE	cascade the forceMerge: 
if	TokenNameif	
(	TokenNameLPAREN	
!	TokenNameNOT	
segmentsToMerge	TokenNameIdentifier	 segments To Merge
.	TokenNameDOT	
containsKey	TokenNameIdentifier	 contains Key
(	TokenNameLPAREN	
merge	TokenNameIdentifier	 merge
.	TokenNameDOT	
info	TokenNameIdentifier	 info
)	TokenNameRPAREN	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
segmentsToMerge	TokenNameIdentifier	 segments To Merge
.	TokenNameDOT	
put	TokenNameIdentifier	 put
(	TokenNameLPAREN	
merge	TokenNameIdentifier	 merge
.	TokenNameDOT	
info	TokenNameIdentifier	 info
,	TokenNameCOMMA	
Boolean	TokenNameIdentifier	 Boolean
.	TokenNameDOT	
FALSE	TokenNameIdentifier	 FALSE
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
}	TokenNameRBRACE	
return	TokenNamereturn	
true	TokenNametrue	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
final	TokenNamefinal	
private	TokenNameprivate	
void	TokenNamevoid	
handleMergeException	TokenNameIdentifier	 handle Merge Exception
(	TokenNameLPAREN	
Throwable	TokenNameIdentifier	 Throwable
t	TokenNameIdentifier	 t
,	TokenNameCOMMA	
MergePolicy	TokenNameIdentifier	 Merge Policy
.	TokenNameDOT	
OneMerge	TokenNameIdentifier	 One Merge
merge	TokenNameIdentifier	 merge
)	TokenNameRPAREN	
throws	TokenNamethrows	
IOException	TokenNameIdentifier	 IO Exception
{	TokenNameLBRACE	
if	TokenNameif	
(	TokenNameLPAREN	
infoStream	TokenNameIdentifier	 info Stream
!=	TokenNameNOT_EQUAL	
null	TokenNamenull	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
message	TokenNameIdentifier	 message
(	TokenNameLPAREN	
"handleMergeException: merge="	TokenNameStringLiteral	handleMergeException: merge=
+	TokenNamePLUS	
merge	TokenNameIdentifier	 merge
.	TokenNameDOT	
segString	TokenNameIdentifier	 seg String
(	TokenNameLPAREN	
directory	TokenNameIdentifier	 directory
)	TokenNameRPAREN	
+	TokenNamePLUS	
" exc="	TokenNameStringLiteral	 exc=
+	TokenNamePLUS	
t	TokenNameIdentifier	 t
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
// Set the exception on the merge, so if 	TokenNameCOMMENT_LINE	Set the exception on the merge, so if 
// forceMerge is waiting on us it sees the root 	TokenNameCOMMENT_LINE	forceMerge is waiting on us it sees the root 
// cause exception: 	TokenNameCOMMENT_LINE	cause exception: 
merge	TokenNameIdentifier	 merge
.	TokenNameDOT	
setException	TokenNameIdentifier	 set Exception
(	TokenNameLPAREN	
t	TokenNameIdentifier	 t
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
addMergeException	TokenNameIdentifier	 add Merge Exception
(	TokenNameLPAREN	
merge	TokenNameIdentifier	 merge
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
if	TokenNameif	
(	TokenNameLPAREN	
t	TokenNameIdentifier	 t
instanceof	TokenNameinstanceof	
MergePolicy	TokenNameIdentifier	 Merge Policy
.	TokenNameDOT	
MergeAbortedException	TokenNameIdentifier	 Merge Aborted Exception
)	TokenNameRPAREN	
{	TokenNameLBRACE	
// We can ignore this exception (it happens when 	TokenNameCOMMENT_LINE	We can ignore this exception (it happens when 
// close(false) or rollback is called), unless the 	TokenNameCOMMENT_LINE	close(false) or rollback is called), unless the 
// merge involves segments from external directories, 	TokenNameCOMMENT_LINE	merge involves segments from external directories, 
// in which case we must throw it so, for example, the 	TokenNameCOMMENT_LINE	in which case we must throw it so, for example, the 
// rollbackTransaction code in addIndexes* is 	TokenNameCOMMENT_LINE	rollbackTransaction code in addIndexes* is 
// executed. 	TokenNameCOMMENT_LINE	executed. 
if	TokenNameif	
(	TokenNameLPAREN	
merge	TokenNameIdentifier	 merge
.	TokenNameDOT	
isExternal	TokenNameIdentifier	 is External
)	TokenNameRPAREN	
throw	TokenNamethrow	
(	TokenNameLPAREN	
MergePolicy	TokenNameIdentifier	 Merge Policy
.	TokenNameDOT	
MergeAbortedException	TokenNameIdentifier	 Merge Aborted Exception
)	TokenNameRPAREN	
t	TokenNameIdentifier	 t
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
else	TokenNameelse	
if	TokenNameif	
(	TokenNameLPAREN	
t	TokenNameIdentifier	 t
instanceof	TokenNameinstanceof	
IOException	TokenNameIdentifier	 IO Exception
)	TokenNameRPAREN	
throw	TokenNamethrow	
(	TokenNameLPAREN	
IOException	TokenNameIdentifier	 IO Exception
)	TokenNameRPAREN	
t	TokenNameIdentifier	 t
;	TokenNameSEMICOLON	
else	TokenNameelse	
if	TokenNameif	
(	TokenNameLPAREN	
t	TokenNameIdentifier	 t
instanceof	TokenNameinstanceof	
RuntimeException	TokenNameIdentifier	 Runtime Exception
)	TokenNameRPAREN	
throw	TokenNamethrow	
(	TokenNameLPAREN	
RuntimeException	TokenNameIdentifier	 Runtime Exception
)	TokenNameRPAREN	
t	TokenNameIdentifier	 t
;	TokenNameSEMICOLON	
else	TokenNameelse	
if	TokenNameif	
(	TokenNameLPAREN	
t	TokenNameIdentifier	 t
instanceof	TokenNameinstanceof	
Error	TokenNameIdentifier	 Error
)	TokenNameRPAREN	
throw	TokenNamethrow	
(	TokenNameLPAREN	
Error	TokenNameIdentifier	 Error
)	TokenNameRPAREN	
t	TokenNameIdentifier	 t
;	TokenNameSEMICOLON	
else	TokenNameelse	
// Should not get here 	TokenNameCOMMENT_LINE	Should not get here 
throw	TokenNamethrow	
new	TokenNamenew	
RuntimeException	TokenNameIdentifier	 Runtime Exception
(	TokenNameLPAREN	
t	TokenNameIdentifier	 t
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
/** * Merges the indicated segments, replacing them in the stack with a * single segment. * * @lucene.experimental */	TokenNameCOMMENT_JAVADOC	 Merges the indicated segments, replacing them in the stack with a single segment. * @lucene.experimental 
public	TokenNamepublic	
void	TokenNamevoid	
merge	TokenNameIdentifier	 merge
(	TokenNameLPAREN	
MergePolicy	TokenNameIdentifier	 Merge Policy
.	TokenNameDOT	
OneMerge	TokenNameIdentifier	 One Merge
merge	TokenNameIdentifier	 merge
)	TokenNameRPAREN	
throws	TokenNamethrows	
CorruptIndexException	TokenNameIdentifier	 Corrupt Index Exception
,	TokenNameCOMMA	
IOException	TokenNameIdentifier	 IO Exception
{	TokenNameLBRACE	
boolean	TokenNameboolean	
success	TokenNameIdentifier	 success
=	TokenNameEQUAL	
false	TokenNamefalse	
;	TokenNameSEMICOLON	
final	TokenNamefinal	
long	TokenNamelong	
t0	TokenNameIdentifier	 t0
=	TokenNameEQUAL	
System	TokenNameIdentifier	 System
.	TokenNameDOT	
currentTimeMillis	TokenNameIdentifier	 current Time Millis
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
//System.out.println(Thread.currentThread().getName() + ": merge start: size=" + (merge.estimatedMergeBytes/1024./1024.) + " MB\n merge=" + merge.segString(directory) + "\n idx=" + segString()); 	TokenNameCOMMENT_LINE	System.out.println(Thread.currentThread().getName() + ": merge start: size=" + (merge.estimatedMergeBytes/1024./1024.) + " MB\n merge=" + merge.segString(directory) + "\n idx=" + segString()); 
try	TokenNametry	
{	TokenNameLBRACE	
try	TokenNametry	
{	TokenNameLBRACE	
try	TokenNametry	
{	TokenNameLBRACE	
mergeInit	TokenNameIdentifier	 merge Init
(	TokenNameLPAREN	
merge	TokenNameIdentifier	 merge
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
if	TokenNameif	
(	TokenNameLPAREN	
infoStream	TokenNameIdentifier	 info Stream
!=	TokenNameNOT_EQUAL	
null	TokenNamenull	
)	TokenNameRPAREN	
message	TokenNameIdentifier	 message
(	TokenNameLPAREN	
"now merge merge="	TokenNameStringLiteral	now merge merge=
+	TokenNamePLUS	
merge	TokenNameIdentifier	 merge
.	TokenNameDOT	
segString	TokenNameIdentifier	 seg String
(	TokenNameLPAREN	
directory	TokenNameIdentifier	 directory
)	TokenNameRPAREN	
+	TokenNamePLUS	
" index="	TokenNameStringLiteral	 index=
+	TokenNamePLUS	
segString	TokenNameIdentifier	 seg String
(	TokenNameLPAREN	
)	TokenNameRPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
mergeMiddle	TokenNameIdentifier	 merge Middle
(	TokenNameLPAREN	
merge	TokenNameIdentifier	 merge
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
mergeSuccess	TokenNameIdentifier	 merge Success
(	TokenNameLPAREN	
merge	TokenNameIdentifier	 merge
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
success	TokenNameIdentifier	 success
=	TokenNameEQUAL	
true	TokenNametrue	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
catch	TokenNamecatch	
(	TokenNameLPAREN	
Throwable	TokenNameIdentifier	 Throwable
t	TokenNameIdentifier	 t
)	TokenNameRPAREN	
{	TokenNameLBRACE	
handleMergeException	TokenNameIdentifier	 handle Merge Exception
(	TokenNameLPAREN	
t	TokenNameIdentifier	 t
,	TokenNameCOMMA	
merge	TokenNameIdentifier	 merge
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
}	TokenNameRBRACE	
finally	TokenNamefinally	
{	TokenNameLBRACE	
synchronized	TokenNamesynchronized	
(	TokenNameLPAREN	
this	TokenNamethis	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
mergeFinish	TokenNameIdentifier	 merge Finish
(	TokenNameLPAREN	
merge	TokenNameIdentifier	 merge
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
if	TokenNameif	
(	TokenNameLPAREN	
!	TokenNameNOT	
success	TokenNameIdentifier	 success
)	TokenNameRPAREN	
{	TokenNameLBRACE	
if	TokenNameif	
(	TokenNameLPAREN	
infoStream	TokenNameIdentifier	 info Stream
!=	TokenNameNOT_EQUAL	
null	TokenNamenull	
)	TokenNameRPAREN	
message	TokenNameIdentifier	 message
(	TokenNameLPAREN	
"hit exception during merge"	TokenNameStringLiteral	hit exception during merge
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
if	TokenNameif	
(	TokenNameLPAREN	
merge	TokenNameIdentifier	 merge
.	TokenNameDOT	
info	TokenNameIdentifier	 info
!=	TokenNameNOT_EQUAL	
null	TokenNamenull	
&&	TokenNameAND_AND	
!	TokenNameNOT	
segmentInfos	TokenNameIdentifier	 segment Infos
.	TokenNameDOT	
contains	TokenNameIdentifier	 contains
(	TokenNameLPAREN	
merge	TokenNameIdentifier	 merge
.	TokenNameDOT	
info	TokenNameIdentifier	 info
)	TokenNameRPAREN	
)	TokenNameRPAREN	
deleter	TokenNameIdentifier	 deleter
.	TokenNameDOT	
refresh	TokenNameIdentifier	 refresh
(	TokenNameLPAREN	
merge	TokenNameIdentifier	 merge
.	TokenNameDOT	
info	TokenNameIdentifier	 info
.	TokenNameDOT	
name	TokenNameIdentifier	 name
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
// This merge (and, generally, any change to the 	TokenNameCOMMENT_LINE	This merge (and, generally, any change to the 
// segments) may now enable new merges, so we call 	TokenNameCOMMENT_LINE	segments) may now enable new merges, so we call 
// merge policy & update pending merges. 	TokenNameCOMMENT_LINE	merge policy & update pending merges. 
if	TokenNameif	
(	TokenNameLPAREN	
success	TokenNameIdentifier	 success
&&	TokenNameAND_AND	
!	TokenNameNOT	
merge	TokenNameIdentifier	 merge
.	TokenNameDOT	
isAborted	TokenNameIdentifier	 is Aborted
(	TokenNameLPAREN	
)	TokenNameRPAREN	
&&	TokenNameAND_AND	
(	TokenNameLPAREN	
merge	TokenNameIdentifier	 merge
.	TokenNameDOT	
maxNumSegments	TokenNameIdentifier	 max Num Segments
!=	TokenNameNOT_EQUAL	
-	TokenNameMINUS	
1	TokenNameIntegerLiteral	
||	TokenNameOR_OR	
(	TokenNameLPAREN	
!	TokenNameNOT	
closed	TokenNameIdentifier	 closed
&&	TokenNameAND_AND	
!	TokenNameNOT	
closing	TokenNameIdentifier	 closing
)	TokenNameRPAREN	
)	TokenNameRPAREN	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
updatePendingMerges	TokenNameIdentifier	 update Pending Merges
(	TokenNameLPAREN	
merge	TokenNameIdentifier	 merge
.	TokenNameDOT	
maxNumSegments	TokenNameIdentifier	 max Num Segments
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
}	TokenNameRBRACE	
}	TokenNameRBRACE	
}	TokenNameRBRACE	
catch	TokenNamecatch	
(	TokenNameLPAREN	
OutOfMemoryError	TokenNameIdentifier	 Out Of Memory Error
oom	TokenNameIdentifier	 oom
)	TokenNameRPAREN	
{	TokenNameLBRACE	
handleOOM	TokenNameIdentifier	 handle OOM
(	TokenNameLPAREN	
oom	TokenNameIdentifier	 oom
,	TokenNameCOMMA	
"merge"	TokenNameStringLiteral	merge
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
if	TokenNameif	
(	TokenNameLPAREN	
infoStream	TokenNameIdentifier	 info Stream
!=	TokenNameNOT_EQUAL	
null	TokenNamenull	
&&	TokenNameAND_AND	
merge	TokenNameIdentifier	 merge
.	TokenNameDOT	
info	TokenNameIdentifier	 info
!=	TokenNameNOT_EQUAL	
null	TokenNamenull	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
message	TokenNameIdentifier	 message
(	TokenNameLPAREN	
"merge time "	TokenNameStringLiteral	merge time 
+	TokenNamePLUS	
(	TokenNameLPAREN	
System	TokenNameIdentifier	 System
.	TokenNameDOT	
currentTimeMillis	TokenNameIdentifier	 current Time Millis
(	TokenNameLPAREN	
)	TokenNameRPAREN	
-	TokenNameMINUS	
t0	TokenNameIdentifier	 t0
)	TokenNameRPAREN	
+	TokenNamePLUS	
" msec for "	TokenNameStringLiteral	 msec for 
+	TokenNamePLUS	
merge	TokenNameIdentifier	 merge
.	TokenNameDOT	
info	TokenNameIdentifier	 info
.	TokenNameDOT	
docCount	TokenNameIdentifier	 doc Count
+	TokenNamePLUS	
" docs"	TokenNameStringLiteral	 docs
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
//System.out.println(Thread.currentThread().getName() + ": merge end"); 	TokenNameCOMMENT_LINE	System.out.println(Thread.currentThread().getName() + ": merge end"); 
}	TokenNameRBRACE	
/** Hook that's called when the specified merge is complete. */	TokenNameCOMMENT_JAVADOC	 Hook that's called when the specified merge is complete. 
void	TokenNamevoid	
mergeSuccess	TokenNameIdentifier	 merge Success
(	TokenNameLPAREN	
MergePolicy	TokenNameIdentifier	 Merge Policy
.	TokenNameDOT	
OneMerge	TokenNameIdentifier	 One Merge
merge	TokenNameIdentifier	 merge
)	TokenNameRPAREN	
{	TokenNameLBRACE	
}	TokenNameRBRACE	
/** Checks whether this merge involves any segments * already participating in a merge. If not, this merge * is "registered", meaning we record that its segments * are now participating in a merge, and true is * returned. Else (the merge conflicts) false is * returned. */	TokenNameCOMMENT_JAVADOC	 Checks whether this merge involves any segments already participating in a merge. If not, this merge is "registered", meaning we record that its segments are now participating in a merge, and true is returned. Else (the merge conflicts) false is returned. 
final	TokenNamefinal	
synchronized	TokenNamesynchronized	
boolean	TokenNameboolean	
registerMerge	TokenNameIdentifier	 register Merge
(	TokenNameLPAREN	
MergePolicy	TokenNameIdentifier	 Merge Policy
.	TokenNameDOT	
OneMerge	TokenNameIdentifier	 One Merge
merge	TokenNameIdentifier	 merge
)	TokenNameRPAREN	
throws	TokenNamethrows	
MergePolicy	TokenNameIdentifier	 Merge Policy
.	TokenNameDOT	
MergeAbortedException	TokenNameIdentifier	 Merge Aborted Exception
,	TokenNameCOMMA	
IOException	TokenNameIdentifier	 IO Exception
{	TokenNameLBRACE	
if	TokenNameif	
(	TokenNameLPAREN	
merge	TokenNameIdentifier	 merge
.	TokenNameDOT	
registerDone	TokenNameIdentifier	 register Done
)	TokenNameRPAREN	
return	TokenNamereturn	
true	TokenNametrue	
;	TokenNameSEMICOLON	
if	TokenNameif	
(	TokenNameLPAREN	
stopMerges	TokenNameIdentifier	 stop Merges
)	TokenNameRPAREN	
{	TokenNameLBRACE	
merge	TokenNameIdentifier	 merge
.	TokenNameDOT	
abort	TokenNameIdentifier	 abort
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
throw	TokenNamethrow	
new	TokenNamenew	
MergePolicy	TokenNameIdentifier	 Merge Policy
.	TokenNameDOT	
MergeAbortedException	TokenNameIdentifier	 Merge Aborted Exception
(	TokenNameLPAREN	
"merge is aborted: "	TokenNameStringLiteral	merge is aborted: 
+	TokenNamePLUS	
merge	TokenNameIdentifier	 merge
.	TokenNameDOT	
segString	TokenNameIdentifier	 seg String
(	TokenNameLPAREN	
directory	TokenNameIdentifier	 directory
)	TokenNameRPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
boolean	TokenNameboolean	
isExternal	TokenNameIdentifier	 is External
=	TokenNameEQUAL	
false	TokenNamefalse	
;	TokenNameSEMICOLON	
for	TokenNamefor	
(	TokenNameLPAREN	
SegmentInfo	TokenNameIdentifier	 Segment Info
info	TokenNameIdentifier	 info
:	TokenNameCOLON	
merge	TokenNameIdentifier	 merge
.	TokenNameDOT	
segments	TokenNameIdentifier	 segments
)	TokenNameRPAREN	
{	TokenNameLBRACE	
if	TokenNameif	
(	TokenNameLPAREN	
mergingSegments	TokenNameIdentifier	 merging Segments
.	TokenNameDOT	
contains	TokenNameIdentifier	 contains
(	TokenNameLPAREN	
info	TokenNameIdentifier	 info
)	TokenNameRPAREN	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
return	TokenNamereturn	
false	TokenNamefalse	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
if	TokenNameif	
(	TokenNameLPAREN	
!	TokenNameNOT	
segmentInfos	TokenNameIdentifier	 segment Infos
.	TokenNameDOT	
contains	TokenNameIdentifier	 contains
(	TokenNameLPAREN	
info	TokenNameIdentifier	 info
)	TokenNameRPAREN	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
return	TokenNamereturn	
false	TokenNamefalse	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
if	TokenNameif	
(	TokenNameLPAREN	
info	TokenNameIdentifier	 info
.	TokenNameDOT	
dir	TokenNameIdentifier	 dir
!=	TokenNameNOT_EQUAL	
directory	TokenNameIdentifier	 directory
)	TokenNameRPAREN	
{	TokenNameLBRACE	
isExternal	TokenNameIdentifier	 is External
=	TokenNameEQUAL	
true	TokenNametrue	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
if	TokenNameif	
(	TokenNameLPAREN	
segmentsToMerge	TokenNameIdentifier	 segments To Merge
.	TokenNameDOT	
containsKey	TokenNameIdentifier	 contains Key
(	TokenNameLPAREN	
info	TokenNameIdentifier	 info
)	TokenNameRPAREN	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
merge	TokenNameIdentifier	 merge
.	TokenNameDOT	
maxNumSegments	TokenNameIdentifier	 max Num Segments
=	TokenNameEQUAL	
mergeMaxNumSegments	TokenNameIdentifier	 merge Max Num Segments
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
}	TokenNameRBRACE	
ensureValidMerge	TokenNameIdentifier	 ensure Valid Merge
(	TokenNameLPAREN	
merge	TokenNameIdentifier	 merge
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
pendingMerges	TokenNameIdentifier	 pending Merges
.	TokenNameDOT	
add	TokenNameIdentifier	 add
(	TokenNameLPAREN	
merge	TokenNameIdentifier	 merge
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
if	TokenNameif	
(	TokenNameLPAREN	
infoStream	TokenNameIdentifier	 info Stream
!=	TokenNameNOT_EQUAL	
null	TokenNamenull	
)	TokenNameRPAREN	
message	TokenNameIdentifier	 message
(	TokenNameLPAREN	
"add merge to pendingMerges: "	TokenNameStringLiteral	add merge to pendingMerges: 
+	TokenNamePLUS	
merge	TokenNameIdentifier	 merge
.	TokenNameDOT	
segString	TokenNameIdentifier	 seg String
(	TokenNameLPAREN	
directory	TokenNameIdentifier	 directory
)	TokenNameRPAREN	
+	TokenNamePLUS	
" [total "	TokenNameStringLiteral	 [total 
+	TokenNamePLUS	
pendingMerges	TokenNameIdentifier	 pending Merges
.	TokenNameDOT	
size	TokenNameIdentifier	 size
(	TokenNameLPAREN	
)	TokenNameRPAREN	
+	TokenNamePLUS	
" pending]"	TokenNameStringLiteral	 pending]
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
merge	TokenNameIdentifier	 merge
.	TokenNameDOT	
mergeGen	TokenNameIdentifier	 merge Gen
=	TokenNameEQUAL	
mergeGen	TokenNameIdentifier	 merge Gen
;	TokenNameSEMICOLON	
merge	TokenNameIdentifier	 merge
.	TokenNameDOT	
isExternal	TokenNameIdentifier	 is External
=	TokenNameEQUAL	
isExternal	TokenNameIdentifier	 is External
;	TokenNameSEMICOLON	
// OK it does not conflict; now record that this merge 	TokenNameCOMMENT_LINE	OK it does not conflict; now record that this merge 
// is running (while synchronized) to avoid race 	TokenNameCOMMENT_LINE	is running (while synchronized) to avoid race 
// condition where two conflicting merges from different 	TokenNameCOMMENT_LINE	condition where two conflicting merges from different 
// threads, start 	TokenNameCOMMENT_LINE	threads, start 
message	TokenNameIdentifier	 message
(	TokenNameLPAREN	
"registerMerge merging="	TokenNameStringLiteral	registerMerge merging=
+	TokenNamePLUS	
mergingSegments	TokenNameIdentifier	 merging Segments
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
for	TokenNamefor	
(	TokenNameLPAREN	
SegmentInfo	TokenNameIdentifier	 Segment Info
info	TokenNameIdentifier	 info
:	TokenNameCOLON	
merge	TokenNameIdentifier	 merge
.	TokenNameDOT	
segments	TokenNameIdentifier	 segments
)	TokenNameRPAREN	
{	TokenNameLBRACE	
message	TokenNameIdentifier	 message
(	TokenNameLPAREN	
"registerMerge info="	TokenNameStringLiteral	registerMerge info=
+	TokenNamePLUS	
info	TokenNameIdentifier	 info
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
mergingSegments	TokenNameIdentifier	 merging Segments
.	TokenNameDOT	
add	TokenNameIdentifier	 add
(	TokenNameLPAREN	
info	TokenNameIdentifier	 info
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
// Merge is now registered 	TokenNameCOMMENT_LINE	Merge is now registered 
merge	TokenNameIdentifier	 merge
.	TokenNameDOT	
registerDone	TokenNameIdentifier	 register Done
=	TokenNameEQUAL	
true	TokenNametrue	
;	TokenNameSEMICOLON	
return	TokenNamereturn	
true	TokenNametrue	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
/** Does initial setup for a merge, which is fast but holds * the synchronized lock on IndexWriter instance. */	TokenNameCOMMENT_JAVADOC	 Does initial setup for a merge, which is fast but holds the synchronized lock on IndexWriter instance. 
final	TokenNamefinal	
synchronized	TokenNamesynchronized	
void	TokenNamevoid	
mergeInit	TokenNameIdentifier	 merge Init
(	TokenNameLPAREN	
MergePolicy	TokenNameIdentifier	 Merge Policy
.	TokenNameDOT	
OneMerge	TokenNameIdentifier	 One Merge
merge	TokenNameIdentifier	 merge
)	TokenNameRPAREN	
throws	TokenNamethrows	
IOException	TokenNameIdentifier	 IO Exception
{	TokenNameLBRACE	
boolean	TokenNameboolean	
success	TokenNameIdentifier	 success
=	TokenNameEQUAL	
false	TokenNamefalse	
;	TokenNameSEMICOLON	
try	TokenNametry	
{	TokenNameLBRACE	
_mergeInit	TokenNameIdentifier	 merge Init
(	TokenNameLPAREN	
merge	TokenNameIdentifier	 merge
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
success	TokenNameIdentifier	 success
=	TokenNameEQUAL	
true	TokenNametrue	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
finally	TokenNamefinally	
{	TokenNameLBRACE	
if	TokenNameif	
(	TokenNameLPAREN	
!	TokenNameNOT	
success	TokenNameIdentifier	 success
)	TokenNameRPAREN	
{	TokenNameLBRACE	
if	TokenNameif	
(	TokenNameLPAREN	
infoStream	TokenNameIdentifier	 info Stream
!=	TokenNameNOT_EQUAL	
null	TokenNamenull	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
message	TokenNameIdentifier	 message
(	TokenNameLPAREN	
"hit exception in mergeInit"	TokenNameStringLiteral	hit exception in mergeInit
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
mergeFinish	TokenNameIdentifier	 merge Finish
(	TokenNameLPAREN	
merge	TokenNameIdentifier	 merge
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
}	TokenNameRBRACE	
}	TokenNameRBRACE	
synchronized	TokenNamesynchronized	
private	TokenNameprivate	
void	TokenNamevoid	
_mergeInit	TokenNameIdentifier	 merge Init
(	TokenNameLPAREN	
MergePolicy	TokenNameIdentifier	 Merge Policy
.	TokenNameDOT	
OneMerge	TokenNameIdentifier	 One Merge
merge	TokenNameIdentifier	 merge
)	TokenNameRPAREN	
throws	TokenNamethrows	
IOException	TokenNameIdentifier	 IO Exception
{	TokenNameLBRACE	
assert	TokenNameassert	
testPoint	TokenNameIdentifier	 test Point
(	TokenNameLPAREN	
"startMergeInit"	TokenNameStringLiteral	startMergeInit
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
assert	TokenNameassert	
merge	TokenNameIdentifier	 merge
.	TokenNameDOT	
registerDone	TokenNameIdentifier	 register Done
;	TokenNameSEMICOLON	
assert	TokenNameassert	
merge	TokenNameIdentifier	 merge
.	TokenNameDOT	
maxNumSegments	TokenNameIdentifier	 max Num Segments
==	TokenNameEQUAL_EQUAL	
-	TokenNameMINUS	
1	TokenNameIntegerLiteral	
||	TokenNameOR_OR	
merge	TokenNameIdentifier	 merge
.	TokenNameDOT	
maxNumSegments	TokenNameIdentifier	 max Num Segments
>	TokenNameGREATER	
0	TokenNameIntegerLiteral	
;	TokenNameSEMICOLON	
if	TokenNameif	
(	TokenNameLPAREN	
hitOOM	TokenNameIdentifier	 hit OOM
)	TokenNameRPAREN	
{	TokenNameLBRACE	
throw	TokenNamethrow	
new	TokenNamenew	
IllegalStateException	TokenNameIdentifier	 Illegal State Exception
(	TokenNameLPAREN	
"this writer hit an OutOfMemoryError; cannot merge"	TokenNameStringLiteral	this writer hit an OutOfMemoryError; cannot merge
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
// TODO: is there any perf benefit to sorting 	TokenNameCOMMENT_LINE	TODO: is there any perf benefit to sorting 
// merged segments? eg biggest to smallest? 	TokenNameCOMMENT_LINE	merged segments? eg biggest to smallest? 
if	TokenNameif	
(	TokenNameLPAREN	
merge	TokenNameIdentifier	 merge
.	TokenNameDOT	
info	TokenNameIdentifier	 info
!=	TokenNameNOT_EQUAL	
null	TokenNamenull	
)	TokenNameRPAREN	
// mergeInit already done 	TokenNameCOMMENT_LINE	mergeInit already done 
return	TokenNamereturn	
;	TokenNameSEMICOLON	
if	TokenNameif	
(	TokenNameLPAREN	
merge	TokenNameIdentifier	 merge
.	TokenNameDOT	
isAborted	TokenNameIdentifier	 is Aborted
(	TokenNameLPAREN	
)	TokenNameRPAREN	
)	TokenNameRPAREN	
return	TokenNamereturn	
;	TokenNameSEMICOLON	
boolean	TokenNameboolean	
hasVectors	TokenNameIdentifier	 has Vectors
=	TokenNameEQUAL	
false	TokenNamefalse	
;	TokenNameSEMICOLON	
for	TokenNamefor	
(	TokenNameLPAREN	
SegmentInfo	TokenNameIdentifier	 Segment Info
sourceSegment	TokenNameIdentifier	 source Segment
:	TokenNameCOLON	
merge	TokenNameIdentifier	 merge
.	TokenNameDOT	
segments	TokenNameIdentifier	 segments
)	TokenNameRPAREN	
{	TokenNameLBRACE	
if	TokenNameif	
(	TokenNameLPAREN	
sourceSegment	TokenNameIdentifier	 source Segment
.	TokenNameDOT	
getHasVectors	TokenNameIdentifier	 get Has Vectors
(	TokenNameLPAREN	
)	TokenNameRPAREN	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
hasVectors	TokenNameIdentifier	 has Vectors
=	TokenNameEQUAL	
true	TokenNametrue	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
}	TokenNameRBRACE	
// Bind a new segment name here so even with 	TokenNameCOMMENT_LINE	Bind a new segment name here so even with 
// ConcurrentMergePolicy we keep deterministic segment 	TokenNameCOMMENT_LINE	ConcurrentMergePolicy we keep deterministic segment 
// names. 	TokenNameCOMMENT_LINE	names. 
merge	TokenNameIdentifier	 merge
.	TokenNameDOT	
info	TokenNameIdentifier	 info
=	TokenNameEQUAL	
new	TokenNamenew	
SegmentInfo	TokenNameIdentifier	 Segment Info
(	TokenNameLPAREN	
newSegmentName	TokenNameIdentifier	 new Segment Name
(	TokenNameLPAREN	
)	TokenNameRPAREN	
,	TokenNameCOMMA	
0	TokenNameIntegerLiteral	
,	TokenNameCOMMA	
directory	TokenNameIdentifier	 directory
,	TokenNameCOMMA	
false	TokenNamefalse	
,	TokenNameCOMMA	
true	TokenNametrue	
,	TokenNameCOMMA	
false	TokenNamefalse	
,	TokenNameCOMMA	
hasVectors	TokenNameIdentifier	 has Vectors
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
// Lock order: IW -> BD 	TokenNameCOMMENT_LINE	Lock order: IW -> BD 
final	TokenNamefinal	
BufferedDeletesStream	TokenNameIdentifier	 Buffered Deletes Stream
.	TokenNameDOT	
ApplyDeletesResult	TokenNameIdentifier	 Apply Deletes Result
result	TokenNameIdentifier	 result
=	TokenNameEQUAL	
bufferedDeletesStream	TokenNameIdentifier	 buffered Deletes Stream
.	TokenNameDOT	
applyDeletes	TokenNameIdentifier	 apply Deletes
(	TokenNameLPAREN	
readerPool	TokenNameIdentifier	 reader Pool
,	TokenNameCOMMA	
merge	TokenNameIdentifier	 merge
.	TokenNameDOT	
segments	TokenNameIdentifier	 segments
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
if	TokenNameif	
(	TokenNameLPAREN	
result	TokenNameIdentifier	 result
.	TokenNameDOT	
anyDeletes	TokenNameIdentifier	 any Deletes
)	TokenNameRPAREN	
{	TokenNameLBRACE	
checkpoint	TokenNameIdentifier	 checkpoint
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
if	TokenNameif	
(	TokenNameLPAREN	
!	TokenNameNOT	
keepFullyDeletedSegments	TokenNameIdentifier	 keep Fully Deleted Segments
&&	TokenNameAND_AND	
result	TokenNameIdentifier	 result
.	TokenNameDOT	
allDeleted	TokenNameIdentifier	 all Deleted
!=	TokenNameNOT_EQUAL	
null	TokenNamenull	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
if	TokenNameif	
(	TokenNameLPAREN	
infoStream	TokenNameIdentifier	 info Stream
!=	TokenNameNOT_EQUAL	
null	TokenNamenull	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
message	TokenNameIdentifier	 message
(	TokenNameLPAREN	
"drop 100% deleted segments: "	TokenNameStringLiteral	drop 100% deleted segments: 
+	TokenNamePLUS	
result	TokenNameIdentifier	 result
.	TokenNameDOT	
allDeleted	TokenNameIdentifier	 all Deleted
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
for	TokenNamefor	
(	TokenNameLPAREN	
SegmentInfo	TokenNameIdentifier	 Segment Info
info	TokenNameIdentifier	 info
:	TokenNameCOLON	
result	TokenNameIdentifier	 result
.	TokenNameDOT	
allDeleted	TokenNameIdentifier	 all Deleted
)	TokenNameRPAREN	
{	TokenNameLBRACE	
segmentInfos	TokenNameIdentifier	 segment Infos
.	TokenNameDOT	
remove	TokenNameIdentifier	 remove
(	TokenNameLPAREN	
info	TokenNameIdentifier	 info
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
if	TokenNameif	
(	TokenNameLPAREN	
merge	TokenNameIdentifier	 merge
.	TokenNameDOT	
segments	TokenNameIdentifier	 segments
.	TokenNameDOT	
contains	TokenNameIdentifier	 contains
(	TokenNameLPAREN	
info	TokenNameIdentifier	 info
)	TokenNameRPAREN	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
mergingSegments	TokenNameIdentifier	 merging Segments
.	TokenNameDOT	
remove	TokenNameIdentifier	 remove
(	TokenNameLPAREN	
info	TokenNameIdentifier	 info
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
merge	TokenNameIdentifier	 merge
.	TokenNameDOT	
segments	TokenNameIdentifier	 segments
.	TokenNameDOT	
remove	TokenNameIdentifier	 remove
(	TokenNameLPAREN	
info	TokenNameIdentifier	 info
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
}	TokenNameRBRACE	
if	TokenNameif	
(	TokenNameLPAREN	
readerPool	TokenNameIdentifier	 reader Pool
!=	TokenNameNOT_EQUAL	
null	TokenNamenull	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
readerPool	TokenNameIdentifier	 reader Pool
.	TokenNameDOT	
drop	TokenNameIdentifier	 drop
(	TokenNameLPAREN	
result	TokenNameIdentifier	 result
.	TokenNameDOT	
allDeleted	TokenNameIdentifier	 all Deleted
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
checkpoint	TokenNameIdentifier	 checkpoint
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
merge	TokenNameIdentifier	 merge
.	TokenNameDOT	
info	TokenNameIdentifier	 info
.	TokenNameDOT	
setBufferedDeletesGen	TokenNameIdentifier	 set Buffered Deletes Gen
(	TokenNameLPAREN	
result	TokenNameIdentifier	 result
.	TokenNameDOT	
gen	TokenNameIdentifier	 gen
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
// Lock order: IW -> BD 	TokenNameCOMMENT_LINE	Lock order: IW -> BD 
bufferedDeletesStream	TokenNameIdentifier	 buffered Deletes Stream
.	TokenNameDOT	
prune	TokenNameIdentifier	 prune
(	TokenNameLPAREN	
segmentInfos	TokenNameIdentifier	 segment Infos
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
Map	TokenNameIdentifier	 Map
<	TokenNameLESS	
String	TokenNameIdentifier	 String
,	TokenNameCOMMA	
String	TokenNameIdentifier	 String
>	TokenNameGREATER	
details	TokenNameIdentifier	 details
=	TokenNameEQUAL	
new	TokenNamenew	
HashMap	TokenNameIdentifier	 Hash Map
<	TokenNameLESS	
String	TokenNameIdentifier	 String
,	TokenNameCOMMA	
String	TokenNameIdentifier	 String
>	TokenNameGREATER	
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
details	TokenNameIdentifier	 details
.	TokenNameDOT	
put	TokenNameIdentifier	 put
(	TokenNameLPAREN	
"mergeMaxNumSegments"	TokenNameStringLiteral	mergeMaxNumSegments
,	TokenNameCOMMA	
""	TokenNameStringLiteral	 
+	TokenNamePLUS	
merge	TokenNameIdentifier	 merge
.	TokenNameDOT	
maxNumSegments	TokenNameIdentifier	 max Num Segments
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
details	TokenNameIdentifier	 details
.	TokenNameDOT	
put	TokenNameIdentifier	 put
(	TokenNameLPAREN	
"mergeFactor"	TokenNameStringLiteral	mergeFactor
,	TokenNameCOMMA	
Integer	TokenNameIdentifier	 Integer
.	TokenNameDOT	
toString	TokenNameIdentifier	 to String
(	TokenNameLPAREN	
merge	TokenNameIdentifier	 merge
.	TokenNameDOT	
segments	TokenNameIdentifier	 segments
.	TokenNameDOT	
size	TokenNameIdentifier	 size
(	TokenNameLPAREN	
)	TokenNameRPAREN	
)	TokenNameRPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
setDiagnostics	TokenNameIdentifier	 set Diagnostics
(	TokenNameLPAREN	
merge	TokenNameIdentifier	 merge
.	TokenNameDOT	
info	TokenNameIdentifier	 info
,	TokenNameCOMMA	
"merge"	TokenNameStringLiteral	merge
,	TokenNameCOMMA	
details	TokenNameIdentifier	 details
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
if	TokenNameif	
(	TokenNameLPAREN	
infoStream	TokenNameIdentifier	 info Stream
!=	TokenNameNOT_EQUAL	
null	TokenNamenull	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
message	TokenNameIdentifier	 message
(	TokenNameLPAREN	
"merge seg="	TokenNameStringLiteral	merge seg=
+	TokenNamePLUS	
merge	TokenNameIdentifier	 merge
.	TokenNameDOT	
info	TokenNameIdentifier	 info
.	TokenNameDOT	
name	TokenNameIdentifier	 name
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
assert	TokenNameassert	
merge	TokenNameIdentifier	 merge
.	TokenNameDOT	
estimatedMergeBytes	TokenNameIdentifier	 estimated Merge Bytes
==	TokenNameEQUAL_EQUAL	
0	TokenNameIntegerLiteral	
;	TokenNameSEMICOLON	
for	TokenNamefor	
(	TokenNameLPAREN	
SegmentInfo	TokenNameIdentifier	 Segment Info
info	TokenNameIdentifier	 info
:	TokenNameCOLON	
merge	TokenNameIdentifier	 merge
.	TokenNameDOT	
segments	TokenNameIdentifier	 segments
)	TokenNameRPAREN	
{	TokenNameLBRACE	
if	TokenNameif	
(	TokenNameLPAREN	
info	TokenNameIdentifier	 info
.	TokenNameDOT	
docCount	TokenNameIdentifier	 doc Count
>	TokenNameGREATER	
0	TokenNameIntegerLiteral	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
final	TokenNamefinal	
int	TokenNameint	
delCount	TokenNameIdentifier	 del Count
=	TokenNameEQUAL	
numDeletedDocs	TokenNameIdentifier	 num Deleted Docs
(	TokenNameLPAREN	
info	TokenNameIdentifier	 info
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
assert	TokenNameassert	
delCount	TokenNameIdentifier	 del Count
<=	TokenNameLESS_EQUAL	
info	TokenNameIdentifier	 info
.	TokenNameDOT	
docCount	TokenNameIdentifier	 doc Count
;	TokenNameSEMICOLON	
final	TokenNamefinal	
double	TokenNamedouble	
delRatio	TokenNameIdentifier	 del Ratio
=	TokenNameEQUAL	
(	TokenNameLPAREN	
(	TokenNameLPAREN	
double	TokenNamedouble	
)	TokenNameRPAREN	
delCount	TokenNameIdentifier	 del Count
)	TokenNameRPAREN	
/	TokenNameDIVIDE	
info	TokenNameIdentifier	 info
.	TokenNameDOT	
docCount	TokenNameIdentifier	 doc Count
;	TokenNameSEMICOLON	
merge	TokenNameIdentifier	 merge
.	TokenNameDOT	
estimatedMergeBytes	TokenNameIdentifier	 estimated Merge Bytes
+=	TokenNamePLUS_EQUAL	
info	TokenNameIdentifier	 info
.	TokenNameDOT	
sizeInBytes	TokenNameIdentifier	 size In Bytes
(	TokenNameLPAREN	
true	TokenNametrue	
)	TokenNameRPAREN	
*	TokenNameMULTIPLY	
(	TokenNameLPAREN	
1.0	TokenNameDoubleLiteral	
-	TokenNameMINUS	
delRatio	TokenNameIdentifier	 del Ratio
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
}	TokenNameRBRACE	
// TODO: I think this should no longer be needed (we 	TokenNameCOMMENT_LINE	TODO: I think this should no longer be needed (we 
// now build CFS before adding segment to the infos); 	TokenNameCOMMENT_LINE	now build CFS before adding segment to the infos); 
// however, on removing it, tests fail for some reason! 	TokenNameCOMMENT_LINE	however, on removing it, tests fail for some reason! 
// Also enroll the merged segment into mergingSegments; 	TokenNameCOMMENT_LINE	Also enroll the merged segment into mergingSegments; 
// this prevents it from getting selected for a merge 	TokenNameCOMMENT_LINE	this prevents it from getting selected for a merge 
// after our merge is done but while we are building the 	TokenNameCOMMENT_LINE	after our merge is done but while we are building the 
// CFS: 	TokenNameCOMMENT_LINE	CFS: 
mergingSegments	TokenNameIdentifier	 merging Segments
.	TokenNameDOT	
add	TokenNameIdentifier	 add
(	TokenNameLPAREN	
merge	TokenNameIdentifier	 merge
.	TokenNameDOT	
info	TokenNameIdentifier	 info
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
private	TokenNameprivate	
void	TokenNamevoid	
setDiagnostics	TokenNameIdentifier	 set Diagnostics
(	TokenNameLPAREN	
SegmentInfo	TokenNameIdentifier	 Segment Info
info	TokenNameIdentifier	 info
,	TokenNameCOMMA	
String	TokenNameIdentifier	 String
source	TokenNameIdentifier	 source
)	TokenNameRPAREN	
{	TokenNameLBRACE	
setDiagnostics	TokenNameIdentifier	 set Diagnostics
(	TokenNameLPAREN	
info	TokenNameIdentifier	 info
,	TokenNameCOMMA	
source	TokenNameIdentifier	 source
,	TokenNameCOMMA	
null	TokenNamenull	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
private	TokenNameprivate	
void	TokenNamevoid	
setDiagnostics	TokenNameIdentifier	 set Diagnostics
(	TokenNameLPAREN	
SegmentInfo	TokenNameIdentifier	 Segment Info
info	TokenNameIdentifier	 info
,	TokenNameCOMMA	
String	TokenNameIdentifier	 String
source	TokenNameIdentifier	 source
,	TokenNameCOMMA	
Map	TokenNameIdentifier	 Map
<	TokenNameLESS	
String	TokenNameIdentifier	 String
,	TokenNameCOMMA	
String	TokenNameIdentifier	 String
>	TokenNameGREATER	
details	TokenNameIdentifier	 details
)	TokenNameRPAREN	
{	TokenNameLBRACE	
Map	TokenNameIdentifier	 Map
<	TokenNameLESS	
String	TokenNameIdentifier	 String
,	TokenNameCOMMA	
String	TokenNameIdentifier	 String
>	TokenNameGREATER	
diagnostics	TokenNameIdentifier	 diagnostics
=	TokenNameEQUAL	
new	TokenNamenew	
HashMap	TokenNameIdentifier	 Hash Map
<	TokenNameLESS	
String	TokenNameIdentifier	 String
,	TokenNameCOMMA	
String	TokenNameIdentifier	 String
>	TokenNameGREATER	
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
diagnostics	TokenNameIdentifier	 diagnostics
.	TokenNameDOT	
put	TokenNameIdentifier	 put
(	TokenNameLPAREN	
"source"	TokenNameStringLiteral	source
,	TokenNameCOMMA	
source	TokenNameIdentifier	 source
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
diagnostics	TokenNameIdentifier	 diagnostics
.	TokenNameDOT	
put	TokenNameIdentifier	 put
(	TokenNameLPAREN	
"lucene.version"	TokenNameStringLiteral	lucene.version
,	TokenNameCOMMA	
Constants	TokenNameIdentifier	 Constants
.	TokenNameDOT	
LUCENE_VERSION	TokenNameIdentifier	 LUCENE  VERSION
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
diagnostics	TokenNameIdentifier	 diagnostics
.	TokenNameDOT	
put	TokenNameIdentifier	 put
(	TokenNameLPAREN	
"os"	TokenNameStringLiteral	os
,	TokenNameCOMMA	
Constants	TokenNameIdentifier	 Constants
.	TokenNameDOT	
OS_NAME	TokenNameIdentifier	 OS  NAME
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
diagnostics	TokenNameIdentifier	 diagnostics
.	TokenNameDOT	
put	TokenNameIdentifier	 put
(	TokenNameLPAREN	
"os.arch"	TokenNameStringLiteral	os.arch
,	TokenNameCOMMA	
Constants	TokenNameIdentifier	 Constants
.	TokenNameDOT	
OS_ARCH	TokenNameIdentifier	 OS  ARCH
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
diagnostics	TokenNameIdentifier	 diagnostics
.	TokenNameDOT	
put	TokenNameIdentifier	 put
(	TokenNameLPAREN	
"os.version"	TokenNameStringLiteral	os.version
,	TokenNameCOMMA	
Constants	TokenNameIdentifier	 Constants
.	TokenNameDOT	
OS_VERSION	TokenNameIdentifier	 OS  VERSION
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
diagnostics	TokenNameIdentifier	 diagnostics
.	TokenNameDOT	
put	TokenNameIdentifier	 put
(	TokenNameLPAREN	
"java.version"	TokenNameStringLiteral	java.version
,	TokenNameCOMMA	
Constants	TokenNameIdentifier	 Constants
.	TokenNameDOT	
JAVA_VERSION	TokenNameIdentifier	 JAVA  VERSION
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
diagnostics	TokenNameIdentifier	 diagnostics
.	TokenNameDOT	
put	TokenNameIdentifier	 put
(	TokenNameLPAREN	
"java.vendor"	TokenNameStringLiteral	java.vendor
,	TokenNameCOMMA	
Constants	TokenNameIdentifier	 Constants
.	TokenNameDOT	
JAVA_VENDOR	TokenNameIdentifier	 JAVA  VENDOR
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
if	TokenNameif	
(	TokenNameLPAREN	
details	TokenNameIdentifier	 details
!=	TokenNameNOT_EQUAL	
null	TokenNamenull	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
diagnostics	TokenNameIdentifier	 diagnostics
.	TokenNameDOT	
putAll	TokenNameIdentifier	 put All
(	TokenNameLPAREN	
details	TokenNameIdentifier	 details
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
info	TokenNameIdentifier	 info
.	TokenNameDOT	
setDiagnostics	TokenNameIdentifier	 set Diagnostics
(	TokenNameLPAREN	
diagnostics	TokenNameIdentifier	 diagnostics
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
/** Does fininishing for a merge, which is fast but holds * the synchronized lock on IndexWriter instance. */	TokenNameCOMMENT_JAVADOC	 Does fininishing for a merge, which is fast but holds the synchronized lock on IndexWriter instance. 
final	TokenNamefinal	
synchronized	TokenNamesynchronized	
void	TokenNamevoid	
mergeFinish	TokenNameIdentifier	 merge Finish
(	TokenNameLPAREN	
MergePolicy	TokenNameIdentifier	 Merge Policy
.	TokenNameDOT	
OneMerge	TokenNameIdentifier	 One Merge
merge	TokenNameIdentifier	 merge
)	TokenNameRPAREN	
throws	TokenNamethrows	
IOException	TokenNameIdentifier	 IO Exception
{	TokenNameLBRACE	
// forceMerge, addIndexes or finishMerges may be waiting 	TokenNameCOMMENT_LINE	forceMerge, addIndexes or finishMerges may be waiting 
// on merges to finish. 	TokenNameCOMMENT_LINE	on merges to finish. 
notifyAll	TokenNameIdentifier	 notify All
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
// It's possible we are called twice, eg if there was an 	TokenNameCOMMENT_LINE	It's possible we are called twice, eg if there was an 
// exception inside mergeInit 	TokenNameCOMMENT_LINE	exception inside mergeInit 
if	TokenNameif	
(	TokenNameLPAREN	
merge	TokenNameIdentifier	 merge
.	TokenNameDOT	
registerDone	TokenNameIdentifier	 register Done
)	TokenNameRPAREN	
{	TokenNameLBRACE	
final	TokenNamefinal	
List	TokenNameIdentifier	 List
<	TokenNameLESS	
SegmentInfo	TokenNameIdentifier	 Segment Info
>	TokenNameGREATER	
sourceSegments	TokenNameIdentifier	 source Segments
=	TokenNameEQUAL	
merge	TokenNameIdentifier	 merge
.	TokenNameDOT	
segments	TokenNameIdentifier	 segments
;	TokenNameSEMICOLON	
for	TokenNamefor	
(	TokenNameLPAREN	
SegmentInfo	TokenNameIdentifier	 Segment Info
info	TokenNameIdentifier	 info
:	TokenNameCOLON	
sourceSegments	TokenNameIdentifier	 source Segments
)	TokenNameRPAREN	
{	TokenNameLBRACE	
mergingSegments	TokenNameIdentifier	 merging Segments
.	TokenNameDOT	
remove	TokenNameIdentifier	 remove
(	TokenNameLPAREN	
info	TokenNameIdentifier	 info
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
// TODO: if we remove the add in _mergeInit, we should 	TokenNameCOMMENT_LINE	TODO: if we remove the add in _mergeInit, we should 
// also remove this: 	TokenNameCOMMENT_LINE	also remove this: 
mergingSegments	TokenNameIdentifier	 merging Segments
.	TokenNameDOT	
remove	TokenNameIdentifier	 remove
(	TokenNameLPAREN	
merge	TokenNameIdentifier	 merge
.	TokenNameDOT	
info	TokenNameIdentifier	 info
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
merge	TokenNameIdentifier	 merge
.	TokenNameDOT	
registerDone	TokenNameIdentifier	 register Done
=	TokenNameEQUAL	
false	TokenNamefalse	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
runningMerges	TokenNameIdentifier	 running Merges
.	TokenNameDOT	
remove	TokenNameIdentifier	 remove
(	TokenNameLPAREN	
merge	TokenNameIdentifier	 merge
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
private	TokenNameprivate	
final	TokenNamefinal	
synchronized	TokenNamesynchronized	
void	TokenNamevoid	
closeMergeReaders	TokenNameIdentifier	 close Merge Readers
(	TokenNameLPAREN	
MergePolicy	TokenNameIdentifier	 Merge Policy
.	TokenNameDOT	
OneMerge	TokenNameIdentifier	 One Merge
merge	TokenNameIdentifier	 merge
,	TokenNameCOMMA	
boolean	TokenNameboolean	
suppressExceptions	TokenNameIdentifier	 suppress Exceptions
)	TokenNameRPAREN	
throws	TokenNamethrows	
IOException	TokenNameIdentifier	 IO Exception
{	TokenNameLBRACE	
final	TokenNamefinal	
int	TokenNameint	
numSegments	TokenNameIdentifier	 num Segments
=	TokenNameEQUAL	
merge	TokenNameIdentifier	 merge
.	TokenNameDOT	
readers	TokenNameIdentifier	 readers
.	TokenNameDOT	
size	TokenNameIdentifier	 size
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
Throwable	TokenNameIdentifier	 Throwable
th	TokenNameIdentifier	 th
=	TokenNameEQUAL	
null	TokenNamenull	
;	TokenNameSEMICOLON	
boolean	TokenNameboolean	
anyChanges	TokenNameIdentifier	 any Changes
=	TokenNameEQUAL	
false	TokenNamefalse	
;	TokenNameSEMICOLON	
boolean	TokenNameboolean	
drop	TokenNameIdentifier	 drop
=	TokenNameEQUAL	
!	TokenNameNOT	
suppressExceptions	TokenNameIdentifier	 suppress Exceptions
;	TokenNameSEMICOLON	
for	TokenNamefor	
(	TokenNameLPAREN	
int	TokenNameint	
i	TokenNameIdentifier	 i
=	TokenNameEQUAL	
0	TokenNameIntegerLiteral	
;	TokenNameSEMICOLON	
i	TokenNameIdentifier	 i
<	TokenNameLESS	
numSegments	TokenNameIdentifier	 num Segments
;	TokenNameSEMICOLON	
i	TokenNameIdentifier	 i
++	TokenNamePLUS_PLUS	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
if	TokenNameif	
(	TokenNameLPAREN	
merge	TokenNameIdentifier	 merge
.	TokenNameDOT	
readers	TokenNameIdentifier	 readers
.	TokenNameDOT	
get	TokenNameIdentifier	 get
(	TokenNameLPAREN	
i	TokenNameIdentifier	 i
)	TokenNameRPAREN	
!=	TokenNameNOT_EQUAL	
null	TokenNamenull	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
try	TokenNametry	
{	TokenNameLBRACE	
anyChanges	TokenNameIdentifier	 any Changes
|=	TokenNameOR_EQUAL	
readerPool	TokenNameIdentifier	 reader Pool
.	TokenNameDOT	
release	TokenNameIdentifier	 release
(	TokenNameLPAREN	
merge	TokenNameIdentifier	 merge
.	TokenNameDOT	
readers	TokenNameIdentifier	 readers
.	TokenNameDOT	
get	TokenNameIdentifier	 get
(	TokenNameLPAREN	
i	TokenNameIdentifier	 i
)	TokenNameRPAREN	
,	TokenNameCOMMA	
drop	TokenNameIdentifier	 drop
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
catch	TokenNamecatch	
(	TokenNameLPAREN	
Throwable	TokenNameIdentifier	 Throwable
t	TokenNameIdentifier	 t
)	TokenNameRPAREN	
{	TokenNameLBRACE	
if	TokenNameif	
(	TokenNameLPAREN	
th	TokenNameIdentifier	 th
==	TokenNameEQUAL_EQUAL	
null	TokenNamenull	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
th	TokenNameIdentifier	 th
=	TokenNameEQUAL	
t	TokenNameIdentifier	 t
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
}	TokenNameRBRACE	
merge	TokenNameIdentifier	 merge
.	TokenNameDOT	
readers	TokenNameIdentifier	 readers
.	TokenNameDOT	
set	TokenNameIdentifier	 set
(	TokenNameLPAREN	
i	TokenNameIdentifier	 i
,	TokenNameCOMMA	
null	TokenNamenull	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
if	TokenNameif	
(	TokenNameLPAREN	
i	TokenNameIdentifier	 i
<	TokenNameLESS	
merge	TokenNameIdentifier	 merge
.	TokenNameDOT	
readerClones	TokenNameIdentifier	 reader Clones
.	TokenNameDOT	
size	TokenNameIdentifier	 size
(	TokenNameLPAREN	
)	TokenNameRPAREN	
&&	TokenNameAND_AND	
merge	TokenNameIdentifier	 merge
.	TokenNameDOT	
readerClones	TokenNameIdentifier	 reader Clones
.	TokenNameDOT	
get	TokenNameIdentifier	 get
(	TokenNameLPAREN	
i	TokenNameIdentifier	 i
)	TokenNameRPAREN	
!=	TokenNameNOT_EQUAL	
null	TokenNamenull	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
try	TokenNametry	
{	TokenNameLBRACE	
merge	TokenNameIdentifier	 merge
.	TokenNameDOT	
readerClones	TokenNameIdentifier	 reader Clones
.	TokenNameDOT	
get	TokenNameIdentifier	 get
(	TokenNameLPAREN	
i	TokenNameIdentifier	 i
)	TokenNameRPAREN	
.	TokenNameDOT	
close	TokenNameIdentifier	 close
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
catch	TokenNamecatch	
(	TokenNameLPAREN	
Throwable	TokenNameIdentifier	 Throwable
t	TokenNameIdentifier	 t
)	TokenNameRPAREN	
{	TokenNameLBRACE	
if	TokenNameif	
(	TokenNameLPAREN	
th	TokenNameIdentifier	 th
==	TokenNameEQUAL_EQUAL	
null	TokenNamenull	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
th	TokenNameIdentifier	 th
=	TokenNameEQUAL	
t	TokenNameIdentifier	 t
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
}	TokenNameRBRACE	
// This was a private clone and we had the 	TokenNameCOMMENT_LINE	This was a private clone and we had the 
// only reference 	TokenNameCOMMENT_LINE	only reference 
assert	TokenNameassert	
merge	TokenNameIdentifier	 merge
.	TokenNameDOT	
readerClones	TokenNameIdentifier	 reader Clones
.	TokenNameDOT	
get	TokenNameIdentifier	 get
(	TokenNameLPAREN	
i	TokenNameIdentifier	 i
)	TokenNameRPAREN	
.	TokenNameDOT	
getRefCount	TokenNameIdentifier	 get Ref Count
(	TokenNameLPAREN	
)	TokenNameRPAREN	
==	TokenNameEQUAL_EQUAL	
0	TokenNameIntegerLiteral	
:	TokenNameCOLON	
"refCount should be 0 but is "	TokenNameStringLiteral	refCount should be 0 but is 
+	TokenNamePLUS	
merge	TokenNameIdentifier	 merge
.	TokenNameDOT	
readerClones	TokenNameIdentifier	 reader Clones
.	TokenNameDOT	
get	TokenNameIdentifier	 get
(	TokenNameLPAREN	
i	TokenNameIdentifier	 i
)	TokenNameRPAREN	
.	TokenNameDOT	
getRefCount	TokenNameIdentifier	 get Ref Count
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
merge	TokenNameIdentifier	 merge
.	TokenNameDOT	
readerClones	TokenNameIdentifier	 reader Clones
.	TokenNameDOT	
set	TokenNameIdentifier	 set
(	TokenNameLPAREN	
i	TokenNameIdentifier	 i
,	TokenNameCOMMA	
null	TokenNamenull	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
}	TokenNameRBRACE	
if	TokenNameif	
(	TokenNameLPAREN	
suppressExceptions	TokenNameIdentifier	 suppress Exceptions
&&	TokenNameAND_AND	
anyChanges	TokenNameIdentifier	 any Changes
)	TokenNameRPAREN	
{	TokenNameLBRACE	
checkpoint	TokenNameIdentifier	 checkpoint
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
// If any error occured, throw it. 	TokenNameCOMMENT_LINE	If any error occured, throw it. 
if	TokenNameif	
(	TokenNameLPAREN	
!	TokenNameNOT	
suppressExceptions	TokenNameIdentifier	 suppress Exceptions
&&	TokenNameAND_AND	
th	TokenNameIdentifier	 th
!=	TokenNameNOT_EQUAL	
null	TokenNamenull	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
if	TokenNameif	
(	TokenNameLPAREN	
th	TokenNameIdentifier	 th
instanceof	TokenNameinstanceof	
IOException	TokenNameIdentifier	 IO Exception
)	TokenNameRPAREN	
throw	TokenNamethrow	
(	TokenNameLPAREN	
IOException	TokenNameIdentifier	 IO Exception
)	TokenNameRPAREN	
th	TokenNameIdentifier	 th
;	TokenNameSEMICOLON	
if	TokenNameif	
(	TokenNameLPAREN	
th	TokenNameIdentifier	 th
instanceof	TokenNameinstanceof	
RuntimeException	TokenNameIdentifier	 Runtime Exception
)	TokenNameRPAREN	
throw	TokenNamethrow	
(	TokenNameLPAREN	
RuntimeException	TokenNameIdentifier	 Runtime Exception
)	TokenNameRPAREN	
th	TokenNameIdentifier	 th
;	TokenNameSEMICOLON	
if	TokenNameif	
(	TokenNameLPAREN	
th	TokenNameIdentifier	 th
instanceof	TokenNameinstanceof	
Error	TokenNameIdentifier	 Error
)	TokenNameRPAREN	
throw	TokenNamethrow	
(	TokenNameLPAREN	
Error	TokenNameIdentifier	 Error
)	TokenNameRPAREN	
th	TokenNameIdentifier	 th
;	TokenNameSEMICOLON	
throw	TokenNamethrow	
new	TokenNamenew	
RuntimeException	TokenNameIdentifier	 Runtime Exception
(	TokenNameLPAREN	
th	TokenNameIdentifier	 th
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
}	TokenNameRBRACE	
/** Does the actual (time-consuming) work of the merge, * but without holding synchronized lock on IndexWriter * instance */	TokenNameCOMMENT_JAVADOC	 Does the actual (time-consuming) work of the merge, but without holding synchronized lock on IndexWriter instance 
final	TokenNamefinal	
private	TokenNameprivate	
int	TokenNameint	
mergeMiddle	TokenNameIdentifier	 merge Middle
(	TokenNameLPAREN	
MergePolicy	TokenNameIdentifier	 Merge Policy
.	TokenNameDOT	
OneMerge	TokenNameIdentifier	 One Merge
merge	TokenNameIdentifier	 merge
)	TokenNameRPAREN	
throws	TokenNamethrows	
CorruptIndexException	TokenNameIdentifier	 Corrupt Index Exception
,	TokenNameCOMMA	
IOException	TokenNameIdentifier	 IO Exception
{	TokenNameLBRACE	
merge	TokenNameIdentifier	 merge
.	TokenNameDOT	
checkAborted	TokenNameIdentifier	 check Aborted
(	TokenNameLPAREN	
directory	TokenNameIdentifier	 directory
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
final	TokenNamefinal	
String	TokenNameIdentifier	 String
mergedName	TokenNameIdentifier	 merged Name
=	TokenNameEQUAL	
merge	TokenNameIdentifier	 merge
.	TokenNameDOT	
info	TokenNameIdentifier	 info
.	TokenNameDOT	
name	TokenNameIdentifier	 name
;	TokenNameSEMICOLON	
int	TokenNameint	
mergedDocCount	TokenNameIdentifier	 merged Doc Count
=	TokenNameEQUAL	
0	TokenNameIntegerLiteral	
;	TokenNameSEMICOLON	
List	TokenNameIdentifier	 List
<	TokenNameLESS	
SegmentInfo	TokenNameIdentifier	 Segment Info
>	TokenNameGREATER	
sourceSegments	TokenNameIdentifier	 source Segments
=	TokenNameEQUAL	
merge	TokenNameIdentifier	 merge
.	TokenNameDOT	
segments	TokenNameIdentifier	 segments
;	TokenNameSEMICOLON	
SegmentMerger	TokenNameIdentifier	 Segment Merger
merger	TokenNameIdentifier	 merger
=	TokenNameEQUAL	
new	TokenNamenew	
SegmentMerger	TokenNameIdentifier	 Segment Merger
(	TokenNameLPAREN	
directory	TokenNameIdentifier	 directory
,	TokenNameCOMMA	
config	TokenNameIdentifier	 config
.	TokenNameDOT	
getTermIndexInterval	TokenNameIdentifier	 get Term Index Interval
(	TokenNameLPAREN	
)	TokenNameRPAREN	
,	TokenNameCOMMA	
mergedName	TokenNameIdentifier	 merged Name
,	TokenNameCOMMA	
merge	TokenNameIdentifier	 merge
,	TokenNameCOMMA	
payloadProcessorProvider	TokenNameIdentifier	 payload Processor Provider
,	TokenNameCOMMA	
(	TokenNameLPAREN	
(	TokenNameLPAREN	
FieldInfos	TokenNameIdentifier	 Field Infos
)	TokenNameRPAREN	
docWriter	TokenNameIdentifier	 doc Writer
.	TokenNameDOT	
getFieldInfos	TokenNameIdentifier	 get Field Infos
(	TokenNameLPAREN	
)	TokenNameRPAREN	
.	TokenNameDOT	
clone	TokenNameIdentifier	 clone
(	TokenNameLPAREN	
)	TokenNameRPAREN	
)	TokenNameRPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
if	TokenNameif	
(	TokenNameLPAREN	
infoStream	TokenNameIdentifier	 info Stream
!=	TokenNameNOT_EQUAL	
null	TokenNamenull	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
message	TokenNameIdentifier	 message
(	TokenNameLPAREN	
"merging "	TokenNameStringLiteral	merging 
+	TokenNamePLUS	
merge	TokenNameIdentifier	 merge
.	TokenNameDOT	
segString	TokenNameIdentifier	 seg String
(	TokenNameLPAREN	
directory	TokenNameIdentifier	 directory
)	TokenNameRPAREN	
+	TokenNamePLUS	
" mergeVectors="	TokenNameStringLiteral	 mergeVectors=
+	TokenNamePLUS	
merge	TokenNameIdentifier	 merge
.	TokenNameDOT	
info	TokenNameIdentifier	 info
.	TokenNameDOT	
getHasVectors	TokenNameIdentifier	 get Has Vectors
(	TokenNameLPAREN	
)	TokenNameRPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
merge	TokenNameIdentifier	 merge
.	TokenNameDOT	
readers	TokenNameIdentifier	 readers
=	TokenNameEQUAL	
new	TokenNamenew	
ArrayList	TokenNameIdentifier	 Array List
<	TokenNameLESS	
SegmentReader	TokenNameIdentifier	 Segment Reader
>	TokenNameGREATER	
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
merge	TokenNameIdentifier	 merge
.	TokenNameDOT	
readerClones	TokenNameIdentifier	 reader Clones
=	TokenNameEQUAL	
new	TokenNamenew	
ArrayList	TokenNameIdentifier	 Array List
<	TokenNameLESS	
SegmentReader	TokenNameIdentifier	 Segment Reader
>	TokenNameGREATER	
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
// This is try/finally to make sure merger's readers are 	TokenNameCOMMENT_LINE	This is try/finally to make sure merger's readers are 
// closed: 	TokenNameCOMMENT_LINE	closed: 
boolean	TokenNameboolean	
success	TokenNameIdentifier	 success
=	TokenNameEQUAL	
false	TokenNamefalse	
;	TokenNameSEMICOLON	
try	TokenNametry	
{	TokenNameLBRACE	
int	TokenNameint	
totDocCount	TokenNameIdentifier	 tot Doc Count
=	TokenNameEQUAL	
0	TokenNameIntegerLiteral	
;	TokenNameSEMICOLON	
int	TokenNameint	
segUpto	TokenNameIdentifier	 seg Upto
=	TokenNameEQUAL	
0	TokenNameIntegerLiteral	
;	TokenNameSEMICOLON	
while	TokenNamewhile	
(	TokenNameLPAREN	
segUpto	TokenNameIdentifier	 seg Upto
<	TokenNameLESS	
sourceSegments	TokenNameIdentifier	 source Segments
.	TokenNameDOT	
size	TokenNameIdentifier	 size
(	TokenNameLPAREN	
)	TokenNameRPAREN	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
final	TokenNamefinal	
SegmentInfo	TokenNameIdentifier	 Segment Info
info	TokenNameIdentifier	 info
=	TokenNameEQUAL	
sourceSegments	TokenNameIdentifier	 source Segments
.	TokenNameDOT	
get	TokenNameIdentifier	 get
(	TokenNameLPAREN	
segUpto	TokenNameIdentifier	 seg Upto
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
// Hold onto the "live" reader; we will use this to 	TokenNameCOMMENT_LINE	Hold onto the "live" reader; we will use this to 
// commit merged deletes 	TokenNameCOMMENT_LINE	commit merged deletes 
final	TokenNamefinal	
SegmentReader	TokenNameIdentifier	 Segment Reader
reader	TokenNameIdentifier	 reader
=	TokenNameEQUAL	
readerPool	TokenNameIdentifier	 reader Pool
.	TokenNameDOT	
get	TokenNameIdentifier	 get
(	TokenNameLPAREN	
info	TokenNameIdentifier	 info
,	TokenNameCOMMA	
true	TokenNametrue	
,	TokenNameCOMMA	
MERGE_READ_BUFFER_SIZE	TokenNameIdentifier	 MERGE  READ  BUFFER  SIZE
,	TokenNameCOMMA	
-	TokenNameMINUS	
1	TokenNameIntegerLiteral	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
merge	TokenNameIdentifier	 merge
.	TokenNameDOT	
readers	TokenNameIdentifier	 readers
.	TokenNameDOT	
add	TokenNameIdentifier	 add
(	TokenNameLPAREN	
reader	TokenNameIdentifier	 reader
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
// We clone the segment readers because other 	TokenNameCOMMENT_LINE	We clone the segment readers because other 
// deletes may come in while we're merging so we 	TokenNameCOMMENT_LINE	deletes may come in while we're merging so we 
// need readers that will not change 	TokenNameCOMMENT_LINE	need readers that will not change 
final	TokenNamefinal	
SegmentReader	TokenNameIdentifier	 Segment Reader
clone	TokenNameIdentifier	 clone
=	TokenNameEQUAL	
(	TokenNameLPAREN	
SegmentReader	TokenNameIdentifier	 Segment Reader
)	TokenNameRPAREN	
reader	TokenNameIdentifier	 reader
.	TokenNameDOT	
clone	TokenNameIdentifier	 clone
(	TokenNameLPAREN	
true	TokenNametrue	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
merge	TokenNameIdentifier	 merge
.	TokenNameDOT	
readerClones	TokenNameIdentifier	 reader Clones
.	TokenNameDOT	
add	TokenNameIdentifier	 add
(	TokenNameLPAREN	
clone	TokenNameIdentifier	 clone
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
if	TokenNameif	
(	TokenNameLPAREN	
clone	TokenNameIdentifier	 clone
.	TokenNameDOT	
numDocs	TokenNameIdentifier	 num Docs
(	TokenNameLPAREN	
)	TokenNameRPAREN	
>	TokenNameGREATER	
0	TokenNameIntegerLiteral	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
merger	TokenNameIdentifier	 merger
.	TokenNameDOT	
add	TokenNameIdentifier	 add
(	TokenNameLPAREN	
clone	TokenNameIdentifier	 clone
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
totDocCount	TokenNameIdentifier	 tot Doc Count
+=	TokenNamePLUS_EQUAL	
clone	TokenNameIdentifier	 clone
.	TokenNameDOT	
numDocs	TokenNameIdentifier	 num Docs
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
segUpto	TokenNameIdentifier	 seg Upto
++	TokenNamePLUS_PLUS	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
if	TokenNameif	
(	TokenNameLPAREN	
infoStream	TokenNameIdentifier	 info Stream
!=	TokenNameNOT_EQUAL	
null	TokenNamenull	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
message	TokenNameIdentifier	 message
(	TokenNameLPAREN	
"merge: total "	TokenNameStringLiteral	merge: total 
+	TokenNamePLUS	
totDocCount	TokenNameIdentifier	 tot Doc Count
+	TokenNamePLUS	
" docs"	TokenNameStringLiteral	 docs
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
merge	TokenNameIdentifier	 merge
.	TokenNameDOT	
checkAborted	TokenNameIdentifier	 check Aborted
(	TokenNameLPAREN	
directory	TokenNameIdentifier	 directory
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
// This is where all the work happens: 	TokenNameCOMMENT_LINE	This is where all the work happens: 
mergedDocCount	TokenNameIdentifier	 merged Doc Count
=	TokenNameEQUAL	
merge	TokenNameIdentifier	 merge
.	TokenNameDOT	
info	TokenNameIdentifier	 info
.	TokenNameDOT	
docCount	TokenNameIdentifier	 doc Count
=	TokenNameEQUAL	
merger	TokenNameIdentifier	 merger
.	TokenNameDOT	
merge	TokenNameIdentifier	 merge
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
// LUCENE-3403: set hasVectors after merge(), so that it is properly set. 	TokenNameCOMMENT_LINE	LUCENE-3403: set hasVectors after merge(), so that it is properly set. 
merge	TokenNameIdentifier	 merge
.	TokenNameDOT	
info	TokenNameIdentifier	 info
.	TokenNameDOT	
setHasVectors	TokenNameIdentifier	 set Has Vectors
(	TokenNameLPAREN	
merger	TokenNameIdentifier	 merger
.	TokenNameDOT	
fieldInfos	TokenNameIdentifier	 field Infos
(	TokenNameLPAREN	
)	TokenNameRPAREN	
.	TokenNameDOT	
hasVectors	TokenNameIdentifier	 has Vectors
(	TokenNameLPAREN	
)	TokenNameRPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
assert	TokenNameassert	
mergedDocCount	TokenNameIdentifier	 merged Doc Count
==	TokenNameEQUAL_EQUAL	
totDocCount	TokenNameIdentifier	 tot Doc Count
;	TokenNameSEMICOLON	
if	TokenNameif	
(	TokenNameLPAREN	
infoStream	TokenNameIdentifier	 info Stream
!=	TokenNameNOT_EQUAL	
null	TokenNamenull	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
message	TokenNameIdentifier	 message
(	TokenNameLPAREN	
"merge store matchedCount="	TokenNameStringLiteral	merge store matchedCount=
+	TokenNamePLUS	
merger	TokenNameIdentifier	 merger
.	TokenNameDOT	
getMatchedSubReaderCount	TokenNameIdentifier	 get Matched Sub Reader Count
(	TokenNameLPAREN	
)	TokenNameRPAREN	
+	TokenNamePLUS	
" vs "	TokenNameStringLiteral	 vs 
+	TokenNamePLUS	
merge	TokenNameIdentifier	 merge
.	TokenNameDOT	
readers	TokenNameIdentifier	 readers
.	TokenNameDOT	
size	TokenNameIdentifier	 size
(	TokenNameLPAREN	
)	TokenNameRPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
anyNonBulkMerges	TokenNameIdentifier	 any Non Bulk Merges
|=	TokenNameOR_EQUAL	
merger	TokenNameIdentifier	 merger
.	TokenNameDOT	
getAnyNonBulkMerges	TokenNameIdentifier	 get Any Non Bulk Merges
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
assert	TokenNameassert	
mergedDocCount	TokenNameIdentifier	 merged Doc Count
==	TokenNameEQUAL_EQUAL	
totDocCount	TokenNameIdentifier	 tot Doc Count
:	TokenNameCOLON	
"mergedDocCount="	TokenNameStringLiteral	mergedDocCount=
+	TokenNamePLUS	
mergedDocCount	TokenNameIdentifier	 merged Doc Count
+	TokenNamePLUS	
" vs "	TokenNameStringLiteral	 vs 
+	TokenNamePLUS	
totDocCount	TokenNameIdentifier	 tot Doc Count
;	TokenNameSEMICOLON	
// Very important to do this before opening the reader 	TokenNameCOMMENT_LINE	Very important to do this before opening the reader 
// because SegmentReader must know if prox was written for 	TokenNameCOMMENT_LINE	because SegmentReader must know if prox was written for 
// this segment: 	TokenNameCOMMENT_LINE	this segment: 
merge	TokenNameIdentifier	 merge
.	TokenNameDOT	
info	TokenNameIdentifier	 info
.	TokenNameDOT	
setHasProx	TokenNameIdentifier	 set Has Prox
(	TokenNameLPAREN	
merger	TokenNameIdentifier	 merger
.	TokenNameDOT	
fieldInfos	TokenNameIdentifier	 field Infos
(	TokenNameLPAREN	
)	TokenNameRPAREN	
.	TokenNameDOT	
hasProx	TokenNameIdentifier	 has Prox
(	TokenNameLPAREN	
)	TokenNameRPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
boolean	TokenNameboolean	
useCompoundFile	TokenNameIdentifier	 use Compound File
;	TokenNameSEMICOLON	
synchronized	TokenNamesynchronized	
(	TokenNameLPAREN	
this	TokenNamethis	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
// Guard segmentInfos 	TokenNameCOMMENT_LINE	Guard segmentInfos 
useCompoundFile	TokenNameIdentifier	 use Compound File
=	TokenNameEQUAL	
mergePolicy	TokenNameIdentifier	 merge Policy
.	TokenNameDOT	
useCompoundFile	TokenNameIdentifier	 use Compound File
(	TokenNameLPAREN	
segmentInfos	TokenNameIdentifier	 segment Infos
,	TokenNameCOMMA	
merge	TokenNameIdentifier	 merge
.	TokenNameDOT	
info	TokenNameIdentifier	 info
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
if	TokenNameif	
(	TokenNameLPAREN	
useCompoundFile	TokenNameIdentifier	 use Compound File
)	TokenNameRPAREN	
{	TokenNameLBRACE	
success	TokenNameIdentifier	 success
=	TokenNameEQUAL	
false	TokenNamefalse	
;	TokenNameSEMICOLON	
final	TokenNamefinal	
String	TokenNameIdentifier	 String
compoundFileName	TokenNameIdentifier	 compound File Name
=	TokenNameEQUAL	
IndexFileNames	TokenNameIdentifier	 Index File Names
.	TokenNameDOT	
segmentFileName	TokenNameIdentifier	 segment File Name
(	TokenNameLPAREN	
mergedName	TokenNameIdentifier	 merged Name
,	TokenNameCOMMA	
IndexFileNames	TokenNameIdentifier	 Index File Names
.	TokenNameDOT	
COMPOUND_FILE_EXTENSION	TokenNameIdentifier	 COMPOUND  FILE  EXTENSION
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
try	TokenNametry	
{	TokenNameLBRACE	
if	TokenNameif	
(	TokenNameLPAREN	
infoStream	TokenNameIdentifier	 info Stream
!=	TokenNameNOT_EQUAL	
null	TokenNamenull	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
message	TokenNameIdentifier	 message
(	TokenNameLPAREN	
"create compound file "	TokenNameStringLiteral	create compound file 
+	TokenNamePLUS	
compoundFileName	TokenNameIdentifier	 compound File Name
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
merger	TokenNameIdentifier	 merger
.	TokenNameDOT	
createCompoundFile	TokenNameIdentifier	 create Compound File
(	TokenNameLPAREN	
compoundFileName	TokenNameIdentifier	 compound File Name
,	TokenNameCOMMA	
merge	TokenNameIdentifier	 merge
.	TokenNameDOT	
info	TokenNameIdentifier	 info
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
success	TokenNameIdentifier	 success
=	TokenNameEQUAL	
true	TokenNametrue	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
catch	TokenNamecatch	
(	TokenNameLPAREN	
IOException	TokenNameIdentifier	 IO Exception
ioe	TokenNameIdentifier	 ioe
)	TokenNameRPAREN	
{	TokenNameLBRACE	
synchronized	TokenNamesynchronized	
(	TokenNameLPAREN	
this	TokenNamethis	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
if	TokenNameif	
(	TokenNameLPAREN	
merge	TokenNameIdentifier	 merge
.	TokenNameDOT	
isAborted	TokenNameIdentifier	 is Aborted
(	TokenNameLPAREN	
)	TokenNameRPAREN	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
// This can happen if rollback or close(false) 	TokenNameCOMMENT_LINE	This can happen if rollback or close(false) 
// is called -- fall through to logic below to 	TokenNameCOMMENT_LINE	is called -- fall through to logic below to 
// remove the partially created CFS: 	TokenNameCOMMENT_LINE	remove the partially created CFS: 
}	TokenNameRBRACE	
else	TokenNameelse	
{	TokenNameLBRACE	
handleMergeException	TokenNameIdentifier	 handle Merge Exception
(	TokenNameLPAREN	
ioe	TokenNameIdentifier	 ioe
,	TokenNameCOMMA	
merge	TokenNameIdentifier	 merge
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
}	TokenNameRBRACE	
}	TokenNameRBRACE	
catch	TokenNamecatch	
(	TokenNameLPAREN	
Throwable	TokenNameIdentifier	 Throwable
t	TokenNameIdentifier	 t
)	TokenNameRPAREN	
{	TokenNameLBRACE	
handleMergeException	TokenNameIdentifier	 handle Merge Exception
(	TokenNameLPAREN	
t	TokenNameIdentifier	 t
,	TokenNameCOMMA	
merge	TokenNameIdentifier	 merge
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
finally	TokenNamefinally	
{	TokenNameLBRACE	
if	TokenNameif	
(	TokenNameLPAREN	
!	TokenNameNOT	
success	TokenNameIdentifier	 success
)	TokenNameRPAREN	
{	TokenNameLBRACE	
if	TokenNameif	
(	TokenNameLPAREN	
infoStream	TokenNameIdentifier	 info Stream
!=	TokenNameNOT_EQUAL	
null	TokenNamenull	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
message	TokenNameIdentifier	 message
(	TokenNameLPAREN	
"hit exception creating compound file during merge"	TokenNameStringLiteral	hit exception creating compound file during merge
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
synchronized	TokenNamesynchronized	
(	TokenNameLPAREN	
this	TokenNamethis	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
deleter	TokenNameIdentifier	 deleter
.	TokenNameDOT	
deleteFile	TokenNameIdentifier	 delete File
(	TokenNameLPAREN	
compoundFileName	TokenNameIdentifier	 compound File Name
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
deleter	TokenNameIdentifier	 deleter
.	TokenNameDOT	
deleteNewFiles	TokenNameIdentifier	 delete New Files
(	TokenNameLPAREN	
merge	TokenNameIdentifier	 merge
.	TokenNameDOT	
info	TokenNameIdentifier	 info
.	TokenNameDOT	
files	TokenNameIdentifier	 files
(	TokenNameLPAREN	
)	TokenNameRPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
}	TokenNameRBRACE	
}	TokenNameRBRACE	
success	TokenNameIdentifier	 success
=	TokenNameEQUAL	
false	TokenNamefalse	
;	TokenNameSEMICOLON	
synchronized	TokenNamesynchronized	
(	TokenNameLPAREN	
this	TokenNamethis	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
// delete new non cfs files directly: they were never 	TokenNameCOMMENT_LINE	delete new non cfs files directly: they were never 
// registered with IFD 	TokenNameCOMMENT_LINE	registered with IFD 
deleter	TokenNameIdentifier	 deleter
.	TokenNameDOT	
deleteNewFiles	TokenNameIdentifier	 delete New Files
(	TokenNameLPAREN	
merge	TokenNameIdentifier	 merge
.	TokenNameDOT	
info	TokenNameIdentifier	 info
.	TokenNameDOT	
files	TokenNameIdentifier	 files
(	TokenNameLPAREN	
)	TokenNameRPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
if	TokenNameif	
(	TokenNameLPAREN	
merge	TokenNameIdentifier	 merge
.	TokenNameDOT	
isAborted	TokenNameIdentifier	 is Aborted
(	TokenNameLPAREN	
)	TokenNameRPAREN	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
if	TokenNameif	
(	TokenNameLPAREN	
infoStream	TokenNameIdentifier	 info Stream
!=	TokenNameNOT_EQUAL	
null	TokenNamenull	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
message	TokenNameIdentifier	 message
(	TokenNameLPAREN	
"abort merge after building CFS"	TokenNameStringLiteral	abort merge after building CFS
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
deleter	TokenNameIdentifier	 deleter
.	TokenNameDOT	
deleteFile	TokenNameIdentifier	 delete File
(	TokenNameLPAREN	
compoundFileName	TokenNameIdentifier	 compound File Name
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
return	TokenNamereturn	
0	TokenNameIntegerLiteral	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
}	TokenNameRBRACE	
merge	TokenNameIdentifier	 merge
.	TokenNameDOT	
info	TokenNameIdentifier	 info
.	TokenNameDOT	
setUseCompoundFile	TokenNameIdentifier	 set Use Compound File
(	TokenNameLPAREN	
true	TokenNametrue	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
if	TokenNameif	
(	TokenNameLPAREN	
infoStream	TokenNameIdentifier	 info Stream
!=	TokenNameNOT_EQUAL	
null	TokenNamenull	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
message	TokenNameIdentifier	 message
(	TokenNameLPAREN	
String	TokenNameIdentifier	 String
.	TokenNameDOT	
format	TokenNameIdentifier	 format
(	TokenNameLPAREN	
"merged segment size=%.3f MB vs estimate=%.3f MB"	TokenNameStringLiteral	merged segment size=%.3f MB vs estimate=%.3f MB
,	TokenNameCOMMA	
merge	TokenNameIdentifier	 merge
.	TokenNameDOT	
info	TokenNameIdentifier	 info
.	TokenNameDOT	
sizeInBytes	TokenNameIdentifier	 size In Bytes
(	TokenNameLPAREN	
true	TokenNametrue	
)	TokenNameRPAREN	
/	TokenNameDIVIDE	
1024.	TokenNameDoubleLiteral	
/	TokenNameDIVIDE	
1024.	TokenNameDoubleLiteral	
,	TokenNameCOMMA	
merge	TokenNameIdentifier	 merge
.	TokenNameDOT	
estimatedMergeBytes	TokenNameIdentifier	 estimated Merge Bytes
/	TokenNameDIVIDE	
1024	TokenNameIntegerLiteral	
/	TokenNameDIVIDE	
1024.	TokenNameDoubleLiteral	
)	TokenNameRPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
final	TokenNamefinal	
IndexReaderWarmer	TokenNameIdentifier	 Index Reader Warmer
mergedSegmentWarmer	TokenNameIdentifier	 merged Segment Warmer
=	TokenNameEQUAL	
config	TokenNameIdentifier	 config
.	TokenNameDOT	
getMergedSegmentWarmer	TokenNameIdentifier	 get Merged Segment Warmer
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
final	TokenNamefinal	
int	TokenNameint	
termsIndexDivisor	TokenNameIdentifier	 terms Index Divisor
;	TokenNameSEMICOLON	
final	TokenNamefinal	
boolean	TokenNameboolean	
loadDocStores	TokenNameIdentifier	 load Doc Stores
;	TokenNameSEMICOLON	
if	TokenNameif	
(	TokenNameLPAREN	
mergedSegmentWarmer	TokenNameIdentifier	 merged Segment Warmer
!=	TokenNameNOT_EQUAL	
null	TokenNamenull	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
// Load terms index & doc stores so the segment 	TokenNameCOMMENT_LINE	Load terms index & doc stores so the segment 
// warmer can run searches, load documents/term 	TokenNameCOMMENT_LINE	warmer can run searches, load documents/term 
// vectors 	TokenNameCOMMENT_LINE	vectors 
termsIndexDivisor	TokenNameIdentifier	 terms Index Divisor
=	TokenNameEQUAL	
config	TokenNameIdentifier	 config
.	TokenNameDOT	
getReaderTermsIndexDivisor	TokenNameIdentifier	 get Reader Terms Index Divisor
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
loadDocStores	TokenNameIdentifier	 load Doc Stores
=	TokenNameEQUAL	
true	TokenNametrue	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
else	TokenNameelse	
{	TokenNameLBRACE	
termsIndexDivisor	TokenNameIdentifier	 terms Index Divisor
=	TokenNameEQUAL	
-	TokenNameMINUS	
1	TokenNameIntegerLiteral	
;	TokenNameSEMICOLON	
loadDocStores	TokenNameIdentifier	 load Doc Stores
=	TokenNameEQUAL	
false	TokenNamefalse	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
// TODO: in the non-realtime case, we may want to only 	TokenNameCOMMENT_LINE	TODO: in the non-realtime case, we may want to only 
// keep deletes (it's costly to open entire reader 	TokenNameCOMMENT_LINE	keep deletes (it's costly to open entire reader 
// when we just need deletes) 	TokenNameCOMMENT_LINE	when we just need deletes) 
final	TokenNamefinal	
SegmentReader	TokenNameIdentifier	 Segment Reader
mergedReader	TokenNameIdentifier	 merged Reader
=	TokenNameEQUAL	
readerPool	TokenNameIdentifier	 reader Pool
.	TokenNameDOT	
get	TokenNameIdentifier	 get
(	TokenNameLPAREN	
merge	TokenNameIdentifier	 merge
.	TokenNameDOT	
info	TokenNameIdentifier	 info
,	TokenNameCOMMA	
loadDocStores	TokenNameIdentifier	 load Doc Stores
,	TokenNameCOMMA	
BufferedIndexInput	TokenNameIdentifier	 Buffered Index Input
.	TokenNameDOT	
BUFFER_SIZE	TokenNameIdentifier	 BUFFER  SIZE
,	TokenNameCOMMA	
termsIndexDivisor	TokenNameIdentifier	 terms Index Divisor
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
try	TokenNametry	
{	TokenNameLBRACE	
if	TokenNameif	
(	TokenNameLPAREN	
poolReaders	TokenNameIdentifier	 pool Readers
&&	TokenNameAND_AND	
mergedSegmentWarmer	TokenNameIdentifier	 merged Segment Warmer
!=	TokenNameNOT_EQUAL	
null	TokenNamenull	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
mergedSegmentWarmer	TokenNameIdentifier	 merged Segment Warmer
.	TokenNameDOT	
warm	TokenNameIdentifier	 warm
(	TokenNameLPAREN	
mergedReader	TokenNameIdentifier	 merged Reader
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
if	TokenNameif	
(	TokenNameLPAREN	
!	TokenNameNOT	
commitMerge	TokenNameIdentifier	 commit Merge
(	TokenNameLPAREN	
merge	TokenNameIdentifier	 merge
,	TokenNameCOMMA	
mergedReader	TokenNameIdentifier	 merged Reader
)	TokenNameRPAREN	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
// commitMerge will return false if this merge was aborted 	TokenNameCOMMENT_LINE	commitMerge will return false if this merge was aborted 
return	TokenNamereturn	
0	TokenNameIntegerLiteral	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
}	TokenNameRBRACE	
finally	TokenNamefinally	
{	TokenNameLBRACE	
synchronized	TokenNamesynchronized	
(	TokenNameLPAREN	
this	TokenNamethis	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
if	TokenNameif	
(	TokenNameLPAREN	
readerPool	TokenNameIdentifier	 reader Pool
.	TokenNameDOT	
release	TokenNameIdentifier	 release
(	TokenNameLPAREN	
mergedReader	TokenNameIdentifier	 merged Reader
)	TokenNameRPAREN	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
// Must checkpoint after releasing the 	TokenNameCOMMENT_LINE	Must checkpoint after releasing the 
// mergedReader since it may have written a new 	TokenNameCOMMENT_LINE	mergedReader since it may have written a new 
// deletes file: 	TokenNameCOMMENT_LINE	deletes file: 
checkpoint	TokenNameIdentifier	 checkpoint
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
}	TokenNameRBRACE	
}	TokenNameRBRACE	
success	TokenNameIdentifier	 success
=	TokenNameEQUAL	
true	TokenNametrue	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
finally	TokenNamefinally	
{	TokenNameLBRACE	
// Readers are already closed in commitMerge if we didn't hit 	TokenNameCOMMENT_LINE	Readers are already closed in commitMerge if we didn't hit 
// an exc: 	TokenNameCOMMENT_LINE	an exc: 
if	TokenNameif	
(	TokenNameLPAREN	
!	TokenNameNOT	
success	TokenNameIdentifier	 success
)	TokenNameRPAREN	
{	TokenNameLBRACE	
closeMergeReaders	TokenNameIdentifier	 close Merge Readers
(	TokenNameLPAREN	
merge	TokenNameIdentifier	 merge
,	TokenNameCOMMA	
true	TokenNametrue	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
}	TokenNameRBRACE	
return	TokenNamereturn	
mergedDocCount	TokenNameIdentifier	 merged Doc Count
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
synchronized	TokenNamesynchronized	
void	TokenNamevoid	
addMergeException	TokenNameIdentifier	 add Merge Exception
(	TokenNameLPAREN	
MergePolicy	TokenNameIdentifier	 Merge Policy
.	TokenNameDOT	
OneMerge	TokenNameIdentifier	 One Merge
merge	TokenNameIdentifier	 merge
)	TokenNameRPAREN	
{	TokenNameLBRACE	
assert	TokenNameassert	
merge	TokenNameIdentifier	 merge
.	TokenNameDOT	
getException	TokenNameIdentifier	 get Exception
(	TokenNameLPAREN	
)	TokenNameRPAREN	
!=	TokenNameNOT_EQUAL	
null	TokenNamenull	
;	TokenNameSEMICOLON	
if	TokenNameif	
(	TokenNameLPAREN	
!	TokenNameNOT	
mergeExceptions	TokenNameIdentifier	 merge Exceptions
.	TokenNameDOT	
contains	TokenNameIdentifier	 contains
(	TokenNameLPAREN	
merge	TokenNameIdentifier	 merge
)	TokenNameRPAREN	
&&	TokenNameAND_AND	
mergeGen	TokenNameIdentifier	 merge Gen
==	TokenNameEQUAL_EQUAL	
merge	TokenNameIdentifier	 merge
.	TokenNameDOT	
mergeGen	TokenNameIdentifier	 merge Gen
)	TokenNameRPAREN	
mergeExceptions	TokenNameIdentifier	 merge Exceptions
.	TokenNameDOT	
add	TokenNameIdentifier	 add
(	TokenNameLPAREN	
merge	TokenNameIdentifier	 merge
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
// For test purposes. 	TokenNameCOMMENT_LINE	For test purposes. 
final	TokenNamefinal	
int	TokenNameint	
getBufferedDeleteTermsSize	TokenNameIdentifier	 get Buffered Delete Terms Size
(	TokenNameLPAREN	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
return	TokenNamereturn	
docWriter	TokenNameIdentifier	 doc Writer
.	TokenNameDOT	
getPendingDeletes	TokenNameIdentifier	 get Pending Deletes
(	TokenNameLPAREN	
)	TokenNameRPAREN	
.	TokenNameDOT	
terms	TokenNameIdentifier	 terms
.	TokenNameDOT	
size	TokenNameIdentifier	 size
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
// For test purposes. 	TokenNameCOMMENT_LINE	For test purposes. 
final	TokenNamefinal	
int	TokenNameint	
getNumBufferedDeleteTerms	TokenNameIdentifier	 get Num Buffered Delete Terms
(	TokenNameLPAREN	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
return	TokenNamereturn	
docWriter	TokenNameIdentifier	 doc Writer
.	TokenNameDOT	
getPendingDeletes	TokenNameIdentifier	 get Pending Deletes
(	TokenNameLPAREN	
)	TokenNameRPAREN	
.	TokenNameDOT	
numTermDeletes	TokenNameIdentifier	 num Term Deletes
.	TokenNameDOT	
get	TokenNameIdentifier	 get
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
// utility routines for tests 	TokenNameCOMMENT_LINE	utility routines for tests 
synchronized	TokenNamesynchronized	
SegmentInfo	TokenNameIdentifier	 Segment Info
newestSegment	TokenNameIdentifier	 newest Segment
(	TokenNameLPAREN	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
return	TokenNamereturn	
segmentInfos	TokenNameIdentifier	 segment Infos
.	TokenNameDOT	
size	TokenNameIdentifier	 size
(	TokenNameLPAREN	
)	TokenNameRPAREN	
>	TokenNameGREATER	
0	TokenNameIntegerLiteral	
?	TokenNameQUESTION	
segmentInfos	TokenNameIdentifier	 segment Infos
.	TokenNameDOT	
info	TokenNameIdentifier	 info
(	TokenNameLPAREN	
segmentInfos	TokenNameIdentifier	 segment Infos
.	TokenNameDOT	
size	TokenNameIdentifier	 size
(	TokenNameLPAREN	
)	TokenNameRPAREN	
-	TokenNameMINUS	
1	TokenNameIntegerLiteral	
)	TokenNameRPAREN	
:	TokenNameCOLON	
null	TokenNamenull	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
/** @lucene.internal */	TokenNameCOMMENT_JAVADOC	 @lucene.internal 
public	TokenNamepublic	
synchronized	TokenNamesynchronized	
String	TokenNameIdentifier	 String
segString	TokenNameIdentifier	 seg String
(	TokenNameLPAREN	
)	TokenNameRPAREN	
throws	TokenNamethrows	
IOException	TokenNameIdentifier	 IO Exception
{	TokenNameLBRACE	
return	TokenNamereturn	
segString	TokenNameIdentifier	 seg String
(	TokenNameLPAREN	
segmentInfos	TokenNameIdentifier	 segment Infos
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
/** @lucene.internal */	TokenNameCOMMENT_JAVADOC	 @lucene.internal 
public	TokenNamepublic	
synchronized	TokenNamesynchronized	
String	TokenNameIdentifier	 String
segString	TokenNameIdentifier	 seg String
(	TokenNameLPAREN	
Iterable	TokenNameIdentifier	 Iterable
<	TokenNameLESS	
SegmentInfo	TokenNameIdentifier	 Segment Info
>	TokenNameGREATER	
infos	TokenNameIdentifier	 infos
)	TokenNameRPAREN	
throws	TokenNamethrows	
IOException	TokenNameIdentifier	 IO Exception
{	TokenNameLBRACE	
final	TokenNamefinal	
StringBuilder	TokenNameIdentifier	 String Builder
buffer	TokenNameIdentifier	 buffer
=	TokenNameEQUAL	
new	TokenNamenew	
StringBuilder	TokenNameIdentifier	 String Builder
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
for	TokenNamefor	
(	TokenNameLPAREN	
final	TokenNamefinal	
SegmentInfo	TokenNameIdentifier	 Segment Info
s	TokenNameIdentifier	 s
:	TokenNameCOLON	
infos	TokenNameIdentifier	 infos
)	TokenNameRPAREN	
{	TokenNameLBRACE	
if	TokenNameif	
(	TokenNameLPAREN	
buffer	TokenNameIdentifier	 buffer
.	TokenNameDOT	
length	TokenNameIdentifier	 length
(	TokenNameLPAREN	
)	TokenNameRPAREN	
>	TokenNameGREATER	
0	TokenNameIntegerLiteral	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
buffer	TokenNameIdentifier	 buffer
.	TokenNameDOT	
append	TokenNameIdentifier	 append
(	TokenNameLPAREN	
' '	TokenNameCharacterLiteral	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
buffer	TokenNameIdentifier	 buffer
.	TokenNameDOT	
append	TokenNameIdentifier	 append
(	TokenNameLPAREN	
segString	TokenNameIdentifier	 seg String
(	TokenNameLPAREN	
s	TokenNameIdentifier	 s
)	TokenNameRPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
return	TokenNamereturn	
buffer	TokenNameIdentifier	 buffer
.	TokenNameDOT	
toString	TokenNameIdentifier	 to String
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
/** @lucene.internal */	TokenNameCOMMENT_JAVADOC	 @lucene.internal 
public	TokenNamepublic	
synchronized	TokenNamesynchronized	
String	TokenNameIdentifier	 String
segString	TokenNameIdentifier	 seg String
(	TokenNameLPAREN	
SegmentInfo	TokenNameIdentifier	 Segment Info
info	TokenNameIdentifier	 info
)	TokenNameRPAREN	
throws	TokenNamethrows	
IOException	TokenNameIdentifier	 IO Exception
{	TokenNameLBRACE	
StringBuilder	TokenNameIdentifier	 String Builder
buffer	TokenNameIdentifier	 buffer
=	TokenNameEQUAL	
new	TokenNamenew	
StringBuilder	TokenNameIdentifier	 String Builder
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
SegmentReader	TokenNameIdentifier	 Segment Reader
reader	TokenNameIdentifier	 reader
=	TokenNameEQUAL	
readerPool	TokenNameIdentifier	 reader Pool
.	TokenNameDOT	
getIfExists	TokenNameIdentifier	 get If Exists
(	TokenNameLPAREN	
info	TokenNameIdentifier	 info
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
try	TokenNametry	
{	TokenNameLBRACE	
if	TokenNameif	
(	TokenNameLPAREN	
reader	TokenNameIdentifier	 reader
!=	TokenNameNOT_EQUAL	
null	TokenNamenull	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
buffer	TokenNameIdentifier	 buffer
.	TokenNameDOT	
append	TokenNameIdentifier	 append
(	TokenNameLPAREN	
reader	TokenNameIdentifier	 reader
.	TokenNameDOT	
toString	TokenNameIdentifier	 to String
(	TokenNameLPAREN	
)	TokenNameRPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
else	TokenNameelse	
{	TokenNameLBRACE	
buffer	TokenNameIdentifier	 buffer
.	TokenNameDOT	
append	TokenNameIdentifier	 append
(	TokenNameLPAREN	
info	TokenNameIdentifier	 info
.	TokenNameDOT	
toString	TokenNameIdentifier	 to String
(	TokenNameLPAREN	
directory	TokenNameIdentifier	 directory
,	TokenNameCOMMA	
0	TokenNameIntegerLiteral	
)	TokenNameRPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
if	TokenNameif	
(	TokenNameLPAREN	
info	TokenNameIdentifier	 info
.	TokenNameDOT	
dir	TokenNameIdentifier	 dir
!=	TokenNameNOT_EQUAL	
directory	TokenNameIdentifier	 directory
)	TokenNameRPAREN	
{	TokenNameLBRACE	
buffer	TokenNameIdentifier	 buffer
.	TokenNameDOT	
append	TokenNameIdentifier	 append
(	TokenNameLPAREN	
"**"	TokenNameStringLiteral	**
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
}	TokenNameRBRACE	
}	TokenNameRBRACE	
finally	TokenNamefinally	
{	TokenNameLBRACE	
if	TokenNameif	
(	TokenNameLPAREN	
reader	TokenNameIdentifier	 reader
!=	TokenNameNOT_EQUAL	
null	TokenNamenull	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
readerPool	TokenNameIdentifier	 reader Pool
.	TokenNameDOT	
release	TokenNameIdentifier	 release
(	TokenNameLPAREN	
reader	TokenNameIdentifier	 reader
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
}	TokenNameRBRACE	
return	TokenNamereturn	
buffer	TokenNameIdentifier	 buffer
.	TokenNameDOT	
toString	TokenNameIdentifier	 to String
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
private	TokenNameprivate	
synchronized	TokenNamesynchronized	
void	TokenNamevoid	
doWait	TokenNameIdentifier	 do Wait
(	TokenNameLPAREN	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
// NOTE: the callers of this method should in theory 	TokenNameCOMMENT_LINE	NOTE: the callers of this method should in theory 
// be able to do simply wait(), but, as a defense 	TokenNameCOMMENT_LINE	be able to do simply wait(), but, as a defense 
// against thread timing hazards where notifyAll() 	TokenNameCOMMENT_LINE	against thread timing hazards where notifyAll() 
// fails to be called, we wait for at most 1 second 	TokenNameCOMMENT_LINE	fails to be called, we wait for at most 1 second 
// and then return so caller can check if wait 	TokenNameCOMMENT_LINE	and then return so caller can check if wait 
// conditions are satisfied: 	TokenNameCOMMENT_LINE	conditions are satisfied: 
try	TokenNametry	
{	TokenNameLBRACE	
wait	TokenNameIdentifier	 wait
(	TokenNameLPAREN	
1000	TokenNameIntegerLiteral	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
catch	TokenNamecatch	
(	TokenNameLPAREN	
InterruptedException	TokenNameIdentifier	 Interrupted Exception
ie	TokenNameIdentifier	 ie
)	TokenNameRPAREN	
{	TokenNameLBRACE	
throw	TokenNamethrow	
new	TokenNamenew	
ThreadInterruptedException	TokenNameIdentifier	 Thread Interrupted Exception
(	TokenNameLPAREN	
ie	TokenNameIdentifier	 ie
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
}	TokenNameRBRACE	
private	TokenNameprivate	
boolean	TokenNameboolean	
keepFullyDeletedSegments	TokenNameIdentifier	 keep Fully Deleted Segments
;	TokenNameSEMICOLON	
/** Only for testing. * * @lucene.internal */	TokenNameCOMMENT_JAVADOC	 Only for testing. * @lucene.internal 
void	TokenNamevoid	
keepFullyDeletedSegments	TokenNameIdentifier	 keep Fully Deleted Segments
(	TokenNameLPAREN	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
keepFullyDeletedSegments	TokenNameIdentifier	 keep Fully Deleted Segments
=	TokenNameEQUAL	
true	TokenNametrue	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
boolean	TokenNameboolean	
getKeepFullyDeletedSegments	TokenNameIdentifier	 get Keep Fully Deleted Segments
(	TokenNameLPAREN	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
return	TokenNamereturn	
keepFullyDeletedSegments	TokenNameIdentifier	 keep Fully Deleted Segments
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
// called only from assert 	TokenNameCOMMENT_LINE	called only from assert 
private	TokenNameprivate	
boolean	TokenNameboolean	
filesExist	TokenNameIdentifier	 files Exist
(	TokenNameLPAREN	
SegmentInfos	TokenNameIdentifier	 Segment Infos
toSync	TokenNameIdentifier	 to Sync
)	TokenNameRPAREN	
throws	TokenNamethrows	
IOException	TokenNameIdentifier	 IO Exception
{	TokenNameLBRACE	
Collection	TokenNameIdentifier	 Collection
<	TokenNameLESS	
String	TokenNameIdentifier	 String
>	TokenNameGREATER	
files	TokenNameIdentifier	 files
=	TokenNameEQUAL	
toSync	TokenNameIdentifier	 to Sync
.	TokenNameDOT	
files	TokenNameIdentifier	 files
(	TokenNameLPAREN	
directory	TokenNameIdentifier	 directory
,	TokenNameCOMMA	
false	TokenNamefalse	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
for	TokenNamefor	
(	TokenNameLPAREN	
final	TokenNamefinal	
String	TokenNameIdentifier	 String
fileName	TokenNameIdentifier	 file Name
:	TokenNameCOLON	
files	TokenNameIdentifier	 files
)	TokenNameRPAREN	
{	TokenNameLBRACE	
assert	TokenNameassert	
directory	TokenNameIdentifier	 directory
.	TokenNameDOT	
fileExists	TokenNameIdentifier	 file Exists
(	TokenNameLPAREN	
fileName	TokenNameIdentifier	 file Name
)	TokenNameRPAREN	
:	TokenNameCOLON	
"file "	TokenNameStringLiteral	file 
+	TokenNamePLUS	
fileName	TokenNameIdentifier	 file Name
+	TokenNamePLUS	
" does not exist"	TokenNameStringLiteral	 does not exist
;	TokenNameSEMICOLON	
// If this trips it means we are missing a call to 	TokenNameCOMMENT_LINE	If this trips it means we are missing a call to 
// .checkpoint somewhere, because by the time we 	TokenNameCOMMENT_LINE	.checkpoint somewhere, because by the time we 
// are called, deleter should know about every 	TokenNameCOMMENT_LINE	are called, deleter should know about every 
// file referenced by the current head 	TokenNameCOMMENT_LINE	file referenced by the current head 
// segmentInfos: 	TokenNameCOMMENT_LINE	segmentInfos: 
assert	TokenNameassert	
deleter	TokenNameIdentifier	 deleter
.	TokenNameDOT	
exists	TokenNameIdentifier	 exists
(	TokenNameLPAREN	
fileName	TokenNameIdentifier	 file Name
)	TokenNameRPAREN	
:	TokenNameCOLON	
"IndexFileDeleter doesn't know about file "	TokenNameStringLiteral	IndexFileDeleter doesn't know about file 
+	TokenNamePLUS	
fileName	TokenNameIdentifier	 file Name
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
return	TokenNamereturn	
true	TokenNametrue	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
/** Walk through all files referenced by the current * segmentInfos and ask the Directory to sync each file, * if it wasn't already. If that succeeds, then we * prepare a new segments_N file but do not fully commit * it. */	TokenNameCOMMENT_JAVADOC	 Walk through all files referenced by the current segmentInfos and ask the Directory to sync each file, if it wasn't already. If that succeeds, then we prepare a new segments_N file but do not fully commit it. 
private	TokenNameprivate	
void	TokenNamevoid	
startCommit	TokenNameIdentifier	 start Commit
(	TokenNameLPAREN	
SegmentInfos	TokenNameIdentifier	 Segment Infos
toSync	TokenNameIdentifier	 to Sync
,	TokenNameCOMMA	
Map	TokenNameIdentifier	 Map
<	TokenNameLESS	
String	TokenNameIdentifier	 String
,	TokenNameCOMMA	
String	TokenNameIdentifier	 String
>	TokenNameGREATER	
commitUserData	TokenNameIdentifier	 commit User Data
)	TokenNameRPAREN	
throws	TokenNamethrows	
IOException	TokenNameIdentifier	 IO Exception
{	TokenNameLBRACE	
assert	TokenNameassert	
testPoint	TokenNameIdentifier	 test Point
(	TokenNameLPAREN	
"startStartCommit"	TokenNameStringLiteral	startStartCommit
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
assert	TokenNameassert	
pendingCommit	TokenNameIdentifier	 pending Commit
==	TokenNameEQUAL_EQUAL	
null	TokenNamenull	
;	TokenNameSEMICOLON	
if	TokenNameif	
(	TokenNameLPAREN	
hitOOM	TokenNameIdentifier	 hit OOM
)	TokenNameRPAREN	
{	TokenNameLBRACE	
throw	TokenNamethrow	
new	TokenNamenew	
IllegalStateException	TokenNameIdentifier	 Illegal State Exception
(	TokenNameLPAREN	
"this writer hit an OutOfMemoryError; cannot commit"	TokenNameStringLiteral	this writer hit an OutOfMemoryError; cannot commit
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
try	TokenNametry	
{	TokenNameLBRACE	
if	TokenNameif	
(	TokenNameLPAREN	
infoStream	TokenNameIdentifier	 info Stream
!=	TokenNameNOT_EQUAL	
null	TokenNamenull	
)	TokenNameRPAREN	
message	TokenNameIdentifier	 message
(	TokenNameLPAREN	
"startCommit(): start"	TokenNameStringLiteral	startCommit(): start
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
synchronized	TokenNamesynchronized	
(	TokenNameLPAREN	
this	TokenNamethis	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
assert	TokenNameassert	
lastCommitChangeCount	TokenNameIdentifier	 last Commit Change Count
<=	TokenNameLESS_EQUAL	
changeCount	TokenNameIdentifier	 change Count
;	TokenNameSEMICOLON	
if	TokenNameif	
(	TokenNameLPAREN	
pendingCommitChangeCount	TokenNameIdentifier	 pending Commit Change Count
==	TokenNameEQUAL_EQUAL	
lastCommitChangeCount	TokenNameIdentifier	 last Commit Change Count
)	TokenNameRPAREN	
{	TokenNameLBRACE	
if	TokenNameif	
(	TokenNameLPAREN	
infoStream	TokenNameIdentifier	 info Stream
!=	TokenNameNOT_EQUAL	
null	TokenNamenull	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
message	TokenNameIdentifier	 message
(	TokenNameLPAREN	
" skip startCommit(): no changes pending"	TokenNameStringLiteral	 skip startCommit(): no changes pending
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
deleter	TokenNameIdentifier	 deleter
.	TokenNameDOT	
decRef	TokenNameIdentifier	 dec Ref
(	TokenNameLPAREN	
filesToCommit	TokenNameIdentifier	 files To Commit
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
filesToCommit	TokenNameIdentifier	 files To Commit
=	TokenNameEQUAL	
null	TokenNamenull	
;	TokenNameSEMICOLON	
return	TokenNamereturn	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
// First, we clone & incref the segmentInfos we intend 	TokenNameCOMMENT_LINE	First, we clone & incref the segmentInfos we intend 
// to sync, then, without locking, we sync() all files 	TokenNameCOMMENT_LINE	to sync, then, without locking, we sync() all files 
// referenced by toSync, in the background. 	TokenNameCOMMENT_LINE	referenced by toSync, in the background. 
if	TokenNameif	
(	TokenNameLPAREN	
infoStream	TokenNameIdentifier	 info Stream
!=	TokenNameNOT_EQUAL	
null	TokenNamenull	
)	TokenNameRPAREN	
message	TokenNameIdentifier	 message
(	TokenNameLPAREN	
"startCommit index="	TokenNameStringLiteral	startCommit index=
+	TokenNamePLUS	
segString	TokenNameIdentifier	 seg String
(	TokenNameLPAREN	
toSync	TokenNameIdentifier	 to Sync
)	TokenNameRPAREN	
+	TokenNamePLUS	
" changeCount="	TokenNameStringLiteral	 changeCount=
+	TokenNamePLUS	
changeCount	TokenNameIdentifier	 change Count
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
assert	TokenNameassert	
filesExist	TokenNameIdentifier	 files Exist
(	TokenNameLPAREN	
toSync	TokenNameIdentifier	 to Sync
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
if	TokenNameif	
(	TokenNameLPAREN	
commitUserData	TokenNameIdentifier	 commit User Data
!=	TokenNameNOT_EQUAL	
null	TokenNamenull	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
toSync	TokenNameIdentifier	 to Sync
.	TokenNameDOT	
setUserData	TokenNameIdentifier	 set User Data
(	TokenNameLPAREN	
commitUserData	TokenNameIdentifier	 commit User Data
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
}	TokenNameRBRACE	
assert	TokenNameassert	
testPoint	TokenNameIdentifier	 test Point
(	TokenNameLPAREN	
"midStartCommit"	TokenNameStringLiteral	midStartCommit
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
boolean	TokenNameboolean	
pendingCommitSet	TokenNameIdentifier	 pending Commit Set
=	TokenNameEQUAL	
false	TokenNamefalse	
;	TokenNameSEMICOLON	
try	TokenNametry	
{	TokenNameLBRACE	
// This call can take a long time -- 10s of seconds 	TokenNameCOMMENT_LINE	This call can take a long time -- 10s of seconds 
// or more. We do it without sync: 	TokenNameCOMMENT_LINE	or more. We do it without sync: 
directory	TokenNameIdentifier	 directory
.	TokenNameDOT	
sync	TokenNameIdentifier	 sync
(	TokenNameLPAREN	
toSync	TokenNameIdentifier	 to Sync
.	TokenNameDOT	
files	TokenNameIdentifier	 files
(	TokenNameLPAREN	
directory	TokenNameIdentifier	 directory
,	TokenNameCOMMA	
false	TokenNamefalse	
)	TokenNameRPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
assert	TokenNameassert	
testPoint	TokenNameIdentifier	 test Point
(	TokenNameLPAREN	
"midStartCommit2"	TokenNameStringLiteral	midStartCommit2
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
synchronized	TokenNamesynchronized	
(	TokenNameLPAREN	
this	TokenNamethis	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
assert	TokenNameassert	
pendingCommit	TokenNameIdentifier	 pending Commit
==	TokenNameEQUAL_EQUAL	
null	TokenNamenull	
;	TokenNameSEMICOLON	
assert	TokenNameassert	
segmentInfos	TokenNameIdentifier	 segment Infos
.	TokenNameDOT	
getGeneration	TokenNameIdentifier	 get Generation
(	TokenNameLPAREN	
)	TokenNameRPAREN	
==	TokenNameEQUAL_EQUAL	
toSync	TokenNameIdentifier	 to Sync
.	TokenNameDOT	
getGeneration	TokenNameIdentifier	 get Generation
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
// Exception here means nothing is prepared 	TokenNameCOMMENT_LINE	Exception here means nothing is prepared 
// (this method unwinds everything it did on 	TokenNameCOMMENT_LINE	(this method unwinds everything it did on 
// an exception) 	TokenNameCOMMENT_LINE	an exception) 
toSync	TokenNameIdentifier	 to Sync
.	TokenNameDOT	
prepareCommit	TokenNameIdentifier	 prepare Commit
(	TokenNameLPAREN	
directory	TokenNameIdentifier	 directory
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
pendingCommitSet	TokenNameIdentifier	 pending Commit Set
=	TokenNameEQUAL	
true	TokenNametrue	
;	TokenNameSEMICOLON	
pendingCommit	TokenNameIdentifier	 pending Commit
=	TokenNameEQUAL	
toSync	TokenNameIdentifier	 to Sync
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
if	TokenNameif	
(	TokenNameLPAREN	
infoStream	TokenNameIdentifier	 info Stream
!=	TokenNameNOT_EQUAL	
null	TokenNamenull	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
message	TokenNameIdentifier	 message
(	TokenNameLPAREN	
"done all syncs"	TokenNameStringLiteral	done all syncs
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
assert	TokenNameassert	
testPoint	TokenNameIdentifier	 test Point
(	TokenNameLPAREN	
"midStartCommitSuccess"	TokenNameStringLiteral	midStartCommitSuccess
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
finally	TokenNamefinally	
{	TokenNameLBRACE	
synchronized	TokenNamesynchronized	
(	TokenNameLPAREN	
this	TokenNamethis	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
// Have our master segmentInfos record the 	TokenNameCOMMENT_LINE	Have our master segmentInfos record the 
// generations we just prepared. We do this 	TokenNameCOMMENT_LINE	generations we just prepared. We do this 
// on error or success so we don't 	TokenNameCOMMENT_LINE	on error or success so we don't 
// double-write a segments_N file. 	TokenNameCOMMENT_LINE	double-write a segments_N file. 
segmentInfos	TokenNameIdentifier	 segment Infos
.	TokenNameDOT	
updateGeneration	TokenNameIdentifier	 update Generation
(	TokenNameLPAREN	
toSync	TokenNameIdentifier	 to Sync
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
if	TokenNameif	
(	TokenNameLPAREN	
!	TokenNameNOT	
pendingCommitSet	TokenNameIdentifier	 pending Commit Set
)	TokenNameRPAREN	
{	TokenNameLBRACE	
if	TokenNameif	
(	TokenNameLPAREN	
infoStream	TokenNameIdentifier	 info Stream
!=	TokenNameNOT_EQUAL	
null	TokenNamenull	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
message	TokenNameIdentifier	 message
(	TokenNameLPAREN	
"hit exception committing segments file"	TokenNameStringLiteral	hit exception committing segments file
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
deleter	TokenNameIdentifier	 deleter
.	TokenNameDOT	
decRef	TokenNameIdentifier	 dec Ref
(	TokenNameLPAREN	
filesToCommit	TokenNameIdentifier	 files To Commit
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
filesToCommit	TokenNameIdentifier	 files To Commit
=	TokenNameEQUAL	
null	TokenNamenull	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
}	TokenNameRBRACE	
}	TokenNameRBRACE	
}	TokenNameRBRACE	
catch	TokenNamecatch	
(	TokenNameLPAREN	
OutOfMemoryError	TokenNameIdentifier	 Out Of Memory Error
oom	TokenNameIdentifier	 oom
)	TokenNameRPAREN	
{	TokenNameLBRACE	
handleOOM	TokenNameIdentifier	 handle OOM
(	TokenNameLPAREN	
oom	TokenNameIdentifier	 oom
,	TokenNameCOMMA	
"startCommit"	TokenNameStringLiteral	startCommit
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
assert	TokenNameassert	
testPoint	TokenNameIdentifier	 test Point
(	TokenNameLPAREN	
"finishStartCommit"	TokenNameStringLiteral	finishStartCommit
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
/** * Returns <code>true</code> iff the index in the named directory is * currently locked. * @param directory the directory to check for a lock * @throws IOException if there is a low-level IO error */	TokenNameCOMMENT_JAVADOC	 Returns <code>true</code> iff the index in the named directory is currently locked. @param directory the directory to check for a lock @throws IOException if there is a low-level IO error 
public	TokenNamepublic	
static	TokenNamestatic	
boolean	TokenNameboolean	
isLocked	TokenNameIdentifier	 is Locked
(	TokenNameLPAREN	
Directory	TokenNameIdentifier	 Directory
directory	TokenNameIdentifier	 directory
)	TokenNameRPAREN	
throws	TokenNamethrows	
IOException	TokenNameIdentifier	 IO Exception
{	TokenNameLBRACE	
return	TokenNamereturn	
directory	TokenNameIdentifier	 directory
.	TokenNameDOT	
makeLock	TokenNameIdentifier	 make Lock
(	TokenNameLPAREN	
WRITE_LOCK_NAME	TokenNameIdentifier	 WRITE  LOCK  NAME
)	TokenNameRPAREN	
.	TokenNameDOT	
isLocked	TokenNameIdentifier	 is Locked
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
/** * Forcibly unlocks the index in the named directory. * <P> * Caution: this should only be used by failure recovery code, * when it is known that no other process nor thread is in fact * currently accessing this index. */	TokenNameCOMMENT_JAVADOC	 Forcibly unlocks the index in the named directory. <P> Caution: this should only be used by failure recovery code, when it is known that no other process nor thread is in fact currently accessing this index. 
public	TokenNamepublic	
static	TokenNamestatic	
void	TokenNamevoid	
unlock	TokenNameIdentifier	 unlock
(	TokenNameLPAREN	
Directory	TokenNameIdentifier	 Directory
directory	TokenNameIdentifier	 directory
)	TokenNameRPAREN	
throws	TokenNamethrows	
IOException	TokenNameIdentifier	 IO Exception
{	TokenNameLBRACE	
directory	TokenNameIdentifier	 directory
.	TokenNameDOT	
makeLock	TokenNameIdentifier	 make Lock
(	TokenNameLPAREN	
IndexWriter	TokenNameIdentifier	 Index Writer
.	TokenNameDOT	
WRITE_LOCK_NAME	TokenNameIdentifier	 WRITE  LOCK  NAME
)	TokenNameRPAREN	
.	TokenNameDOT	
release	TokenNameIdentifier	 release
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
/** * Specifies maximum field length (in number of tokens/terms) in * {@link IndexWriter} constructors. {@link #setMaxFieldLength(int)} overrides * the value set by the constructor. * * @deprecated use {@link LimitTokenCountAnalyzer} instead. */	TokenNameCOMMENT_JAVADOC	 Specifies maximum field length (in number of tokens/terms) in {@link IndexWriter} constructors. {@link #setMaxFieldLength(int)} overrides the value set by the constructor. * @deprecated use {@link LimitTokenCountAnalyzer} instead. 
@	TokenNameAT	
Deprecated	TokenNameIdentifier	 Deprecated
public	TokenNamepublic	
static	TokenNamestatic	
final	TokenNamefinal	
class	TokenNameclass	
MaxFieldLength	TokenNameIdentifier	 Max Field Length
{	TokenNameLBRACE	
private	TokenNameprivate	
int	TokenNameint	
limit	TokenNameIdentifier	 limit
;	TokenNameSEMICOLON	
private	TokenNameprivate	
String	TokenNameIdentifier	 String
name	TokenNameIdentifier	 name
;	TokenNameSEMICOLON	
/** * Private type-safe-enum-pattern constructor. * * @param name instance name * @param limit maximum field length */	TokenNameCOMMENT_JAVADOC	 Private type-safe-enum-pattern constructor. * @param name instance name @param limit maximum field length 
private	TokenNameprivate	
MaxFieldLength	TokenNameIdentifier	 Max Field Length
(	TokenNameLPAREN	
String	TokenNameIdentifier	 String
name	TokenNameIdentifier	 name
,	TokenNameCOMMA	
int	TokenNameint	
limit	TokenNameIdentifier	 limit
)	TokenNameRPAREN	
{	TokenNameLBRACE	
this	TokenNamethis	
.	TokenNameDOT	
name	TokenNameIdentifier	 name
=	TokenNameEQUAL	
name	TokenNameIdentifier	 name
;	TokenNameSEMICOLON	
this	TokenNamethis	
.	TokenNameDOT	
limit	TokenNameIdentifier	 limit
=	TokenNameEQUAL	
limit	TokenNameIdentifier	 limit
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
/** * Public constructor to allow users to specify the maximum field size limit. * * @param limit The maximum field length */	TokenNameCOMMENT_JAVADOC	 Public constructor to allow users to specify the maximum field size limit. * @param limit The maximum field length 
public	TokenNamepublic	
MaxFieldLength	TokenNameIdentifier	 Max Field Length
(	TokenNameLPAREN	
int	TokenNameint	
limit	TokenNameIdentifier	 limit
)	TokenNameRPAREN	
{	TokenNameLBRACE	
this	TokenNamethis	
(	TokenNameLPAREN	
"User-specified"	TokenNameStringLiteral	User-specified
,	TokenNameCOMMA	
limit	TokenNameIdentifier	 limit
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
public	TokenNamepublic	
int	TokenNameint	
getLimit	TokenNameIdentifier	 get Limit
(	TokenNameLPAREN	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
return	TokenNamereturn	
limit	TokenNameIdentifier	 limit
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
@	TokenNameAT	
Override	TokenNameIdentifier	 Override
public	TokenNamepublic	
String	TokenNameIdentifier	 String
toString	TokenNameIdentifier	 to String
(	TokenNameLPAREN	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
return	TokenNamereturn	
name	TokenNameIdentifier	 name
+	TokenNamePLUS	
":"	TokenNameStringLiteral	:
+	TokenNamePLUS	
limit	TokenNameIdentifier	 limit
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
/** Sets the maximum field length to {@link Integer#MAX_VALUE}. */	TokenNameCOMMENT_JAVADOC	 Sets the maximum field length to {@link Integer#MAX_VALUE}. 
public	TokenNamepublic	
static	TokenNamestatic	
final	TokenNamefinal	
MaxFieldLength	TokenNameIdentifier	 Max Field Length
UNLIMITED	TokenNameIdentifier	 UNLIMITED
=	TokenNameEQUAL	
new	TokenNamenew	
MaxFieldLength	TokenNameIdentifier	 Max Field Length
(	TokenNameLPAREN	
"UNLIMITED"	TokenNameStringLiteral	UNLIMITED
,	TokenNameCOMMA	
Integer	TokenNameIdentifier	 Integer
.	TokenNameDOT	
MAX_VALUE	TokenNameIdentifier	 MAX  VALUE
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
/** * Sets the maximum field length to * {@link #DEFAULT_MAX_FIELD_LENGTH} * */	TokenNameCOMMENT_JAVADOC	 Sets the maximum field length to {@link #DEFAULT_MAX_FIELD_LENGTH} 
public	TokenNamepublic	
static	TokenNamestatic	
final	TokenNamefinal	
MaxFieldLength	TokenNameIdentifier	 Max Field Length
LIMITED	TokenNameIdentifier	 LIMITED
=	TokenNameEQUAL	
new	TokenNamenew	
MaxFieldLength	TokenNameIdentifier	 Max Field Length
(	TokenNameLPAREN	
"LIMITED"	TokenNameStringLiteral	LIMITED
,	TokenNameCOMMA	
10000	TokenNameIntegerLiteral	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
/** If {@link #getReader} has been called (ie, this writer * is in near real-time mode), then after a merge * completes, this class can be invoked to warm the * reader on the newly merged segment, before the merge * commits. This is not required for near real-time * search, but will reduce search latency on opening a * new near real-time reader after a merge completes. * * @lucene.experimental * * <p><b>NOTE</b>: warm is called before any deletes have * been carried over to the merged segment. */	TokenNameCOMMENT_JAVADOC	 If {@link #getReader} has been called (ie, this writer is in near real-time mode), then after a merge completes, this class can be invoked to warm the reader on the newly merged segment, before the merge commits. This is not required for near real-time search, but will reduce search latency on opening a new near real-time reader after a merge completes. * @lucene.experimental * <p><b>NOTE</b>: warm is called before any deletes have been carried over to the merged segment. 
public	TokenNamepublic	
static	TokenNamestatic	
abstract	TokenNameabstract	
class	TokenNameclass	
IndexReaderWarmer	TokenNameIdentifier	 Index Reader Warmer
{	TokenNameLBRACE	
public	TokenNamepublic	
abstract	TokenNameabstract	
void	TokenNamevoid	
warm	TokenNameIdentifier	 warm
(	TokenNameLPAREN	
IndexReader	TokenNameIdentifier	 Index Reader
reader	TokenNameIdentifier	 reader
)	TokenNameRPAREN	
throws	TokenNamethrows	
IOException	TokenNameIdentifier	 IO Exception
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
/** * Set the merged segment warmer. See {@link IndexReaderWarmer}. * * @deprecated use * {@link IndexWriterConfig#setMergedSegmentWarmer} * instead. */	TokenNameCOMMENT_JAVADOC	 Set the merged segment warmer. See {@link IndexReaderWarmer}. * @deprecated use {@link IndexWriterConfig#setMergedSegmentWarmer} instead. 
@	TokenNameAT	
Deprecated	TokenNameIdentifier	 Deprecated
public	TokenNamepublic	
void	TokenNamevoid	
setMergedSegmentWarmer	TokenNameIdentifier	 set Merged Segment Warmer
(	TokenNameLPAREN	
IndexReaderWarmer	TokenNameIdentifier	 Index Reader Warmer
warmer	TokenNameIdentifier	 warmer
)	TokenNameRPAREN	
{	TokenNameLBRACE	
config	TokenNameIdentifier	 config
.	TokenNameDOT	
setMergedSegmentWarmer	TokenNameIdentifier	 set Merged Segment Warmer
(	TokenNameLPAREN	
warmer	TokenNameIdentifier	 warmer
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
/** * Returns the current merged segment warmer. See {@link IndexReaderWarmer}. * * @deprecated use {@link IndexWriterConfig#getMergedSegmentWarmer()} instead. */	TokenNameCOMMENT_JAVADOC	 Returns the current merged segment warmer. See {@link IndexReaderWarmer}. * @deprecated use {@link IndexWriterConfig#getMergedSegmentWarmer()} instead. 
@	TokenNameAT	
Deprecated	TokenNameIdentifier	 Deprecated
public	TokenNamepublic	
IndexReaderWarmer	TokenNameIdentifier	 Index Reader Warmer
getMergedSegmentWarmer	TokenNameIdentifier	 get Merged Segment Warmer
(	TokenNameLPAREN	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
return	TokenNamereturn	
config	TokenNameIdentifier	 config
.	TokenNameDOT	
getMergedSegmentWarmer	TokenNameIdentifier	 get Merged Segment Warmer
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
private	TokenNameprivate	
void	TokenNamevoid	
handleOOM	TokenNameIdentifier	 handle OOM
(	TokenNameLPAREN	
OutOfMemoryError	TokenNameIdentifier	 Out Of Memory Error
oom	TokenNameIdentifier	 oom
,	TokenNameCOMMA	
String	TokenNameIdentifier	 String
location	TokenNameIdentifier	 location
)	TokenNameRPAREN	
{	TokenNameLBRACE	
if	TokenNameif	
(	TokenNameLPAREN	
infoStream	TokenNameIdentifier	 info Stream
!=	TokenNameNOT_EQUAL	
null	TokenNamenull	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
message	TokenNameIdentifier	 message
(	TokenNameLPAREN	
"hit OutOfMemoryError inside "	TokenNameStringLiteral	hit OutOfMemoryError inside 
+	TokenNamePLUS	
location	TokenNameIdentifier	 location
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
hitOOM	TokenNameIdentifier	 hit OOM
=	TokenNameEQUAL	
true	TokenNametrue	
;	TokenNameSEMICOLON	
throw	TokenNamethrow	
oom	TokenNameIdentifier	 oom
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
// Used only by assert for testing. Current points: 	TokenNameCOMMENT_LINE	Used only by assert for testing. Current points: 
// startDoFlush 	TokenNameCOMMENT_LINE	startDoFlush 
// startCommitMerge 	TokenNameCOMMENT_LINE	startCommitMerge 
// startStartCommit 	TokenNameCOMMENT_LINE	startStartCommit 
// midStartCommit 	TokenNameCOMMENT_LINE	midStartCommit 
// midStartCommit2 	TokenNameCOMMENT_LINE	midStartCommit2 
// midStartCommitSuccess 	TokenNameCOMMENT_LINE	midStartCommitSuccess 
// finishStartCommit 	TokenNameCOMMENT_LINE	finishStartCommit 
// startCommitMergeDeletes 	TokenNameCOMMENT_LINE	startCommitMergeDeletes 
// startMergeInit 	TokenNameCOMMENT_LINE	startMergeInit 
// DocumentsWriter.ThreadState.init start 	TokenNameCOMMENT_LINE	DocumentsWriter.ThreadState.init start 
boolean	TokenNameboolean	
testPoint	TokenNameIdentifier	 test Point
(	TokenNameLPAREN	
String	TokenNameIdentifier	 String
name	TokenNameIdentifier	 name
)	TokenNameRPAREN	
{	TokenNameLBRACE	
return	TokenNamereturn	
true	TokenNametrue	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
synchronized	TokenNamesynchronized	
boolean	TokenNameboolean	
nrtIsCurrent	TokenNameIdentifier	 nrt Is Current
(	TokenNameLPAREN	
SegmentInfos	TokenNameIdentifier	 Segment Infos
infos	TokenNameIdentifier	 infos
)	TokenNameRPAREN	
{	TokenNameLBRACE	
//System.out.println("IW.nrtIsCurrent " + (infos.version == segmentInfos.version && !docWriter.anyChanges() && !bufferedDeletesStream.any())); 	TokenNameCOMMENT_LINE	System.out.println("IW.nrtIsCurrent " + (infos.version == segmentInfos.version && !docWriter.anyChanges() && !bufferedDeletesStream.any())); 
ensureOpen	TokenNameIdentifier	 ensure Open
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
return	TokenNamereturn	
infos	TokenNameIdentifier	 infos
.	TokenNameDOT	
version	TokenNameIdentifier	 version
==	TokenNameEQUAL_EQUAL	
segmentInfos	TokenNameIdentifier	 segment Infos
.	TokenNameDOT	
version	TokenNameIdentifier	 version
&&	TokenNameAND_AND	
!	TokenNameNOT	
docWriter	TokenNameIdentifier	 doc Writer
.	TokenNameDOT	
anyChanges	TokenNameIdentifier	 any Changes
(	TokenNameLPAREN	
)	TokenNameRPAREN	
&&	TokenNameAND_AND	
!	TokenNameNOT	
bufferedDeletesStream	TokenNameIdentifier	 buffered Deletes Stream
.	TokenNameDOT	
any	TokenNameIdentifier	 any
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
synchronized	TokenNamesynchronized	
boolean	TokenNameboolean	
isClosed	TokenNameIdentifier	 is Closed
(	TokenNameLPAREN	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
return	TokenNamereturn	
closed	TokenNameIdentifier	 closed
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
/** Expert: remove any index files that are no longer * used. * * <p> IndexWriter normally deletes unused files itself, * during indexing. However, on Windows, which disallows * deletion of open files, if there is a reader open on * the index then those files cannot be deleted. This is * fine, because IndexWriter will periodically retry * the deletion.</p> * * <p> However, IndexWriter doesn't try that often: only * on open, close, flushing a new segment, and finishing * a merge. If you don't do any of these actions with your * IndexWriter, you'll see the unused files linger. If * that's a problem, call this method to delete them * (once you've closed the open readers that were * preventing their deletion). * * <p> In addition, you can call this method to delete * unreferenced index commits. This might be useful if you * are using an {@link IndexDeletionPolicy} which holds * onto index commits until some criteria are met, but those * commits are no longer needed. Otherwise, those commits will * be deleted the next time commit() is called. */	TokenNameCOMMENT_JAVADOC	 Expert: remove any index files that are no longer used. * <p> IndexWriter normally deletes unused files itself, during indexing. However, on Windows, which disallows deletion of open files, if there is a reader open on the index then those files cannot be deleted. This is fine, because IndexWriter will periodically retry the deletion.</p> * <p> However, IndexWriter doesn't try that often: only on open, close, flushing a new segment, and finishing a merge. If you don't do any of these actions with your IndexWriter, you'll see the unused files linger. If that's a problem, call this method to delete them (once you've closed the open readers that were preventing their deletion). * <p> In addition, you can call this method to delete unreferenced index commits. This might be useful if you are using an {@link IndexDeletionPolicy} which holds onto index commits until some criteria are met, but those commits are no longer needed. Otherwise, those commits will be deleted the next time commit() is called. 
public	TokenNamepublic	
synchronized	TokenNamesynchronized	
void	TokenNamevoid	
deleteUnusedFiles	TokenNameIdentifier	 delete Unused Files
(	TokenNameLPAREN	
)	TokenNameRPAREN	
throws	TokenNamethrows	
IOException	TokenNameIdentifier	 IO Exception
{	TokenNameLBRACE	
ensureOpen	TokenNameIdentifier	 ensure Open
(	TokenNameLPAREN	
false	TokenNamefalse	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
deleter	TokenNameIdentifier	 deleter
.	TokenNameDOT	
deletePendingFiles	TokenNameIdentifier	 delete Pending Files
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
deleter	TokenNameIdentifier	 deleter
.	TokenNameDOT	
revisitPolicy	TokenNameIdentifier	 revisit Policy
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
// Called by DirectoryReader.doClose 	TokenNameCOMMENT_LINE	Called by DirectoryReader.doClose 
synchronized	TokenNamesynchronized	
void	TokenNamevoid	
deletePendingFiles	TokenNameIdentifier	 delete Pending Files
(	TokenNameLPAREN	
)	TokenNameRPAREN	
throws	TokenNamethrows	
IOException	TokenNameIdentifier	 IO Exception
{	TokenNameLBRACE	
deleter	TokenNameIdentifier	 deleter
.	TokenNameDOT	
deletePendingFiles	TokenNameIdentifier	 delete Pending Files
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
/** * Sets the {@link PayloadProcessorProvider} to use when merging payloads. * Note that the given <code>pcp</code> will be invoked for every segment that * is merged, not only external ones that are given through * {@link #addIndexes}. If you want only the payloads of the external segments * to be processed, you can return <code>null</code> whenever a * {@link PayloadProcessorProvider.ReaderPayloadProcessor} is requested for the {@link Directory} of the * {@link IndexWriter}. * <p> * The default is <code>null</code> which means payloads are processed * normally (copied) during segment merges. You can also unset it by passing * <code>null</code>. * <p> * <b>NOTE:</b> the set {@link PayloadProcessorProvider} will be in effect * immediately, potentially for already running merges too. If you want to be * sure it is used for further operations only, such as {@link #addIndexes} or * {@link #forceMerge}, you can call {@link #waitForMerges()} before. */	TokenNameCOMMENT_JAVADOC	 Sets the {@link PayloadProcessorProvider} to use when merging payloads. Note that the given <code>pcp</code> will be invoked for every segment that is merged, not only external ones that are given through {@link #addIndexes}. If you want only the payloads of the external segments to be processed, you can return <code>null</code> whenever a {@link PayloadProcessorProvider.ReaderPayloadProcessor} is requested for the {@link Directory} of the {@link IndexWriter}. <p> The default is <code>null</code> which means payloads are processed normally (copied) during segment merges. You can also unset it by passing <code>null</code>. <p> <b>NOTE:</b> the set {@link PayloadProcessorProvider} will be in effect immediately, potentially for already running merges too. If you want to be sure it is used for further operations only, such as {@link #addIndexes} or {@link #forceMerge}, you can call {@link #waitForMerges()} before. 
public	TokenNamepublic	
void	TokenNamevoid	
setPayloadProcessorProvider	TokenNameIdentifier	 set Payload Processor Provider
(	TokenNameLPAREN	
PayloadProcessorProvider	TokenNameIdentifier	 Payload Processor Provider
pcp	TokenNameIdentifier	 pcp
)	TokenNameRPAREN	
{	TokenNameLBRACE	
ensureOpen	TokenNameIdentifier	 ensure Open
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
payloadProcessorProvider	TokenNameIdentifier	 payload Processor Provider
=	TokenNameEQUAL	
pcp	TokenNameIdentifier	 pcp
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
/** * Returns the {@link PayloadProcessorProvider} that is used during segment * merges to process payloads. */	TokenNameCOMMENT_JAVADOC	 Returns the {@link PayloadProcessorProvider} that is used during segment merges to process payloads. 
public	TokenNamepublic	
PayloadProcessorProvider	TokenNameIdentifier	 Payload Processor Provider
getPayloadProcessorProvider	TokenNameIdentifier	 get Payload Processor Provider
(	TokenNameLPAREN	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
ensureOpen	TokenNameIdentifier	 ensure Open
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
return	TokenNamereturn	
payloadProcessorProvider	TokenNameIdentifier	 payload Processor Provider
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
// decides when flushes happen 	TokenNameCOMMENT_LINE	decides when flushes happen 
final	TokenNamefinal	
class	TokenNameclass	
FlushControl	TokenNameIdentifier	 Flush Control
{	TokenNameLBRACE	
private	TokenNameprivate	
boolean	TokenNameboolean	
flushPending	TokenNameIdentifier	 flush Pending
;	TokenNameSEMICOLON	
private	TokenNameprivate	
boolean	TokenNameboolean	
flushDeletes	TokenNameIdentifier	 flush Deletes
;	TokenNameSEMICOLON	
private	TokenNameprivate	
int	TokenNameint	
delCount	TokenNameIdentifier	 del Count
;	TokenNameSEMICOLON	
private	TokenNameprivate	
int	TokenNameint	
docCount	TokenNameIdentifier	 doc Count
;	TokenNameSEMICOLON	
private	TokenNameprivate	
boolean	TokenNameboolean	
flushing	TokenNameIdentifier	 flushing
;	TokenNameSEMICOLON	
private	TokenNameprivate	
synchronized	TokenNamesynchronized	
boolean	TokenNameboolean	
setFlushPending	TokenNameIdentifier	 set Flush Pending
(	TokenNameLPAREN	
String	TokenNameIdentifier	 String
reason	TokenNameIdentifier	 reason
,	TokenNameCOMMA	
boolean	TokenNameboolean	
doWait	TokenNameIdentifier	 do Wait
)	TokenNameRPAREN	
{	TokenNameLBRACE	
if	TokenNameif	
(	TokenNameLPAREN	
flushPending	TokenNameIdentifier	 flush Pending
||	TokenNameOR_OR	
flushing	TokenNameIdentifier	 flushing
)	TokenNameRPAREN	
{	TokenNameLBRACE	
if	TokenNameif	
(	TokenNameLPAREN	
doWait	TokenNameIdentifier	 do Wait
)	TokenNameRPAREN	
{	TokenNameLBRACE	
while	TokenNamewhile	
(	TokenNameLPAREN	
flushPending	TokenNameIdentifier	 flush Pending
||	TokenNameOR_OR	
flushing	TokenNameIdentifier	 flushing
)	TokenNameRPAREN	
{	TokenNameLBRACE	
try	TokenNametry	
{	TokenNameLBRACE	
wait	TokenNameIdentifier	 wait
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
catch	TokenNamecatch	
(	TokenNameLPAREN	
InterruptedException	TokenNameIdentifier	 Interrupted Exception
ie	TokenNameIdentifier	 ie
)	TokenNameRPAREN	
{	TokenNameLBRACE	
throw	TokenNamethrow	
new	TokenNamenew	
ThreadInterruptedException	TokenNameIdentifier	 Thread Interrupted Exception
(	TokenNameLPAREN	
ie	TokenNameIdentifier	 ie
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
}	TokenNameRBRACE	
}	TokenNameRBRACE	
return	TokenNamereturn	
false	TokenNamefalse	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
else	TokenNameelse	
{	TokenNameLBRACE	
if	TokenNameif	
(	TokenNameLPAREN	
infoStream	TokenNameIdentifier	 info Stream
!=	TokenNameNOT_EQUAL	
null	TokenNamenull	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
message	TokenNameIdentifier	 message
(	TokenNameLPAREN	
"now trigger flush reason="	TokenNameStringLiteral	now trigger flush reason=
+	TokenNamePLUS	
reason	TokenNameIdentifier	 reason
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
flushPending	TokenNameIdentifier	 flush Pending
=	TokenNameEQUAL	
true	TokenNametrue	
;	TokenNameSEMICOLON	
return	TokenNamereturn	
flushPending	TokenNameIdentifier	 flush Pending
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
}	TokenNameRBRACE	
public	TokenNamepublic	
synchronized	TokenNamesynchronized	
void	TokenNamevoid	
setFlushPendingNoWait	TokenNameIdentifier	 set Flush Pending No Wait
(	TokenNameLPAREN	
String	TokenNameIdentifier	 String
reason	TokenNameIdentifier	 reason
)	TokenNameRPAREN	
{	TokenNameLBRACE	
setFlushPending	TokenNameIdentifier	 set Flush Pending
(	TokenNameLPAREN	
reason	TokenNameIdentifier	 reason
,	TokenNameCOMMA	
false	TokenNamefalse	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
public	TokenNamepublic	
synchronized	TokenNamesynchronized	
boolean	TokenNameboolean	
getFlushPending	TokenNameIdentifier	 get Flush Pending
(	TokenNameLPAREN	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
return	TokenNamereturn	
flushPending	TokenNameIdentifier	 flush Pending
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
public	TokenNamepublic	
synchronized	TokenNamesynchronized	
boolean	TokenNameboolean	
getFlushDeletes	TokenNameIdentifier	 get Flush Deletes
(	TokenNameLPAREN	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
return	TokenNamereturn	
flushDeletes	TokenNameIdentifier	 flush Deletes
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
public	TokenNamepublic	
synchronized	TokenNamesynchronized	
void	TokenNamevoid	
clearFlushPending	TokenNameIdentifier	 clear Flush Pending
(	TokenNameLPAREN	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
if	TokenNameif	
(	TokenNameLPAREN	
infoStream	TokenNameIdentifier	 info Stream
!=	TokenNameNOT_EQUAL	
null	TokenNamenull	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
message	TokenNameIdentifier	 message
(	TokenNameLPAREN	
"clearFlushPending"	TokenNameStringLiteral	clearFlushPending
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
flushPending	TokenNameIdentifier	 flush Pending
=	TokenNameEQUAL	
false	TokenNamefalse	
;	TokenNameSEMICOLON	
flushDeletes	TokenNameIdentifier	 flush Deletes
=	TokenNameEQUAL	
false	TokenNamefalse	
;	TokenNameSEMICOLON	
docCount	TokenNameIdentifier	 doc Count
=	TokenNameEQUAL	
0	TokenNameIntegerLiteral	
;	TokenNameSEMICOLON	
notifyAll	TokenNameIdentifier	 notify All
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
public	TokenNamepublic	
synchronized	TokenNamesynchronized	
void	TokenNamevoid	
clearDeletes	TokenNameIdentifier	 clear Deletes
(	TokenNameLPAREN	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
delCount	TokenNameIdentifier	 del Count
=	TokenNameEQUAL	
0	TokenNameIntegerLiteral	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
public	TokenNamepublic	
synchronized	TokenNamesynchronized	
boolean	TokenNameboolean	
waitUpdate	TokenNameIdentifier	 wait Update
(	TokenNameLPAREN	
int	TokenNameint	
docInc	TokenNameIdentifier	 doc Inc
,	TokenNameCOMMA	
int	TokenNameint	
delInc	TokenNameIdentifier	 del Inc
)	TokenNameRPAREN	
{	TokenNameLBRACE	
return	TokenNamereturn	
waitUpdate	TokenNameIdentifier	 wait Update
(	TokenNameLPAREN	
docInc	TokenNameIdentifier	 doc Inc
,	TokenNameCOMMA	
delInc	TokenNameIdentifier	 del Inc
,	TokenNameCOMMA	
false	TokenNamefalse	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
public	TokenNamepublic	
synchronized	TokenNamesynchronized	
boolean	TokenNameboolean	
waitUpdate	TokenNameIdentifier	 wait Update
(	TokenNameLPAREN	
int	TokenNameint	
docInc	TokenNameIdentifier	 doc Inc
,	TokenNameCOMMA	
int	TokenNameint	
delInc	TokenNameIdentifier	 del Inc
,	TokenNameCOMMA	
boolean	TokenNameboolean	
skipWait	TokenNameIdentifier	 skip Wait
)	TokenNameRPAREN	
{	TokenNameLBRACE	
while	TokenNamewhile	
(	TokenNameLPAREN	
flushPending	TokenNameIdentifier	 flush Pending
)	TokenNameRPAREN	
{	TokenNameLBRACE	
try	TokenNametry	
{	TokenNameLBRACE	
wait	TokenNameIdentifier	 wait
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
catch	TokenNamecatch	
(	TokenNameLPAREN	
InterruptedException	TokenNameIdentifier	 Interrupted Exception
ie	TokenNameIdentifier	 ie
)	TokenNameRPAREN	
{	TokenNameLBRACE	
throw	TokenNamethrow	
new	TokenNamenew	
ThreadInterruptedException	TokenNameIdentifier	 Thread Interrupted Exception
(	TokenNameLPAREN	
ie	TokenNameIdentifier	 ie
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
}	TokenNameRBRACE	
docCount	TokenNameIdentifier	 doc Count
+=	TokenNamePLUS_EQUAL	
docInc	TokenNameIdentifier	 doc Inc
;	TokenNameSEMICOLON	
delCount	TokenNameIdentifier	 del Count
+=	TokenNamePLUS_EQUAL	
delInc	TokenNameIdentifier	 del Inc
;	TokenNameSEMICOLON	
// skipWait is only used when a thread is BOTH adding 	TokenNameCOMMENT_LINE	skipWait is only used when a thread is BOTH adding 
// a doc and buffering a del term, and, the adding of 	TokenNameCOMMENT_LINE	a doc and buffering a del term, and, the adding of 
// the doc already triggered a flush 	TokenNameCOMMENT_LINE	the doc already triggered a flush 
if	TokenNameif	
(	TokenNameLPAREN	
skipWait	TokenNameIdentifier	 skip Wait
)	TokenNameRPAREN	
{	TokenNameLBRACE	
return	TokenNamereturn	
false	TokenNamefalse	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
final	TokenNamefinal	
int	TokenNameint	
maxBufferedDocs	TokenNameIdentifier	 max Buffered Docs
=	TokenNameEQUAL	
config	TokenNameIdentifier	 config
.	TokenNameDOT	
getMaxBufferedDocs	TokenNameIdentifier	 get Max Buffered Docs
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
if	TokenNameif	
(	TokenNameLPAREN	
maxBufferedDocs	TokenNameIdentifier	 max Buffered Docs
!=	TokenNameNOT_EQUAL	
IndexWriterConfig	TokenNameIdentifier	 Index Writer Config
.	TokenNameDOT	
DISABLE_AUTO_FLUSH	TokenNameIdentifier	 DISABLE  AUTO  FLUSH
&&	TokenNameAND_AND	
docCount	TokenNameIdentifier	 doc Count
>=	TokenNameGREATER_EQUAL	
maxBufferedDocs	TokenNameIdentifier	 max Buffered Docs
)	TokenNameRPAREN	
{	TokenNameLBRACE	
return	TokenNamereturn	
setFlushPending	TokenNameIdentifier	 set Flush Pending
(	TokenNameLPAREN	
"maxBufferedDocs"	TokenNameStringLiteral	maxBufferedDocs
,	TokenNameCOMMA	
true	TokenNametrue	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
final	TokenNamefinal	
int	TokenNameint	
maxBufferedDeleteTerms	TokenNameIdentifier	 max Buffered Delete Terms
=	TokenNameEQUAL	
config	TokenNameIdentifier	 config
.	TokenNameDOT	
getMaxBufferedDeleteTerms	TokenNameIdentifier	 get Max Buffered Delete Terms
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
if	TokenNameif	
(	TokenNameLPAREN	
maxBufferedDeleteTerms	TokenNameIdentifier	 max Buffered Delete Terms
!=	TokenNameNOT_EQUAL	
IndexWriterConfig	TokenNameIdentifier	 Index Writer Config
.	TokenNameDOT	
DISABLE_AUTO_FLUSH	TokenNameIdentifier	 DISABLE  AUTO  FLUSH
&&	TokenNameAND_AND	
delCount	TokenNameIdentifier	 del Count
>=	TokenNameGREATER_EQUAL	
maxBufferedDeleteTerms	TokenNameIdentifier	 max Buffered Delete Terms
)	TokenNameRPAREN	
{	TokenNameLBRACE	
flushDeletes	TokenNameIdentifier	 flush Deletes
=	TokenNameEQUAL	
true	TokenNametrue	
;	TokenNameSEMICOLON	
return	TokenNamereturn	
setFlushPending	TokenNameIdentifier	 set Flush Pending
(	TokenNameLPAREN	
"maxBufferedDeleteTerms"	TokenNameStringLiteral	maxBufferedDeleteTerms
,	TokenNameCOMMA	
true	TokenNametrue	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
return	TokenNamereturn	
flushByRAMUsage	TokenNameIdentifier	 flush By RAM Usage
(	TokenNameLPAREN	
"add delete/doc"	TokenNameStringLiteral	add delete/doc
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
public	TokenNamepublic	
synchronized	TokenNamesynchronized	
boolean	TokenNameboolean	
flushByRAMUsage	TokenNameIdentifier	 flush By RAM Usage
(	TokenNameLPAREN	
String	TokenNameIdentifier	 String
reason	TokenNameIdentifier	 reason
)	TokenNameRPAREN	
{	TokenNameLBRACE	
final	TokenNamefinal	
double	TokenNamedouble	
ramBufferSizeMB	TokenNameIdentifier	 ram Buffer Size MB
=	TokenNameEQUAL	
config	TokenNameIdentifier	 config
.	TokenNameDOT	
getRAMBufferSizeMB	TokenNameIdentifier	 get RAM Buffer Size MB
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
if	TokenNameif	
(	TokenNameLPAREN	
ramBufferSizeMB	TokenNameIdentifier	 ram Buffer Size MB
!=	TokenNameNOT_EQUAL	
IndexWriterConfig	TokenNameIdentifier	 Index Writer Config
.	TokenNameDOT	
DISABLE_AUTO_FLUSH	TokenNameIdentifier	 DISABLE  AUTO  FLUSH
)	TokenNameRPAREN	
{	TokenNameLBRACE	
final	TokenNamefinal	
long	TokenNamelong	
limit	TokenNameIdentifier	 limit
=	TokenNameEQUAL	
(	TokenNameLPAREN	
long	TokenNamelong	
)	TokenNameRPAREN	
(	TokenNameLPAREN	
ramBufferSizeMB	TokenNameIdentifier	 ram Buffer Size MB
*	TokenNameMULTIPLY	
1024	TokenNameIntegerLiteral	
*	TokenNameMULTIPLY	
1024	TokenNameIntegerLiteral	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
long	TokenNamelong	
used	TokenNameIdentifier	 used
=	TokenNameEQUAL	
bufferedDeletesStream	TokenNameIdentifier	 buffered Deletes Stream
.	TokenNameDOT	
bytesUsed	TokenNameIdentifier	 bytes Used
(	TokenNameLPAREN	
)	TokenNameRPAREN	
+	TokenNamePLUS	
docWriter	TokenNameIdentifier	 doc Writer
.	TokenNameDOT	
bytesUsed	TokenNameIdentifier	 bytes Used
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
if	TokenNameif	
(	TokenNameLPAREN	
used	TokenNameIdentifier	 used
>=	TokenNameGREATER_EQUAL	
limit	TokenNameIdentifier	 limit
)	TokenNameRPAREN	
{	TokenNameLBRACE	
// DocumentsWriter may be able to free up some 	TokenNameCOMMENT_LINE	DocumentsWriter may be able to free up some 
// RAM: 	TokenNameCOMMENT_LINE	RAM: 
// Lock order: FC -> DW 	TokenNameCOMMENT_LINE	Lock order: FC -> DW 
docWriter	TokenNameIdentifier	 doc Writer
.	TokenNameDOT	
balanceRAM	TokenNameIdentifier	 balance RAM
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
used	TokenNameIdentifier	 used
=	TokenNameEQUAL	
bufferedDeletesStream	TokenNameIdentifier	 buffered Deletes Stream
.	TokenNameDOT	
bytesUsed	TokenNameIdentifier	 bytes Used
(	TokenNameLPAREN	
)	TokenNameRPAREN	
+	TokenNamePLUS	
docWriter	TokenNameIdentifier	 doc Writer
.	TokenNameDOT	
bytesUsed	TokenNameIdentifier	 bytes Used
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
if	TokenNameif	
(	TokenNameLPAREN	
used	TokenNameIdentifier	 used
>=	TokenNameGREATER_EQUAL	
limit	TokenNameIdentifier	 limit
)	TokenNameRPAREN	
{	TokenNameLBRACE	
return	TokenNamereturn	
setFlushPending	TokenNameIdentifier	 set Flush Pending
(	TokenNameLPAREN	
"ram full: "	TokenNameStringLiteral	ram full: 
+	TokenNamePLUS	
reason	TokenNameIdentifier	 reason
,	TokenNameCOMMA	
false	TokenNamefalse	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
}	TokenNameRBRACE	
}	TokenNameRBRACE	
return	TokenNamereturn	
false	TokenNamefalse	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
}	TokenNameRBRACE	
final	TokenNamefinal	
FlushControl	TokenNameIdentifier	 Flush Control
flushControl	TokenNameIdentifier	 flush Control
=	TokenNameEQUAL	
new	TokenNamenew	
FlushControl	TokenNameIdentifier	 Flush Control
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	

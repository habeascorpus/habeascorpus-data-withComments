package	TokenNamepackage	
org	TokenNameIdentifier	 org
.	TokenNameDOT	
apache	TokenNameIdentifier	 apache
.	TokenNameDOT	
lucene	TokenNameIdentifier	 lucene
.	TokenNameDOT	
facet	TokenNameIdentifier	 facet
.	TokenNameDOT	
search	TokenNameIdentifier	 search
.	TokenNameDOT	
sampling	TokenNameIdentifier	 sampling
;	TokenNameSEMICOLON	
import	TokenNameimport	
java	TokenNameIdentifier	 java
.	TokenNameDOT	
io	TokenNameIdentifier	 io
.	TokenNameDOT	
IOException	TokenNameIdentifier	 IO Exception
;	TokenNameSEMICOLON	
import	TokenNameimport	
org	TokenNameIdentifier	 org
.	TokenNameDOT	
apache	TokenNameIdentifier	 apache
.	TokenNameDOT	
lucene	TokenNameIdentifier	 lucene
.	TokenNameDOT	
index	TokenNameIdentifier	 index
.	TokenNameDOT	
IndexReader	TokenNameIdentifier	 Index Reader
;	TokenNameSEMICOLON	
import	TokenNameimport	
org	TokenNameIdentifier	 org
.	TokenNameDOT	
apache	TokenNameIdentifier	 apache
.	TokenNameDOT	
lucene	TokenNameIdentifier	 lucene
.	TokenNameDOT	
index	TokenNameIdentifier	 index
.	TokenNameDOT	
Term	TokenNameIdentifier	 Term
;	TokenNameSEMICOLON	
import	TokenNameimport	
org	TokenNameIdentifier	 org
.	TokenNameDOT	
apache	TokenNameIdentifier	 apache
.	TokenNameDOT	
lucene	TokenNameIdentifier	 lucene
.	TokenNameDOT	
index	TokenNameIdentifier	 index
.	TokenNameDOT	
TermDocs	TokenNameIdentifier	 Term Docs
;	TokenNameSEMICOLON	
import	TokenNameimport	
org	TokenNameIdentifier	 org
.	TokenNameDOT	
apache	TokenNameIdentifier	 apache
.	TokenNameDOT	
lucene	TokenNameIdentifier	 lucene
.	TokenNameDOT	
facet	TokenNameIdentifier	 facet
.	TokenNameDOT	
search	TokenNameIdentifier	 search
.	TokenNameDOT	
DrillDown	TokenNameIdentifier	 Drill Down
;	TokenNameSEMICOLON	
import	TokenNameimport	
org	TokenNameIdentifier	 org
.	TokenNameDOT	
apache	TokenNameIdentifier	 apache
.	TokenNameDOT	
lucene	TokenNameIdentifier	 lucene
.	TokenNameDOT	
facet	TokenNameIdentifier	 facet
.	TokenNameDOT	
search	TokenNameIdentifier	 search
.	TokenNameDOT	
ScoredDocIDs	TokenNameIdentifier	 Scored Doc I Ds
;	TokenNameSEMICOLON	
import	TokenNameimport	
org	TokenNameIdentifier	 org
.	TokenNameDOT	
apache	TokenNameIdentifier	 apache
.	TokenNameDOT	
lucene	TokenNameIdentifier	 lucene
.	TokenNameDOT	
facet	TokenNameIdentifier	 facet
.	TokenNameDOT	
search	TokenNameIdentifier	 search
.	TokenNameDOT	
ScoredDocIDsIterator	TokenNameIdentifier	 Scored Doc I Ds Iterator
;	TokenNameSEMICOLON	
import	TokenNameimport	
org	TokenNameIdentifier	 org
.	TokenNameDOT	
apache	TokenNameIdentifier	 apache
.	TokenNameDOT	
lucene	TokenNameIdentifier	 lucene
.	TokenNameDOT	
facet	TokenNameIdentifier	 facet
.	TokenNameDOT	
search	TokenNameIdentifier	 search
.	TokenNameDOT	
params	TokenNameIdentifier	 params
.	TokenNameDOT	
FacetSearchParams	TokenNameIdentifier	 Facet Search Params
;	TokenNameSEMICOLON	
import	TokenNameimport	
org	TokenNameIdentifier	 org
.	TokenNameDOT	
apache	TokenNameIdentifier	 apache
.	TokenNameDOT	
lucene	TokenNameIdentifier	 lucene
.	TokenNameDOT	
facet	TokenNameIdentifier	 facet
.	TokenNameDOT	
search	TokenNameIdentifier	 search
.	TokenNameDOT	
results	TokenNameIdentifier	 results
.	TokenNameDOT	
FacetResult	TokenNameIdentifier	 Facet Result
;	TokenNameSEMICOLON	
import	TokenNameimport	
org	TokenNameIdentifier	 org
.	TokenNameDOT	
apache	TokenNameIdentifier	 apache
.	TokenNameDOT	
lucene	TokenNameIdentifier	 lucene
.	TokenNameDOT	
facet	TokenNameIdentifier	 facet
.	TokenNameDOT	
search	TokenNameIdentifier	 search
.	TokenNameDOT	
results	TokenNameIdentifier	 results
.	TokenNameDOT	
FacetResultNode	TokenNameIdentifier	 Facet Result Node
;	TokenNameSEMICOLON	
import	TokenNameimport	
org	TokenNameIdentifier	 org
.	TokenNameDOT	
apache	TokenNameIdentifier	 apache
.	TokenNameDOT	
lucene	TokenNameIdentifier	 lucene
.	TokenNameDOT	
facet	TokenNameIdentifier	 facet
.	TokenNameDOT	
taxonomy	TokenNameIdentifier	 taxonomy
.	TokenNameDOT	
CategoryPath	TokenNameIdentifier	 Category Path
;	TokenNameSEMICOLON	
import	TokenNameimport	
org	TokenNameIdentifier	 org
.	TokenNameDOT	
apache	TokenNameIdentifier	 apache
.	TokenNameDOT	
lucene	TokenNameIdentifier	 lucene
.	TokenNameDOT	
facet	TokenNameIdentifier	 facet
.	TokenNameDOT	
taxonomy	TokenNameIdentifier	 taxonomy
.	TokenNameDOT	
TaxonomyReader	TokenNameIdentifier	 Taxonomy Reader
;	TokenNameSEMICOLON	
/** * Licensed to the Apache Software Foundation (ASF) under one or more * contributor license agreements. See the NOTICE file distributed with * this work for additional information regarding copyright ownership. * The ASF licenses this file to You under the Apache License, Version 2.0 * (the "License"); you may not use this file except in compliance with * the License. You may obtain a copy of the License at * * http://www.apache.org/licenses/LICENSE-2.0 * * Unless required by applicable law or agreed to in writing, software * distributed under the License is distributed on an "AS IS" BASIS, * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. * See the License for the specific language governing permissions and * limitations under the License. */	TokenNameCOMMENT_JAVADOC	 Licensed to the Apache Software Foundation (ASF) under one or more contributor license agreements. See the NOTICE file distributed with this work for additional information regarding copyright ownership. The ASF licenses this file to You under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with the License. You may obtain a copy of the License at * http://www.apache.org/licenses/LICENSE-2.0 * Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License. 
/** * Fix sampling results by counting the intersection between two lists: a * TermDocs (list of documents in a certain category) and a DocIdSetIterator * (list of documents matching the query). * * * @lucene.experimental */	TokenNameCOMMENT_JAVADOC	 Fix sampling results by counting the intersection between two lists: a TermDocs (list of documents in a certain category) and a DocIdSetIterator (list of documents matching the query). * @lucene.experimental 
// TODO (Facet): implement also an estimated fixing by ratio (taking into 	TokenNameCOMMENT_LINE	TODO (Facet): implement also an estimated fixing by ratio (taking into 
// account "translation" of counts!) 	TokenNameCOMMENT_LINE	account "translation" of counts!) 
class	TokenNameclass	
TakmiSampleFixer	TokenNameIdentifier	 Takmi Sample Fixer
implements	TokenNameimplements	
SampleFixer	TokenNameIdentifier	 Sample Fixer
{	TokenNameLBRACE	
private	TokenNameprivate	
TaxonomyReader	TokenNameIdentifier	 Taxonomy Reader
taxonomyReader	TokenNameIdentifier	 taxonomy Reader
;	TokenNameSEMICOLON	
private	TokenNameprivate	
IndexReader	TokenNameIdentifier	 Index Reader
indexReader	TokenNameIdentifier	 index Reader
;	TokenNameSEMICOLON	
private	TokenNameprivate	
FacetSearchParams	TokenNameIdentifier	 Facet Search Params
searchParams	TokenNameIdentifier	 search Params
;	TokenNameSEMICOLON	
public	TokenNamepublic	
TakmiSampleFixer	TokenNameIdentifier	 Takmi Sample Fixer
(	TokenNameLPAREN	
IndexReader	TokenNameIdentifier	 Index Reader
indexReader	TokenNameIdentifier	 index Reader
,	TokenNameCOMMA	
TaxonomyReader	TokenNameIdentifier	 Taxonomy Reader
taxonomyReader	TokenNameIdentifier	 taxonomy Reader
,	TokenNameCOMMA	
FacetSearchParams	TokenNameIdentifier	 Facet Search Params
searchParams	TokenNameIdentifier	 search Params
)	TokenNameRPAREN	
{	TokenNameLBRACE	
this	TokenNamethis	
.	TokenNameDOT	
indexReader	TokenNameIdentifier	 index Reader
=	TokenNameEQUAL	
indexReader	TokenNameIdentifier	 index Reader
;	TokenNameSEMICOLON	
this	TokenNamethis	
.	TokenNameDOT	
taxonomyReader	TokenNameIdentifier	 taxonomy Reader
=	TokenNameEQUAL	
taxonomyReader	TokenNameIdentifier	 taxonomy Reader
;	TokenNameSEMICOLON	
this	TokenNamethis	
.	TokenNameDOT	
searchParams	TokenNameIdentifier	 search Params
=	TokenNameEQUAL	
searchParams	TokenNameIdentifier	 search Params
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
public	TokenNamepublic	
void	TokenNamevoid	
fixResult	TokenNameIdentifier	 fix Result
(	TokenNameLPAREN	
ScoredDocIDs	TokenNameIdentifier	 Scored Doc I Ds
origDocIds	TokenNameIdentifier	 orig Doc Ids
,	TokenNameCOMMA	
FacetResult	TokenNameIdentifier	 Facet Result
fres	TokenNameIdentifier	 fres
)	TokenNameRPAREN	
throws	TokenNamethrows	
IOException	TokenNameIdentifier	 IO Exception
{	TokenNameLBRACE	
FacetResultNode	TokenNameIdentifier	 Facet Result Node
topRes	TokenNameIdentifier	 top Res
=	TokenNameEQUAL	
fres	TokenNameIdentifier	 fres
.	TokenNameDOT	
getFacetResultNode	TokenNameIdentifier	 get Facet Result Node
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
fixResultNode	TokenNameIdentifier	 fix Result Node
(	TokenNameLPAREN	
topRes	TokenNameIdentifier	 top Res
,	TokenNameCOMMA	
origDocIds	TokenNameIdentifier	 orig Doc Ids
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
/** * Fix result node count, and, recursively, fix all its children * * @param facetResNode * result node to be fixed * @param docIds * docids in effect * @throws IOException */	TokenNameCOMMENT_JAVADOC	 Fix result node count, and, recursively, fix all its children * @param facetResNode result node to be fixed @param docIds docids in effect @throws IOException 
private	TokenNameprivate	
void	TokenNamevoid	
fixResultNode	TokenNameIdentifier	 fix Result Node
(	TokenNameLPAREN	
FacetResultNode	TokenNameIdentifier	 Facet Result Node
facetResNode	TokenNameIdentifier	 facet Res Node
,	TokenNameCOMMA	
ScoredDocIDs	TokenNameIdentifier	 Scored Doc I Ds
docIds	TokenNameIdentifier	 doc Ids
)	TokenNameRPAREN	
throws	TokenNamethrows	
IOException	TokenNameIdentifier	 IO Exception
{	TokenNameLBRACE	
recount	TokenNameIdentifier	 recount
(	TokenNameLPAREN	
facetResNode	TokenNameIdentifier	 facet Res Node
,	TokenNameCOMMA	
docIds	TokenNameIdentifier	 doc Ids
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
for	TokenNamefor	
(	TokenNameLPAREN	
FacetResultNode	TokenNameIdentifier	 Facet Result Node
frn	TokenNameIdentifier	 frn
:	TokenNameCOLON	
facetResNode	TokenNameIdentifier	 facet Res Node
.	TokenNameDOT	
getSubResults	TokenNameIdentifier	 get Sub Results
(	TokenNameLPAREN	
)	TokenNameRPAREN	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
fixResultNode	TokenNameIdentifier	 fix Result Node
(	TokenNameLPAREN	
frn	TokenNameIdentifier	 frn
,	TokenNameCOMMA	
docIds	TokenNameIdentifier	 doc Ids
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
}	TokenNameRBRACE	
/** * Internal utility: recount for a facet result node * * @param fresNode * result node to be recounted * @param docIds * full set of matching documents. * @throws IOException */	TokenNameCOMMENT_JAVADOC	 Internal utility: recount for a facet result node * @param fresNode result node to be recounted @param docIds full set of matching documents. @throws IOException 
private	TokenNameprivate	
void	TokenNamevoid	
recount	TokenNameIdentifier	 recount
(	TokenNameLPAREN	
FacetResultNode	TokenNameIdentifier	 Facet Result Node
fresNode	TokenNameIdentifier	 fres Node
,	TokenNameCOMMA	
ScoredDocIDs	TokenNameIdentifier	 Scored Doc I Ds
docIds	TokenNameIdentifier	 doc Ids
)	TokenNameRPAREN	
throws	TokenNamethrows	
IOException	TokenNameIdentifier	 IO Exception
{	TokenNameLBRACE	
// TODO (Facet): change from void to return the new, smaller docSet, and use 	TokenNameCOMMENT_LINE	TODO (Facet): change from void to return the new, smaller docSet, and use 
// that for the children, as this will make their intersection ops faster. 	TokenNameCOMMENT_LINE	that for the children, as this will make their intersection ops faster. 
// can do this only when the new set is "sufficiently" smaller. 	TokenNameCOMMENT_LINE	can do this only when the new set is "sufficiently" smaller. 
/* We need the category's path name in order to do its recounting. * If it is missing, because the option to label only part of the * facet results was exercise, we need to calculate them anyway, so * in essence sampling with recounting spends some extra cycles for * labeling results for which labels are not required. */	TokenNameCOMMENT_BLOCK	 We need the category's path name in order to do its recounting. If it is missing, because the option to label only part of the facet results was exercise, we need to calculate them anyway, so in essence sampling with recounting spends some extra cycles for labeling results for which labels are not required. 
CategoryPath	TokenNameIdentifier	 Category Path
catPath	TokenNameIdentifier	 cat Path
=	TokenNameEQUAL	
fresNode	TokenNameIdentifier	 fres Node
.	TokenNameDOT	
getLabel	TokenNameIdentifier	 get Label
(	TokenNameLPAREN	
taxonomyReader	TokenNameIdentifier	 taxonomy Reader
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
// force labeling 	TokenNameCOMMENT_LINE	force labeling 
Term	TokenNameIdentifier	 Term
drillDownTerm	TokenNameIdentifier	 drill Down Term
=	TokenNameEQUAL	
DrillDown	TokenNameIdentifier	 Drill Down
.	TokenNameDOT	
term	TokenNameIdentifier	 term
(	TokenNameLPAREN	
searchParams	TokenNameIdentifier	 search Params
,	TokenNameCOMMA	
catPath	TokenNameIdentifier	 cat Path
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
int	TokenNameint	
updatedCount	TokenNameIdentifier	 updated Count
=	TokenNameEQUAL	
countIntersection	TokenNameIdentifier	 count Intersection
(	TokenNameLPAREN	
indexReader	TokenNameIdentifier	 index Reader
.	TokenNameDOT	
termDocs	TokenNameIdentifier	 term Docs
(	TokenNameLPAREN	
drillDownTerm	TokenNameIdentifier	 drill Down Term
)	TokenNameRPAREN	
,	TokenNameCOMMA	
docIds	TokenNameIdentifier	 doc Ids
.	TokenNameDOT	
iterator	TokenNameIdentifier	 iterator
(	TokenNameLPAREN	
)	TokenNameRPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
fresNode	TokenNameIdentifier	 fres Node
.	TokenNameDOT	
setValue	TokenNameIdentifier	 set Value
(	TokenNameLPAREN	
updatedCount	TokenNameIdentifier	 updated Count
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
/** * Count the size of the intersection between two lists: a TermDocs (list of * documents in a certain category) and a DocIdSetIterator (list of documents * matching a query). */	TokenNameCOMMENT_JAVADOC	 Count the size of the intersection between two lists: a TermDocs (list of documents in a certain category) and a DocIdSetIterator (list of documents matching a query). 
private	TokenNameprivate	
static	TokenNamestatic	
int	TokenNameint	
countIntersection	TokenNameIdentifier	 count Intersection
(	TokenNameLPAREN	
TermDocs	TokenNameIdentifier	 Term Docs
p1	TokenNameIdentifier	 p1
,	TokenNameCOMMA	
ScoredDocIDsIterator	TokenNameIdentifier	 Scored Doc I Ds Iterator
p2	TokenNameIdentifier	 p2
)	TokenNameRPAREN	
throws	TokenNamethrows	
IOException	TokenNameIdentifier	 IO Exception
{	TokenNameLBRACE	
// The documentation of of both TermDocs and DocIdSetIterator claim 	TokenNameCOMMENT_LINE	The documentation of of both TermDocs and DocIdSetIterator claim 
// that we must do next() before doc(). So we do, and if one of the 	TokenNameCOMMENT_LINE	that we must do next() before doc(). So we do, and if one of the 
// lists is empty, obviously return 0; 	TokenNameCOMMENT_LINE	lists is empty, obviously return 0; 
if	TokenNameif	
(	TokenNameLPAREN	
!	TokenNameNOT	
p1	TokenNameIdentifier	 p1
.	TokenNameDOT	
next	TokenNameIdentifier	 next
(	TokenNameLPAREN	
)	TokenNameRPAREN	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
return	TokenNamereturn	
0	TokenNameIntegerLiteral	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
if	TokenNameif	
(	TokenNameLPAREN	
!	TokenNameNOT	
p2	TokenNameIdentifier	 p2
.	TokenNameDOT	
next	TokenNameIdentifier	 next
(	TokenNameLPAREN	
)	TokenNameRPAREN	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
return	TokenNamereturn	
0	TokenNameIntegerLiteral	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
int	TokenNameint	
d1	TokenNameIdentifier	 d1
=	TokenNameEQUAL	
p1	TokenNameIdentifier	 p1
.	TokenNameDOT	
doc	TokenNameIdentifier	 doc
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
int	TokenNameint	
d2	TokenNameIdentifier	 d2
=	TokenNameEQUAL	
p2	TokenNameIdentifier	 p2
.	TokenNameDOT	
getDocID	TokenNameIdentifier	 get Doc ID
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
int	TokenNameint	
count	TokenNameIdentifier	 count
=	TokenNameEQUAL	
0	TokenNameIntegerLiteral	
;	TokenNameSEMICOLON	
for	TokenNamefor	
(	TokenNameLPAREN	
;	TokenNameSEMICOLON	
;	TokenNameSEMICOLON	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
if	TokenNameif	
(	TokenNameLPAREN	
d1	TokenNameIdentifier	 d1
==	TokenNameEQUAL_EQUAL	
d2	TokenNameIdentifier	 d2
)	TokenNameRPAREN	
{	TokenNameLBRACE	
++	TokenNamePLUS_PLUS	
count	TokenNameIdentifier	 count
;	TokenNameSEMICOLON	
if	TokenNameif	
(	TokenNameLPAREN	
!	TokenNameNOT	
p1	TokenNameIdentifier	 p1
.	TokenNameDOT	
next	TokenNameIdentifier	 next
(	TokenNameLPAREN	
)	TokenNameRPAREN	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
break	TokenNamebreak	
;	TokenNameSEMICOLON	
// end of list 1, nothing more in intersection 	TokenNameCOMMENT_LINE	end of list 1, nothing more in intersection 
}	TokenNameRBRACE	
d1	TokenNameIdentifier	 d1
=	TokenNameEQUAL	
p1	TokenNameIdentifier	 p1
.	TokenNameDOT	
doc	TokenNameIdentifier	 doc
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
if	TokenNameif	
(	TokenNameLPAREN	
!	TokenNameNOT	
advance	TokenNameIdentifier	 advance
(	TokenNameLPAREN	
p2	TokenNameIdentifier	 p2
,	TokenNameCOMMA	
d1	TokenNameIdentifier	 d1
)	TokenNameRPAREN	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
break	TokenNamebreak	
;	TokenNameSEMICOLON	
// end of list 2, nothing more in intersection 	TokenNameCOMMENT_LINE	end of list 2, nothing more in intersection 
}	TokenNameRBRACE	
d2	TokenNameIdentifier	 d2
=	TokenNameEQUAL	
p2	TokenNameIdentifier	 p2
.	TokenNameDOT	
getDocID	TokenNameIdentifier	 get Doc ID
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
else	TokenNameelse	
if	TokenNameif	
(	TokenNameLPAREN	
d1	TokenNameIdentifier	 d1
<	TokenNameLESS	
d2	TokenNameIdentifier	 d2
)	TokenNameRPAREN	
{	TokenNameLBRACE	
if	TokenNameif	
(	TokenNameLPAREN	
!	TokenNameNOT	
p1	TokenNameIdentifier	 p1
.	TokenNameDOT	
skipTo	TokenNameIdentifier	 skip To
(	TokenNameLPAREN	
d2	TokenNameIdentifier	 d2
)	TokenNameRPAREN	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
break	TokenNamebreak	
;	TokenNameSEMICOLON	
// end of list 1, nothing more in intersection 	TokenNameCOMMENT_LINE	end of list 1, nothing more in intersection 
}	TokenNameRBRACE	
d1	TokenNameIdentifier	 d1
=	TokenNameEQUAL	
p1	TokenNameIdentifier	 p1
.	TokenNameDOT	
doc	TokenNameIdentifier	 doc
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
else	TokenNameelse	
/* d1>d2 */	TokenNameCOMMENT_BLOCK	 d1>d2 
{	TokenNameLBRACE	
if	TokenNameif	
(	TokenNameLPAREN	
!	TokenNameNOT	
advance	TokenNameIdentifier	 advance
(	TokenNameLPAREN	
p2	TokenNameIdentifier	 p2
,	TokenNameCOMMA	
d1	TokenNameIdentifier	 d1
)	TokenNameRPAREN	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
break	TokenNamebreak	
;	TokenNameSEMICOLON	
// end of list 2, nothing more in intersection 	TokenNameCOMMENT_LINE	end of list 2, nothing more in intersection 
}	TokenNameRBRACE	
d2	TokenNameIdentifier	 d2
=	TokenNameEQUAL	
p2	TokenNameIdentifier	 p2
.	TokenNameDOT	
getDocID	TokenNameIdentifier	 get Doc ID
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
}	TokenNameRBRACE	
return	TokenNamereturn	
count	TokenNameIdentifier	 count
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
/** * utility: advance the iterator until finding (or exceeding) specific * document * * @param iterator * iterator being advanced * @param targetDoc * target of advancing * @return false if iterator exhausted, true otherwise. */	TokenNameCOMMENT_JAVADOC	 utility: advance the iterator until finding (or exceeding) specific document * @param iterator iterator being advanced @param targetDoc target of advancing @return false if iterator exhausted, true otherwise. 
private	TokenNameprivate	
static	TokenNamestatic	
boolean	TokenNameboolean	
advance	TokenNameIdentifier	 advance
(	TokenNameLPAREN	
ScoredDocIDsIterator	TokenNameIdentifier	 Scored Doc I Ds Iterator
iterator	TokenNameIdentifier	 iterator
,	TokenNameCOMMA	
int	TokenNameint	
targetDoc	TokenNameIdentifier	 target Doc
)	TokenNameRPAREN	
{	TokenNameLBRACE	
while	TokenNamewhile	
(	TokenNameLPAREN	
iterator	TokenNameIdentifier	 iterator
.	TokenNameDOT	
next	TokenNameIdentifier	 next
(	TokenNameLPAREN	
)	TokenNameRPAREN	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
if	TokenNameif	
(	TokenNameLPAREN	
iterator	TokenNameIdentifier	 iterator
.	TokenNameDOT	
getDocID	TokenNameIdentifier	 get Doc ID
(	TokenNameLPAREN	
)	TokenNameRPAREN	
>=	TokenNameGREATER_EQUAL	
targetDoc	TokenNameIdentifier	 target Doc
)	TokenNameRPAREN	
{	TokenNameLBRACE	
return	TokenNamereturn	
true	TokenNametrue	
;	TokenNameSEMICOLON	
// target reached 	TokenNameCOMMENT_LINE	target reached 
}	TokenNameRBRACE	
}	TokenNameRBRACE	
return	TokenNamereturn	
false	TokenNamefalse	
;	TokenNameSEMICOLON	
// exhausted 	TokenNameCOMMENT_LINE	exhausted 
}	TokenNameRBRACE	
}	TokenNameRBRACE	

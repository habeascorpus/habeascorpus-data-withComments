package	TokenNamepackage	
org	TokenNameIdentifier	 org
.	TokenNameDOT	
apache	TokenNameIdentifier	 apache
.	TokenNameDOT	
lucene	TokenNameIdentifier	 lucene
.	TokenNameDOT	
facet	TokenNameIdentifier	 facet
.	TokenNameDOT	
taxonomy	TokenNameIdentifier	 taxonomy
.	TokenNameDOT	
directory	TokenNameIdentifier	 directory
;	TokenNameSEMICOLON	
import	TokenNameimport	
java	TokenNameIdentifier	 java
.	TokenNameDOT	
io	TokenNameIdentifier	 io
.	TokenNameDOT	
BufferedInputStream	TokenNameIdentifier	 Buffered Input Stream
;	TokenNameSEMICOLON	
import	TokenNameimport	
java	TokenNameIdentifier	 java
.	TokenNameDOT	
io	TokenNameIdentifier	 io
.	TokenNameDOT	
BufferedOutputStream	TokenNameIdentifier	 Buffered Output Stream
;	TokenNameSEMICOLON	
import	TokenNameimport	
java	TokenNameIdentifier	 java
.	TokenNameDOT	
io	TokenNameIdentifier	 io
.	TokenNameDOT	
DataInputStream	TokenNameIdentifier	 Data Input Stream
;	TokenNameSEMICOLON	
import	TokenNameimport	
java	TokenNameIdentifier	 java
.	TokenNameDOT	
io	TokenNameIdentifier	 io
.	TokenNameDOT	
DataOutputStream	TokenNameIdentifier	 Data Output Stream
;	TokenNameSEMICOLON	
import	TokenNameimport	
java	TokenNameIdentifier	 java
.	TokenNameDOT	
io	TokenNameIdentifier	 io
.	TokenNameDOT	
File	TokenNameIdentifier	 File
;	TokenNameSEMICOLON	
import	TokenNameimport	
java	TokenNameIdentifier	 java
.	TokenNameDOT	
io	TokenNameIdentifier	 io
.	TokenNameDOT	
FileInputStream	TokenNameIdentifier	 File Input Stream
;	TokenNameSEMICOLON	
import	TokenNameimport	
java	TokenNameIdentifier	 java
.	TokenNameDOT	
io	TokenNameIdentifier	 io
.	TokenNameDOT	
FileNotFoundException	TokenNameIdentifier	 File Not Found Exception
;	TokenNameSEMICOLON	
import	TokenNameimport	
java	TokenNameIdentifier	 java
.	TokenNameDOT	
io	TokenNameIdentifier	 io
.	TokenNameDOT	
FileOutputStream	TokenNameIdentifier	 File Output Stream
;	TokenNameSEMICOLON	
import	TokenNameimport	
java	TokenNameIdentifier	 java
.	TokenNameDOT	
io	TokenNameIdentifier	 io
.	TokenNameDOT	
IOException	TokenNameIdentifier	 IO Exception
;	TokenNameSEMICOLON	
import	TokenNameimport	
java	TokenNameIdentifier	 java
.	TokenNameDOT	
util	TokenNameIdentifier	 util
.	TokenNameDOT	
HashMap	TokenNameIdentifier	 Hash Map
;	TokenNameSEMICOLON	
import	TokenNameimport	
java	TokenNameIdentifier	 java
.	TokenNameDOT	
util	TokenNameIdentifier	 util
.	TokenNameDOT	
Map	TokenNameIdentifier	 Map
;	TokenNameSEMICOLON	
import	TokenNameimport	
org	TokenNameIdentifier	 org
.	TokenNameDOT	
apache	TokenNameIdentifier	 apache
.	TokenNameDOT	
lucene	TokenNameIdentifier	 lucene
.	TokenNameDOT	
analysis	TokenNameIdentifier	 analysis
.	TokenNameDOT	
KeywordAnalyzer	TokenNameIdentifier	 Keyword Analyzer
;	TokenNameSEMICOLON	
import	TokenNameimport	
org	TokenNameIdentifier	 org
.	TokenNameDOT	
apache	TokenNameIdentifier	 apache
.	TokenNameDOT	
lucene	TokenNameIdentifier	 lucene
.	TokenNameDOT	
analysis	TokenNameIdentifier	 analysis
.	TokenNameDOT	
TokenStream	TokenNameIdentifier	 Token Stream
;	TokenNameSEMICOLON	
import	TokenNameimport	
org	TokenNameIdentifier	 org
.	TokenNameDOT	
apache	TokenNameIdentifier	 apache
.	TokenNameDOT	
lucene	TokenNameIdentifier	 lucene
.	TokenNameDOT	
analysis	TokenNameIdentifier	 analysis
.	TokenNameDOT	
tokenattributes	TokenNameIdentifier	 tokenattributes
.	TokenNameDOT	
PositionIncrementAttribute	TokenNameIdentifier	 Position Increment Attribute
;	TokenNameSEMICOLON	
import	TokenNameimport	
org	TokenNameIdentifier	 org
.	TokenNameDOT	
apache	TokenNameIdentifier	 apache
.	TokenNameDOT	
lucene	TokenNameIdentifier	 lucene
.	TokenNameDOT	
analysis	TokenNameIdentifier	 analysis
.	TokenNameDOT	
tokenattributes	TokenNameIdentifier	 tokenattributes
.	TokenNameDOT	
CharTermAttribute	TokenNameIdentifier	 Char Term Attribute
;	TokenNameSEMICOLON	
import	TokenNameimport	
org	TokenNameIdentifier	 org
.	TokenNameDOT	
apache	TokenNameIdentifier	 apache
.	TokenNameDOT	
lucene	TokenNameIdentifier	 lucene
.	TokenNameDOT	
document	TokenNameIdentifier	 document
.	TokenNameDOT	
Document	TokenNameIdentifier	 Document
;	TokenNameSEMICOLON	
import	TokenNameimport	
org	TokenNameIdentifier	 org
.	TokenNameDOT	
apache	TokenNameIdentifier	 apache
.	TokenNameDOT	
lucene	TokenNameIdentifier	 lucene
.	TokenNameDOT	
document	TokenNameIdentifier	 document
.	TokenNameDOT	
Field	TokenNameIdentifier	 Field
;	TokenNameSEMICOLON	
import	TokenNameimport	
org	TokenNameIdentifier	 org
.	TokenNameDOT	
apache	TokenNameIdentifier	 apache
.	TokenNameDOT	
lucene	TokenNameIdentifier	 lucene
.	TokenNameDOT	
document	TokenNameIdentifier	 document
.	TokenNameDOT	
Field	TokenNameIdentifier	 Field
.	TokenNameDOT	
Index	TokenNameIdentifier	 Index
;	TokenNameSEMICOLON	
import	TokenNameimport	
org	TokenNameIdentifier	 org
.	TokenNameDOT	
apache	TokenNameIdentifier	 apache
.	TokenNameDOT	
lucene	TokenNameIdentifier	 lucene
.	TokenNameDOT	
document	TokenNameIdentifier	 document
.	TokenNameDOT	
Field	TokenNameIdentifier	 Field
.	TokenNameDOT	
Store	TokenNameIdentifier	 Store
;	TokenNameSEMICOLON	
import	TokenNameimport	
org	TokenNameIdentifier	 org
.	TokenNameDOT	
apache	TokenNameIdentifier	 apache
.	TokenNameDOT	
lucene	TokenNameIdentifier	 lucene
.	TokenNameDOT	
index	TokenNameIdentifier	 index
.	TokenNameDOT	
CorruptIndexException	TokenNameIdentifier	 Corrupt Index Exception
;	TokenNameSEMICOLON	
import	TokenNameimport	
org	TokenNameIdentifier	 org
.	TokenNameDOT	
apache	TokenNameIdentifier	 apache
.	TokenNameDOT	
lucene	TokenNameIdentifier	 lucene
.	TokenNameDOT	
index	TokenNameIdentifier	 index
.	TokenNameDOT	
FieldInfo	TokenNameIdentifier	 Field Info
.	TokenNameDOT	
IndexOptions	TokenNameIdentifier	 Index Options
;	TokenNameSEMICOLON	
import	TokenNameimport	
org	TokenNameIdentifier	 org
.	TokenNameDOT	
apache	TokenNameIdentifier	 apache
.	TokenNameDOT	
lucene	TokenNameIdentifier	 lucene
.	TokenNameDOT	
index	TokenNameIdentifier	 index
.	TokenNameDOT	
IndexReader	TokenNameIdentifier	 Index Reader
;	TokenNameSEMICOLON	
import	TokenNameimport	
org	TokenNameIdentifier	 org
.	TokenNameDOT	
apache	TokenNameIdentifier	 apache
.	TokenNameDOT	
lucene	TokenNameIdentifier	 lucene
.	TokenNameDOT	
index	TokenNameIdentifier	 index
.	TokenNameDOT	
IndexWriter	TokenNameIdentifier	 Index Writer
;	TokenNameSEMICOLON	
import	TokenNameimport	
org	TokenNameIdentifier	 org
.	TokenNameDOT	
apache	TokenNameIdentifier	 apache
.	TokenNameDOT	
lucene	TokenNameIdentifier	 lucene
.	TokenNameDOT	
index	TokenNameIdentifier	 index
.	TokenNameDOT	
IndexWriterConfig	TokenNameIdentifier	 Index Writer Config
;	TokenNameSEMICOLON	
import	TokenNameimport	
org	TokenNameIdentifier	 org
.	TokenNameDOT	
apache	TokenNameIdentifier	 apache
.	TokenNameDOT	
lucene	TokenNameIdentifier	 lucene
.	TokenNameDOT	
index	TokenNameIdentifier	 index
.	TokenNameDOT	
IndexWriterConfig	TokenNameIdentifier	 Index Writer Config
.	TokenNameDOT	
OpenMode	TokenNameIdentifier	 Open Mode
;	TokenNameSEMICOLON	
import	TokenNameimport	
org	TokenNameIdentifier	 org
.	TokenNameDOT	
apache	TokenNameIdentifier	 apache
.	TokenNameDOT	
lucene	TokenNameIdentifier	 lucene
.	TokenNameDOT	
index	TokenNameIdentifier	 index
.	TokenNameDOT	
LogByteSizeMergePolicy	TokenNameIdentifier	 Log Byte Size Merge Policy
;	TokenNameSEMICOLON	
import	TokenNameimport	
org	TokenNameIdentifier	 org
.	TokenNameDOT	
apache	TokenNameIdentifier	 apache
.	TokenNameDOT	
lucene	TokenNameIdentifier	 lucene
.	TokenNameDOT	
index	TokenNameIdentifier	 index
.	TokenNameDOT	
SegmentInfos	TokenNameIdentifier	 Segment Infos
;	TokenNameSEMICOLON	
import	TokenNameimport	
org	TokenNameIdentifier	 org
.	TokenNameDOT	
apache	TokenNameIdentifier	 apache
.	TokenNameDOT	
lucene	TokenNameIdentifier	 lucene
.	TokenNameDOT	
index	TokenNameIdentifier	 index
.	TokenNameDOT	
Term	TokenNameIdentifier	 Term
;	TokenNameSEMICOLON	
import	TokenNameimport	
org	TokenNameIdentifier	 org
.	TokenNameDOT	
apache	TokenNameIdentifier	 apache
.	TokenNameDOT	
lucene	TokenNameIdentifier	 lucene
.	TokenNameDOT	
index	TokenNameIdentifier	 index
.	TokenNameDOT	
TermDocs	TokenNameIdentifier	 Term Docs
;	TokenNameSEMICOLON	
import	TokenNameimport	
org	TokenNameIdentifier	 org
.	TokenNameDOT	
apache	TokenNameIdentifier	 apache
.	TokenNameDOT	
lucene	TokenNameIdentifier	 lucene
.	TokenNameDOT	
index	TokenNameIdentifier	 index
.	TokenNameDOT	
TermEnum	TokenNameIdentifier	 Term Enum
;	TokenNameSEMICOLON	
import	TokenNameimport	
org	TokenNameIdentifier	 org
.	TokenNameDOT	
apache	TokenNameIdentifier	 apache
.	TokenNameDOT	
lucene	TokenNameIdentifier	 lucene
.	TokenNameDOT	
index	TokenNameIdentifier	 index
.	TokenNameDOT	
TieredMergePolicy	TokenNameIdentifier	 Tiered Merge Policy
;	TokenNameSEMICOLON	
import	TokenNameimport	
org	TokenNameIdentifier	 org
.	TokenNameDOT	
apache	TokenNameIdentifier	 apache
.	TokenNameDOT	
lucene	TokenNameIdentifier	 lucene
.	TokenNameDOT	
store	TokenNameIdentifier	 store
.	TokenNameDOT	
AlreadyClosedException	TokenNameIdentifier	 Already Closed Exception
;	TokenNameSEMICOLON	
import	TokenNameimport	
org	TokenNameIdentifier	 org
.	TokenNameDOT	
apache	TokenNameIdentifier	 apache
.	TokenNameDOT	
lucene	TokenNameIdentifier	 lucene
.	TokenNameDOT	
store	TokenNameIdentifier	 store
.	TokenNameDOT	
Directory	TokenNameIdentifier	 Directory
;	TokenNameSEMICOLON	
import	TokenNameimport	
org	TokenNameIdentifier	 org
.	TokenNameDOT	
apache	TokenNameIdentifier	 apache
.	TokenNameDOT	
lucene	TokenNameIdentifier	 lucene
.	TokenNameDOT	
store	TokenNameIdentifier	 store
.	TokenNameDOT	
LockObtainFailedException	TokenNameIdentifier	 Lock Obtain Failed Exception
;	TokenNameSEMICOLON	
import	TokenNameimport	
org	TokenNameIdentifier	 org
.	TokenNameDOT	
apache	TokenNameIdentifier	 apache
.	TokenNameDOT	
lucene	TokenNameIdentifier	 lucene
.	TokenNameDOT	
store	TokenNameIdentifier	 store
.	TokenNameDOT	
NativeFSLockFactory	TokenNameIdentifier	 Native FS Lock Factory
;	TokenNameSEMICOLON	
import	TokenNameimport	
org	TokenNameIdentifier	 org
.	TokenNameDOT	
apache	TokenNameIdentifier	 apache
.	TokenNameDOT	
lucene	TokenNameIdentifier	 lucene
.	TokenNameDOT	
store	TokenNameIdentifier	 store
.	TokenNameDOT	
SimpleFSLockFactory	TokenNameIdentifier	 Simple FS Lock Factory
;	TokenNameSEMICOLON	
import	TokenNameimport	
org	TokenNameIdentifier	 org
.	TokenNameDOT	
apache	TokenNameIdentifier	 apache
.	TokenNameDOT	
lucene	TokenNameIdentifier	 lucene
.	TokenNameDOT	
util	TokenNameIdentifier	 util
.	TokenNameDOT	
Version	TokenNameIdentifier	 Version
;	TokenNameSEMICOLON	
import	TokenNameimport	
org	TokenNameIdentifier	 org
.	TokenNameDOT	
apache	TokenNameIdentifier	 apache
.	TokenNameDOT	
lucene	TokenNameIdentifier	 lucene
.	TokenNameDOT	
facet	TokenNameIdentifier	 facet
.	TokenNameDOT	
taxonomy	TokenNameIdentifier	 taxonomy
.	TokenNameDOT	
CategoryPath	TokenNameIdentifier	 Category Path
;	TokenNameSEMICOLON	
import	TokenNameimport	
org	TokenNameIdentifier	 org
.	TokenNameDOT	
apache	TokenNameIdentifier	 apache
.	TokenNameDOT	
lucene	TokenNameIdentifier	 lucene
.	TokenNameDOT	
facet	TokenNameIdentifier	 facet
.	TokenNameDOT	
taxonomy	TokenNameIdentifier	 taxonomy
.	TokenNameDOT	
TaxonomyReader	TokenNameIdentifier	 Taxonomy Reader
;	TokenNameSEMICOLON	
import	TokenNameimport	
org	TokenNameIdentifier	 org
.	TokenNameDOT	
apache	TokenNameIdentifier	 apache
.	TokenNameDOT	
lucene	TokenNameIdentifier	 lucene
.	TokenNameDOT	
facet	TokenNameIdentifier	 facet
.	TokenNameDOT	
taxonomy	TokenNameIdentifier	 taxonomy
.	TokenNameDOT	
TaxonomyWriter	TokenNameIdentifier	 Taxonomy Writer
;	TokenNameSEMICOLON	
import	TokenNameimport	
org	TokenNameIdentifier	 org
.	TokenNameDOT	
apache	TokenNameIdentifier	 apache
.	TokenNameDOT	
lucene	TokenNameIdentifier	 lucene
.	TokenNameDOT	
facet	TokenNameIdentifier	 facet
.	TokenNameDOT	
taxonomy	TokenNameIdentifier	 taxonomy
.	TokenNameDOT	
writercache	TokenNameIdentifier	 writercache
.	TokenNameDOT	
TaxonomyWriterCache	TokenNameIdentifier	 Taxonomy Writer Cache
;	TokenNameSEMICOLON	
import	TokenNameimport	
org	TokenNameIdentifier	 org
.	TokenNameDOT	
apache	TokenNameIdentifier	 apache
.	TokenNameDOT	
lucene	TokenNameIdentifier	 lucene
.	TokenNameDOT	
facet	TokenNameIdentifier	 facet
.	TokenNameDOT	
taxonomy	TokenNameIdentifier	 taxonomy
.	TokenNameDOT	
writercache	TokenNameIdentifier	 writercache
.	TokenNameDOT	
cl2o	TokenNameIdentifier	 cl2o
.	TokenNameDOT	
Cl2oTaxonomyWriterCache	TokenNameIdentifier	 Cl2o Taxonomy Writer Cache
;	TokenNameSEMICOLON	
import	TokenNameimport	
org	TokenNameIdentifier	 org
.	TokenNameDOT	
apache	TokenNameIdentifier	 apache
.	TokenNameDOT	
lucene	TokenNameIdentifier	 lucene
.	TokenNameDOT	
facet	TokenNameIdentifier	 facet
.	TokenNameDOT	
taxonomy	TokenNameIdentifier	 taxonomy
.	TokenNameDOT	
writercache	TokenNameIdentifier	 writercache
.	TokenNameDOT	
lru	TokenNameIdentifier	 lru
.	TokenNameDOT	
LruTaxonomyWriterCache	TokenNameIdentifier	 Lru Taxonomy Writer Cache
;	TokenNameSEMICOLON	
/** * Licensed to the Apache Software Foundation (ASF) under one or more * contributor license agreements. See the NOTICE file distributed with * this work for additional information regarding copyright ownership. * The ASF licenses this file to You under the Apache License, Version 2.0 * (the "License"); you may not use this file except in compliance with * the License. You may obtain a copy of the License at * * http://www.apache.org/licenses/LICENSE-2.0 * * Unless required by applicable law or agreed to in writing, software * distributed under the License is distributed on an "AS IS" BASIS, * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. * See the License for the specific language governing permissions and * limitations under the License. */	TokenNameCOMMENT_JAVADOC	 Licensed to the Apache Software Foundation (ASF) under one or more contributor license agreements. See the NOTICE file distributed with this work for additional information regarding copyright ownership. The ASF licenses this file to You under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with the License. You may obtain a copy of the License at * http://www.apache.org/licenses/LICENSE-2.0 * Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License. 
/** * {@link TaxonomyWriter} which uses a {@link Directory} to store the taxonomy * information on disk, and keeps an additional in-memory cache of some or all * categories. * <p> * In addition to the permanently-stored information in the {@link Directory}, * efficiency dictates that we also keep an in-memory cache of <B>recently * seen</B> or <B>all</B> categories, so that we do not need to go back to disk * for every category addition to see which ordinal this category already has, * if any. A {@link TaxonomyWriterCache} object determines the specific caching * algorithm used. * <p> * This class offers some hooks for extending classes to control the * {@link IndexWriter} instance that is used. See {@link #openIndexWriter}. * * @lucene.experimental */	TokenNameCOMMENT_JAVADOC	 {@link TaxonomyWriter} which uses a {@link Directory} to store the taxonomy information on disk, and keeps an additional in-memory cache of some or all categories. <p> In addition to the permanently-stored information in the {@link Directory}, efficiency dictates that we also keep an in-memory cache of <B>recently seen</B> or <B>all</B> categories, so that we do not need to go back to disk for every category addition to see which ordinal this category already has, if any. A {@link TaxonomyWriterCache} object determines the specific caching algorithm used. <p> This class offers some hooks for extending classes to control the {@link IndexWriter} instance that is used. See {@link #openIndexWriter}. * @lucene.experimental 
public	TokenNamepublic	
class	TokenNameclass	
DirectoryTaxonomyWriter	TokenNameIdentifier	 Directory Taxonomy Writer
implements	TokenNameimplements	
TaxonomyWriter	TokenNameIdentifier	 Taxonomy Writer
{	TokenNameLBRACE	
/** * Property name of user commit data that contains the creation time of a * taxonomy index. * <p> * Applications should not use this property in their commit data because it * will be overridden by this taxonomy writer. */	TokenNameCOMMENT_JAVADOC	 Property name of user commit data that contains the creation time of a taxonomy index. <p> Applications should not use this property in their commit data because it will be overridden by this taxonomy writer. 
public	TokenNamepublic	
static	TokenNamestatic	
final	TokenNamefinal	
String	TokenNameIdentifier	 String
INDEX_CREATE_TIME	TokenNameIdentifier	 INDEX  CREATE  TIME
=	TokenNameEQUAL	
"index.create.time"	TokenNameStringLiteral	index.create.time
;	TokenNameSEMICOLON	
private	TokenNameprivate	
IndexWriter	TokenNameIdentifier	 Index Writer
indexWriter	TokenNameIdentifier	 index Writer
;	TokenNameSEMICOLON	
private	TokenNameprivate	
int	TokenNameint	
nextID	TokenNameIdentifier	 next ID
;	TokenNameSEMICOLON	
private	TokenNameprivate	
char	TokenNamechar	
delimiter	TokenNameIdentifier	 delimiter
=	TokenNameEQUAL	
Consts	TokenNameIdentifier	 Consts
.	TokenNameDOT	
DEFAULT_DELIMITER	TokenNameIdentifier	 DEFAULT  DELIMITER
;	TokenNameSEMICOLON	
private	TokenNameprivate	
SinglePositionTokenStream	TokenNameIdentifier	 Single Position Token Stream
parentStream	TokenNameIdentifier	 parent Stream
=	TokenNameEQUAL	
new	TokenNamenew	
SinglePositionTokenStream	TokenNameIdentifier	 Single Position Token Stream
(	TokenNameLPAREN	
Consts	TokenNameIdentifier	 Consts
.	TokenNameDOT	
PAYLOAD_PARENT	TokenNameIdentifier	 PAYLOAD  PARENT
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
private	TokenNameprivate	
Field	TokenNameIdentifier	 Field
parentStreamField	TokenNameIdentifier	 parent Stream Field
;	TokenNameSEMICOLON	
private	TokenNameprivate	
Field	TokenNameIdentifier	 Field
fullPathField	TokenNameIdentifier	 full Path Field
;	TokenNameSEMICOLON	
private	TokenNameprivate	
TaxonomyWriterCache	TokenNameIdentifier	 Taxonomy Writer Cache
cache	TokenNameIdentifier	 cache
;	TokenNameSEMICOLON	
/** * We call the cache "complete" if we know that every category in our * taxonomy is in the cache. When the cache is <B>not</B> complete, and * we can't find a category in the cache, we still need to look for it * in the on-disk index; Therefore when the cache is not complete, we * need to open a "reader" to the taxonomy index. * The cache becomes incomplete if it was never filled with the existing * categories, or if a put() to the cache ever returned true (meaning * that some of the cached data was cleared). */	TokenNameCOMMENT_JAVADOC	 We call the cache "complete" if we know that every category in our taxonomy is in the cache. When the cache is <B>not</B> complete, and we can't find a category in the cache, we still need to look for it in the on-disk index; Therefore when the cache is not complete, we need to open a "reader" to the taxonomy index. The cache becomes incomplete if it was never filled with the existing categories, or if a put() to the cache ever returned true (meaning that some of the cached data was cleared). 
private	TokenNameprivate	
boolean	TokenNameboolean	
cacheIsComplete	TokenNameIdentifier	 cache Is Complete
;	TokenNameSEMICOLON	
private	TokenNameprivate	
IndexReader	TokenNameIdentifier	 Index Reader
reader	TokenNameIdentifier	 reader
;	TokenNameSEMICOLON	
private	TokenNameprivate	
int	TokenNameint	
cacheMisses	TokenNameIdentifier	 cache Misses
;	TokenNameSEMICOLON	
/** Records the taxonomy index creation time. */	TokenNameCOMMENT_JAVADOC	 Records the taxonomy index creation time. 
private	TokenNameprivate	
final	TokenNamefinal	
String	TokenNameIdentifier	 String
createTime	TokenNameIdentifier	 create Time
;	TokenNameSEMICOLON	
/** Reads the commit data from a Directory. */	TokenNameCOMMENT_JAVADOC	 Reads the commit data from a Directory. 
private	TokenNameprivate	
static	TokenNamestatic	
Map	TokenNameIdentifier	 Map
<	TokenNameLESS	
String	TokenNameIdentifier	 String
,	TokenNameCOMMA	
String	TokenNameIdentifier	 String
>	TokenNameGREATER	
readCommitData	TokenNameIdentifier	 read Commit Data
(	TokenNameLPAREN	
Directory	TokenNameIdentifier	 Directory
dir	TokenNameIdentifier	 dir
)	TokenNameRPAREN	
throws	TokenNamethrows	
IOException	TokenNameIdentifier	 IO Exception
{	TokenNameLBRACE	
SegmentInfos	TokenNameIdentifier	 Segment Infos
infos	TokenNameIdentifier	 infos
=	TokenNameEQUAL	
new	TokenNamenew	
SegmentInfos	TokenNameIdentifier	 Segment Infos
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
infos	TokenNameIdentifier	 infos
.	TokenNameDOT	
read	TokenNameIdentifier	 read
(	TokenNameLPAREN	
dir	TokenNameIdentifier	 dir
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
return	TokenNamereturn	
infos	TokenNameIdentifier	 infos
.	TokenNameDOT	
getUserData	TokenNameIdentifier	 get User Data
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
/** * setDelimiter changes the character that the taxonomy uses in its internal * storage as a delimiter between category components. Do not use this * method unless you really know what you are doing. It has nothing to do * with whatever character the application may be using to represent * categories for its own use. * <P> * If you do use this method, make sure you call it before any other methods * that actually queries the taxonomy. Moreover, make sure you always pass * the same delimiter for all LuceneTaxonomyWriter and LuceneTaxonomyReader * objects you create for the same directory. */	TokenNameCOMMENT_JAVADOC	 setDelimiter changes the character that the taxonomy uses in its internal storage as a delimiter between category components. Do not use this method unless you really know what you are doing. It has nothing to do with whatever character the application may be using to represent categories for its own use. <P> If you do use this method, make sure you call it before any other methods that actually queries the taxonomy. Moreover, make sure you always pass the same delimiter for all LuceneTaxonomyWriter and LuceneTaxonomyReader objects you create for the same directory. 
public	TokenNamepublic	
void	TokenNamevoid	
setDelimiter	TokenNameIdentifier	 set Delimiter
(	TokenNameLPAREN	
char	TokenNamechar	
delimiter	TokenNameIdentifier	 delimiter
)	TokenNameRPAREN	
{	TokenNameLBRACE	
ensureOpen	TokenNameIdentifier	 ensure Open
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
this	TokenNamethis	
.	TokenNameDOT	
delimiter	TokenNameIdentifier	 delimiter
=	TokenNameEQUAL	
delimiter	TokenNameIdentifier	 delimiter
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
/** * Forcibly unlocks the taxonomy in the named directory. * <P> * Caution: this should only be used by failure recovery code, when it is * known that no other process nor thread is in fact currently accessing * this taxonomy. * <P> * This method is unnecessary if your {@link Directory} uses a * {@link NativeFSLockFactory} instead of the default * {@link SimpleFSLockFactory}. When the "native" lock is used, a lock * does not stay behind forever when the process using it dies. */	TokenNameCOMMENT_JAVADOC	 Forcibly unlocks the taxonomy in the named directory. <P> Caution: this should only be used by failure recovery code, when it is known that no other process nor thread is in fact currently accessing this taxonomy. <P> This method is unnecessary if your {@link Directory} uses a {@link NativeFSLockFactory} instead of the default {@link SimpleFSLockFactory}. When the "native" lock is used, a lock does not stay behind forever when the process using it dies. 
public	TokenNamepublic	
static	TokenNamestatic	
void	TokenNamevoid	
unlock	TokenNameIdentifier	 unlock
(	TokenNameLPAREN	
Directory	TokenNameIdentifier	 Directory
directory	TokenNameIdentifier	 directory
)	TokenNameRPAREN	
throws	TokenNamethrows	
IOException	TokenNameIdentifier	 IO Exception
{	TokenNameLBRACE	
IndexWriter	TokenNameIdentifier	 Index Writer
.	TokenNameDOT	
unlock	TokenNameIdentifier	 unlock
(	TokenNameLPAREN	
directory	TokenNameIdentifier	 directory
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
/** * Construct a Taxonomy writer. * * @param directory * The {@link Directory} in which to store the taxonomy. Note that * the taxonomy is written directly to that directory (not to a * subdirectory of it). * @param openMode * Specifies how to open a taxonomy for writing: <code>APPEND</code> * means open an existing index for append (failing if the index does * not yet exist). <code>CREATE</code> means create a new index (first * deleting the old one if it already existed). * <code>APPEND_OR_CREATE</code> appends to an existing index if there * is one, otherwise it creates a new index. * @param cache * A {@link TaxonomyWriterCache} implementation which determines * the in-memory caching policy. See for example * {@link LruTaxonomyWriterCache} and {@link Cl2oTaxonomyWriterCache}. * If null or missing, {@link #defaultTaxonomyWriterCache()} is used. * @throws CorruptIndexException * if the taxonomy is corrupted. * @throws LockObtainFailedException * if the taxonomy is locked by another writer. If it is known * that no other concurrent writer is active, the lock might * have been left around by an old dead process, and should be * removed using {@link #unlock(Directory)}. * @throws IOException * if another error occurred. */	TokenNameCOMMENT_JAVADOC	 Construct a Taxonomy writer. * @param directory The {@link Directory} in which to store the taxonomy. Note that the taxonomy is written directly to that directory (not to a subdirectory of it). @param openMode Specifies how to open a taxonomy for writing: <code>APPEND</code> means open an existing index for append (failing if the index does not yet exist). <code>CREATE</code> means create a new index (first deleting the old one if it already existed). <code>APPEND_OR_CREATE</code> appends to an existing index if there is one, otherwise it creates a new index. @param cache A {@link TaxonomyWriterCache} implementation which determines the in-memory caching policy. See for example {@link LruTaxonomyWriterCache} and {@link Cl2oTaxonomyWriterCache}. If null or missing, {@link #defaultTaxonomyWriterCache()} is used. @throws CorruptIndexException if the taxonomy is corrupted. @throws LockObtainFailedException if the taxonomy is locked by another writer. If it is known that no other concurrent writer is active, the lock might have been left around by an old dead process, and should be removed using {@link #unlock(Directory)}. @throws IOException if another error occurred. 
public	TokenNamepublic	
DirectoryTaxonomyWriter	TokenNameIdentifier	 Directory Taxonomy Writer
(	TokenNameLPAREN	
Directory	TokenNameIdentifier	 Directory
directory	TokenNameIdentifier	 directory
,	TokenNameCOMMA	
OpenMode	TokenNameIdentifier	 Open Mode
openMode	TokenNameIdentifier	 open Mode
,	TokenNameCOMMA	
TaxonomyWriterCache	TokenNameIdentifier	 Taxonomy Writer Cache
cache	TokenNameIdentifier	 cache
)	TokenNameRPAREN	
throws	TokenNamethrows	
IOException	TokenNameIdentifier	 IO Exception
{	TokenNameLBRACE	
if	TokenNameif	
(	TokenNameLPAREN	
!	TokenNameNOT	
IndexReader	TokenNameIdentifier	 Index Reader
.	TokenNameDOT	
indexExists	TokenNameIdentifier	 index Exists
(	TokenNameLPAREN	
directory	TokenNameIdentifier	 directory
)	TokenNameRPAREN	
||	TokenNameOR_OR	
openMode	TokenNameIdentifier	 open Mode
==	TokenNameEQUAL_EQUAL	
OpenMode	TokenNameIdentifier	 Open Mode
.	TokenNameDOT	
CREATE	TokenNameIdentifier	 CREATE
)	TokenNameRPAREN	
{	TokenNameLBRACE	
createTime	TokenNameIdentifier	 create Time
=	TokenNameEQUAL	
Long	TokenNameIdentifier	 Long
.	TokenNameDOT	
toString	TokenNameIdentifier	 to String
(	TokenNameLPAREN	
System	TokenNameIdentifier	 System
.	TokenNameDOT	
nanoTime	TokenNameIdentifier	 nano Time
(	TokenNameLPAREN	
)	TokenNameRPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
else	TokenNameelse	
{	TokenNameLBRACE	
Map	TokenNameIdentifier	 Map
<	TokenNameLESS	
String	TokenNameIdentifier	 String
,	TokenNameCOMMA	
String	TokenNameIdentifier	 String
>	TokenNameGREATER	
commitData	TokenNameIdentifier	 commit Data
=	TokenNameEQUAL	
readCommitData	TokenNameIdentifier	 read Commit Data
(	TokenNameLPAREN	
directory	TokenNameIdentifier	 directory
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
if	TokenNameif	
(	TokenNameLPAREN	
commitData	TokenNameIdentifier	 commit Data
!=	TokenNameNOT_EQUAL	
null	TokenNamenull	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
// It is ok if an existing index doesn't have commitData, or the 	TokenNameCOMMENT_LINE	It is ok if an existing index doesn't have commitData, or the 
// INDEX_CREATE_TIME property. If ever it will be recreated, we'll set 	TokenNameCOMMENT_LINE	INDEX_CREATE_TIME property. If ever it will be recreated, we'll set 
// createTime accordingly in the above 'if'. 	TokenNameCOMMENT_LINE	createTime accordingly in the above 'if'. 
createTime	TokenNameIdentifier	 create Time
=	TokenNameEQUAL	
commitData	TokenNameIdentifier	 commit Data
.	TokenNameDOT	
get	TokenNameIdentifier	 get
(	TokenNameLPAREN	
INDEX_CREATE_TIME	TokenNameIdentifier	 INDEX  CREATE  TIME
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
else	TokenNameelse	
{	TokenNameLBRACE	
createTime	TokenNameIdentifier	 create Time
=	TokenNameEQUAL	
null	TokenNamenull	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
}	TokenNameRBRACE	
IndexWriterConfig	TokenNameIdentifier	 Index Writer Config
config	TokenNameIdentifier	 config
=	TokenNameEQUAL	
createIndexWriterConfig	TokenNameIdentifier	 create Index Writer Config
(	TokenNameLPAREN	
openMode	TokenNameIdentifier	 open Mode
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
indexWriter	TokenNameIdentifier	 index Writer
=	TokenNameEQUAL	
openIndexWriter	TokenNameIdentifier	 open Index Writer
(	TokenNameLPAREN	
directory	TokenNameIdentifier	 directory
,	TokenNameCOMMA	
config	TokenNameIdentifier	 config
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
// verify (to some extent) that merge policy in effect would preserve category docids 	TokenNameCOMMENT_LINE	verify (to some extent) that merge policy in effect would preserve category docids 
assert	TokenNameassert	
!	TokenNameNOT	
(	TokenNameLPAREN	
indexWriter	TokenNameIdentifier	 index Writer
.	TokenNameDOT	
getConfig	TokenNameIdentifier	 get Config
(	TokenNameLPAREN	
)	TokenNameRPAREN	
.	TokenNameDOT	
getMergePolicy	TokenNameIdentifier	 get Merge Policy
(	TokenNameLPAREN	
)	TokenNameRPAREN	
instanceof	TokenNameinstanceof	
TieredMergePolicy	TokenNameIdentifier	 Tiered Merge Policy
)	TokenNameRPAREN	
:	TokenNameCOLON	
"for preserving category docids, merging none-adjacent segments is not allowed"	TokenNameStringLiteral	for preserving category docids, merging none-adjacent segments is not allowed
;	TokenNameSEMICOLON	
reader	TokenNameIdentifier	 reader
=	TokenNameEQUAL	
null	TokenNamenull	
;	TokenNameSEMICOLON	
parentStreamField	TokenNameIdentifier	 parent Stream Field
=	TokenNameEQUAL	
new	TokenNamenew	
Field	TokenNameIdentifier	 Field
(	TokenNameLPAREN	
Consts	TokenNameIdentifier	 Consts
.	TokenNameDOT	
FIELD_PAYLOADS	TokenNameIdentifier	 FIELD  PAYLOADS
,	TokenNameCOMMA	
parentStream	TokenNameIdentifier	 parent Stream
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
parentStreamField	TokenNameIdentifier	 parent Stream Field
.	TokenNameDOT	
setOmitNorms	TokenNameIdentifier	 set Omit Norms
(	TokenNameLPAREN	
true	TokenNametrue	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
fullPathField	TokenNameIdentifier	 full Path Field
=	TokenNameEQUAL	
new	TokenNamenew	
Field	TokenNameIdentifier	 Field
(	TokenNameLPAREN	
Consts	TokenNameIdentifier	 Consts
.	TokenNameDOT	
FULL	TokenNameIdentifier	 FULL
,	TokenNameCOMMA	
""	TokenNameStringLiteral	 
,	TokenNameCOMMA	
Store	TokenNameIdentifier	 Store
.	TokenNameDOT	
YES	TokenNameIdentifier	 YES
,	TokenNameCOMMA	
Index	TokenNameIdentifier	 Index
.	TokenNameDOT	
NOT_ANALYZED_NO_NORMS	TokenNameIdentifier	 NOT  ANALYZED  NO  NORMS
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
fullPathField	TokenNameIdentifier	 full Path Field
.	TokenNameDOT	
setIndexOptions	TokenNameIdentifier	 set Index Options
(	TokenNameLPAREN	
IndexOptions	TokenNameIdentifier	 Index Options
.	TokenNameDOT	
DOCS_ONLY	TokenNameIdentifier	 DOCS  ONLY
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
this	TokenNamethis	
.	TokenNameDOT	
nextID	TokenNameIdentifier	 next ID
=	TokenNameEQUAL	
indexWriter	TokenNameIdentifier	 index Writer
.	TokenNameDOT	
maxDoc	TokenNameIdentifier	 max Doc
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
if	TokenNameif	
(	TokenNameLPAREN	
cache	TokenNameIdentifier	 cache
==	TokenNameEQUAL_EQUAL	
null	TokenNamenull	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
cache	TokenNameIdentifier	 cache
=	TokenNameEQUAL	
defaultTaxonomyWriterCache	TokenNameIdentifier	 default Taxonomy Writer Cache
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
this	TokenNamethis	
.	TokenNameDOT	
cache	TokenNameIdentifier	 cache
=	TokenNameEQUAL	
cache	TokenNameIdentifier	 cache
;	TokenNameSEMICOLON	
if	TokenNameif	
(	TokenNameLPAREN	
nextID	TokenNameIdentifier	 next ID
==	TokenNameEQUAL_EQUAL	
0	TokenNameIntegerLiteral	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
cacheIsComplete	TokenNameIdentifier	 cache Is Complete
=	TokenNameEQUAL	
true	TokenNametrue	
;	TokenNameSEMICOLON	
// Make sure that the taxonomy always contain the root category 	TokenNameCOMMENT_LINE	Make sure that the taxonomy always contain the root category 
// with category id 0. 	TokenNameCOMMENT_LINE	with category id 0. 
addCategory	TokenNameIdentifier	 add Category
(	TokenNameLPAREN	
new	TokenNamenew	
CategoryPath	TokenNameIdentifier	 Category Path
(	TokenNameLPAREN	
)	TokenNameRPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
refreshReader	TokenNameIdentifier	 refresh Reader
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
else	TokenNameelse	
{	TokenNameLBRACE	
// There are some categories on the disk, which we have not yet 	TokenNameCOMMENT_LINE	There are some categories on the disk, which we have not yet 
// read into the cache, and therefore the cache is incomplete. 	TokenNameCOMMENT_LINE	read into the cache, and therefore the cache is incomplete. 
// We chose not to read all the categories into the cache now, 	TokenNameCOMMENT_LINE	We chose not to read all the categories into the cache now, 
// to avoid terrible performance when a taxonomy index is opened 	TokenNameCOMMENT_LINE	to avoid terrible performance when a taxonomy index is opened 
// to add just a single category. We will do it later, after we 	TokenNameCOMMENT_LINE	to add just a single category. We will do it later, after we 
// notice a few cache misses. 	TokenNameCOMMENT_LINE	notice a few cache misses. 
cacheIsComplete	TokenNameIdentifier	 cache Is Complete
=	TokenNameEQUAL	
false	TokenNamefalse	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
cacheMisses	TokenNameIdentifier	 cache Misses
=	TokenNameEQUAL	
0	TokenNameIntegerLiteral	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
/** * Open internal index writer, which contains the taxonomy data. * <p> * Extensions may provide their own {@link IndexWriter} implementation or instance. * <br><b>NOTE:</b> the instance this method returns will be closed upon calling * to {@link #close()}. * <br><b>NOTE:</b> the merge policy in effect must not merge none adjacent segments. See * comment in {@link #createIndexWriterConfig(IndexWriterConfig.OpenMode)} for the logic behind this. * * @see #createIndexWriterConfig(IndexWriterConfig.OpenMode) * * @param directory * the {@link Directory} on top of which an {@link IndexWriter} * should be opened. * @param config * configuration for the internal index writer. */	TokenNameCOMMENT_JAVADOC	 Open internal index writer, which contains the taxonomy data. <p> Extensions may provide their own {@link IndexWriter} implementation or instance. <br><b>NOTE:</b> the instance this method returns will be closed upon calling to {@link #close()}. <br><b>NOTE:</b> the merge policy in effect must not merge none adjacent segments. See comment in {@link #createIndexWriterConfig(IndexWriterConfig.OpenMode)} for the logic behind this. * @see #createIndexWriterConfig(IndexWriterConfig.OpenMode) * @param directory the {@link Directory} on top of which an {@link IndexWriter} should be opened. @param config configuration for the internal index writer. 
protected	TokenNameprotected	
IndexWriter	TokenNameIdentifier	 Index Writer
openIndexWriter	TokenNameIdentifier	 open Index Writer
(	TokenNameLPAREN	
Directory	TokenNameIdentifier	 Directory
directory	TokenNameIdentifier	 directory
,	TokenNameCOMMA	
IndexWriterConfig	TokenNameIdentifier	 Index Writer Config
config	TokenNameIdentifier	 config
)	TokenNameRPAREN	
throws	TokenNamethrows	
IOException	TokenNameIdentifier	 IO Exception
{	TokenNameLBRACE	
// Make sure we use a MergePolicy which merges segments in-order and thus 	TokenNameCOMMENT_LINE	Make sure we use a MergePolicy which merges segments in-order and thus 
// keeps the doc IDs ordered as well (this is crucial for the taxonomy 	TokenNameCOMMENT_LINE	keeps the doc IDs ordered as well (this is crucial for the taxonomy 
// index). 	TokenNameCOMMENT_LINE	index). 
return	TokenNamereturn	
new	TokenNamenew	
IndexWriter	TokenNameIdentifier	 Index Writer
(	TokenNameLPAREN	
directory	TokenNameIdentifier	 directory
,	TokenNameCOMMA	
config	TokenNameIdentifier	 config
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
/** * Create the {@link IndexWriterConfig} that would be used for opening the internal index writer. * <br>Extensions can configure the {@link IndexWriter} as they see fit, * including setting a {@link org.apache.lucene.index.MergeScheduler merge-scheduler}, or * {@link org.apache.lucene.index.IndexDeletionPolicy deletion-policy}, different RAM size * etc.<br> * <br><b>NOTE:</b> internal docids of the configured index must not be altered. * For that, categories are never deleted from the taxonomy index. * In addition, merge policy in effect must not merge none adjacent segments. * * @see #openIndexWriter(Directory, IndexWriterConfig) * * @param openMode see {@link OpenMode} */	TokenNameCOMMENT_JAVADOC	 Create the {@link IndexWriterConfig} that would be used for opening the internal index writer. <br>Extensions can configure the {@link IndexWriter} as they see fit, including setting a {@link org.apache.lucene.index.MergeScheduler merge-scheduler}, or {@link org.apache.lucene.index.IndexDeletionPolicy deletion-policy}, different RAM size etc.<br> <br><b>NOTE:</b> internal docids of the configured index must not be altered. For that, categories are never deleted from the taxonomy index. In addition, merge policy in effect must not merge none adjacent segments. * @see #openIndexWriter(Directory, IndexWriterConfig) * @param openMode see {@link OpenMode} 
protected	TokenNameprotected	
IndexWriterConfig	TokenNameIdentifier	 Index Writer Config
createIndexWriterConfig	TokenNameIdentifier	 create Index Writer Config
(	TokenNameLPAREN	
OpenMode	TokenNameIdentifier	 Open Mode
openMode	TokenNameIdentifier	 open Mode
)	TokenNameRPAREN	
{	TokenNameLBRACE	
// Make sure we use a MergePolicy which always merges adjacent segments and thus 	TokenNameCOMMENT_LINE	Make sure we use a MergePolicy which always merges adjacent segments and thus 
// keeps the doc IDs ordered as well (this is crucial for the taxonomy index). 	TokenNameCOMMENT_LINE	keeps the doc IDs ordered as well (this is crucial for the taxonomy index). 
return	TokenNamereturn	
new	TokenNamenew	
IndexWriterConfig	TokenNameIdentifier	 Index Writer Config
(	TokenNameLPAREN	
Version	TokenNameIdentifier	 Version
.	TokenNameDOT	
LUCENE_36	TokenNameIdentifier	 LUCENE 36
,	TokenNameCOMMA	
new	TokenNamenew	
KeywordAnalyzer	TokenNameIdentifier	 Keyword Analyzer
(	TokenNameLPAREN	
)	TokenNameRPAREN	
)	TokenNameRPAREN	
.	TokenNameDOT	
setOpenMode	TokenNameIdentifier	 set Open Mode
(	TokenNameLPAREN	
openMode	TokenNameIdentifier	 open Mode
)	TokenNameRPAREN	
.	TokenNameDOT	
setMergePolicy	TokenNameIdentifier	 set Merge Policy
(	TokenNameLPAREN	
new	TokenNamenew	
LogByteSizeMergePolicy	TokenNameIdentifier	 Log Byte Size Merge Policy
(	TokenNameLPAREN	
)	TokenNameRPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
// Currently overridden by a unit test that verifies that every index we open is close()ed. 	TokenNameCOMMENT_LINE	Currently overridden by a unit test that verifies that every index we open is close()ed. 
/** * Open an {@link IndexReader} from the internal {@link IndexWriter}, by * calling {@link IndexReader#open(IndexWriter, boolean)}. Extending classes can override * this method to return their own {@link IndexReader}. */	TokenNameCOMMENT_JAVADOC	 Open an {@link IndexReader} from the internal {@link IndexWriter}, by calling {@link IndexReader#open(IndexWriter, boolean)}. Extending classes can override this method to return their own {@link IndexReader}. 
protected	TokenNameprotected	
IndexReader	TokenNameIdentifier	 Index Reader
openReader	TokenNameIdentifier	 open Reader
(	TokenNameLPAREN	
)	TokenNameRPAREN	
throws	TokenNamethrows	
IOException	TokenNameIdentifier	 IO Exception
{	TokenNameLBRACE	
return	TokenNamereturn	
IndexReader	TokenNameIdentifier	 Index Reader
.	TokenNameDOT	
open	TokenNameIdentifier	 open
(	TokenNameLPAREN	
indexWriter	TokenNameIdentifier	 index Writer
,	TokenNameCOMMA	
true	TokenNametrue	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
/** * Creates a new instance with a default cached as defined by * {@link #defaultTaxonomyWriterCache()}. */	TokenNameCOMMENT_JAVADOC	 Creates a new instance with a default cached as defined by {@link #defaultTaxonomyWriterCache()}. 
public	TokenNamepublic	
DirectoryTaxonomyWriter	TokenNameIdentifier	 Directory Taxonomy Writer
(	TokenNameLPAREN	
Directory	TokenNameIdentifier	 Directory
directory	TokenNameIdentifier	 directory
,	TokenNameCOMMA	
OpenMode	TokenNameIdentifier	 Open Mode
openMode	TokenNameIdentifier	 open Mode
)	TokenNameRPAREN	
throws	TokenNamethrows	
CorruptIndexException	TokenNameIdentifier	 Corrupt Index Exception
,	TokenNameCOMMA	
LockObtainFailedException	TokenNameIdentifier	 Lock Obtain Failed Exception
,	TokenNameCOMMA	
IOException	TokenNameIdentifier	 IO Exception
{	TokenNameLBRACE	
this	TokenNamethis	
(	TokenNameLPAREN	
directory	TokenNameIdentifier	 directory
,	TokenNameCOMMA	
openMode	TokenNameIdentifier	 open Mode
,	TokenNameCOMMA	
defaultTaxonomyWriterCache	TokenNameIdentifier	 default Taxonomy Writer Cache
(	TokenNameLPAREN	
)	TokenNameRPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
/** * Defines the default {@link TaxonomyWriterCache} to use in constructors * which do not specify one. * <P> * The current default is {@link Cl2oTaxonomyWriterCache} constructed * with the parameters (1024, 0.15f, 3), i.e., the entire taxonomy is * cached in memory while building it. */	TokenNameCOMMENT_JAVADOC	 Defines the default {@link TaxonomyWriterCache} to use in constructors which do not specify one. <P> The current default is {@link Cl2oTaxonomyWriterCache} constructed with the parameters (1024, 0.15f, 3), i.e., the entire taxonomy is cached in memory while building it. 
public	TokenNamepublic	
static	TokenNamestatic	
TaxonomyWriterCache	TokenNameIdentifier	 Taxonomy Writer Cache
defaultTaxonomyWriterCache	TokenNameIdentifier	 default Taxonomy Writer Cache
(	TokenNameLPAREN	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
return	TokenNamereturn	
new	TokenNamenew	
Cl2oTaxonomyWriterCache	TokenNameIdentifier	 Cl2o Taxonomy Writer Cache
(	TokenNameLPAREN	
1024	TokenNameIntegerLiteral	
,	TokenNameCOMMA	
0.15f	TokenNameFloatingPointLiteral	
,	TokenNameCOMMA	
3	TokenNameIntegerLiteral	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
// convenience constructors: 	TokenNameCOMMENT_LINE	convenience constructors: 
public	TokenNamepublic	
DirectoryTaxonomyWriter	TokenNameIdentifier	 Directory Taxonomy Writer
(	TokenNameLPAREN	
Directory	TokenNameIdentifier	 Directory
d	TokenNameIdentifier	 d
)	TokenNameRPAREN	
throws	TokenNamethrows	
CorruptIndexException	TokenNameIdentifier	 Corrupt Index Exception
,	TokenNameCOMMA	
LockObtainFailedException	TokenNameIdentifier	 Lock Obtain Failed Exception
,	TokenNameCOMMA	
IOException	TokenNameIdentifier	 IO Exception
{	TokenNameLBRACE	
this	TokenNamethis	
(	TokenNameLPAREN	
d	TokenNameIdentifier	 d
,	TokenNameCOMMA	
OpenMode	TokenNameIdentifier	 Open Mode
.	TokenNameDOT	
CREATE_OR_APPEND	TokenNameIdentifier	 CREATE  OR  APPEND
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
/** * Frees used resources as well as closes the underlying {@link IndexWriter}, * which commits whatever changes made to it to the underlying * {@link Directory}. */	TokenNameCOMMENT_JAVADOC	 Frees used resources as well as closes the underlying {@link IndexWriter}, which commits whatever changes made to it to the underlying {@link Directory}. 
public	TokenNamepublic	
synchronized	TokenNamesynchronized	
void	TokenNamevoid	
close	TokenNameIdentifier	 close
(	TokenNameLPAREN	
)	TokenNameRPAREN	
throws	TokenNamethrows	
CorruptIndexException	TokenNameIdentifier	 Corrupt Index Exception
,	TokenNameCOMMA	
IOException	TokenNameIdentifier	 IO Exception
{	TokenNameLBRACE	
if	TokenNameif	
(	TokenNameLPAREN	
indexWriter	TokenNameIdentifier	 index Writer
!=	TokenNameNOT_EQUAL	
null	TokenNamenull	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
indexWriter	TokenNameIdentifier	 index Writer
.	TokenNameDOT	
commit	TokenNameIdentifier	 commit
(	TokenNameLPAREN	
combinedCommitData	TokenNameIdentifier	 combined Commit Data
(	TokenNameLPAREN	
null	TokenNamenull	
)	TokenNameRPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
doClose	TokenNameIdentifier	 do Close
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
}	TokenNameRBRACE	
private	TokenNameprivate	
void	TokenNamevoid	
doClose	TokenNameIdentifier	 do Close
(	TokenNameLPAREN	
)	TokenNameRPAREN	
throws	TokenNamethrows	
CorruptIndexException	TokenNameIdentifier	 Corrupt Index Exception
,	TokenNameCOMMA	
IOException	TokenNameIdentifier	 IO Exception
{	TokenNameLBRACE	
indexWriter	TokenNameIdentifier	 index Writer
.	TokenNameDOT	
close	TokenNameIdentifier	 close
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
indexWriter	TokenNameIdentifier	 index Writer
=	TokenNameEQUAL	
null	TokenNamenull	
;	TokenNameSEMICOLON	
closeResources	TokenNameIdentifier	 close Resources
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
/** * Returns the number of memory bytes used by the cache. * @return Number of cache bytes in memory, for CL2O only; zero otherwise. */	TokenNameCOMMENT_JAVADOC	 Returns the number of memory bytes used by the cache. @return Number of cache bytes in memory, for CL2O only; zero otherwise. 
public	TokenNamepublic	
int	TokenNameint	
getCacheMemoryUsage	TokenNameIdentifier	 get Cache Memory Usage
(	TokenNameLPAREN	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
ensureOpen	TokenNameIdentifier	 ensure Open
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
if	TokenNameif	
(	TokenNameLPAREN	
this	TokenNamethis	
.	TokenNameDOT	
cache	TokenNameIdentifier	 cache
==	TokenNameEQUAL_EQUAL	
null	TokenNamenull	
||	TokenNameOR_OR	
!	TokenNameNOT	
(	TokenNameLPAREN	
this	TokenNamethis	
.	TokenNameDOT	
cache	TokenNameIdentifier	 cache
instanceof	TokenNameinstanceof	
Cl2oTaxonomyWriterCache	TokenNameIdentifier	 Cl2o Taxonomy Writer Cache
)	TokenNameRPAREN	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
return	TokenNamereturn	
0	TokenNameIntegerLiteral	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
return	TokenNamereturn	
(	TokenNameLPAREN	
(	TokenNameLPAREN	
Cl2oTaxonomyWriterCache	TokenNameIdentifier	 Cl2o Taxonomy Writer Cache
)	TokenNameRPAREN	
this	TokenNamethis	
.	TokenNameDOT	
cache	TokenNameIdentifier	 cache
)	TokenNameRPAREN	
.	TokenNameDOT	
getMemoryUsage	TokenNameIdentifier	 get Memory Usage
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
/** * A hook for extending classes to close additional resources that were used. * The default implementation closes the {@link IndexReader} as well as the * {@link TaxonomyWriterCache} instances that were used. <br> * <b>NOTE:</b> if you override this method, you should include a * <code>super.closeResources()</code> call in your implementation. */	TokenNameCOMMENT_JAVADOC	 A hook for extending classes to close additional resources that were used. The default implementation closes the {@link IndexReader} as well as the {@link TaxonomyWriterCache} instances that were used. <br> <b>NOTE:</b> if you override this method, you should include a <code>super.closeResources()</code> call in your implementation. 
protected	TokenNameprotected	
synchronized	TokenNamesynchronized	
void	TokenNamevoid	
closeResources	TokenNameIdentifier	 close Resources
(	TokenNameLPAREN	
)	TokenNameRPAREN	
throws	TokenNamethrows	
IOException	TokenNameIdentifier	 IO Exception
{	TokenNameLBRACE	
if	TokenNameif	
(	TokenNameLPAREN	
reader	TokenNameIdentifier	 reader
!=	TokenNameNOT_EQUAL	
null	TokenNamenull	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
reader	TokenNameIdentifier	 reader
.	TokenNameDOT	
close	TokenNameIdentifier	 close
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
reader	TokenNameIdentifier	 reader
=	TokenNameEQUAL	
null	TokenNamenull	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
if	TokenNameif	
(	TokenNameLPAREN	
cache	TokenNameIdentifier	 cache
!=	TokenNameNOT_EQUAL	
null	TokenNamenull	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
cache	TokenNameIdentifier	 cache
.	TokenNameDOT	
close	TokenNameIdentifier	 close
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
cache	TokenNameIdentifier	 cache
=	TokenNameEQUAL	
null	TokenNamenull	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
}	TokenNameRBRACE	
/** * Look up the given category in the cache and/or the on-disk storage, * returning the category's ordinal, or a negative number in case the * category does not yet exist in the taxonomy. */	TokenNameCOMMENT_JAVADOC	 Look up the given category in the cache and/or the on-disk storage, returning the category's ordinal, or a negative number in case the category does not yet exist in the taxonomy. 
protected	TokenNameprotected	
int	TokenNameint	
findCategory	TokenNameIdentifier	 find Category
(	TokenNameLPAREN	
CategoryPath	TokenNameIdentifier	 Category Path
categoryPath	TokenNameIdentifier	 category Path
)	TokenNameRPAREN	
throws	TokenNamethrows	
IOException	TokenNameIdentifier	 IO Exception
{	TokenNameLBRACE	
// If we can find the category in our cache, we can return the 	TokenNameCOMMENT_LINE	If we can find the category in our cache, we can return the 
// response directly from it: 	TokenNameCOMMENT_LINE	response directly from it: 
int	TokenNameint	
res	TokenNameIdentifier	 res
=	TokenNameEQUAL	
cache	TokenNameIdentifier	 cache
.	TokenNameDOT	
get	TokenNameIdentifier	 get
(	TokenNameLPAREN	
categoryPath	TokenNameIdentifier	 category Path
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
if	TokenNameif	
(	TokenNameLPAREN	
res	TokenNameIdentifier	 res
>=	TokenNameGREATER_EQUAL	
0	TokenNameIntegerLiteral	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
return	TokenNamereturn	
res	TokenNameIdentifier	 res
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
// If we know that the cache is complete, i.e., contains every category 	TokenNameCOMMENT_LINE	If we know that the cache is complete, i.e., contains every category 
// which exists, we can return -1 immediately. However, if the cache is 	TokenNameCOMMENT_LINE	which exists, we can return -1 immediately. However, if the cache is 
// not complete, we need to check the disk. 	TokenNameCOMMENT_LINE	not complete, we need to check the disk. 
if	TokenNameif	
(	TokenNameLPAREN	
cacheIsComplete	TokenNameIdentifier	 cache Is Complete
)	TokenNameRPAREN	
{	TokenNameLBRACE	
return	TokenNamereturn	
-	TokenNameMINUS	
1	TokenNameIntegerLiteral	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
cacheMisses	TokenNameIdentifier	 cache Misses
++	TokenNamePLUS_PLUS	
;	TokenNameSEMICOLON	
// After a few cache misses, it makes sense to read all the categories 	TokenNameCOMMENT_LINE	After a few cache misses, it makes sense to read all the categories 
// from disk and into the cache. The reason not to do this on the first 	TokenNameCOMMENT_LINE	from disk and into the cache. The reason not to do this on the first 
// cache miss (or even when opening the writer) is that it will 	TokenNameCOMMENT_LINE	cache miss (or even when opening the writer) is that it will 
// significantly slow down the case when a taxonomy is opened just to 	TokenNameCOMMENT_LINE	significantly slow down the case when a taxonomy is opened just to 
// add one category. The idea only spending a long time on reading 	TokenNameCOMMENT_LINE	add one category. The idea only spending a long time on reading 
// after enough time was spent on cache misses is known as a "online 	TokenNameCOMMENT_LINE	after enough time was spent on cache misses is known as a "online 
// algorithm". 	TokenNameCOMMENT_LINE	algorithm". 
if	TokenNameif	
(	TokenNameLPAREN	
perhapsFillCache	TokenNameIdentifier	 perhaps Fill Cache
(	TokenNameLPAREN	
)	TokenNameRPAREN	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
return	TokenNamereturn	
cache	TokenNameIdentifier	 cache
.	TokenNameDOT	
get	TokenNameIdentifier	 get
(	TokenNameLPAREN	
categoryPath	TokenNameIdentifier	 category Path
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
// We need to get an answer from the on-disk index. If a reader 	TokenNameCOMMENT_LINE	We need to get an answer from the on-disk index. If a reader 
// is not yet open, do it now: 	TokenNameCOMMENT_LINE	is not yet open, do it now: 
if	TokenNameif	
(	TokenNameLPAREN	
reader	TokenNameIdentifier	 reader
==	TokenNameEQUAL_EQUAL	
null	TokenNamenull	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
reader	TokenNameIdentifier	 reader
=	TokenNameEQUAL	
openReader	TokenNameIdentifier	 open Reader
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
TermDocs	TokenNameIdentifier	 Term Docs
docs	TokenNameIdentifier	 docs
=	TokenNameEQUAL	
reader	TokenNameIdentifier	 reader
.	TokenNameDOT	
termDocs	TokenNameIdentifier	 term Docs
(	TokenNameLPAREN	
Consts	TokenNameIdentifier	 Consts
.	TokenNameDOT	
FULL_TERM	TokenNameIdentifier	 FULL  TERM
.	TokenNameDOT	
createTerm	TokenNameIdentifier	 create Term
(	TokenNameLPAREN	
categoryPath	TokenNameIdentifier	 category Path
.	TokenNameDOT	
toString	TokenNameIdentifier	 to String
(	TokenNameLPAREN	
delimiter	TokenNameIdentifier	 delimiter
)	TokenNameRPAREN	
)	TokenNameRPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
if	TokenNameif	
(	TokenNameLPAREN	
!	TokenNameNOT	
docs	TokenNameIdentifier	 docs
.	TokenNameDOT	
next	TokenNameIdentifier	 next
(	TokenNameLPAREN	
)	TokenNameRPAREN	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
return	TokenNamereturn	
-	TokenNameMINUS	
1	TokenNameIntegerLiteral	
;	TokenNameSEMICOLON	
// category does not exist in taxonomy 	TokenNameCOMMENT_LINE	category does not exist in taxonomy 
}	TokenNameRBRACE	
// Note: we do NOT add to the cache the fact that the category 	TokenNameCOMMENT_LINE	Note: we do NOT add to the cache the fact that the category 
// does not exist. The reason is that our only use for this 	TokenNameCOMMENT_LINE	does not exist. The reason is that our only use for this 
// method is just before we actually add this category. If 	TokenNameCOMMENT_LINE	method is just before we actually add this category. If 
// in the future this usage changes, we should consider caching 	TokenNameCOMMENT_LINE	in the future this usage changes, we should consider caching 
// the fact that the category is not in the taxonomy. 	TokenNameCOMMENT_LINE	the fact that the category is not in the taxonomy. 
addToCache	TokenNameIdentifier	 add To Cache
(	TokenNameLPAREN	
categoryPath	TokenNameIdentifier	 category Path
,	TokenNameCOMMA	
docs	TokenNameIdentifier	 docs
.	TokenNameDOT	
doc	TokenNameIdentifier	 doc
(	TokenNameLPAREN	
)	TokenNameRPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
return	TokenNamereturn	
docs	TokenNameIdentifier	 docs
.	TokenNameDOT	
doc	TokenNameIdentifier	 doc
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
/** * Look up the given prefix of the given category in the cache and/or the * on-disk storage, returning that prefix's ordinal, or a negative number in * case the category does not yet exist in the taxonomy. */	TokenNameCOMMENT_JAVADOC	 Look up the given prefix of the given category in the cache and/or the on-disk storage, returning that prefix's ordinal, or a negative number in case the category does not yet exist in the taxonomy. 
private	TokenNameprivate	
int	TokenNameint	
findCategory	TokenNameIdentifier	 find Category
(	TokenNameLPAREN	
CategoryPath	TokenNameIdentifier	 Category Path
categoryPath	TokenNameIdentifier	 category Path
,	TokenNameCOMMA	
int	TokenNameint	
prefixLen	TokenNameIdentifier	 prefix Len
)	TokenNameRPAREN	
throws	TokenNamethrows	
IOException	TokenNameIdentifier	 IO Exception
{	TokenNameLBRACE	
int	TokenNameint	
res	TokenNameIdentifier	 res
=	TokenNameEQUAL	
cache	TokenNameIdentifier	 cache
.	TokenNameDOT	
get	TokenNameIdentifier	 get
(	TokenNameLPAREN	
categoryPath	TokenNameIdentifier	 category Path
,	TokenNameCOMMA	
prefixLen	TokenNameIdentifier	 prefix Len
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
if	TokenNameif	
(	TokenNameLPAREN	
res	TokenNameIdentifier	 res
>=	TokenNameGREATER_EQUAL	
0	TokenNameIntegerLiteral	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
return	TokenNamereturn	
res	TokenNameIdentifier	 res
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
if	TokenNameif	
(	TokenNameLPAREN	
cacheIsComplete	TokenNameIdentifier	 cache Is Complete
)	TokenNameRPAREN	
{	TokenNameLBRACE	
return	TokenNamereturn	
-	TokenNameMINUS	
1	TokenNameIntegerLiteral	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
cacheMisses	TokenNameIdentifier	 cache Misses
++	TokenNamePLUS_PLUS	
;	TokenNameSEMICOLON	
if	TokenNameif	
(	TokenNameLPAREN	
perhapsFillCache	TokenNameIdentifier	 perhaps Fill Cache
(	TokenNameLPAREN	
)	TokenNameRPAREN	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
return	TokenNamereturn	
cache	TokenNameIdentifier	 cache
.	TokenNameDOT	
get	TokenNameIdentifier	 get
(	TokenNameLPAREN	
categoryPath	TokenNameIdentifier	 category Path
,	TokenNameCOMMA	
prefixLen	TokenNameIdentifier	 prefix Len
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
if	TokenNameif	
(	TokenNameLPAREN	
reader	TokenNameIdentifier	 reader
==	TokenNameEQUAL_EQUAL	
null	TokenNamenull	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
reader	TokenNameIdentifier	 reader
=	TokenNameEQUAL	
openReader	TokenNameIdentifier	 open Reader
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
TermDocs	TokenNameIdentifier	 Term Docs
docs	TokenNameIdentifier	 docs
=	TokenNameEQUAL	
reader	TokenNameIdentifier	 reader
.	TokenNameDOT	
termDocs	TokenNameIdentifier	 term Docs
(	TokenNameLPAREN	
Consts	TokenNameIdentifier	 Consts
.	TokenNameDOT	
FULL_TERM	TokenNameIdentifier	 FULL  TERM
.	TokenNameDOT	
createTerm	TokenNameIdentifier	 create Term
(	TokenNameLPAREN	
categoryPath	TokenNameIdentifier	 category Path
.	TokenNameDOT	
toString	TokenNameIdentifier	 to String
(	TokenNameLPAREN	
delimiter	TokenNameIdentifier	 delimiter
,	TokenNameCOMMA	
prefixLen	TokenNameIdentifier	 prefix Len
)	TokenNameRPAREN	
)	TokenNameRPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
if	TokenNameif	
(	TokenNameLPAREN	
!	TokenNameNOT	
docs	TokenNameIdentifier	 docs
.	TokenNameDOT	
next	TokenNameIdentifier	 next
(	TokenNameLPAREN	
)	TokenNameRPAREN	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
return	TokenNamereturn	
-	TokenNameMINUS	
1	TokenNameIntegerLiteral	
;	TokenNameSEMICOLON	
// category does not exist in taxonomy 	TokenNameCOMMENT_LINE	category does not exist in taxonomy 
}	TokenNameRBRACE	
addToCache	TokenNameIdentifier	 add To Cache
(	TokenNameLPAREN	
categoryPath	TokenNameIdentifier	 category Path
,	TokenNameCOMMA	
prefixLen	TokenNameIdentifier	 prefix Len
,	TokenNameCOMMA	
docs	TokenNameIdentifier	 docs
.	TokenNameDOT	
doc	TokenNameIdentifier	 doc
(	TokenNameLPAREN	
)	TokenNameRPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
return	TokenNamereturn	
docs	TokenNameIdentifier	 docs
.	TokenNameDOT	
doc	TokenNameIdentifier	 doc
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
// TODO (Facet): addCategory() is synchronized. This means that if indexing is 	TokenNameCOMMENT_LINE	TODO (Facet): addCategory() is synchronized. This means that if indexing is 
// multi-threaded, a new category that needs to be written to disk (and 	TokenNameCOMMENT_LINE	multi-threaded, a new category that needs to be written to disk (and 
// potentially even trigger a lengthy merge) locks out other addCategory() 	TokenNameCOMMENT_LINE	potentially even trigger a lengthy merge) locks out other addCategory() 
// calls - even those which could immediately return a cached value. 	TokenNameCOMMENT_LINE	calls - even those which could immediately return a cached value. 
// We definitely need to fix this situation! 	TokenNameCOMMENT_LINE	We definitely need to fix this situation! 
public	TokenNamepublic	
synchronized	TokenNamesynchronized	
int	TokenNameint	
addCategory	TokenNameIdentifier	 add Category
(	TokenNameLPAREN	
CategoryPath	TokenNameIdentifier	 Category Path
categoryPath	TokenNameIdentifier	 category Path
)	TokenNameRPAREN	
throws	TokenNamethrows	
IOException	TokenNameIdentifier	 IO Exception
{	TokenNameLBRACE	
ensureOpen	TokenNameIdentifier	 ensure Open
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
// If the category is already in the cache and/or the taxonomy, we 	TokenNameCOMMENT_LINE	If the category is already in the cache and/or the taxonomy, we 
// should return its existing ordinal: 	TokenNameCOMMENT_LINE	should return its existing ordinal: 
int	TokenNameint	
res	TokenNameIdentifier	 res
=	TokenNameEQUAL	
findCategory	TokenNameIdentifier	 find Category
(	TokenNameLPAREN	
categoryPath	TokenNameIdentifier	 category Path
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
if	TokenNameif	
(	TokenNameLPAREN	
res	TokenNameIdentifier	 res
<	TokenNameLESS	
0	TokenNameIntegerLiteral	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
// This is a new category, and we need to insert it into the index 	TokenNameCOMMENT_LINE	This is a new category, and we need to insert it into the index 
// (and the cache). Actually, we might also need to add some of 	TokenNameCOMMENT_LINE	(and the cache). Actually, we might also need to add some of 
// the category's ancestors before we can add the category itself 	TokenNameCOMMENT_LINE	the category's ancestors before we can add the category itself 
// (while keeping the invariant that a parent is always added to 	TokenNameCOMMENT_LINE	(while keeping the invariant that a parent is always added to 
// the taxonomy before its child). internalAddCategory() does all 	TokenNameCOMMENT_LINE	the taxonomy before its child). internalAddCategory() does all 
// this recursively: 	TokenNameCOMMENT_LINE	this recursively: 
res	TokenNameIdentifier	 res
=	TokenNameEQUAL	
internalAddCategory	TokenNameIdentifier	 internal Add Category
(	TokenNameLPAREN	
categoryPath	TokenNameIdentifier	 category Path
,	TokenNameCOMMA	
categoryPath	TokenNameIdentifier	 category Path
.	TokenNameDOT	
length	TokenNameIdentifier	 length
(	TokenNameLPAREN	
)	TokenNameRPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
return	TokenNamereturn	
res	TokenNameIdentifier	 res
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
/** * Add a new category into the index (and the cache), and return its new * ordinal. * <P> * Actually, we might also need to add some of the category's ancestors * before we can add the category itself (while keeping the invariant that a * parent is always added to the taxonomy before its child). We do this by * recursion. */	TokenNameCOMMENT_JAVADOC	 Add a new category into the index (and the cache), and return its new ordinal. <P> Actually, we might also need to add some of the category's ancestors before we can add the category itself (while keeping the invariant that a parent is always added to the taxonomy before its child). We do this by recursion. 
private	TokenNameprivate	
int	TokenNameint	
internalAddCategory	TokenNameIdentifier	 internal Add Category
(	TokenNameLPAREN	
CategoryPath	TokenNameIdentifier	 Category Path
categoryPath	TokenNameIdentifier	 category Path
,	TokenNameCOMMA	
int	TokenNameint	
length	TokenNameIdentifier	 length
)	TokenNameRPAREN	
throws	TokenNamethrows	
CorruptIndexException	TokenNameIdentifier	 Corrupt Index Exception
,	TokenNameCOMMA	
IOException	TokenNameIdentifier	 IO Exception
{	TokenNameLBRACE	
// Find our parent's ordinal (recursively adding the parent category 	TokenNameCOMMENT_LINE	Find our parent's ordinal (recursively adding the parent category 
// to the taxonomy if it's not already there). Then add the parent 	TokenNameCOMMENT_LINE	to the taxonomy if it's not already there). Then add the parent 
// ordinal as payloads (rather than a stored field; payloads can be 	TokenNameCOMMENT_LINE	ordinal as payloads (rather than a stored field; payloads can be 
// more efficiently read into memory in bulk by LuceneTaxonomyReader) 	TokenNameCOMMENT_LINE	more efficiently read into memory in bulk by LuceneTaxonomyReader) 
int	TokenNameint	
parent	TokenNameIdentifier	 parent
;	TokenNameSEMICOLON	
if	TokenNameif	
(	TokenNameLPAREN	
length	TokenNameIdentifier	 length
>	TokenNameGREATER	
1	TokenNameIntegerLiteral	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
parent	TokenNameIdentifier	 parent
=	TokenNameEQUAL	
findCategory	TokenNameIdentifier	 find Category
(	TokenNameLPAREN	
categoryPath	TokenNameIdentifier	 category Path
,	TokenNameCOMMA	
length	TokenNameIdentifier	 length
-	TokenNameMINUS	
1	TokenNameIntegerLiteral	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
if	TokenNameif	
(	TokenNameLPAREN	
parent	TokenNameIdentifier	 parent
<	TokenNameLESS	
0	TokenNameIntegerLiteral	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
parent	TokenNameIdentifier	 parent
=	TokenNameEQUAL	
internalAddCategory	TokenNameIdentifier	 internal Add Category
(	TokenNameLPAREN	
categoryPath	TokenNameIdentifier	 category Path
,	TokenNameCOMMA	
length	TokenNameIdentifier	 length
-	TokenNameMINUS	
1	TokenNameIntegerLiteral	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
}	TokenNameRBRACE	
else	TokenNameelse	
if	TokenNameif	
(	TokenNameLPAREN	
length	TokenNameIdentifier	 length
==	TokenNameEQUAL_EQUAL	
1	TokenNameIntegerLiteral	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
parent	TokenNameIdentifier	 parent
=	TokenNameEQUAL	
TaxonomyReader	TokenNameIdentifier	 Taxonomy Reader
.	TokenNameDOT	
ROOT_ORDINAL	TokenNameIdentifier	 ROOT  ORDINAL
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
else	TokenNameelse	
{	TokenNameLBRACE	
parent	TokenNameIdentifier	 parent
=	TokenNameEQUAL	
TaxonomyReader	TokenNameIdentifier	 Taxonomy Reader
.	TokenNameDOT	
INVALID_ORDINAL	TokenNameIdentifier	 INVALID  ORDINAL
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
int	TokenNameint	
id	TokenNameIdentifier	 id
=	TokenNameEQUAL	
addCategoryDocument	TokenNameIdentifier	 add Category Document
(	TokenNameLPAREN	
categoryPath	TokenNameIdentifier	 category Path
,	TokenNameCOMMA	
length	TokenNameIdentifier	 length
,	TokenNameCOMMA	
parent	TokenNameIdentifier	 parent
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
return	TokenNamereturn	
id	TokenNameIdentifier	 id
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
/** * Verifies that this instance wasn't closed, or throws * {@link AlreadyClosedException} if it is. */	TokenNameCOMMENT_JAVADOC	 Verifies that this instance wasn't closed, or throws {@link AlreadyClosedException} if it is. 
protected	TokenNameprotected	
final	TokenNamefinal	
void	TokenNamevoid	
ensureOpen	TokenNameIdentifier	 ensure Open
(	TokenNameLPAREN	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
if	TokenNameif	
(	TokenNameLPAREN	
indexWriter	TokenNameIdentifier	 index Writer
==	TokenNameEQUAL_EQUAL	
null	TokenNamenull	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
throw	TokenNamethrow	
new	TokenNamenew	
AlreadyClosedException	TokenNameIdentifier	 Already Closed Exception
(	TokenNameLPAREN	
"The taxonomy writer has already been closed"	TokenNameStringLiteral	The taxonomy writer has already been closed
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
}	TokenNameRBRACE	
// Note that the methods calling addCategoryDocument() are synchornized, 	TokenNameCOMMENT_LINE	Note that the methods calling addCategoryDocument() are synchornized, 
// so this method is effectively synchronized as well, but we'll add 	TokenNameCOMMENT_LINE	so this method is effectively synchronized as well, but we'll add 
// synchronized to be on the safe side, and we can reuse class-local objects 	TokenNameCOMMENT_LINE	synchronized to be on the safe side, and we can reuse class-local objects 
// instead of allocating them every time 	TokenNameCOMMENT_LINE	instead of allocating them every time 
protected	TokenNameprotected	
synchronized	TokenNamesynchronized	
int	TokenNameint	
addCategoryDocument	TokenNameIdentifier	 add Category Document
(	TokenNameLPAREN	
CategoryPath	TokenNameIdentifier	 Category Path
categoryPath	TokenNameIdentifier	 category Path
,	TokenNameCOMMA	
int	TokenNameint	
length	TokenNameIdentifier	 length
,	TokenNameCOMMA	
int	TokenNameint	
parent	TokenNameIdentifier	 parent
)	TokenNameRPAREN	
throws	TokenNamethrows	
CorruptIndexException	TokenNameIdentifier	 Corrupt Index Exception
,	TokenNameCOMMA	
IOException	TokenNameIdentifier	 IO Exception
{	TokenNameLBRACE	
// Before Lucene 2.9, position increments >=0 were supported, so we 	TokenNameCOMMENT_LINE	Before Lucene 2.9, position increments >=0 were supported, so we 
// added 1 to parent to allow the parent -1 (the parent of the root). 	TokenNameCOMMENT_LINE	added 1 to parent to allow the parent -1 (the parent of the root). 
// Unfortunately, starting with Lucene 2.9, after LUCENE-1542, this is 	TokenNameCOMMENT_LINE	Unfortunately, starting with Lucene 2.9, after LUCENE-1542, this is 
// no longer enough, since 0 is not encoded consistently either (see 	TokenNameCOMMENT_LINE	no longer enough, since 0 is not encoded consistently either (see 
// comment in SinglePositionTokenStream). But because we must be 	TokenNameCOMMENT_LINE	comment in SinglePositionTokenStream). But because we must be 
// backward-compatible with existing indexes, we can't just fix what 	TokenNameCOMMENT_LINE	backward-compatible with existing indexes, we can't just fix what 
// we write here (e.g., to write parent+2), and need to do a workaround 	TokenNameCOMMENT_LINE	we write here (e.g., to write parent+2), and need to do a workaround 
// in the reader (which knows that anyway only category 0 has a parent 	TokenNameCOMMENT_LINE	in the reader (which knows that anyway only category 0 has a parent 
// -1). 	TokenNameCOMMENT_LINE	-1). 
parentStream	TokenNameIdentifier	 parent Stream
.	TokenNameDOT	
set	TokenNameIdentifier	 set
(	TokenNameLPAREN	
parent	TokenNameIdentifier	 parent
+	TokenNamePLUS	
1	TokenNameIntegerLiteral	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
Document	TokenNameIdentifier	 Document
d	TokenNameIdentifier	 d
=	TokenNameEQUAL	
new	TokenNamenew	
Document	TokenNameIdentifier	 Document
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
d	TokenNameIdentifier	 d
.	TokenNameDOT	
add	TokenNameIdentifier	 add
(	TokenNameLPAREN	
parentStreamField	TokenNameIdentifier	 parent Stream Field
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
fullPathField	TokenNameIdentifier	 full Path Field
.	TokenNameDOT	
setValue	TokenNameIdentifier	 set Value
(	TokenNameLPAREN	
categoryPath	TokenNameIdentifier	 category Path
.	TokenNameDOT	
toString	TokenNameIdentifier	 to String
(	TokenNameLPAREN	
delimiter	TokenNameIdentifier	 delimiter
,	TokenNameCOMMA	
length	TokenNameIdentifier	 length
)	TokenNameRPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
d	TokenNameIdentifier	 d
.	TokenNameDOT	
add	TokenNameIdentifier	 add
(	TokenNameLPAREN	
fullPathField	TokenNameIdentifier	 full Path Field
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
// Note that we do no pass an Analyzer here because the fields that are 	TokenNameCOMMENT_LINE	Note that we do no pass an Analyzer here because the fields that are 
// added to the Document are untokenized or contains their own TokenStream. 	TokenNameCOMMENT_LINE	added to the Document are untokenized or contains their own TokenStream. 
// Therefore the IndexWriter's Analyzer has no effect. 	TokenNameCOMMENT_LINE	Therefore the IndexWriter's Analyzer has no effect. 
indexWriter	TokenNameIdentifier	 index Writer
.	TokenNameDOT	
addDocument	TokenNameIdentifier	 add Document
(	TokenNameLPAREN	
d	TokenNameIdentifier	 d
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
int	TokenNameint	
id	TokenNameIdentifier	 id
=	TokenNameEQUAL	
nextID	TokenNameIdentifier	 next ID
++	TokenNamePLUS_PLUS	
;	TokenNameSEMICOLON	
addToCache	TokenNameIdentifier	 add To Cache
(	TokenNameLPAREN	
categoryPath	TokenNameIdentifier	 category Path
,	TokenNameCOMMA	
length	TokenNameIdentifier	 length
,	TokenNameCOMMA	
id	TokenNameIdentifier	 id
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
// also add to the parent array 	TokenNameCOMMENT_LINE	also add to the parent array 
getParentArray	TokenNameIdentifier	 get Parent Array
(	TokenNameLPAREN	
)	TokenNameRPAREN	
.	TokenNameDOT	
add	TokenNameIdentifier	 add
(	TokenNameLPAREN	
id	TokenNameIdentifier	 id
,	TokenNameCOMMA	
parent	TokenNameIdentifier	 parent
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
return	TokenNamereturn	
id	TokenNameIdentifier	 id
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
private	TokenNameprivate	
static	TokenNamestatic	
class	TokenNameclass	
SinglePositionTokenStream	TokenNameIdentifier	 Single Position Token Stream
extends	TokenNameextends	
TokenStream	TokenNameIdentifier	 Token Stream
{	TokenNameLBRACE	
private	TokenNameprivate	
CharTermAttribute	TokenNameIdentifier	 Char Term Attribute
termAtt	TokenNameIdentifier	 term Att
;	TokenNameSEMICOLON	
private	TokenNameprivate	
PositionIncrementAttribute	TokenNameIdentifier	 Position Increment Attribute
posIncrAtt	TokenNameIdentifier	 pos Incr Att
;	TokenNameSEMICOLON	
private	TokenNameprivate	
boolean	TokenNameboolean	
returned	TokenNameIdentifier	 returned
;	TokenNameSEMICOLON	
public	TokenNamepublic	
SinglePositionTokenStream	TokenNameIdentifier	 Single Position Token Stream
(	TokenNameLPAREN	
String	TokenNameIdentifier	 String
word	TokenNameIdentifier	 word
)	TokenNameRPAREN	
{	TokenNameLBRACE	
termAtt	TokenNameIdentifier	 term Att
=	TokenNameEQUAL	
addAttribute	TokenNameIdentifier	 add Attribute
(	TokenNameLPAREN	
CharTermAttribute	TokenNameIdentifier	 Char Term Attribute
.	TokenNameDOT	
class	TokenNameclass	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
posIncrAtt	TokenNameIdentifier	 pos Incr Att
=	TokenNameEQUAL	
addAttribute	TokenNameIdentifier	 add Attribute
(	TokenNameLPAREN	
PositionIncrementAttribute	TokenNameIdentifier	 Position Increment Attribute
.	TokenNameDOT	
class	TokenNameclass	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
termAtt	TokenNameIdentifier	 term Att
.	TokenNameDOT	
setEmpty	TokenNameIdentifier	 set Empty
(	TokenNameLPAREN	
)	TokenNameRPAREN	
.	TokenNameDOT	
append	TokenNameIdentifier	 append
(	TokenNameLPAREN	
word	TokenNameIdentifier	 word
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
returned	TokenNameIdentifier	 returned
=	TokenNameEQUAL	
true	TokenNametrue	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
/** * Set the value we want to keep, as the position increment. * Note that when TermPositions.nextPosition() is later used to * retrieve this value, val-1 will be returned, not val. * <P> * IMPORTANT NOTE: Before Lucene 2.9, val>=0 were safe (for val==0, * the retrieved position would be -1). But starting with Lucene 2.9, * this unfortunately changed, and only val>0 are safe. val=0 can * still be used, but don't count on the value you retrieve later * (it could be 0 or -1, depending on circumstances or versions). * This change is described in Lucene's JIRA: LUCENE-1542. */	TokenNameCOMMENT_JAVADOC	 Set the value we want to keep, as the position increment. Note that when TermPositions.nextPosition() is later used to retrieve this value, val-1 will be returned, not val. <P> IMPORTANT NOTE: Before Lucene 2.9, val>=0 were safe (for val==0, the retrieved position would be -1). But starting with Lucene 2.9, this unfortunately changed, and only val>0 are safe. val=0 can still be used, but don't count on the value you retrieve later (it could be 0 or -1, depending on circumstances or versions). This change is described in Lucene's JIRA: LUCENE-1542. 
public	TokenNamepublic	
void	TokenNamevoid	
set	TokenNameIdentifier	 set
(	TokenNameLPAREN	
int	TokenNameint	
val	TokenNameIdentifier	 val
)	TokenNameRPAREN	
{	TokenNameLBRACE	
posIncrAtt	TokenNameIdentifier	 pos Incr Att
.	TokenNameDOT	
setPositionIncrement	TokenNameIdentifier	 set Position Increment
(	TokenNameLPAREN	
val	TokenNameIdentifier	 val
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
returned	TokenNameIdentifier	 returned
=	TokenNameEQUAL	
false	TokenNamefalse	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
@	TokenNameAT	
Override	TokenNameIdentifier	 Override
public	TokenNamepublic	
boolean	TokenNameboolean	
incrementToken	TokenNameIdentifier	 increment Token
(	TokenNameLPAREN	
)	TokenNameRPAREN	
throws	TokenNamethrows	
IOException	TokenNameIdentifier	 IO Exception
{	TokenNameLBRACE	
if	TokenNameif	
(	TokenNameLPAREN	
returned	TokenNameIdentifier	 returned
)	TokenNameRPAREN	
{	TokenNameLBRACE	
return	TokenNamereturn	
false	TokenNamefalse	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
returned	TokenNameIdentifier	 returned
=	TokenNameEQUAL	
true	TokenNametrue	
;	TokenNameSEMICOLON	
return	TokenNamereturn	
true	TokenNametrue	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
}	TokenNameRBRACE	
private	TokenNameprivate	
void	TokenNamevoid	
addToCache	TokenNameIdentifier	 add To Cache
(	TokenNameLPAREN	
CategoryPath	TokenNameIdentifier	 Category Path
categoryPath	TokenNameIdentifier	 category Path
,	TokenNameCOMMA	
int	TokenNameint	
id	TokenNameIdentifier	 id
)	TokenNameRPAREN	
throws	TokenNamethrows	
CorruptIndexException	TokenNameIdentifier	 Corrupt Index Exception
,	TokenNameCOMMA	
IOException	TokenNameIdentifier	 IO Exception
{	TokenNameLBRACE	
if	TokenNameif	
(	TokenNameLPAREN	
cache	TokenNameIdentifier	 cache
.	TokenNameDOT	
put	TokenNameIdentifier	 put
(	TokenNameLPAREN	
categoryPath	TokenNameIdentifier	 category Path
,	TokenNameCOMMA	
id	TokenNameIdentifier	 id
)	TokenNameRPAREN	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
// If cache.put() returned true, it means the cache was limited in 	TokenNameCOMMENT_LINE	If cache.put() returned true, it means the cache was limited in 
// size, became full, so parts of it had to be cleared. 	TokenNameCOMMENT_LINE	size, became full, so parts of it had to be cleared. 
// Unfortunately we don't know which part was cleared - it is 	TokenNameCOMMENT_LINE	Unfortunately we don't know which part was cleared - it is 
// possible that a relatively-new category that hasn't yet been 	TokenNameCOMMENT_LINE	possible that a relatively-new category that hasn't yet been 
// committed to disk (and therefore isn't yet visible in our 	TokenNameCOMMENT_LINE	committed to disk (and therefore isn't yet visible in our 
// "reader") was deleted from the cache, and therefore we must 	TokenNameCOMMENT_LINE	"reader") was deleted from the cache, and therefore we must 
// now refresh the reader. 	TokenNameCOMMENT_LINE	now refresh the reader. 
// Because this is a slow operation, cache implementations are 	TokenNameCOMMENT_LINE	Because this is a slow operation, cache implementations are 
// expected not to delete entries one-by-one but rather in bulk 	TokenNameCOMMENT_LINE	expected not to delete entries one-by-one but rather in bulk 
// (LruTaxonomyWriterCache removes the 2/3rd oldest entries). 	TokenNameCOMMENT_LINE	(LruTaxonomyWriterCache removes the 2/3rd oldest entries). 
refreshReader	TokenNameIdentifier	 refresh Reader
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
cacheIsComplete	TokenNameIdentifier	 cache Is Complete
=	TokenNameEQUAL	
false	TokenNamefalse	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
}	TokenNameRBRACE	
private	TokenNameprivate	
void	TokenNamevoid	
addToCache	TokenNameIdentifier	 add To Cache
(	TokenNameLPAREN	
CategoryPath	TokenNameIdentifier	 Category Path
categoryPath	TokenNameIdentifier	 category Path
,	TokenNameCOMMA	
int	TokenNameint	
prefixLen	TokenNameIdentifier	 prefix Len
,	TokenNameCOMMA	
int	TokenNameint	
id	TokenNameIdentifier	 id
)	TokenNameRPAREN	
throws	TokenNamethrows	
CorruptIndexException	TokenNameIdentifier	 Corrupt Index Exception
,	TokenNameCOMMA	
IOException	TokenNameIdentifier	 IO Exception
{	TokenNameLBRACE	
if	TokenNameif	
(	TokenNameLPAREN	
cache	TokenNameIdentifier	 cache
.	TokenNameDOT	
put	TokenNameIdentifier	 put
(	TokenNameLPAREN	
categoryPath	TokenNameIdentifier	 category Path
,	TokenNameCOMMA	
prefixLen	TokenNameIdentifier	 prefix Len
,	TokenNameCOMMA	
id	TokenNameIdentifier	 id
)	TokenNameRPAREN	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
refreshReader	TokenNameIdentifier	 refresh Reader
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
cacheIsComplete	TokenNameIdentifier	 cache Is Complete
=	TokenNameEQUAL	
false	TokenNamefalse	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
}	TokenNameRBRACE	
private	TokenNameprivate	
synchronized	TokenNamesynchronized	
void	TokenNamevoid	
refreshReader	TokenNameIdentifier	 refresh Reader
(	TokenNameLPAREN	
)	TokenNameRPAREN	
throws	TokenNamethrows	
IOException	TokenNameIdentifier	 IO Exception
{	TokenNameLBRACE	
if	TokenNameif	
(	TokenNameLPAREN	
reader	TokenNameIdentifier	 reader
!=	TokenNameNOT_EQUAL	
null	TokenNamenull	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
IndexReader	TokenNameIdentifier	 Index Reader
r2	TokenNameIdentifier	 r2
=	TokenNameEQUAL	
IndexReader	TokenNameIdentifier	 Index Reader
.	TokenNameDOT	
openIfChanged	TokenNameIdentifier	 open If Changed
(	TokenNameLPAREN	
reader	TokenNameIdentifier	 reader
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
if	TokenNameif	
(	TokenNameLPAREN	
r2	TokenNameIdentifier	 r2
!=	TokenNameNOT_EQUAL	
null	TokenNamenull	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
reader	TokenNameIdentifier	 reader
.	TokenNameDOT	
close	TokenNameIdentifier	 close
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
reader	TokenNameIdentifier	 reader
=	TokenNameEQUAL	
r2	TokenNameIdentifier	 r2
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
}	TokenNameRBRACE	
}	TokenNameRBRACE	
/** * Calling commit() ensures that all the categories written so far are * visible to a reader that is opened (or reopened) after that call. * When the index is closed(), commit() is also implicitly done. * See {@link TaxonomyWriter#commit()} */	TokenNameCOMMENT_JAVADOC	 Calling commit() ensures that all the categories written so far are visible to a reader that is opened (or reopened) after that call. When the index is closed(), commit() is also implicitly done. See {@link TaxonomyWriter#commit()} 
public	TokenNamepublic	
synchronized	TokenNamesynchronized	
void	TokenNamevoid	
commit	TokenNameIdentifier	 commit
(	TokenNameLPAREN	
)	TokenNameRPAREN	
throws	TokenNamethrows	
CorruptIndexException	TokenNameIdentifier	 Corrupt Index Exception
,	TokenNameCOMMA	
IOException	TokenNameIdentifier	 IO Exception
{	TokenNameLBRACE	
ensureOpen	TokenNameIdentifier	 ensure Open
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
indexWriter	TokenNameIdentifier	 index Writer
.	TokenNameDOT	
commit	TokenNameIdentifier	 commit
(	TokenNameLPAREN	
combinedCommitData	TokenNameIdentifier	 combined Commit Data
(	TokenNameLPAREN	
null	TokenNamenull	
)	TokenNameRPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
refreshReader	TokenNameIdentifier	 refresh Reader
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
/** * Combine original user data with that of the taxonomy creation time */	TokenNameCOMMENT_JAVADOC	 Combine original user data with that of the taxonomy creation time 
private	TokenNameprivate	
Map	TokenNameIdentifier	 Map
<	TokenNameLESS	
String	TokenNameIdentifier	 String
,	TokenNameCOMMA	
String	TokenNameIdentifier	 String
>	TokenNameGREATER	
combinedCommitData	TokenNameIdentifier	 combined Commit Data
(	TokenNameLPAREN	
Map	TokenNameIdentifier	 Map
<	TokenNameLESS	
String	TokenNameIdentifier	 String
,	TokenNameCOMMA	
String	TokenNameIdentifier	 String
>	TokenNameGREATER	
userData	TokenNameIdentifier	 user Data
)	TokenNameRPAREN	
{	TokenNameLBRACE	
Map	TokenNameIdentifier	 Map
<	TokenNameLESS	
String	TokenNameIdentifier	 String
,	TokenNameCOMMA	
String	TokenNameIdentifier	 String
>	TokenNameGREATER	
m	TokenNameIdentifier	 m
=	TokenNameEQUAL	
new	TokenNamenew	
HashMap	TokenNameIdentifier	 Hash Map
<	TokenNameLESS	
String	TokenNameIdentifier	 String
,	TokenNameCOMMA	
String	TokenNameIdentifier	 String
>	TokenNameGREATER	
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
if	TokenNameif	
(	TokenNameLPAREN	
userData	TokenNameIdentifier	 user Data
!=	TokenNameNOT_EQUAL	
null	TokenNamenull	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
m	TokenNameIdentifier	 m
.	TokenNameDOT	
putAll	TokenNameIdentifier	 put All
(	TokenNameLPAREN	
userData	TokenNameIdentifier	 user Data
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
if	TokenNameif	
(	TokenNameLPAREN	
createTime	TokenNameIdentifier	 create Time
!=	TokenNameNOT_EQUAL	
null	TokenNamenull	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
m	TokenNameIdentifier	 m
.	TokenNameDOT	
put	TokenNameIdentifier	 put
(	TokenNameLPAREN	
INDEX_CREATE_TIME	TokenNameIdentifier	 INDEX  CREATE  TIME
,	TokenNameCOMMA	
createTime	TokenNameIdentifier	 create Time
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
return	TokenNamereturn	
m	TokenNameIdentifier	 m
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
/** * Like commit(), but also store properties with the index. These properties * are retrievable by {@link DirectoryTaxonomyReader#getCommitUserData}. * See {@link TaxonomyWriter#commit(Map)}. */	TokenNameCOMMENT_JAVADOC	 Like commit(), but also store properties with the index. These properties are retrievable by {@link DirectoryTaxonomyReader#getCommitUserData}. See {@link TaxonomyWriter#commit(Map)}. 
public	TokenNamepublic	
synchronized	TokenNamesynchronized	
void	TokenNamevoid	
commit	TokenNameIdentifier	 commit
(	TokenNameLPAREN	
Map	TokenNameIdentifier	 Map
<	TokenNameLESS	
String	TokenNameIdentifier	 String
,	TokenNameCOMMA	
String	TokenNameIdentifier	 String
>	TokenNameGREATER	
commitUserData	TokenNameIdentifier	 commit User Data
)	TokenNameRPAREN	
throws	TokenNamethrows	
CorruptIndexException	TokenNameIdentifier	 Corrupt Index Exception
,	TokenNameCOMMA	
IOException	TokenNameIdentifier	 IO Exception
{	TokenNameLBRACE	
ensureOpen	TokenNameIdentifier	 ensure Open
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
indexWriter	TokenNameIdentifier	 index Writer
.	TokenNameDOT	
commit	TokenNameIdentifier	 commit
(	TokenNameLPAREN	
combinedCommitData	TokenNameIdentifier	 combined Commit Data
(	TokenNameLPAREN	
commitUserData	TokenNameIdentifier	 commit User Data
)	TokenNameRPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
refreshReader	TokenNameIdentifier	 refresh Reader
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
/** * prepare most of the work needed for a two-phase commit. * See {@link IndexWriter#prepareCommit}. */	TokenNameCOMMENT_JAVADOC	 prepare most of the work needed for a two-phase commit. See {@link IndexWriter#prepareCommit}. 
public	TokenNamepublic	
synchronized	TokenNamesynchronized	
void	TokenNamevoid	
prepareCommit	TokenNameIdentifier	 prepare Commit
(	TokenNameLPAREN	
)	TokenNameRPAREN	
throws	TokenNamethrows	
CorruptIndexException	TokenNameIdentifier	 Corrupt Index Exception
,	TokenNameCOMMA	
IOException	TokenNameIdentifier	 IO Exception
{	TokenNameLBRACE	
ensureOpen	TokenNameIdentifier	 ensure Open
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
indexWriter	TokenNameIdentifier	 index Writer
.	TokenNameDOT	
prepareCommit	TokenNameIdentifier	 prepare Commit
(	TokenNameLPAREN	
combinedCommitData	TokenNameIdentifier	 combined Commit Data
(	TokenNameLPAREN	
null	TokenNamenull	
)	TokenNameRPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
/** * Like above, and also prepares to store user data with the index. * See {@link IndexWriter#prepareCommit(Map)} */	TokenNameCOMMENT_JAVADOC	 Like above, and also prepares to store user data with the index. See {@link IndexWriter#prepareCommit(Map)} 
public	TokenNamepublic	
synchronized	TokenNamesynchronized	
void	TokenNamevoid	
prepareCommit	TokenNameIdentifier	 prepare Commit
(	TokenNameLPAREN	
Map	TokenNameIdentifier	 Map
<	TokenNameLESS	
String	TokenNameIdentifier	 String
,	TokenNameCOMMA	
String	TokenNameIdentifier	 String
>	TokenNameGREATER	
commitUserData	TokenNameIdentifier	 commit User Data
)	TokenNameRPAREN	
throws	TokenNamethrows	
CorruptIndexException	TokenNameIdentifier	 Corrupt Index Exception
,	TokenNameCOMMA	
IOException	TokenNameIdentifier	 IO Exception
{	TokenNameLBRACE	
ensureOpen	TokenNameIdentifier	 ensure Open
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
indexWriter	TokenNameIdentifier	 index Writer
.	TokenNameDOT	
prepareCommit	TokenNameIdentifier	 prepare Commit
(	TokenNameLPAREN	
combinedCommitData	TokenNameIdentifier	 combined Commit Data
(	TokenNameLPAREN	
commitUserData	TokenNameIdentifier	 commit User Data
)	TokenNameRPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
/** * getSize() returns the number of categories in the taxonomy. * <P> * Because categories are numbered consecutively starting with 0, it means * the taxonomy contains ordinals 0 through getSize()-1. * <P> * Note that the number returned by getSize() is often slightly higher than * the number of categories inserted into the taxonomy; This is because when * a category is added to the taxonomy, its ancestors are also added * automatically (including the root, which always get ordinal 0). */	TokenNameCOMMENT_JAVADOC	 getSize() returns the number of categories in the taxonomy. <P> Because categories are numbered consecutively starting with 0, it means the taxonomy contains ordinals 0 through getSize()-1. <P> Note that the number returned by getSize() is often slightly higher than the number of categories inserted into the taxonomy; This is because when a category is added to the taxonomy, its ancestors are also added automatically (including the root, which always get ordinal 0). 
synchronized	TokenNamesynchronized	
public	TokenNamepublic	
int	TokenNameint	
getSize	TokenNameIdentifier	 get Size
(	TokenNameLPAREN	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
ensureOpen	TokenNameIdentifier	 ensure Open
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
return	TokenNamereturn	
indexWriter	TokenNameIdentifier	 index Writer
.	TokenNameDOT	
maxDoc	TokenNameIdentifier	 max Doc
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
private	TokenNameprivate	
boolean	TokenNameboolean	
alreadyCalledFillCache	TokenNameIdentifier	 already Called Fill Cache
=	TokenNameEQUAL	
false	TokenNamefalse	
;	TokenNameSEMICOLON	
/** * Set the number of cache misses before an attempt is made to read the * entire taxonomy into the in-memory cache. * <P> * LuceneTaxonomyWriter holds an in-memory cache of recently seen * categories to speed up operation. On each cache-miss, the on-disk index * needs to be consulted. When an existing taxonomy is opened, a lot of * slow disk reads like that are needed until the cache is filled, so it * is more efficient to read the entire taxonomy into memory at once. * We do this complete read after a certain number (defined by this method) * of cache misses. * <P> * If the number is set to <CODE>0</CODE>, the entire taxonomy is read * into the cache on first use, without fetching individual categories * first. * <P> * Note that if the memory cache of choice is limited in size, and cannot * hold the entire content of the on-disk taxonomy, then it is never * read in its entirety into the cache, regardless of the setting of this * method. */	TokenNameCOMMENT_JAVADOC	 Set the number of cache misses before an attempt is made to read the entire taxonomy into the in-memory cache. <P> LuceneTaxonomyWriter holds an in-memory cache of recently seen categories to speed up operation. On each cache-miss, the on-disk index needs to be consulted. When an existing taxonomy is opened, a lot of slow disk reads like that are needed until the cache is filled, so it is more efficient to read the entire taxonomy into memory at once. We do this complete read after a certain number (defined by this method) of cache misses. <P> If the number is set to <CODE>0</CODE>, the entire taxonomy is read into the cache on first use, without fetching individual categories first. <P> Note that if the memory cache of choice is limited in size, and cannot hold the entire content of the on-disk taxonomy, then it is never read in its entirety into the cache, regardless of the setting of this method. 
public	TokenNamepublic	
void	TokenNamevoid	
setCacheMissesUntilFill	TokenNameIdentifier	 set Cache Misses Until Fill
(	TokenNameLPAREN	
int	TokenNameint	
i	TokenNameIdentifier	 i
)	TokenNameRPAREN	
{	TokenNameLBRACE	
ensureOpen	TokenNameIdentifier	 ensure Open
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
cacheMissesUntilFill	TokenNameIdentifier	 cache Misses Until Fill
=	TokenNameEQUAL	
i	TokenNameIdentifier	 i
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
private	TokenNameprivate	
int	TokenNameint	
cacheMissesUntilFill	TokenNameIdentifier	 cache Misses Until Fill
=	TokenNameEQUAL	
11	TokenNameIntegerLiteral	
;	TokenNameSEMICOLON	
private	TokenNameprivate	
boolean	TokenNameboolean	
perhapsFillCache	TokenNameIdentifier	 perhaps Fill Cache
(	TokenNameLPAREN	
)	TokenNameRPAREN	
throws	TokenNamethrows	
IOException	TokenNameIdentifier	 IO Exception
{	TokenNameLBRACE	
// Note: we assume that we're only called when cacheIsComplete==false. 	TokenNameCOMMENT_LINE	Note: we assume that we're only called when cacheIsComplete==false. 
// TODO (Facet): parametrize this criterion: 	TokenNameCOMMENT_LINE	TODO (Facet): parametrize this criterion: 
if	TokenNameif	
(	TokenNameLPAREN	
cacheMisses	TokenNameIdentifier	 cache Misses
<	TokenNameLESS	
cacheMissesUntilFill	TokenNameIdentifier	 cache Misses Until Fill
)	TokenNameRPAREN	
{	TokenNameLBRACE	
return	TokenNamereturn	
false	TokenNamefalse	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
// If the cache was already filled (or we decided not to fill it because 	TokenNameCOMMENT_LINE	If the cache was already filled (or we decided not to fill it because 
// there was no room), there is no sense in trying it again. 	TokenNameCOMMENT_LINE	there was no room), there is no sense in trying it again. 
if	TokenNameif	
(	TokenNameLPAREN	
alreadyCalledFillCache	TokenNameIdentifier	 already Called Fill Cache
)	TokenNameRPAREN	
{	TokenNameLBRACE	
return	TokenNamereturn	
false	TokenNamefalse	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
alreadyCalledFillCache	TokenNameIdentifier	 already Called Fill Cache
=	TokenNameEQUAL	
true	TokenNametrue	
;	TokenNameSEMICOLON	
// TODO (Facet): we should probably completely clear the cache before starting 	TokenNameCOMMENT_LINE	TODO (Facet): we should probably completely clear the cache before starting 
// to read it? 	TokenNameCOMMENT_LINE	to read it? 
if	TokenNameif	
(	TokenNameLPAREN	
reader	TokenNameIdentifier	 reader
==	TokenNameEQUAL_EQUAL	
null	TokenNamenull	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
reader	TokenNameIdentifier	 reader
=	TokenNameEQUAL	
openReader	TokenNameIdentifier	 open Reader
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
if	TokenNameif	
(	TokenNameLPAREN	
!	TokenNameNOT	
cache	TokenNameIdentifier	 cache
.	TokenNameDOT	
hasRoom	TokenNameIdentifier	 has Room
(	TokenNameLPAREN	
reader	TokenNameIdentifier	 reader
.	TokenNameDOT	
numDocs	TokenNameIdentifier	 num Docs
(	TokenNameLPAREN	
)	TokenNameRPAREN	
)	TokenNameRPAREN	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
return	TokenNamereturn	
false	TokenNamefalse	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
CategoryPath	TokenNameIdentifier	 Category Path
cp	TokenNameIdentifier	 cp
=	TokenNameEQUAL	
new	TokenNamenew	
CategoryPath	TokenNameIdentifier	 Category Path
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
TermDocs	TokenNameIdentifier	 Term Docs
td	TokenNameIdentifier	 td
=	TokenNameEQUAL	
reader	TokenNameIdentifier	 reader
.	TokenNameDOT	
termDocs	TokenNameIdentifier	 term Docs
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
String	TokenNameIdentifier	 String
field	TokenNameIdentifier	 field
=	TokenNameEQUAL	
Consts	TokenNameIdentifier	 Consts
.	TokenNameDOT	
FULL_TERM	TokenNameIdentifier	 FULL  TERM
.	TokenNameDOT	
field	TokenNameIdentifier	 field
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
// needed so we can later use != 	TokenNameCOMMENT_LINE	needed so we can later use != 
TermEnum	TokenNameIdentifier	 Term Enum
terms	TokenNameIdentifier	 terms
=	TokenNameEQUAL	
reader	TokenNameIdentifier	 reader
.	TokenNameDOT	
terms	TokenNameIdentifier	 terms
(	TokenNameLPAREN	
Consts	TokenNameIdentifier	 Consts
.	TokenNameDOT	
FULL_TERM	TokenNameIdentifier	 FULL  TERM
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
// The check is done here to avoid checking it on every iteration of the 	TokenNameCOMMENT_LINE	The check is done here to avoid checking it on every iteration of the 
// below loop. A null term wlil be returned if there are no terms in the 	TokenNameCOMMENT_LINE	below loop. A null term wlil be returned if there are no terms in the 
// lexicon, or after the Consts.FULL term. However while the loop is 	TokenNameCOMMENT_LINE	lexicon, or after the Consts.FULL term. However while the loop is 
// executed we're safe, because we only iterate as long as there are next() 	TokenNameCOMMENT_LINE	executed we're safe, because we only iterate as long as there are next() 
// terms. 	TokenNameCOMMENT_LINE	terms. 
if	TokenNameif	
(	TokenNameLPAREN	
terms	TokenNameIdentifier	 terms
.	TokenNameDOT	
term	TokenNameIdentifier	 term
(	TokenNameLPAREN	
)	TokenNameRPAREN	
!=	TokenNameNOT_EQUAL	
null	TokenNamenull	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
do	TokenNamedo	
{	TokenNameLBRACE	
Term	TokenNameIdentifier	 Term
t	TokenNameIdentifier	 t
=	TokenNameEQUAL	
terms	TokenNameIdentifier	 terms
.	TokenNameDOT	
term	TokenNameIdentifier	 term
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
if	TokenNameif	
(	TokenNameLPAREN	
t	TokenNameIdentifier	 t
.	TokenNameDOT	
field	TokenNameIdentifier	 field
(	TokenNameLPAREN	
)	TokenNameRPAREN	
!=	TokenNameNOT_EQUAL	
field	TokenNameIdentifier	 field
)	TokenNameRPAREN	
break	TokenNamebreak	
;	TokenNameSEMICOLON	
// Since we guarantee uniqueness of categories, each term has exactly 	TokenNameCOMMENT_LINE	Since we guarantee uniqueness of categories, each term has exactly 
// one document. Also, since we do not allow removing categories (and 	TokenNameCOMMENT_LINE	one document. Also, since we do not allow removing categories (and 
// hence documents), there are no deletions in the index. Therefore, it 	TokenNameCOMMENT_LINE	hence documents), there are no deletions in the index. Therefore, it 
// is sufficient to call next(), and then doc(), exactly once with no 	TokenNameCOMMENT_LINE	is sufficient to call next(), and then doc(), exactly once with no 
// 'validation' checks. 	TokenNameCOMMENT_LINE	'validation' checks. 
td	TokenNameIdentifier	 td
.	TokenNameDOT	
seek	TokenNameIdentifier	 seek
(	TokenNameLPAREN	
t	TokenNameIdentifier	 t
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
td	TokenNameIdentifier	 td
.	TokenNameDOT	
next	TokenNameIdentifier	 next
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
cp	TokenNameIdentifier	 cp
.	TokenNameDOT	
clear	TokenNameIdentifier	 clear
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
cp	TokenNameIdentifier	 cp
.	TokenNameDOT	
add	TokenNameIdentifier	 add
(	TokenNameLPAREN	
t	TokenNameIdentifier	 t
.	TokenNameDOT	
text	TokenNameIdentifier	 text
(	TokenNameLPAREN	
)	TokenNameRPAREN	
,	TokenNameCOMMA	
delimiter	TokenNameIdentifier	 delimiter
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
cache	TokenNameIdentifier	 cache
.	TokenNameDOT	
put	TokenNameIdentifier	 put
(	TokenNameLPAREN	
cp	TokenNameIdentifier	 cp
,	TokenNameCOMMA	
td	TokenNameIdentifier	 td
.	TokenNameDOT	
doc	TokenNameIdentifier	 doc
(	TokenNameLPAREN	
)	TokenNameRPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
while	TokenNamewhile	
(	TokenNameLPAREN	
terms	TokenNameIdentifier	 terms
.	TokenNameDOT	
next	TokenNameIdentifier	 next
(	TokenNameLPAREN	
)	TokenNameRPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
cacheIsComplete	TokenNameIdentifier	 cache Is Complete
=	TokenNameEQUAL	
true	TokenNametrue	
;	TokenNameSEMICOLON	
// No sense to keep the reader open - we will not need to read from it 	TokenNameCOMMENT_LINE	No sense to keep the reader open - we will not need to read from it 
// if everything is in the cache. 	TokenNameCOMMENT_LINE	if everything is in the cache. 
reader	TokenNameIdentifier	 reader
.	TokenNameDOT	
close	TokenNameIdentifier	 close
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
reader	TokenNameIdentifier	 reader
=	TokenNameEQUAL	
null	TokenNamenull	
;	TokenNameSEMICOLON	
return	TokenNamereturn	
true	TokenNametrue	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
private	TokenNameprivate	
ParentArray	TokenNameIdentifier	 Parent Array
parentArray	TokenNameIdentifier	 parent Array
;	TokenNameSEMICOLON	
private	TokenNameprivate	
synchronized	TokenNamesynchronized	
ParentArray	TokenNameIdentifier	 Parent Array
getParentArray	TokenNameIdentifier	 get Parent Array
(	TokenNameLPAREN	
)	TokenNameRPAREN	
throws	TokenNamethrows	
IOException	TokenNameIdentifier	 IO Exception
{	TokenNameLBRACE	
if	TokenNameif	
(	TokenNameLPAREN	
parentArray	TokenNameIdentifier	 parent Array
==	TokenNameEQUAL_EQUAL	
null	TokenNamenull	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
if	TokenNameif	
(	TokenNameLPAREN	
reader	TokenNameIdentifier	 reader
==	TokenNameEQUAL_EQUAL	
null	TokenNamenull	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
reader	TokenNameIdentifier	 reader
=	TokenNameEQUAL	
openReader	TokenNameIdentifier	 open Reader
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
parentArray	TokenNameIdentifier	 parent Array
=	TokenNameEQUAL	
new	TokenNamenew	
ParentArray	TokenNameIdentifier	 Parent Array
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
parentArray	TokenNameIdentifier	 parent Array
.	TokenNameDOT	
refresh	TokenNameIdentifier	 refresh
(	TokenNameLPAREN	
reader	TokenNameIdentifier	 reader
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
return	TokenNamereturn	
parentArray	TokenNameIdentifier	 parent Array
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
public	TokenNamepublic	
int	TokenNameint	
getParent	TokenNameIdentifier	 get Parent
(	TokenNameLPAREN	
int	TokenNameint	
ordinal	TokenNameIdentifier	 ordinal
)	TokenNameRPAREN	
throws	TokenNamethrows	
IOException	TokenNameIdentifier	 IO Exception
{	TokenNameLBRACE	
ensureOpen	TokenNameIdentifier	 ensure Open
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
// Note: the following if() just enforces that a user can never ask 	TokenNameCOMMENT_LINE	Note: the following if() just enforces that a user can never ask 
// for the parent of a nonexistant category - even if the parent array 	TokenNameCOMMENT_LINE	for the parent of a nonexistant category - even if the parent array 
// was allocated bigger than it really needs to be. 	TokenNameCOMMENT_LINE	was allocated bigger than it really needs to be. 
if	TokenNameif	
(	TokenNameLPAREN	
ordinal	TokenNameIdentifier	 ordinal
>=	TokenNameGREATER_EQUAL	
getSize	TokenNameIdentifier	 get Size
(	TokenNameLPAREN	
)	TokenNameRPAREN	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
throw	TokenNamethrow	
new	TokenNamenew	
ArrayIndexOutOfBoundsException	TokenNameIdentifier	 Array Index Out Of Bounds Exception
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
return	TokenNamereturn	
getParentArray	TokenNameIdentifier	 get Parent Array
(	TokenNameLPAREN	
)	TokenNameRPAREN	
.	TokenNameDOT	
getArray	TokenNameIdentifier	 get Array
(	TokenNameLPAREN	
)	TokenNameRPAREN	
[	TokenNameLBRACKET	
ordinal	TokenNameIdentifier	 ordinal
]	TokenNameRBRACKET	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
/** * Takes the categories from the given taxonomy directory, and adds the * missing ones to this taxonomy. Additionally, it fills the given * {@link OrdinalMap} with a mapping from the original ordinal to the new * ordinal. */	TokenNameCOMMENT_JAVADOC	 Takes the categories from the given taxonomy directory, and adds the missing ones to this taxonomy. Additionally, it fills the given {@link OrdinalMap} with a mapping from the original ordinal to the new ordinal. 
public	TokenNamepublic	
void	TokenNamevoid	
addTaxonomy	TokenNameIdentifier	 add Taxonomy
(	TokenNameLPAREN	
Directory	TokenNameIdentifier	 Directory
taxoDir	TokenNameIdentifier	 taxo Dir
,	TokenNameCOMMA	
OrdinalMap	TokenNameIdentifier	 Ordinal Map
map	TokenNameIdentifier	 map
)	TokenNameRPAREN	
throws	TokenNamethrows	
IOException	TokenNameIdentifier	 IO Exception
{	TokenNameLBRACE	
ensureOpen	TokenNameIdentifier	 ensure Open
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
IndexReader	TokenNameIdentifier	 Index Reader
r	TokenNameIdentifier	 r
=	TokenNameEQUAL	
IndexReader	TokenNameIdentifier	 Index Reader
.	TokenNameDOT	
open	TokenNameIdentifier	 open
(	TokenNameLPAREN	
taxoDir	TokenNameIdentifier	 taxo Dir
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
try	TokenNametry	
{	TokenNameLBRACE	
final	TokenNamefinal	
int	TokenNameint	
size	TokenNameIdentifier	 size
=	TokenNameEQUAL	
r	TokenNameIdentifier	 r
.	TokenNameDOT	
numDocs	TokenNameIdentifier	 num Docs
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
final	TokenNamefinal	
OrdinalMap	TokenNameIdentifier	 Ordinal Map
ordinalMap	TokenNameIdentifier	 ordinal Map
=	TokenNameEQUAL	
map	TokenNameIdentifier	 map
;	TokenNameSEMICOLON	
ordinalMap	TokenNameIdentifier	 ordinal Map
.	TokenNameDOT	
setSize	TokenNameIdentifier	 set Size
(	TokenNameLPAREN	
size	TokenNameIdentifier	 size
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
CategoryPath	TokenNameIdentifier	 Category Path
cp	TokenNameIdentifier	 cp
=	TokenNameEQUAL	
new	TokenNamenew	
CategoryPath	TokenNameIdentifier	 Category Path
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
TermEnum	TokenNameIdentifier	 Term Enum
te	TokenNameIdentifier	 te
=	TokenNameEQUAL	
r	TokenNameIdentifier	 r
.	TokenNameDOT	
terms	TokenNameIdentifier	 terms
(	TokenNameLPAREN	
Consts	TokenNameIdentifier	 Consts
.	TokenNameDOT	
FULL_TERM	TokenNameIdentifier	 FULL  TERM
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
TermDocs	TokenNameIdentifier	 Term Docs
docs	TokenNameIdentifier	 docs
=	TokenNameEQUAL	
r	TokenNameIdentifier	 r
.	TokenNameDOT	
termDocs	TokenNameIdentifier	 term Docs
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
// we call next() first, to skip the root category which always exists. 	TokenNameCOMMENT_LINE	we call next() first, to skip the root category which always exists. 
while	TokenNamewhile	
(	TokenNameLPAREN	
te	TokenNameIdentifier	 te
.	TokenNameDOT	
next	TokenNameIdentifier	 next
(	TokenNameLPAREN	
)	TokenNameRPAREN	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
Term	TokenNameIdentifier	 Term
term	TokenNameIdentifier	 term
=	TokenNameEQUAL	
te	TokenNameIdentifier	 te
.	TokenNameDOT	
term	TokenNameIdentifier	 term
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
if	TokenNameif	
(	TokenNameLPAREN	
term	TokenNameIdentifier	 term
.	TokenNameDOT	
field	TokenNameIdentifier	 field
(	TokenNameLPAREN	
)	TokenNameRPAREN	
!=	TokenNameNOT_EQUAL	
Consts	TokenNameIdentifier	 Consts
.	TokenNameDOT	
FULL	TokenNameIdentifier	 FULL
)	TokenNameRPAREN	
break	TokenNamebreak	
;	TokenNameSEMICOLON	
cp	TokenNameIdentifier	 cp
.	TokenNameDOT	
clear	TokenNameIdentifier	 clear
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
cp	TokenNameIdentifier	 cp
.	TokenNameDOT	
add	TokenNameIdentifier	 add
(	TokenNameLPAREN	
term	TokenNameIdentifier	 term
.	TokenNameDOT	
text	TokenNameIdentifier	 text
(	TokenNameLPAREN	
)	TokenNameRPAREN	
,	TokenNameCOMMA	
Consts	TokenNameIdentifier	 Consts
.	TokenNameDOT	
DEFAULT_DELIMITER	TokenNameIdentifier	 DEFAULT  DELIMITER
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
final	TokenNamefinal	
int	TokenNameint	
ordinal	TokenNameIdentifier	 ordinal
=	TokenNameEQUAL	
addCategory	TokenNameIdentifier	 add Category
(	TokenNameLPAREN	
cp	TokenNameIdentifier	 cp
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
docs	TokenNameIdentifier	 docs
.	TokenNameDOT	
seek	TokenNameIdentifier	 seek
(	TokenNameLPAREN	
term	TokenNameIdentifier	 term
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
docs	TokenNameIdentifier	 docs
.	TokenNameDOT	
next	TokenNameIdentifier	 next
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
ordinalMap	TokenNameIdentifier	 ordinal Map
.	TokenNameDOT	
addMapping	TokenNameIdentifier	 add Mapping
(	TokenNameLPAREN	
docs	TokenNameIdentifier	 docs
.	TokenNameDOT	
doc	TokenNameIdentifier	 doc
(	TokenNameLPAREN	
)	TokenNameRPAREN	
,	TokenNameCOMMA	
ordinal	TokenNameIdentifier	 ordinal
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
// we must add the root ordinal map, so that the map will be complete 	TokenNameCOMMENT_LINE	we must add the root ordinal map, so that the map will be complete 
// (otherwise e.g. DiskOrdinalMap may fail because it expects more 	TokenNameCOMMENT_LINE	(otherwise e.g. DiskOrdinalMap may fail because it expects more 
// categories to exist in the file). 	TokenNameCOMMENT_LINE	categories to exist in the file). 
ordinalMap	TokenNameIdentifier	 ordinal Map
.	TokenNameDOT	
addMapping	TokenNameIdentifier	 add Mapping
(	TokenNameLPAREN	
0	TokenNameIntegerLiteral	
,	TokenNameCOMMA	
0	TokenNameIntegerLiteral	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
ordinalMap	TokenNameIdentifier	 ordinal Map
.	TokenNameDOT	
addDone	TokenNameIdentifier	 add Done
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
finally	TokenNamefinally	
{	TokenNameLBRACE	
r	TokenNameIdentifier	 r
.	TokenNameDOT	
close	TokenNameIdentifier	 close
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
}	TokenNameRBRACE	
/** * Mapping from old ordinal to new ordinals, used when merging indexes * wit separate taxonomies. * <p> * addToTaxonomies() merges one or more taxonomies into the given taxonomy * (this). An OrdinalMap is filled for each of the added taxonomies, * containing the new ordinal (in the merged taxonomy) of each of the * categories in the old taxonomy. * <P> * There exist two implementations of OrdinalMap: MemoryOrdinalMap and * DiskOrdinalMap. As their names suggest, the former keeps the map in * memory and the latter in a temporary disk file. Because these maps will * later be needed one by one (to remap the counting lists), not all at the * same time, it is recommended to put the first taxonomy's map in memory, * and all the rest on disk (later to be automatically read into memory one * by one, when needed). */	TokenNameCOMMENT_JAVADOC	 Mapping from old ordinal to new ordinals, used when merging indexes wit separate taxonomies. <p> addToTaxonomies() merges one or more taxonomies into the given taxonomy (this). An OrdinalMap is filled for each of the added taxonomies, containing the new ordinal (in the merged taxonomy) of each of the categories in the old taxonomy. <P> There exist two implementations of OrdinalMap: MemoryOrdinalMap and DiskOrdinalMap. As their names suggest, the former keeps the map in memory and the latter in a temporary disk file. Because these maps will later be needed one by one (to remap the counting lists), not all at the same time, it is recommended to put the first taxonomy's map in memory, and all the rest on disk (later to be automatically read into memory one by one, when needed). 
public	TokenNamepublic	
static	TokenNamestatic	
interface	TokenNameinterface	
OrdinalMap	TokenNameIdentifier	 Ordinal Map
{	TokenNameLBRACE	
/** * Set the size of the map. This MUST be called before addMapping(). * It is assumed (but not verified) that addMapping() will then be * called exactly 'size' times, with different origOrdinals between 0 * and size-1. */	TokenNameCOMMENT_JAVADOC	 Set the size of the map. This MUST be called before addMapping(). It is assumed (but not verified) that addMapping() will then be called exactly 'size' times, with different origOrdinals between 0 and size-1. 
public	TokenNamepublic	
void	TokenNamevoid	
setSize	TokenNameIdentifier	 set Size
(	TokenNameLPAREN	
int	TokenNameint	
size	TokenNameIdentifier	 size
)	TokenNameRPAREN	
throws	TokenNamethrows	
IOException	TokenNameIdentifier	 IO Exception
;	TokenNameSEMICOLON	
public	TokenNamepublic	
void	TokenNamevoid	
addMapping	TokenNameIdentifier	 add Mapping
(	TokenNameLPAREN	
int	TokenNameint	
origOrdinal	TokenNameIdentifier	 orig Ordinal
,	TokenNameCOMMA	
int	TokenNameint	
newOrdinal	TokenNameIdentifier	 new Ordinal
)	TokenNameRPAREN	
throws	TokenNamethrows	
IOException	TokenNameIdentifier	 IO Exception
;	TokenNameSEMICOLON	
/** * Call addDone() to say that all addMapping() have been done. * In some implementations this might free some resources. */	TokenNameCOMMENT_JAVADOC	 Call addDone() to say that all addMapping() have been done. In some implementations this might free some resources. 
public	TokenNamepublic	
void	TokenNamevoid	
addDone	TokenNameIdentifier	 add Done
(	TokenNameLPAREN	
)	TokenNameRPAREN	
throws	TokenNamethrows	
IOException	TokenNameIdentifier	 IO Exception
;	TokenNameSEMICOLON	
/** * Return the map from the taxonomy's original (consecutive) ordinals * to the new taxonomy's ordinals. If the map has to be read from disk * and ordered appropriately, it is done when getMap() is called. * getMap() should only be called once, and only when the map is actually * needed. Calling it will also free all resources that the map might * be holding (such as temporary disk space), other than the returned int[]. */	TokenNameCOMMENT_JAVADOC	 Return the map from the taxonomy's original (consecutive) ordinals to the new taxonomy's ordinals. If the map has to be read from disk and ordered appropriately, it is done when getMap() is called. getMap() should only be called once, and only when the map is actually needed. Calling it will also free all resources that the map might be holding (such as temporary disk space), other than the returned int[]. 
public	TokenNamepublic	
int	TokenNameint	
[	TokenNameLBRACKET	
]	TokenNameRBRACKET	
getMap	TokenNameIdentifier	 get Map
(	TokenNameLPAREN	
)	TokenNameRPAREN	
throws	TokenNamethrows	
IOException	TokenNameIdentifier	 IO Exception
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
/** * {@link OrdinalMap} maintained in memory */	TokenNameCOMMENT_JAVADOC	 {@link OrdinalMap} maintained in memory 
public	TokenNamepublic	
static	TokenNamestatic	
final	TokenNamefinal	
class	TokenNameclass	
MemoryOrdinalMap	TokenNameIdentifier	 Memory Ordinal Map
implements	TokenNameimplements	
OrdinalMap	TokenNameIdentifier	 Ordinal Map
{	TokenNameLBRACE	
int	TokenNameint	
[	TokenNameLBRACKET	
]	TokenNameRBRACKET	
map	TokenNameIdentifier	 map
;	TokenNameSEMICOLON	
public	TokenNamepublic	
void	TokenNamevoid	
setSize	TokenNameIdentifier	 set Size
(	TokenNameLPAREN	
int	TokenNameint	
taxonomySize	TokenNameIdentifier	 taxonomy Size
)	TokenNameRPAREN	
{	TokenNameLBRACE	
map	TokenNameIdentifier	 map
=	TokenNameEQUAL	
new	TokenNamenew	
int	TokenNameint	
[	TokenNameLBRACKET	
taxonomySize	TokenNameIdentifier	 taxonomy Size
]	TokenNameRBRACKET	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
public	TokenNamepublic	
void	TokenNamevoid	
addMapping	TokenNameIdentifier	 add Mapping
(	TokenNameLPAREN	
int	TokenNameint	
origOrdinal	TokenNameIdentifier	 orig Ordinal
,	TokenNameCOMMA	
int	TokenNameint	
newOrdinal	TokenNameIdentifier	 new Ordinal
)	TokenNameRPAREN	
{	TokenNameLBRACE	
map	TokenNameIdentifier	 map
[	TokenNameLBRACKET	
origOrdinal	TokenNameIdentifier	 orig Ordinal
]	TokenNameRBRACKET	
=	TokenNameEQUAL	
newOrdinal	TokenNameIdentifier	 new Ordinal
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
public	TokenNamepublic	
void	TokenNamevoid	
addDone	TokenNameIdentifier	 add Done
(	TokenNameLPAREN	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
/* nothing to do */	TokenNameCOMMENT_BLOCK	 nothing to do 
}	TokenNameRBRACE	
public	TokenNamepublic	
int	TokenNameint	
[	TokenNameLBRACKET	
]	TokenNameRBRACKET	
getMap	TokenNameIdentifier	 get Map
(	TokenNameLPAREN	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
return	TokenNamereturn	
map	TokenNameIdentifier	 map
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
}	TokenNameRBRACE	
/** * {@link OrdinalMap} maintained on file system */	TokenNameCOMMENT_JAVADOC	 {@link OrdinalMap} maintained on file system 
public	TokenNamepublic	
static	TokenNamestatic	
final	TokenNamefinal	
class	TokenNameclass	
DiskOrdinalMap	TokenNameIdentifier	 Disk Ordinal Map
implements	TokenNameimplements	
OrdinalMap	TokenNameIdentifier	 Ordinal Map
{	TokenNameLBRACE	
File	TokenNameIdentifier	 File
tmpfile	TokenNameIdentifier	 tmpfile
;	TokenNameSEMICOLON	
DataOutputStream	TokenNameIdentifier	 Data Output Stream
out	TokenNameIdentifier	 out
;	TokenNameSEMICOLON	
public	TokenNamepublic	
DiskOrdinalMap	TokenNameIdentifier	 Disk Ordinal Map
(	TokenNameLPAREN	
File	TokenNameIdentifier	 File
tmpfile	TokenNameIdentifier	 tmpfile
)	TokenNameRPAREN	
throws	TokenNamethrows	
FileNotFoundException	TokenNameIdentifier	 File Not Found Exception
{	TokenNameLBRACE	
this	TokenNamethis	
.	TokenNameDOT	
tmpfile	TokenNameIdentifier	 tmpfile
=	TokenNameEQUAL	
tmpfile	TokenNameIdentifier	 tmpfile
;	TokenNameSEMICOLON	
out	TokenNameIdentifier	 out
=	TokenNameEQUAL	
new	TokenNamenew	
DataOutputStream	TokenNameIdentifier	 Data Output Stream
(	TokenNameLPAREN	
new	TokenNamenew	
BufferedOutputStream	TokenNameIdentifier	 Buffered Output Stream
(	TokenNameLPAREN	
new	TokenNamenew	
FileOutputStream	TokenNameIdentifier	 File Output Stream
(	TokenNameLPAREN	
tmpfile	TokenNameIdentifier	 tmpfile
)	TokenNameRPAREN	
)	TokenNameRPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
public	TokenNamepublic	
void	TokenNamevoid	
addMapping	TokenNameIdentifier	 add Mapping
(	TokenNameLPAREN	
int	TokenNameint	
origOrdinal	TokenNameIdentifier	 orig Ordinal
,	TokenNameCOMMA	
int	TokenNameint	
newOrdinal	TokenNameIdentifier	 new Ordinal
)	TokenNameRPAREN	
throws	TokenNamethrows	
IOException	TokenNameIdentifier	 IO Exception
{	TokenNameLBRACE	
out	TokenNameIdentifier	 out
.	TokenNameDOT	
writeInt	TokenNameIdentifier	 write Int
(	TokenNameLPAREN	
origOrdinal	TokenNameIdentifier	 orig Ordinal
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
out	TokenNameIdentifier	 out
.	TokenNameDOT	
writeInt	TokenNameIdentifier	 write Int
(	TokenNameLPAREN	
newOrdinal	TokenNameIdentifier	 new Ordinal
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
public	TokenNamepublic	
void	TokenNamevoid	
setSize	TokenNameIdentifier	 set Size
(	TokenNameLPAREN	
int	TokenNameint	
taxonomySize	TokenNameIdentifier	 taxonomy Size
)	TokenNameRPAREN	
throws	TokenNamethrows	
IOException	TokenNameIdentifier	 IO Exception
{	TokenNameLBRACE	
out	TokenNameIdentifier	 out
.	TokenNameDOT	
writeInt	TokenNameIdentifier	 write Int
(	TokenNameLPAREN	
taxonomySize	TokenNameIdentifier	 taxonomy Size
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
public	TokenNamepublic	
void	TokenNamevoid	
addDone	TokenNameIdentifier	 add Done
(	TokenNameLPAREN	
)	TokenNameRPAREN	
throws	TokenNamethrows	
IOException	TokenNameIdentifier	 IO Exception
{	TokenNameLBRACE	
if	TokenNameif	
(	TokenNameLPAREN	
out	TokenNameIdentifier	 out
!=	TokenNameNOT_EQUAL	
null	TokenNamenull	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
out	TokenNameIdentifier	 out
.	TokenNameDOT	
close	TokenNameIdentifier	 close
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
out	TokenNameIdentifier	 out
=	TokenNameEQUAL	
null	TokenNamenull	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
}	TokenNameRBRACE	
int	TokenNameint	
[	TokenNameLBRACKET	
]	TokenNameRBRACKET	
map	TokenNameIdentifier	 map
=	TokenNameEQUAL	
null	TokenNamenull	
;	TokenNameSEMICOLON	
public	TokenNamepublic	
int	TokenNameint	
[	TokenNameLBRACKET	
]	TokenNameRBRACKET	
getMap	TokenNameIdentifier	 get Map
(	TokenNameLPAREN	
)	TokenNameRPAREN	
throws	TokenNamethrows	
IOException	TokenNameIdentifier	 IO Exception
{	TokenNameLBRACE	
if	TokenNameif	
(	TokenNameLPAREN	
map	TokenNameIdentifier	 map
!=	TokenNameNOT_EQUAL	
null	TokenNamenull	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
return	TokenNamereturn	
map	TokenNameIdentifier	 map
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
addDone	TokenNameIdentifier	 add Done
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
// in case this wasn't previously called 	TokenNameCOMMENT_LINE	in case this wasn't previously called 
DataInputStream	TokenNameIdentifier	 Data Input Stream
in	TokenNameIdentifier	 in
=	TokenNameEQUAL	
new	TokenNamenew	
DataInputStream	TokenNameIdentifier	 Data Input Stream
(	TokenNameLPAREN	
new	TokenNamenew	
BufferedInputStream	TokenNameIdentifier	 Buffered Input Stream
(	TokenNameLPAREN	
new	TokenNamenew	
FileInputStream	TokenNameIdentifier	 File Input Stream
(	TokenNameLPAREN	
tmpfile	TokenNameIdentifier	 tmpfile
)	TokenNameRPAREN	
)	TokenNameRPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
map	TokenNameIdentifier	 map
=	TokenNameEQUAL	
new	TokenNamenew	
int	TokenNameint	
[	TokenNameLBRACKET	
in	TokenNameIdentifier	 in
.	TokenNameDOT	
readInt	TokenNameIdentifier	 read Int
(	TokenNameLPAREN	
)	TokenNameRPAREN	
]	TokenNameRBRACKET	
;	TokenNameSEMICOLON	
// NOTE: The current code assumes here that the map is complete, 	TokenNameCOMMENT_LINE	NOTE: The current code assumes here that the map is complete, 
// i.e., every ordinal gets one and exactly one value. Otherwise, 	TokenNameCOMMENT_LINE	i.e., every ordinal gets one and exactly one value. Otherwise, 
// we may run into an EOF here, or vice versa, not read everything. 	TokenNameCOMMENT_LINE	we may run into an EOF here, or vice versa, not read everything. 
for	TokenNamefor	
(	TokenNameLPAREN	
int	TokenNameint	
i	TokenNameIdentifier	 i
=	TokenNameEQUAL	
0	TokenNameIntegerLiteral	
;	TokenNameSEMICOLON	
i	TokenNameIdentifier	 i
<	TokenNameLESS	
map	TokenNameIdentifier	 map
.	TokenNameDOT	
length	TokenNameIdentifier	 length
;	TokenNameSEMICOLON	
i	TokenNameIdentifier	 i
++	TokenNamePLUS_PLUS	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
int	TokenNameint	
origordinal	TokenNameIdentifier	 origordinal
=	TokenNameEQUAL	
in	TokenNameIdentifier	 in
.	TokenNameDOT	
readInt	TokenNameIdentifier	 read Int
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
int	TokenNameint	
newordinal	TokenNameIdentifier	 newordinal
=	TokenNameEQUAL	
in	TokenNameIdentifier	 in
.	TokenNameDOT	
readInt	TokenNameIdentifier	 read Int
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
map	TokenNameIdentifier	 map
[	TokenNameLBRACKET	
origordinal	TokenNameIdentifier	 origordinal
]	TokenNameRBRACKET	
=	TokenNameEQUAL	
newordinal	TokenNameIdentifier	 newordinal
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
in	TokenNameIdentifier	 in
.	TokenNameDOT	
close	TokenNameIdentifier	 close
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
// Delete the temporary file, which is no longer needed. 	TokenNameCOMMENT_LINE	Delete the temporary file, which is no longer needed. 
if	TokenNameif	
(	TokenNameLPAREN	
!	TokenNameNOT	
tmpfile	TokenNameIdentifier	 tmpfile
.	TokenNameDOT	
delete	TokenNameIdentifier	 delete
(	TokenNameLPAREN	
)	TokenNameRPAREN	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
tmpfile	TokenNameIdentifier	 tmpfile
.	TokenNameDOT	
deleteOnExit	TokenNameIdentifier	 delete On Exit
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
return	TokenNamereturn	
map	TokenNameIdentifier	 map
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
}	TokenNameRBRACE	
/** * Rollback changes to the taxonomy writer and closes the instance. Following * this method the instance becomes unusable (calling any of its API methods * will yield an {@link AlreadyClosedException}). */	TokenNameCOMMENT_JAVADOC	 Rollback changes to the taxonomy writer and closes the instance. Following this method the instance becomes unusable (calling any of its API methods will yield an {@link AlreadyClosedException}). 
public	TokenNamepublic	
void	TokenNamevoid	
rollback	TokenNameIdentifier	 rollback
(	TokenNameLPAREN	
)	TokenNameRPAREN	
throws	TokenNamethrows	
IOException	TokenNameIdentifier	 IO Exception
{	TokenNameLBRACE	
ensureOpen	TokenNameIdentifier	 ensure Open
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
indexWriter	TokenNameIdentifier	 index Writer
.	TokenNameDOT	
rollback	TokenNameIdentifier	 rollback
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
// since IndexWriter.rollback() closes the IW instance, we should close too. 	TokenNameCOMMENT_LINE	since IndexWriter.rollback() closes the IW instance, we should close too. 
doClose	TokenNameIdentifier	 do Close
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
}	TokenNameRBRACE	

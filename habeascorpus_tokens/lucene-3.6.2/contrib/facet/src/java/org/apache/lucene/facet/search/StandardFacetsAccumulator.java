package	TokenNamepackage	
org	TokenNameIdentifier	 org
.	TokenNameDOT	
apache	TokenNameIdentifier	 apache
.	TokenNameDOT	
lucene	TokenNameIdentifier	 lucene
.	TokenNameDOT	
facet	TokenNameIdentifier	 facet
.	TokenNameDOT	
search	TokenNameIdentifier	 search
;	TokenNameSEMICOLON	
import	TokenNameimport	
java	TokenNameIdentifier	 java
.	TokenNameDOT	
io	TokenNameIdentifier	 io
.	TokenNameDOT	
IOException	TokenNameIdentifier	 IO Exception
;	TokenNameSEMICOLON	
import	TokenNameimport	
java	TokenNameIdentifier	 java
.	TokenNameDOT	
util	TokenNameIdentifier	 util
.	TokenNameDOT	
ArrayList	TokenNameIdentifier	 Array List
;	TokenNameSEMICOLON	
import	TokenNameimport	
java	TokenNameIdentifier	 java
.	TokenNameDOT	
util	TokenNameIdentifier	 util
.	TokenNameDOT	
HashMap	TokenNameIdentifier	 Hash Map
;	TokenNameSEMICOLON	
import	TokenNameimport	
java	TokenNameIdentifier	 java
.	TokenNameDOT	
util	TokenNameIdentifier	 util
.	TokenNameDOT	
List	TokenNameIdentifier	 List
;	TokenNameSEMICOLON	
import	TokenNameimport	
java	TokenNameIdentifier	 java
.	TokenNameDOT	
util	TokenNameIdentifier	 util
.	TokenNameDOT	
Map	TokenNameIdentifier	 Map
.	TokenNameDOT	
Entry	TokenNameIdentifier	 Entry
;	TokenNameSEMICOLON	
import	TokenNameimport	
java	TokenNameIdentifier	 java
.	TokenNameDOT	
util	TokenNameIdentifier	 util
.	TokenNameDOT	
logging	TokenNameIdentifier	 logging
.	TokenNameDOT	
Level	TokenNameIdentifier	 Level
;	TokenNameSEMICOLON	
import	TokenNameimport	
java	TokenNameIdentifier	 java
.	TokenNameDOT	
util	TokenNameIdentifier	 util
.	TokenNameDOT	
logging	TokenNameIdentifier	 logging
.	TokenNameDOT	
Logger	TokenNameIdentifier	 Logger
;	TokenNameSEMICOLON	
import	TokenNameimport	
org	TokenNameIdentifier	 org
.	TokenNameDOT	
apache	TokenNameIdentifier	 apache
.	TokenNameDOT	
lucene	TokenNameIdentifier	 lucene
.	TokenNameDOT	
index	TokenNameIdentifier	 index
.	TokenNameDOT	
IndexReader	TokenNameIdentifier	 Index Reader
;	TokenNameSEMICOLON	
import	TokenNameimport	
org	TokenNameIdentifier	 org
.	TokenNameDOT	
apache	TokenNameIdentifier	 apache
.	TokenNameDOT	
lucene	TokenNameIdentifier	 lucene
.	TokenNameDOT	
facet	TokenNameIdentifier	 facet
.	TokenNameDOT	
search	TokenNameIdentifier	 search
.	TokenNameDOT	
aggregator	TokenNameIdentifier	 aggregator
.	TokenNameDOT	
Aggregator	TokenNameIdentifier	 Aggregator
;	TokenNameSEMICOLON	
import	TokenNameimport	
org	TokenNameIdentifier	 org
.	TokenNameDOT	
apache	TokenNameIdentifier	 apache
.	TokenNameDOT	
lucene	TokenNameIdentifier	 lucene
.	TokenNameDOT	
facet	TokenNameIdentifier	 facet
.	TokenNameDOT	
search	TokenNameIdentifier	 search
.	TokenNameDOT	
params	TokenNameIdentifier	 params
.	TokenNameDOT	
FacetSearchParams	TokenNameIdentifier	 Facet Search Params
;	TokenNameSEMICOLON	
import	TokenNameimport	
org	TokenNameIdentifier	 org
.	TokenNameDOT	
apache	TokenNameIdentifier	 apache
.	TokenNameDOT	
lucene	TokenNameIdentifier	 lucene
.	TokenNameDOT	
facet	TokenNameIdentifier	 facet
.	TokenNameDOT	
search	TokenNameIdentifier	 search
.	TokenNameDOT	
params	TokenNameIdentifier	 params
.	TokenNameDOT	
FacetRequest	TokenNameIdentifier	 Facet Request
;	TokenNameSEMICOLON	
import	TokenNameimport	
org	TokenNameIdentifier	 org
.	TokenNameDOT	
apache	TokenNameIdentifier	 apache
.	TokenNameDOT	
lucene	TokenNameIdentifier	 lucene
.	TokenNameDOT	
facet	TokenNameIdentifier	 facet
.	TokenNameDOT	
search	TokenNameIdentifier	 search
.	TokenNameDOT	
results	TokenNameIdentifier	 results
.	TokenNameDOT	
FacetResult	TokenNameIdentifier	 Facet Result
;	TokenNameSEMICOLON	
import	TokenNameimport	
org	TokenNameIdentifier	 org
.	TokenNameDOT	
apache	TokenNameIdentifier	 apache
.	TokenNameDOT	
lucene	TokenNameIdentifier	 lucene
.	TokenNameDOT	
facet	TokenNameIdentifier	 facet
.	TokenNameDOT	
search	TokenNameIdentifier	 search
.	TokenNameDOT	
results	TokenNameIdentifier	 results
.	TokenNameDOT	
IntermediateFacetResult	TokenNameIdentifier	 Intermediate Facet Result
;	TokenNameSEMICOLON	
import	TokenNameimport	
org	TokenNameIdentifier	 org
.	TokenNameDOT	
apache	TokenNameIdentifier	 apache
.	TokenNameDOT	
lucene	TokenNameIdentifier	 lucene
.	TokenNameDOT	
facet	TokenNameIdentifier	 facet
.	TokenNameDOT	
taxonomy	TokenNameIdentifier	 taxonomy
.	TokenNameDOT	
TaxonomyReader	TokenNameIdentifier	 Taxonomy Reader
;	TokenNameSEMICOLON	
import	TokenNameimport	
org	TokenNameIdentifier	 org
.	TokenNameDOT	
apache	TokenNameIdentifier	 apache
.	TokenNameDOT	
lucene	TokenNameIdentifier	 lucene
.	TokenNameDOT	
facet	TokenNameIdentifier	 facet
.	TokenNameDOT	
util	TokenNameIdentifier	 util
.	TokenNameDOT	
PartitionsUtils	TokenNameIdentifier	 Partitions Utils
;	TokenNameSEMICOLON	
import	TokenNameimport	
org	TokenNameIdentifier	 org
.	TokenNameDOT	
apache	TokenNameIdentifier	 apache
.	TokenNameDOT	
lucene	TokenNameIdentifier	 lucene
.	TokenNameDOT	
facet	TokenNameIdentifier	 facet
.	TokenNameDOT	
util	TokenNameIdentifier	 util
.	TokenNameDOT	
ScoredDocIdsUtils	TokenNameIdentifier	 Scored Doc Ids Utils
;	TokenNameSEMICOLON	
/** * Licensed to the Apache Software Foundation (ASF) under one or more * contributor license agreements. See the NOTICE file distributed with * this work for additional information regarding copyright ownership. * The ASF licenses this file to You under the Apache License, Version 2.0 * (the "License"); you may not use this file except in compliance with * the License. You may obtain a copy of the License at * * http://www.apache.org/licenses/LICENSE-2.0 * * Unless required by applicable law or agreed to in writing, software * distributed under the License is distributed on an "AS IS" BASIS, * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. * See the License for the specific language governing permissions and * limitations under the License. */	TokenNameCOMMENT_JAVADOC	 Licensed to the Apache Software Foundation (ASF) under one or more contributor license agreements. See the NOTICE file distributed with this work for additional information regarding copyright ownership. The ASF licenses this file to You under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with the License. You may obtain a copy of the License at * http://www.apache.org/licenses/LICENSE-2.0 * Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License. 
/** * Standard implementation for {@link FacetsAccumulator}, utilizing partitions to save on memory. * <p> * Why partitions? Because if there are say 100M categories out of which * only top K are required, we must first compute value for all 100M categories * (going over all documents) and only then could we select top K. * This is made easier on memory by working in partitions of distinct categories: * Once a values for a partition are found, we take the top K for that * partition and work on the next partition, them merge the top K of both, * and so forth, thereby computing top K with RAM needs for the size of * a single partition rather than for the size of all the 100M categories. * <p> * Decision on partitions size is done at indexing time, and the facet information * for each partition is maintained separately. * <p> * <u>Implementation detail:</u> Since facets information of each partition is * maintained in a separate "category list", we can be more efficient * at search time, because only the facet info for a single partition * need to be read while processing that partition. * * @lucene.experimental */	TokenNameCOMMENT_JAVADOC	 Standard implementation for {@link FacetsAccumulator}, utilizing partitions to save on memory. <p> Why partitions? Because if there are say 100M categories out of which only top K are required, we must first compute value for all 100M categories (going over all documents) and only then could we select top K. This is made easier on memory by working in partitions of distinct categories: Once a values for a partition are found, we take the top K for that partition and work on the next partition, them merge the top K of both, and so forth, thereby computing top K with RAM needs for the size of a single partition rather than for the size of all the 100M categories. <p> Decision on partitions size is done at indexing time, and the facet information for each partition is maintained separately. <p> <u>Implementation detail:</u> Since facets information of each partition is maintained in a separate "category list", we can be more efficient at search time, because only the facet info for a single partition need to be read while processing that partition. * @lucene.experimental 
public	TokenNamepublic	
class	TokenNameclass	
StandardFacetsAccumulator	TokenNameIdentifier	 Standard Facets Accumulator
extends	TokenNameextends	
FacetsAccumulator	TokenNameIdentifier	 Facets Accumulator
{	TokenNameLBRACE	
private	TokenNameprivate	
static	TokenNamestatic	
final	TokenNamefinal	
Logger	TokenNameIdentifier	 Logger
logger	TokenNameIdentifier	 logger
=	TokenNameEQUAL	
Logger	TokenNameIdentifier	 Logger
.	TokenNameDOT	
getLogger	TokenNameIdentifier	 get Logger
(	TokenNameLPAREN	
StandardFacetsAccumulator	TokenNameIdentifier	 Standard Facets Accumulator
.	TokenNameDOT	
class	TokenNameclass	
.	TokenNameDOT	
getName	TokenNameIdentifier	 get Name
(	TokenNameLPAREN	
)	TokenNameRPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
protected	TokenNameprotected	
final	TokenNamefinal	
IntArrayAllocator	TokenNameIdentifier	 Int Array Allocator
intArrayAllocator	TokenNameIdentifier	 int Array Allocator
;	TokenNameSEMICOLON	
protected	TokenNameprotected	
final	TokenNamefinal	
FloatArrayAllocator	TokenNameIdentifier	 Float Array Allocator
floatArrayAllocator	TokenNameIdentifier	 float Array Allocator
;	TokenNameSEMICOLON	
protected	TokenNameprotected	
int	TokenNameint	
partitionSize	TokenNameIdentifier	 partition Size
;	TokenNameSEMICOLON	
protected	TokenNameprotected	
int	TokenNameint	
maxPartitions	TokenNameIdentifier	 max Partitions
;	TokenNameSEMICOLON	
protected	TokenNameprotected	
boolean	TokenNameboolean	
isUsingComplements	TokenNameIdentifier	 is Using Complements
;	TokenNameSEMICOLON	
private	TokenNameprivate	
TotalFacetCounts	TokenNameIdentifier	 Total Facet Counts
totalFacetCounts	TokenNameIdentifier	 total Facet Counts
;	TokenNameSEMICOLON	
private	TokenNameprivate	
Object	TokenNameIdentifier	 Object
accumulateGuard	TokenNameIdentifier	 accumulate Guard
;	TokenNameSEMICOLON	
public	TokenNamepublic	
StandardFacetsAccumulator	TokenNameIdentifier	 Standard Facets Accumulator
(	TokenNameLPAREN	
FacetSearchParams	TokenNameIdentifier	 Facet Search Params
searchParams	TokenNameIdentifier	 search Params
,	TokenNameCOMMA	
IndexReader	TokenNameIdentifier	 Index Reader
indexReader	TokenNameIdentifier	 index Reader
,	TokenNameCOMMA	
TaxonomyReader	TokenNameIdentifier	 Taxonomy Reader
taxonomyReader	TokenNameIdentifier	 taxonomy Reader
,	TokenNameCOMMA	
IntArrayAllocator	TokenNameIdentifier	 Int Array Allocator
intArrayAllocator	TokenNameIdentifier	 int Array Allocator
,	TokenNameCOMMA	
FloatArrayAllocator	TokenNameIdentifier	 Float Array Allocator
floatArrayAllocator	TokenNameIdentifier	 float Array Allocator
)	TokenNameRPAREN	
{	TokenNameLBRACE	
super	TokenNamesuper	
(	TokenNameLPAREN	
searchParams	TokenNameIdentifier	 search Params
,	TokenNameCOMMA	
indexReader	TokenNameIdentifier	 index Reader
,	TokenNameCOMMA	
taxonomyReader	TokenNameIdentifier	 taxonomy Reader
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
int	TokenNameint	
realPartitionSize	TokenNameIdentifier	 real Partition Size
=	TokenNameEQUAL	
intArrayAllocator	TokenNameIdentifier	 int Array Allocator
==	TokenNameEQUAL_EQUAL	
null	TokenNamenull	
||	TokenNameOR_OR	
floatArrayAllocator	TokenNameIdentifier	 float Array Allocator
==	TokenNameEQUAL_EQUAL	
null	TokenNamenull	
?	TokenNameQUESTION	
PartitionsUtils	TokenNameIdentifier	 Partitions Utils
.	TokenNameDOT	
partitionSize	TokenNameIdentifier	 partition Size
(	TokenNameLPAREN	
searchParams	TokenNameIdentifier	 search Params
,	TokenNameCOMMA	
taxonomyReader	TokenNameIdentifier	 taxonomy Reader
)	TokenNameRPAREN	
:	TokenNameCOLON	
-	TokenNameMINUS	
1	TokenNameIntegerLiteral	
;	TokenNameSEMICOLON	
// -1 if not needed. 	TokenNameCOMMENT_LINE	-1 if not needed. 
this	TokenNamethis	
.	TokenNameDOT	
intArrayAllocator	TokenNameIdentifier	 int Array Allocator
=	TokenNameEQUAL	
intArrayAllocator	TokenNameIdentifier	 int Array Allocator
!=	TokenNameNOT_EQUAL	
null	TokenNamenull	
?	TokenNameQUESTION	
intArrayAllocator	TokenNameIdentifier	 int Array Allocator
// create a default one if null was provided 	TokenNameCOMMENT_LINE	create a default one if null was provided 
:	TokenNameCOLON	
new	TokenNamenew	
IntArrayAllocator	TokenNameIdentifier	 Int Array Allocator
(	TokenNameLPAREN	
realPartitionSize	TokenNameIdentifier	 real Partition Size
,	TokenNameCOMMA	
1	TokenNameIntegerLiteral	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
this	TokenNamethis	
.	TokenNameDOT	
floatArrayAllocator	TokenNameIdentifier	 float Array Allocator
=	TokenNameEQUAL	
floatArrayAllocator	TokenNameIdentifier	 float Array Allocator
!=	TokenNameNOT_EQUAL	
null	TokenNamenull	
?	TokenNameQUESTION	
floatArrayAllocator	TokenNameIdentifier	 float Array Allocator
// create a default one if null provided 	TokenNameCOMMENT_LINE	create a default one if null provided 
:	TokenNameCOLON	
new	TokenNamenew	
FloatArrayAllocator	TokenNameIdentifier	 Float Array Allocator
(	TokenNameLPAREN	
realPartitionSize	TokenNameIdentifier	 real Partition Size
,	TokenNameCOMMA	
1	TokenNameIntegerLiteral	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
// can only be computed later when docids size is known 	TokenNameCOMMENT_LINE	can only be computed later when docids size is known 
isUsingComplements	TokenNameIdentifier	 is Using Complements
=	TokenNameEQUAL	
false	TokenNamefalse	
;	TokenNameSEMICOLON	
partitionSize	TokenNameIdentifier	 partition Size
=	TokenNameEQUAL	
PartitionsUtils	TokenNameIdentifier	 Partitions Utils
.	TokenNameDOT	
partitionSize	TokenNameIdentifier	 partition Size
(	TokenNameLPAREN	
searchParams	TokenNameIdentifier	 search Params
,	TokenNameCOMMA	
taxonomyReader	TokenNameIdentifier	 taxonomy Reader
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
maxPartitions	TokenNameIdentifier	 max Partitions
=	TokenNameEQUAL	
(	TokenNameLPAREN	
int	TokenNameint	
)	TokenNameRPAREN	
Math	TokenNameIdentifier	 Math
.	TokenNameDOT	
ceil	TokenNameIdentifier	 ceil
(	TokenNameLPAREN	
this	TokenNamethis	
.	TokenNameDOT	
taxonomyReader	TokenNameIdentifier	 taxonomy Reader
.	TokenNameDOT	
getSize	TokenNameIdentifier	 get Size
(	TokenNameLPAREN	
)	TokenNameRPAREN	
/	TokenNameDIVIDE	
(	TokenNameLPAREN	
double	TokenNamedouble	
)	TokenNameRPAREN	
partitionSize	TokenNameIdentifier	 partition Size
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
accumulateGuard	TokenNameIdentifier	 accumulate Guard
=	TokenNameEQUAL	
new	TokenNamenew	
Object	TokenNameIdentifier	 Object
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
public	TokenNamepublic	
StandardFacetsAccumulator	TokenNameIdentifier	 Standard Facets Accumulator
(	TokenNameLPAREN	
FacetSearchParams	TokenNameIdentifier	 Facet Search Params
searchParams	TokenNameIdentifier	 search Params
,	TokenNameCOMMA	
IndexReader	TokenNameIdentifier	 Index Reader
indexReader	TokenNameIdentifier	 index Reader
,	TokenNameCOMMA	
TaxonomyReader	TokenNameIdentifier	 Taxonomy Reader
taxonomyReader	TokenNameIdentifier	 taxonomy Reader
)	TokenNameRPAREN	
{	TokenNameLBRACE	
this	TokenNamethis	
(	TokenNameLPAREN	
searchParams	TokenNameIdentifier	 search Params
,	TokenNameCOMMA	
indexReader	TokenNameIdentifier	 index Reader
,	TokenNameCOMMA	
taxonomyReader	TokenNameIdentifier	 taxonomy Reader
,	TokenNameCOMMA	
null	TokenNamenull	
,	TokenNameCOMMA	
null	TokenNamenull	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
@	TokenNameAT	
Override	TokenNameIdentifier	 Override
public	TokenNamepublic	
List	TokenNameIdentifier	 List
<	TokenNameLESS	
FacetResult	TokenNameIdentifier	 Facet Result
>	TokenNameGREATER	
accumulate	TokenNameIdentifier	 accumulate
(	TokenNameLPAREN	
ScoredDocIDs	TokenNameIdentifier	 Scored Doc I Ds
docids	TokenNameIdentifier	 docids
)	TokenNameRPAREN	
throws	TokenNamethrows	
IOException	TokenNameIdentifier	 IO Exception
{	TokenNameLBRACE	
// synchronize to prevent calling two accumulate()'s at the same time. 	TokenNameCOMMENT_LINE	synchronize to prevent calling two accumulate()'s at the same time. 
// We decided not to synchronize the method because that might mislead 	TokenNameCOMMENT_LINE	We decided not to synchronize the method because that might mislead 
// users to feel encouraged to call this method simultaneously. 	TokenNameCOMMENT_LINE	users to feel encouraged to call this method simultaneously. 
synchronized	TokenNamesynchronized	
(	TokenNameLPAREN	
accumulateGuard	TokenNameIdentifier	 accumulate Guard
)	TokenNameRPAREN	
{	TokenNameLBRACE	
// only now we can compute this 	TokenNameCOMMENT_LINE	only now we can compute this 
isUsingComplements	TokenNameIdentifier	 is Using Complements
=	TokenNameEQUAL	
shouldComplement	TokenNameIdentifier	 should Complement
(	TokenNameLPAREN	
docids	TokenNameIdentifier	 docids
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
if	TokenNameif	
(	TokenNameLPAREN	
isUsingComplements	TokenNameIdentifier	 is Using Complements
)	TokenNameRPAREN	
{	TokenNameLBRACE	
try	TokenNametry	
{	TokenNameLBRACE	
totalFacetCounts	TokenNameIdentifier	 total Facet Counts
=	TokenNameEQUAL	
TotalFacetCountsCache	TokenNameIdentifier	 Total Facet Counts Cache
.	TokenNameDOT	
getSingleton	TokenNameIdentifier	 get Singleton
(	TokenNameLPAREN	
)	TokenNameRPAREN	
.	TokenNameDOT	
getTotalCounts	TokenNameIdentifier	 get Total Counts
(	TokenNameLPAREN	
indexReader	TokenNameIdentifier	 index Reader
,	TokenNameCOMMA	
taxonomyReader	TokenNameIdentifier	 taxonomy Reader
,	TokenNameCOMMA	
searchParams	TokenNameIdentifier	 search Params
.	TokenNameDOT	
getFacetIndexingParams	TokenNameIdentifier	 get Facet Indexing Params
(	TokenNameLPAREN	
)	TokenNameRPAREN	
,	TokenNameCOMMA	
searchParams	TokenNameIdentifier	 search Params
.	TokenNameDOT	
getClCache	TokenNameIdentifier	 get Cl Cache
(	TokenNameLPAREN	
)	TokenNameRPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
if	TokenNameif	
(	TokenNameLPAREN	
totalFacetCounts	TokenNameIdentifier	 total Facet Counts
!=	TokenNameNOT_EQUAL	
null	TokenNamenull	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
docids	TokenNameIdentifier	 docids
=	TokenNameEQUAL	
ScoredDocIdsUtils	TokenNameIdentifier	 Scored Doc Ids Utils
.	TokenNameDOT	
getComplementSet	TokenNameIdentifier	 get Complement Set
(	TokenNameLPAREN	
docids	TokenNameIdentifier	 docids
,	TokenNameCOMMA	
indexReader	TokenNameIdentifier	 index Reader
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
else	TokenNameelse	
{	TokenNameLBRACE	
isUsingComplements	TokenNameIdentifier	 is Using Complements
=	TokenNameEQUAL	
false	TokenNamefalse	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
}	TokenNameRBRACE	
catch	TokenNamecatch	
(	TokenNameLPAREN	
UnsupportedOperationException	TokenNameIdentifier	 Unsupported Operation Exception
e	TokenNameIdentifier	 e
)	TokenNameRPAREN	
{	TokenNameLBRACE	
// TODO (Facet): this exception is thrown from TotalCountsKey if the 	TokenNameCOMMENT_LINE	TODO (Facet): this exception is thrown from TotalCountsKey if the 
// IndexReader used does not support getVersion(). We should re-think 	TokenNameCOMMENT_LINE	IndexReader used does not support getVersion(). We should re-think 
// this: is this tiny detail worth disabling total counts completely 	TokenNameCOMMENT_LINE	this: is this tiny detail worth disabling total counts completely 
// for such readers? Currently, it's not supported by Parallel and 	TokenNameCOMMENT_LINE	for such readers? Currently, it's not supported by Parallel and 
// MultiReader, which might be problematic for several applications. 	TokenNameCOMMENT_LINE	MultiReader, which might be problematic for several applications. 
// We could, for example, base our "isCurrent" logic on something else 	TokenNameCOMMENT_LINE	We could, for example, base our "isCurrent" logic on something else 
// than the reader's version. Need to think more deeply about it. 	TokenNameCOMMENT_LINE	than the reader's version. Need to think more deeply about it. 
if	TokenNameif	
(	TokenNameLPAREN	
logger	TokenNameIdentifier	 logger
.	TokenNameDOT	
isLoggable	TokenNameIdentifier	 is Loggable
(	TokenNameLPAREN	
Level	TokenNameIdentifier	 Level
.	TokenNameDOT	
FINEST	TokenNameIdentifier	 FINEST
)	TokenNameRPAREN	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
logger	TokenNameIdentifier	 logger
.	TokenNameDOT	
log	TokenNameIdentifier	 log
(	TokenNameLPAREN	
Level	TokenNameIdentifier	 Level
.	TokenNameDOT	
FINEST	TokenNameIdentifier	 FINEST
,	TokenNameCOMMA	
"IndexReader used does not support completents: "	TokenNameStringLiteral	IndexReader used does not support completents: 
,	TokenNameCOMMA	
e	TokenNameIdentifier	 e
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
isUsingComplements	TokenNameIdentifier	 is Using Complements
=	TokenNameEQUAL	
false	TokenNamefalse	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
catch	TokenNamecatch	
(	TokenNameLPAREN	
IOException	TokenNameIdentifier	 IO Exception
e	TokenNameIdentifier	 e
)	TokenNameRPAREN	
{	TokenNameLBRACE	
if	TokenNameif	
(	TokenNameLPAREN	
logger	TokenNameIdentifier	 logger
.	TokenNameDOT	
isLoggable	TokenNameIdentifier	 is Loggable
(	TokenNameLPAREN	
Level	TokenNameIdentifier	 Level
.	TokenNameDOT	
FINEST	TokenNameIdentifier	 FINEST
)	TokenNameRPAREN	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
logger	TokenNameIdentifier	 logger
.	TokenNameDOT	
log	TokenNameIdentifier	 log
(	TokenNameLPAREN	
Level	TokenNameIdentifier	 Level
.	TokenNameDOT	
FINEST	TokenNameIdentifier	 FINEST
,	TokenNameCOMMA	
"Failed to load/calculate total counts (complement counting disabled): "	TokenNameStringLiteral	Failed to load/calculate total counts (complement counting disabled): 
,	TokenNameCOMMA	
e	TokenNameIdentifier	 e
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
// silently fail if for some reason failed to load/save from/to dir 	TokenNameCOMMENT_LINE	silently fail if for some reason failed to load/save from/to dir 
isUsingComplements	TokenNameIdentifier	 is Using Complements
=	TokenNameEQUAL	
false	TokenNamefalse	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
catch	TokenNamecatch	
(	TokenNameLPAREN	
Exception	TokenNameIdentifier	 Exception
e	TokenNameIdentifier	 e
)	TokenNameRPAREN	
{	TokenNameLBRACE	
// give up: this should not happen! 	TokenNameCOMMENT_LINE	give up: this should not happen! 
IOException	TokenNameIdentifier	 IO Exception
ioEx	TokenNameIdentifier	 io Ex
=	TokenNameEQUAL	
new	TokenNamenew	
IOException	TokenNameIdentifier	 IO Exception
(	TokenNameLPAREN	
"PANIC: Got unexpected exception while trying to get/calculate total counts: "	TokenNameStringLiteral	PANIC: Got unexpected exception while trying to get/calculate total counts: 
+	TokenNamePLUS	
e	TokenNameIdentifier	 e
.	TokenNameDOT	
getMessage	TokenNameIdentifier	 get Message
(	TokenNameLPAREN	
)	TokenNameRPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
ioEx	TokenNameIdentifier	 io Ex
.	TokenNameDOT	
initCause	TokenNameIdentifier	 init Cause
(	TokenNameLPAREN	
e	TokenNameIdentifier	 e
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
throw	TokenNamethrow	
ioEx	TokenNameIdentifier	 io Ex
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
}	TokenNameRBRACE	
docids	TokenNameIdentifier	 docids
=	TokenNameEQUAL	
actualDocsToAccumulate	TokenNameIdentifier	 actual Docs To Accumulate
(	TokenNameLPAREN	
docids	TokenNameIdentifier	 docids
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
FacetArrays	TokenNameIdentifier	 Facet Arrays
facetArrays	TokenNameIdentifier	 facet Arrays
=	TokenNameEQUAL	
new	TokenNamenew	
FacetArrays	TokenNameIdentifier	 Facet Arrays
(	TokenNameLPAREN	
intArrayAllocator	TokenNameIdentifier	 int Array Allocator
,	TokenNameCOMMA	
floatArrayAllocator	TokenNameIdentifier	 float Array Allocator
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
HashMap	TokenNameIdentifier	 Hash Map
<	TokenNameLESS	
FacetRequest	TokenNameIdentifier	 Facet Request
,	TokenNameCOMMA	
IntermediateFacetResult	TokenNameIdentifier	 Intermediate Facet Result
>	TokenNameGREATER	
fr2tmpRes	TokenNameIdentifier	 fr2tmp Res
=	TokenNameEQUAL	
new	TokenNamenew	
HashMap	TokenNameIdentifier	 Hash Map
<	TokenNameLESS	
FacetRequest	TokenNameIdentifier	 Facet Request
,	TokenNameCOMMA	
IntermediateFacetResult	TokenNameIdentifier	 Intermediate Facet Result
>	TokenNameGREATER	
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
try	TokenNametry	
{	TokenNameLBRACE	
for	TokenNamefor	
(	TokenNameLPAREN	
int	TokenNameint	
part	TokenNameIdentifier	 part
=	TokenNameEQUAL	
0	TokenNameIntegerLiteral	
;	TokenNameSEMICOLON	
part	TokenNameIdentifier	 part
<	TokenNameLESS	
maxPartitions	TokenNameIdentifier	 max Partitions
;	TokenNameSEMICOLON	
part	TokenNameIdentifier	 part
++	TokenNamePLUS_PLUS	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
// fill arrays from category lists 	TokenNameCOMMENT_LINE	fill arrays from category lists 
fillArraysForPartition	TokenNameIdentifier	 fill Arrays For Partition
(	TokenNameLPAREN	
docids	TokenNameIdentifier	 docids
,	TokenNameCOMMA	
facetArrays	TokenNameIdentifier	 facet Arrays
,	TokenNameCOMMA	
part	TokenNameIdentifier	 part
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
int	TokenNameint	
offset	TokenNameIdentifier	 offset
=	TokenNameEQUAL	
part	TokenNameIdentifier	 part
*	TokenNameMULTIPLY	
partitionSize	TokenNameIdentifier	 partition Size
;	TokenNameSEMICOLON	
// for each partition we go over all requests and handle 	TokenNameCOMMENT_LINE	for each partition we go over all requests and handle 
// each, where 	TokenNameCOMMENT_LINE	each, where 
// the request maintains the merged result. 	TokenNameCOMMENT_LINE	the request maintains the merged result. 
// In this implementation merges happen after each 	TokenNameCOMMENT_LINE	In this implementation merges happen after each 
// partition, 	TokenNameCOMMENT_LINE	partition, 
// but other impl could merge only at the end. 	TokenNameCOMMENT_LINE	but other impl could merge only at the end. 
for	TokenNamefor	
(	TokenNameLPAREN	
FacetRequest	TokenNameIdentifier	 Facet Request
fr	TokenNameIdentifier	 fr
:	TokenNameCOLON	
searchParams	TokenNameIdentifier	 search Params
.	TokenNameDOT	
getFacetRequests	TokenNameIdentifier	 get Facet Requests
(	TokenNameLPAREN	
)	TokenNameRPAREN	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
FacetResultsHandler	TokenNameIdentifier	 Facet Results Handler
frHndlr	TokenNameIdentifier	 fr Hndlr
=	TokenNameEQUAL	
fr	TokenNameIdentifier	 fr
.	TokenNameDOT	
createFacetResultsHandler	TokenNameIdentifier	 create Facet Results Handler
(	TokenNameLPAREN	
taxonomyReader	TokenNameIdentifier	 taxonomy Reader
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
IntermediateFacetResult	TokenNameIdentifier	 Intermediate Facet Result
res4fr	TokenNameIdentifier	 res4fr
=	TokenNameEQUAL	
frHndlr	TokenNameIdentifier	 fr Hndlr
.	TokenNameDOT	
fetchPartitionResult	TokenNameIdentifier	 fetch Partition Result
(	TokenNameLPAREN	
facetArrays	TokenNameIdentifier	 facet Arrays
,	TokenNameCOMMA	
offset	TokenNameIdentifier	 offset
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
IntermediateFacetResult	TokenNameIdentifier	 Intermediate Facet Result
oldRes	TokenNameIdentifier	 old Res
=	TokenNameEQUAL	
fr2tmpRes	TokenNameIdentifier	 fr2tmp Res
.	TokenNameDOT	
get	TokenNameIdentifier	 get
(	TokenNameLPAREN	
fr	TokenNameIdentifier	 fr
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
if	TokenNameif	
(	TokenNameLPAREN	
oldRes	TokenNameIdentifier	 old Res
!=	TokenNameNOT_EQUAL	
null	TokenNamenull	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
res4fr	TokenNameIdentifier	 res4fr
=	TokenNameEQUAL	
frHndlr	TokenNameIdentifier	 fr Hndlr
.	TokenNameDOT	
mergeResults	TokenNameIdentifier	 merge Results
(	TokenNameLPAREN	
oldRes	TokenNameIdentifier	 old Res
,	TokenNameCOMMA	
res4fr	TokenNameIdentifier	 res4fr
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
fr2tmpRes	TokenNameIdentifier	 fr2tmp Res
.	TokenNameDOT	
put	TokenNameIdentifier	 put
(	TokenNameLPAREN	
fr	TokenNameIdentifier	 fr
,	TokenNameCOMMA	
res4fr	TokenNameIdentifier	 res4fr
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
}	TokenNameRBRACE	
}	TokenNameRBRACE	
finally	TokenNamefinally	
{	TokenNameLBRACE	
facetArrays	TokenNameIdentifier	 facet Arrays
.	TokenNameDOT	
free	TokenNameIdentifier	 free
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
// gather results from all requests into a list for returning them 	TokenNameCOMMENT_LINE	gather results from all requests into a list for returning them 
List	TokenNameIdentifier	 List
<	TokenNameLESS	
FacetResult	TokenNameIdentifier	 Facet Result
>	TokenNameGREATER	
res	TokenNameIdentifier	 res
=	TokenNameEQUAL	
new	TokenNamenew	
ArrayList	TokenNameIdentifier	 Array List
<	TokenNameLESS	
FacetResult	TokenNameIdentifier	 Facet Result
>	TokenNameGREATER	
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
for	TokenNamefor	
(	TokenNameLPAREN	
FacetRequest	TokenNameIdentifier	 Facet Request
fr	TokenNameIdentifier	 fr
:	TokenNameCOLON	
searchParams	TokenNameIdentifier	 search Params
.	TokenNameDOT	
getFacetRequests	TokenNameIdentifier	 get Facet Requests
(	TokenNameLPAREN	
)	TokenNameRPAREN	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
FacetResultsHandler	TokenNameIdentifier	 Facet Results Handler
frHndlr	TokenNameIdentifier	 fr Hndlr
=	TokenNameEQUAL	
fr	TokenNameIdentifier	 fr
.	TokenNameDOT	
createFacetResultsHandler	TokenNameIdentifier	 create Facet Results Handler
(	TokenNameLPAREN	
taxonomyReader	TokenNameIdentifier	 taxonomy Reader
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
IntermediateFacetResult	TokenNameIdentifier	 Intermediate Facet Result
tmpResult	TokenNameIdentifier	 tmp Result
=	TokenNameEQUAL	
fr2tmpRes	TokenNameIdentifier	 fr2tmp Res
.	TokenNameDOT	
get	TokenNameIdentifier	 get
(	TokenNameLPAREN	
fr	TokenNameIdentifier	 fr
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
if	TokenNameif	
(	TokenNameLPAREN	
tmpResult	TokenNameIdentifier	 tmp Result
==	TokenNameEQUAL_EQUAL	
null	TokenNamenull	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
continue	TokenNamecontinue	
;	TokenNameSEMICOLON	
// do not add a null to the list. 	TokenNameCOMMENT_LINE	do not add a null to the list. 
}	TokenNameRBRACE	
FacetResult	TokenNameIdentifier	 Facet Result
facetRes	TokenNameIdentifier	 facet Res
=	TokenNameEQUAL	
frHndlr	TokenNameIdentifier	 fr Hndlr
.	TokenNameDOT	
renderFacetResult	TokenNameIdentifier	 render Facet Result
(	TokenNameLPAREN	
tmpResult	TokenNameIdentifier	 tmp Result
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
// final labeling if allowed (because labeling is a costly operation) 	TokenNameCOMMENT_LINE	final labeling if allowed (because labeling is a costly operation) 
if	TokenNameif	
(	TokenNameLPAREN	
isAllowLabeling	TokenNameIdentifier	 is Allow Labeling
(	TokenNameLPAREN	
)	TokenNameRPAREN	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
frHndlr	TokenNameIdentifier	 fr Hndlr
.	TokenNameDOT	
labelResult	TokenNameIdentifier	 label Result
(	TokenNameLPAREN	
facetRes	TokenNameIdentifier	 facet Res
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
res	TokenNameIdentifier	 res
.	TokenNameDOT	
add	TokenNameIdentifier	 add
(	TokenNameLPAREN	
facetRes	TokenNameIdentifier	 facet Res
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
return	TokenNamereturn	
res	TokenNameIdentifier	 res
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
}	TokenNameRBRACE	
/** * Set the actual set of documents over which accumulation should take place. * <p> * Allows to override the set of documents to accumulate for. Invoked just * before actual accumulating starts. From this point that set of documents * remains unmodified. Default implementation just returns the input * unchanged. * * @param docids * candidate documents to accumulate for * @return actual documents to accumulate for */	TokenNameCOMMENT_JAVADOC	 Set the actual set of documents over which accumulation should take place. <p> Allows to override the set of documents to accumulate for. Invoked just before actual accumulating starts. From this point that set of documents remains unmodified. Default implementation just returns the input unchanged. * @param docids candidate documents to accumulate for @return actual documents to accumulate for 
protected	TokenNameprotected	
ScoredDocIDs	TokenNameIdentifier	 Scored Doc I Ds
actualDocsToAccumulate	TokenNameIdentifier	 actual Docs To Accumulate
(	TokenNameLPAREN	
ScoredDocIDs	TokenNameIdentifier	 Scored Doc I Ds
docids	TokenNameIdentifier	 docids
)	TokenNameRPAREN	
throws	TokenNamethrows	
IOException	TokenNameIdentifier	 IO Exception
{	TokenNameLBRACE	
return	TokenNamereturn	
docids	TokenNameIdentifier	 docids
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
/** Check if it is worth to use complements */	TokenNameCOMMENT_JAVADOC	 Check if it is worth to use complements 
protected	TokenNameprotected	
boolean	TokenNameboolean	
shouldComplement	TokenNameIdentifier	 should Complement
(	TokenNameLPAREN	
ScoredDocIDs	TokenNameIdentifier	 Scored Doc I Ds
docids	TokenNameIdentifier	 docids
)	TokenNameRPAREN	
{	TokenNameLBRACE	
return	TokenNamereturn	
mayComplement	TokenNameIdentifier	 may Complement
(	TokenNameLPAREN	
)	TokenNameRPAREN	
&&	TokenNameAND_AND	
(	TokenNameLPAREN	
docids	TokenNameIdentifier	 docids
.	TokenNameDOT	
size	TokenNameIdentifier	 size
(	TokenNameLPAREN	
)	TokenNameRPAREN	
>	TokenNameGREATER	
indexReader	TokenNameIdentifier	 index Reader
.	TokenNameDOT	
numDocs	TokenNameIdentifier	 num Docs
(	TokenNameLPAREN	
)	TokenNameRPAREN	
*	TokenNameMULTIPLY	
getComplementThreshold	TokenNameIdentifier	 get Complement Threshold
(	TokenNameLPAREN	
)	TokenNameRPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
/** * Iterate over the documents for this partition and fill the facet arrays with the correct * count/complement count/value. * @param internalCollector * @param facetArrays * @param part * @throws IOException */	TokenNameCOMMENT_JAVADOC	 Iterate over the documents for this partition and fill the facet arrays with the correct count/complement count/value. @param internalCollector @param facetArrays @param part @throws IOException 
private	TokenNameprivate	
final	TokenNamefinal	
void	TokenNamevoid	
fillArraysForPartition	TokenNameIdentifier	 fill Arrays For Partition
(	TokenNameLPAREN	
ScoredDocIDs	TokenNameIdentifier	 Scored Doc I Ds
docids	TokenNameIdentifier	 docids
,	TokenNameCOMMA	
FacetArrays	TokenNameIdentifier	 Facet Arrays
facetArrays	TokenNameIdentifier	 facet Arrays
,	TokenNameCOMMA	
int	TokenNameint	
partition	TokenNameIdentifier	 partition
)	TokenNameRPAREN	
throws	TokenNamethrows	
IOException	TokenNameIdentifier	 IO Exception
{	TokenNameLBRACE	
if	TokenNameif	
(	TokenNameLPAREN	
isUsingComplements	TokenNameIdentifier	 is Using Complements
)	TokenNameRPAREN	
{	TokenNameLBRACE	
initArraysByTotalCounts	TokenNameIdentifier	 init Arrays By Total Counts
(	TokenNameLPAREN	
facetArrays	TokenNameIdentifier	 facet Arrays
,	TokenNameCOMMA	
partition	TokenNameIdentifier	 partition
,	TokenNameCOMMA	
docids	TokenNameIdentifier	 docids
.	TokenNameDOT	
size	TokenNameIdentifier	 size
(	TokenNameLPAREN	
)	TokenNameRPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
else	TokenNameelse	
{	TokenNameLBRACE	
facetArrays	TokenNameIdentifier	 facet Arrays
.	TokenNameDOT	
free	TokenNameIdentifier	 free
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
// to get a cleared array for this partition 	TokenNameCOMMENT_LINE	to get a cleared array for this partition 
}	TokenNameRBRACE	
HashMap	TokenNameIdentifier	 Hash Map
<	TokenNameLESS	
CategoryListIterator	TokenNameIdentifier	 Category List Iterator
,	TokenNameCOMMA	
Aggregator	TokenNameIdentifier	 Aggregator
>	TokenNameGREATER	
categoryLists	TokenNameIdentifier	 category Lists
=	TokenNameEQUAL	
getCategoryListMap	TokenNameIdentifier	 get Category List Map
(	TokenNameLPAREN	
facetArrays	TokenNameIdentifier	 facet Arrays
,	TokenNameCOMMA	
partition	TokenNameIdentifier	 partition
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
for	TokenNamefor	
(	TokenNameLPAREN	
Entry	TokenNameIdentifier	 Entry
<	TokenNameLESS	
CategoryListIterator	TokenNameIdentifier	 Category List Iterator
,	TokenNameCOMMA	
Aggregator	TokenNameIdentifier	 Aggregator
>	TokenNameGREATER	
entry	TokenNameIdentifier	 entry
:	TokenNameCOLON	
categoryLists	TokenNameIdentifier	 category Lists
.	TokenNameDOT	
entrySet	TokenNameIdentifier	 entry Set
(	TokenNameLPAREN	
)	TokenNameRPAREN	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
CategoryListIterator	TokenNameIdentifier	 Category List Iterator
categoryList	TokenNameIdentifier	 category List
=	TokenNameEQUAL	
entry	TokenNameIdentifier	 entry
.	TokenNameDOT	
getKey	TokenNameIdentifier	 get Key
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
if	TokenNameif	
(	TokenNameLPAREN	
!	TokenNameNOT	
categoryList	TokenNameIdentifier	 category List
.	TokenNameDOT	
init	TokenNameIdentifier	 init
(	TokenNameLPAREN	
)	TokenNameRPAREN	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
continue	TokenNamecontinue	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
Aggregator	TokenNameIdentifier	 Aggregator
categorator	TokenNameIdentifier	 categorator
=	TokenNameEQUAL	
entry	TokenNameIdentifier	 entry
.	TokenNameDOT	
getValue	TokenNameIdentifier	 get Value
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
ScoredDocIDsIterator	TokenNameIdentifier	 Scored Doc I Ds Iterator
iterator	TokenNameIdentifier	 iterator
=	TokenNameEQUAL	
docids	TokenNameIdentifier	 docids
.	TokenNameDOT	
iterator	TokenNameIdentifier	 iterator
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
while	TokenNamewhile	
(	TokenNameLPAREN	
iterator	TokenNameIdentifier	 iterator
.	TokenNameDOT	
next	TokenNameIdentifier	 next
(	TokenNameLPAREN	
)	TokenNameRPAREN	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
int	TokenNameint	
docID	TokenNameIdentifier	 doc ID
=	TokenNameEQUAL	
iterator	TokenNameIdentifier	 iterator
.	TokenNameDOT	
getDocID	TokenNameIdentifier	 get Doc ID
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
if	TokenNameif	
(	TokenNameLPAREN	
!	TokenNameNOT	
categoryList	TokenNameIdentifier	 category List
.	TokenNameDOT	
skipTo	TokenNameIdentifier	 skip To
(	TokenNameLPAREN	
docID	TokenNameIdentifier	 doc ID
)	TokenNameRPAREN	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
continue	TokenNamecontinue	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
categorator	TokenNameIdentifier	 categorator
.	TokenNameDOT	
setNextDoc	TokenNameIdentifier	 set Next Doc
(	TokenNameLPAREN	
docID	TokenNameIdentifier	 doc ID
,	TokenNameCOMMA	
iterator	TokenNameIdentifier	 iterator
.	TokenNameDOT	
getScore	TokenNameIdentifier	 get Score
(	TokenNameLPAREN	
)	TokenNameRPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
long	TokenNamelong	
ordinal	TokenNameIdentifier	 ordinal
;	TokenNameSEMICOLON	
while	TokenNamewhile	
(	TokenNameLPAREN	
(	TokenNameLPAREN	
ordinal	TokenNameIdentifier	 ordinal
=	TokenNameEQUAL	
categoryList	TokenNameIdentifier	 category List
.	TokenNameDOT	
nextCategory	TokenNameIdentifier	 next Category
(	TokenNameLPAREN	
)	TokenNameRPAREN	
)	TokenNameRPAREN	
<=	TokenNameLESS_EQUAL	
Integer	TokenNameIdentifier	 Integer
.	TokenNameDOT	
MAX_VALUE	TokenNameIdentifier	 MAX  VALUE
)	TokenNameRPAREN	
{	TokenNameLBRACE	
categorator	TokenNameIdentifier	 categorator
.	TokenNameDOT	
aggregate	TokenNameIdentifier	 aggregate
(	TokenNameLPAREN	
(	TokenNameLPAREN	
int	TokenNameint	
)	TokenNameRPAREN	
ordinal	TokenNameIdentifier	 ordinal
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
}	TokenNameRBRACE	
}	TokenNameRBRACE	
}	TokenNameRBRACE	
/** * Init arrays for partition by total counts, optionally applying a factor */	TokenNameCOMMENT_JAVADOC	 Init arrays for partition by total counts, optionally applying a factor 
private	TokenNameprivate	
final	TokenNamefinal	
void	TokenNamevoid	
initArraysByTotalCounts	TokenNameIdentifier	 init Arrays By Total Counts
(	TokenNameLPAREN	
FacetArrays	TokenNameIdentifier	 Facet Arrays
facetArrays	TokenNameIdentifier	 facet Arrays
,	TokenNameCOMMA	
int	TokenNameint	
partition	TokenNameIdentifier	 partition
,	TokenNameCOMMA	
int	TokenNameint	
nAccumulatedDocs	TokenNameIdentifier	 n Accumulated Docs
)	TokenNameRPAREN	
{	TokenNameLBRACE	
int	TokenNameint	
[	TokenNameLBRACKET	
]	TokenNameRBRACKET	
intArray	TokenNameIdentifier	 int Array
=	TokenNameEQUAL	
facetArrays	TokenNameIdentifier	 facet Arrays
.	TokenNameDOT	
getIntArray	TokenNameIdentifier	 get Int Array
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
totalFacetCounts	TokenNameIdentifier	 total Facet Counts
.	TokenNameDOT	
fillTotalCountsForPartition	TokenNameIdentifier	 fill Total Counts For Partition
(	TokenNameLPAREN	
intArray	TokenNameIdentifier	 int Array
,	TokenNameCOMMA	
partition	TokenNameIdentifier	 partition
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
double	TokenNamedouble	
totalCountsFactor	TokenNameIdentifier	 total Counts Factor
=	TokenNameEQUAL	
getTotalCountsFactor	TokenNameIdentifier	 get Total Counts Factor
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
// fix total counts, but only if the effect of this would be meaningfull. 	TokenNameCOMMENT_LINE	fix total counts, but only if the effect of this would be meaningfull. 
if	TokenNameif	
(	TokenNameLPAREN	
totalCountsFactor	TokenNameIdentifier	 total Counts Factor
<	TokenNameLESS	
0.99999	TokenNameDoubleLiteral	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
int	TokenNameint	
delta	TokenNameIdentifier	 delta
=	TokenNameEQUAL	
nAccumulatedDocs	TokenNameIdentifier	 n Accumulated Docs
+	TokenNamePLUS	
1	TokenNameIntegerLiteral	
;	TokenNameSEMICOLON	
for	TokenNamefor	
(	TokenNameLPAREN	
int	TokenNameint	
i	TokenNameIdentifier	 i
=	TokenNameEQUAL	
0	TokenNameIntegerLiteral	
;	TokenNameSEMICOLON	
i	TokenNameIdentifier	 i
<	TokenNameLESS	
intArray	TokenNameIdentifier	 int Array
.	TokenNameDOT	
length	TokenNameIdentifier	 length
;	TokenNameSEMICOLON	
i	TokenNameIdentifier	 i
++	TokenNamePLUS_PLUS	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
intArray	TokenNameIdentifier	 int Array
[	TokenNameLBRACKET	
i	TokenNameIdentifier	 i
]	TokenNameRBRACKET	
*=	TokenNameMULTIPLY_EQUAL	
totalCountsFactor	TokenNameIdentifier	 total Counts Factor
;	TokenNameSEMICOLON	
// also translate to prevent loss of non-positive values 	TokenNameCOMMENT_LINE	also translate to prevent loss of non-positive values 
// due to complement sampling (ie if sampled docs all decremented a certain category). 	TokenNameCOMMENT_LINE	due to complement sampling (ie if sampled docs all decremented a certain category). 
intArray	TokenNameIdentifier	 int Array
[	TokenNameLBRACKET	
i	TokenNameIdentifier	 i
]	TokenNameRBRACKET	
+=	TokenNamePLUS_EQUAL	
delta	TokenNameIdentifier	 delta
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
}	TokenNameRBRACE	
}	TokenNameRBRACE	
/** * Expert: factor by which counts should be multiplied when initializing * the count arrays from total counts. * Default implementation for this returns 1, which is a no op. * @return a factor by which total counts should be multiplied */	TokenNameCOMMENT_JAVADOC	 Expert: factor by which counts should be multiplied when initializing the count arrays from total counts. Default implementation for this returns 1, which is a no op. @return a factor by which total counts should be multiplied 
protected	TokenNameprotected	
double	TokenNamedouble	
getTotalCountsFactor	TokenNameIdentifier	 get Total Counts Factor
(	TokenNameLPAREN	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
return	TokenNamereturn	
1	TokenNameIntegerLiteral	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
/** * Create an {@link Aggregator} and a {@link CategoryListIterator} for each * and every {@link FacetRequest}. Generating a map, matching each * categoryListIterator to its matching aggregator. * <p> * If two CategoryListIterators are served by the same aggregator, a single * aggregator is returned for both. * * <b>NOTE: </b>If a given category list iterator is needed with two different * aggregators (e.g counting and association) - an exception is thrown as this * functionality is not supported at this time. */	TokenNameCOMMENT_JAVADOC	 Create an {@link Aggregator} and a {@link CategoryListIterator} for each and every {@link FacetRequest}. Generating a map, matching each categoryListIterator to its matching aggregator. <p> If two CategoryListIterators are served by the same aggregator, a single aggregator is returned for both. * <b>NOTE: </b>If a given category list iterator is needed with two different aggregators (e.g counting and association) - an exception is thrown as this functionality is not supported at this time. 
protected	TokenNameprotected	
HashMap	TokenNameIdentifier	 Hash Map
<	TokenNameLESS	
CategoryListIterator	TokenNameIdentifier	 Category List Iterator
,	TokenNameCOMMA	
Aggregator	TokenNameIdentifier	 Aggregator
>	TokenNameGREATER	
getCategoryListMap	TokenNameIdentifier	 get Category List Map
(	TokenNameLPAREN	
FacetArrays	TokenNameIdentifier	 Facet Arrays
facetArrays	TokenNameIdentifier	 facet Arrays
,	TokenNameCOMMA	
int	TokenNameint	
partition	TokenNameIdentifier	 partition
)	TokenNameRPAREN	
throws	TokenNamethrows	
IOException	TokenNameIdentifier	 IO Exception
{	TokenNameLBRACE	
HashMap	TokenNameIdentifier	 Hash Map
<	TokenNameLESS	
CategoryListIterator	TokenNameIdentifier	 Category List Iterator
,	TokenNameCOMMA	
Aggregator	TokenNameIdentifier	 Aggregator
>	TokenNameGREATER	
categoryLists	TokenNameIdentifier	 category Lists
=	TokenNameEQUAL	
new	TokenNamenew	
HashMap	TokenNameIdentifier	 Hash Map
<	TokenNameLESS	
CategoryListIterator	TokenNameIdentifier	 Category List Iterator
,	TokenNameCOMMA	
Aggregator	TokenNameIdentifier	 Aggregator
>	TokenNameGREATER	
(	TokenNameLPAREN	
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
for	TokenNamefor	
(	TokenNameLPAREN	
FacetRequest	TokenNameIdentifier	 Facet Request
facetRequest	TokenNameIdentifier	 facet Request
:	TokenNameCOLON	
searchParams	TokenNameIdentifier	 search Params
.	TokenNameDOT	
getFacetRequests	TokenNameIdentifier	 get Facet Requests
(	TokenNameLPAREN	
)	TokenNameRPAREN	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
Aggregator	TokenNameIdentifier	 Aggregator
categoryAggregator	TokenNameIdentifier	 category Aggregator
=	TokenNameEQUAL	
facetRequest	TokenNameIdentifier	 facet Request
.	TokenNameDOT	
createAggregator	TokenNameIdentifier	 create Aggregator
(	TokenNameLPAREN	
isUsingComplements	TokenNameIdentifier	 is Using Complements
,	TokenNameCOMMA	
facetArrays	TokenNameIdentifier	 facet Arrays
,	TokenNameCOMMA	
indexReader	TokenNameIdentifier	 index Reader
,	TokenNameCOMMA	
taxonomyReader	TokenNameIdentifier	 taxonomy Reader
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
CategoryListIterator	TokenNameIdentifier	 Category List Iterator
cli	TokenNameIdentifier	 cli
=	TokenNameEQUAL	
facetRequest	TokenNameIdentifier	 facet Request
.	TokenNameDOT	
createCategoryListIterator	TokenNameIdentifier	 create Category List Iterator
(	TokenNameLPAREN	
indexReader	TokenNameIdentifier	 index Reader
,	TokenNameCOMMA	
taxonomyReader	TokenNameIdentifier	 taxonomy Reader
,	TokenNameCOMMA	
searchParams	TokenNameIdentifier	 search Params
,	TokenNameCOMMA	
partition	TokenNameIdentifier	 partition
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
// get the aggregator 	TokenNameCOMMENT_LINE	get the aggregator 
Aggregator	TokenNameIdentifier	 Aggregator
old	TokenNameIdentifier	 old
=	TokenNameEQUAL	
categoryLists	TokenNameIdentifier	 category Lists
.	TokenNameDOT	
put	TokenNameIdentifier	 put
(	TokenNameLPAREN	
cli	TokenNameIdentifier	 cli
,	TokenNameCOMMA	
categoryAggregator	TokenNameIdentifier	 category Aggregator
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
if	TokenNameif	
(	TokenNameLPAREN	
old	TokenNameIdentifier	 old
!=	TokenNameNOT_EQUAL	
null	TokenNamenull	
&&	TokenNameAND_AND	
!	TokenNameNOT	
old	TokenNameIdentifier	 old
.	TokenNameDOT	
equals	TokenNameIdentifier	 equals
(	TokenNameLPAREN	
categoryAggregator	TokenNameIdentifier	 category Aggregator
)	TokenNameRPAREN	
)	TokenNameRPAREN	
{	TokenNameLBRACE	
// TODO (Facet): create a more meaningful RE class, and throw it. 	TokenNameCOMMENT_LINE	TODO (Facet): create a more meaningful RE class, and throw it. 
throw	TokenNamethrow	
new	TokenNamenew	
RuntimeException	TokenNameIdentifier	 Runtime Exception
(	TokenNameLPAREN	
"Overriding existing category list with different aggregator. THAT'S A NO NO!"	TokenNameStringLiteral	Overriding existing category list with different aggregator. THAT'S A NO NO!
)	TokenNameRPAREN	
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
// if the aggregator is the same we're covered 	TokenNameCOMMENT_LINE	if the aggregator is the same we're covered 
}	TokenNameRBRACE	
return	TokenNamereturn	
categoryLists	TokenNameIdentifier	 category Lists
;	TokenNameSEMICOLON	
}	TokenNameRBRACE	
}	TokenNameRBRACE	
